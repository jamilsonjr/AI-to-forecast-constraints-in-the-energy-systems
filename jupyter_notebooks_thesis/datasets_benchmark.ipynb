{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of this Article** \n",
    "- Loading best hyperparameters for each model\n",
    "- Model training\n",
    "- Results discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best hyperparameters for each model\n",
    "\n",
    "TODO... explain this model bench mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hyperparameters dataset.\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse hyperparameters: 8/8\n",
      "Focused hyperparameters: 8/8\n",
      "Balanced hyperparameters: 8/8\n",
      "Filtered hyperparameters: 8/8\n",
      "Sparse classifier hyperparameters: 8/8\n",
      "Balanced classifier hyperparameters: 8/8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparse_hyper_params = {}\n",
    "focused_hyper_params = {}\n",
    "balanced_hyper_params = {}\n",
    "filtered_hyper_params = {}\n",
    "sparse_class_hyper_params = {}\n",
    "balanced_class_hyper_params = {}\n",
    "for file in os.listdir('hyper_params_results_mcc'):\n",
    "    if file.endswith('.csv') and 'regression_sparse' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'regression_focused' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        focused_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'regression_balanced' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        balanced_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'filtered' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        filtered_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'sparse_classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_class_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'balanced_classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        balanced_class_hyper_params[file] = df\n",
    "print('Sparse hyperparameters: {}/8'.format(len(sparse_hyper_params)))\n",
    "print('Focused hyperparameters: {}/8'.format(len(focused_hyper_params)))\n",
    "print('Balanced hyperparameters: {}/8'.format(len(balanced_hyper_params)))\n",
    "print('Filtered hyperparameters: {}/8'.format(len(filtered_hyper_params)))\n",
    "print('Sparse classifier hyperparameters: {}/8'.format(len(sparse_class_hyper_params)))\n",
    "print('Balanced classifier hyperparameters: {}/8'.format(len(balanced_class_hyper_params)))\n",
    "print('\\n')\n",
    "# print('Sparse hyper params:\\n')\n",
    "# for key in sparse_hyper_params.keys():\n",
    "#     print(key, ':\\n ',sparse_hyper_params[key])\n",
    "# print('Focused hyper params:\\n')\n",
    "# for key in focused_hyper_params.keys():\n",
    "#     print(key, ':\\n',focused_hyper_params[key])\n",
    "# print('Boolean hyper params:\\n')\n",
    "# for key in sparse_class_hyper_params.keys():\n",
    "#     print(key, ':\\n',sparse_class_hyper_params[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 34,\n",
       " 'n_layers': 3,\n",
       " 'dropout': 0.0030412321477918842,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'sgd',\n",
       " 'lr': 9.741292351005151e-05,\n",
       " 'epochs': 55,\n",
       " 'batch_size': 8,\n",
       " 'classifier': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "def get_hyper_params_from_df(df):\n",
    "    output = {}\n",
    "    for row in df.iterrows():\n",
    "        if row[1]['params'] != 'value':\n",
    "            try:\n",
    "                output[row[1]['params']] = ast.literal_eval(row[1]['value'])\n",
    "            except :\n",
    "                output[row[1]['params']] = row[1]['value']\n",
    "    return output\n",
    "get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_max_u.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..');from thesis_package import aimodels as my_ai, utils, metrics\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression data sparse\n",
    "y_max_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv').drop(columns=['timestamps'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_sparse, test_size=0.2, scaling=True)\n",
    "data_max_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_sparse, test_size=0.2, scaling=True)\n",
    "data_min_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data sparse\n",
    "y_max_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_sparse_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_sparse_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_max_u_bool = y_max_u_bool[utils.cols_with_positive_values(y_max_u_bool)]\n",
    "y_min_u_bool = y_min_u_bool[utils.cols_with_positive_values(y_min_u_bool)]\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_bool, test_size=0.2, scaling=True)\n",
    "data_max_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_bool, test_size=0.2, scaling=True)\n",
    "data_min_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered data\n",
    "y_max_u_filtered = deepcopy(y_max_u_sparse[utils.cols_with_positive_values(y_max_u_bool)])\n",
    "y_min_u_filtered = deepcopy(y_min_u_sparse[utils.cols_with_positive_values(y_min_u_bool)])\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_filtered, test_size=0.2, scaling=True)\n",
    "data_max_u_filtered = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_filtered, test_size=0.2, scaling=True)\n",
    "data_min_u_filtered = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification data size:  (9044, 11)\n",
      "Regression data size:  (9044, 11)\n",
      "Positive in classification data:  4949.0\n",
      "Positive in regression data:  4949\n",
      "Theshhold:  0.0016733255333549746\n",
      "\n",
      "\n",
      "Classification data size:  (9044, 10)\n",
      "Regression data size:  (9044, 10)\n",
      "Positive in classification data:  6022.0\n",
      "Positive in regression data:  6022\n",
      "Theshhold:  0.002022118621573741\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the classiciation testing data and the filtered testing data\n",
    "print('Classification data size: ', data_max_u_bool['y_test'].shape)\n",
    "print('Regression data size: ', data_max_u_filtered['y_test'].shape)\n",
    "print('Positive in classification data: ', utils.count_positives_class(data_max_u_bool['y_test']))\n",
    "#unscaled_y_test = pd.DataFrame(data_max_u_filtered['scaler']['y'].inverse_transform(data_max_u_filtered['y_test']), columns=data_max_u_filtered['y_test'].columns)\n",
    "unscaled_y_test = data_max_u_filtered['y_test'] * data_max_u_sparse['scaler']['y']\n",
    "print('Positive in regression data: ', utils.count_positives_reg(unscaled_y_test, utils.compute_threshold(y_max_u_sparse)))\n",
    "print('Theshhold: ', utils.compute_threshold(y_max_u_sparse))\n",
    "# Same for min_u\n",
    "print('\\n')\n",
    "print('Classification data size: ', data_min_u_bool['y_test'].shape)\n",
    "print('Regression data size: ', data_min_u_filtered['y_test'].shape)\n",
    "print('Positive in classification data: ', utils.count_positives_class(data_min_u_bool['y_test']))\n",
    "#unscaled_y_test = pd.DataFrame(data_min_u_filtered['scaler']['y'].inverse_transform(data_min_u_filtered['y_test']), columns=data_min_u_filtered['y_test'].columns)\n",
    "unscaled_y_test = data_min_u_filtered['y_test'] * data_min_u_sparse['scaler']['y']\n",
    "print('Positive in regression data: ', utils.count_positives_reg(unscaled_y_test, utils.compute_threshold(y_min_u_sparse)))\n",
    "print('Theshhold: ', utils.compute_threshold(y_min_u_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data focused\n",
    "y_max_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_focused_constr.csv')\n",
    "exogenous_data_focused_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_focused.csv').drop(columns=['date'])\n",
    "y_min_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_focused_constr.csv')\n",
    "exogenous_data_focused_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_focused.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_max_u, y_max_u_focused, test_size=0.2, scaling=True)\n",
    "data_max_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_min_u, y_min_u_focused, test_size=0.2, scaling=True)\n",
    "data_min_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data balanced\n",
    "y_max_u_balanced = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_constr.csv')\n",
    "exogenous_data_balanced_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "y_min_u_balanced = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_constr.csv')\n",
    "exogenous_data_balanced_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_max_u, y_max_u_balanced, test_size=0.2, scaling=True)\n",
    "data_max_u_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_min_u, y_min_u_balanced, test_size=0.2, scaling=True)\n",
    "data_min_u_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data balanced\n",
    "y_max_u_balanced_class = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_bool_constr.csv')\n",
    "exogenous_data_balanced_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "y_min_u_balanced_class = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_bool_constr.csv')\n",
    "exogenous_data_balanced_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "y_max_u_balanced_class = y_max_u_balanced_class[utils.cols_with_positive_values(y_max_u_balanced_class)]\n",
    "y_min_u_balanced_class = y_min_u_balanced_class[utils.cols_with_positive_values(y_min_u_balanced_class)]\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_max_u, y_max_u_balanced_class, test_size=0.2, scaling=True)\n",
    "data_max_u_bool_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_min_u, y_min_u_balanced_class, test_size=0.2, scaling=True)\n",
    "data_min_u_bool_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a quick sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count in classification data max_u : 4949.0\n",
      "Positive count in regression data max_u with threshold 0.0016733255333549746 : 4949\n",
      "\n",
      "\n",
      "Positive count in classification data min_u : 6022.0\n",
      "Positive count in regression data min_u with threshold 0.002022118621573741 : 6022\n",
      "\n",
      "\n",
      "Negative count in classification data max_u : 94535.0\n",
      "Negative count in regression data max_u with threshold 0.0016733255333549746 : 94535\n",
      "\n",
      "\n",
      "Negative count in classification data min_u : 84418.0\n",
      "Negative count in regression data min_u with threshold 0.002022118621573741 : 84418\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.check_positive_count(data_max_u_filtered['y_test']* data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')\n",
    "utils.check_positive_count(data_min_u_filtered['y_test']* data_min_u_filtered['scaler']['y'], data_min_u_bool['y_test'], utils.compute_threshold(y_min_u_sparse), experiment='min_u')\n",
    "utils.check_negative_count(data_max_u_filtered['y_test']* data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')\n",
    "utils.check_negative_count(data_min_u_filtered['y_test']* data_min_u_filtered['scaler']['y'], data_min_u_bool['y_test'], utils.compute_threshold(y_min_u_sparse), experiment='min_u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count in classification data max_u : 4949.0\n",
      "Positive count in regression data max_u with threshold 0.0016733255333549746 : 4949\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.check_positive_count(data_max_u_filtered['y_test'] * data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "In this section the models will be trained with the hyperparameters loaded above. All the models will be stored in the same `Context` object for later evaluation. The `Context` object is a class that stores all the models and their respective hyperparameters. The `Context` object is defined in the `aimodels.py` file. The `Context` object is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_models = ['lr', 'gb', 'xgb', 'svr', 'mlp']\n",
    "class_models =  ['gb', 'xgb', 'svr', 'mlp']\n",
    "max_u_threshold = utils.compute_threshold(y_max_u_sparse)\n",
    "min_u_threshold = utils.compute_threshold(y_min_u_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params_gradient_boost_regression_sparse_max_u.csv', 'params_gradient_boost_regression_sparse_min_u.csv', 'params_mlp_regression_sparse_max_u.csv', 'params_mlp_regression_sparse_min_u.csv', 'params_support_vector_regression_sparse_max_u.csv', 'params_support_vector_regression_sparse_min_u.csv', 'params_xgboost_regression_sparse_max_u.csv', 'params_xgboost_regression_sparse_min_u.csv'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_hyper_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression sparse\n"
     ]
    }
   ],
   "source": [
    "# max_u regression sparse\n",
    "if 'max_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_max_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_max_u.csv']) \n",
    "    regressor_max_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regression_sparse_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_sparse['y_train'].shape[1]\n",
    "    regressor_max_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse', regressor_max_u)\n",
    "else:\n",
    "    print('Loading max_u regression sparse') \n",
    "    regressor_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse')\n",
    "\n",
    "testing_data = {'max_u_regressor_sparse': {}}\n",
    "for model, strategy in zip(reg_models, regressor_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_sparse['y_test'].columns)\n",
    "    testing_data['max_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_sparse'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression focused\n"
     ]
    }
   ],
   "source": [
    "# max_u regression focused\n",
    "if 'max_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_max_u.csv']) \n",
    "    regressor_max_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_focused['y_train'].shape[1]\n",
    "    regressor_max_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_focused', regressor_max_u_focused)\n",
    "else: \n",
    "    print('Loading max_u regression focused')\n",
    "    regressor_max_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\\\max_u_regressor_focused')\n",
    "\n",
    "testing_data['max_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    testing_data['max_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_focused'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u filtered regression\n"
     ]
    }
   ],
   "source": [
    "# max_u regression filtered\n",
    "if 'max_u_filtered_regressor.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression filtered')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_filtered = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_gradient_boost_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_xgboost_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_support_vector_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_mlp_regression_filtered_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_filtered['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_filtered['y_train'].shape[1]\n",
    "    regressor_max_u_filtered.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_filtered_regressor', regressor_max_u_filtered)\n",
    "else: \n",
    "    print('Loading max_u filtered regression')\n",
    "    regressor_max_u_filtered = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_filtered_regressor')\n",
    "\n",
    "testing_data['max_u_filtered_regressor'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_filtered.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_filtered['y_test'].columns)\n",
    "    testing_data['max_u_filtered_regressor'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_filtered_regressor'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_filtered_regressor'][model]['real'] = deepcopy(data_max_u_sparse['y_test'][utils.cols_with_positive_values(prediction)].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9044, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy = regressor_max_u_filtered.strategies[0]\n",
    "prediction = strategy.predict(data=data_max_u_sparse)\n",
    "prediction.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression balanced\n"
     ]
    }
   ],
   "source": [
    "# max u regression balanced\n",
    "if 'max_u_regressor_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression balanced')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_balanced = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_gradient_boost_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_xgboost_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_support_vector_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_mlp_regression_balanced_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_balanced['y_train'].shape[1]\n",
    "    regressor_max_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_balanced', regressor_max_u_balanced)\n",
    "else: \n",
    "    print('Loading max_u regression balanced')\n",
    "    regressor_max_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_balanced')\n",
    "\n",
    "testing_data['max_u_regressor_balanced'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    testing_data['max_u_regressor_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_balanced'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u classification\n"
     ]
    }
   ],
   "source": [
    "# max_u classification\n",
    "if 'max_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_gradient_boost_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_xgboost_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_support_vector_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_mlp_sparse_classifier_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_bool['y_train'].shape[1]\n",
    "    classifier_max_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier', classifier_max_u)\n",
    "else: \n",
    "    print('Loading max_u classification')\n",
    "    classifier_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier')\n",
    "\n",
    "testing_data['max_u_classifier'] = {}\n",
    "for model, strategy in zip(class_models, classifier_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_bool)\n",
    "    testing_data['max_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_classifier'][model]['real'] = deepcopy(data_max_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u classification balanced\n"
     ]
    }
   ],
   "source": [
    "# max_u classification balanced\n",
    "if 'max_u_classifier_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification balanced')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_gradient_boost_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_xgboost_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_support_vector_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_mlp_balanced_classifier_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_bool_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_bool_balanced['y_train'].shape[1]\n",
    "    classifier_max_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier_balanced', classifier_max_u_balanced)\n",
    "else: \n",
    "    print('Loading max_u classification balanced')\n",
    "    classifier_max_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier_balanced')\n",
    "\n",
    "testing_data['max_u_classifier_balanced'] = {}\n",
    "for model, strategy in zip(class_models, classifier_max_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_bool)\n",
    "    testing_data['max_u_classifier_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_classifier_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_classifier_balanced'][model]['real'] = deepcopy(data_max_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=XGBClassifier(alpha=0.19774958488491742,\n",
       "                                              base_score=None, booster=&#x27;dart&#x27;,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=0.824966208242803,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eta=0.1039306615628526,\n",
       "                                              eval_metric=None,\n",
       "                                              gamma=0.6835098793603533,\n",
       "                                              gpu_id=None,\n",
       "                                              grow_policy=&#x27;depthwise&#x27;,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              lambda=0.00015884090078506437,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=5,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=8, missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              normalize_type=&#x27;tree&#x27;,\n",
       "                                              num_parallel_tree=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=XGBClassifier(alpha=0.19774958488491742,\n",
       "                                              base_score=None, booster=&#x27;dart&#x27;,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=0.824966208242803,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eta=0.1039306615628526,\n",
       "                                              eval_metric=None,\n",
       "                                              gamma=0.6835098793603533,\n",
       "                                              gpu_id=None,\n",
       "                                              grow_policy=&#x27;depthwise&#x27;,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              lambda=0.00015884090078506437,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=5,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=8, missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              normalize_type=&#x27;tree&#x27;,\n",
       "                                              num_parallel_tree=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.19774958488491742, base_score=None, booster=&#x27;dart&#x27;,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.824966208242803, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.1039306615628526,\n",
       "              eval_metric=None, gamma=0.6835098793603533, gpu_id=None,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=None, lambda=0.00015884090078506437,\n",
       "              learning_rate=None, max_bin=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=8, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, normalize_type=&#x27;tree&#x27;,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.19774958488491742, base_score=None, booster=&#x27;dart&#x27;,\n",
       "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.824966208242803, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.1039306615628526,\n",
       "              eval_metric=None, gamma=0.6835098793603533, gpu_id=None,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=None, lambda=0.00015884090078506437,\n",
       "              learning_rate=None, max_bin=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=8, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, normalize_type=&#x27;tree&#x27;,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(alpha=0.19774958488491742,\n",
       "                                              base_score=None, booster='dart',\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=0.824966208242803,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eta=0.1039306615628526,\n",
       "                                              eval_metric=None,\n",
       "                                              gamma=0.6835098793603533,\n",
       "                                              gpu_id=None,\n",
       "                                              grow_policy='depthwise',\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              lambda=0.00015884090078506437,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=5,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=8, missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              normalize_type='tree',\n",
       "                                              num_parallel_tree=None, ...))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_max_u_balanced.strategies[1].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import permutation_importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_importance = permutation_importance(classifier_max_u_balanced.strategies[1].model, data_max_u_bool['X_test'].reset_index(drop=True), data_max_u_bool['y_test'].reset_index(drop=True))\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(data_max_u_bool['X_test'].reset_index(drop=True).columns[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "# add grid, title with font size 20, x and y labels with font size 20.as_integer_ratio. figure size is 10, 5.\n",
    "plt.grid()\n",
    "plt.title('Permutation Importance', fontsize=20)\n",
    "plt.xlabel('Permutation Importance', fontsize=20)\n",
    "plt.ylabel('Features', fontsize=20)\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "# increse the font size of the ticks\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_data['max_u_regressor_sparse']['gb']['predicted'][['bus_30', 'bus_1', 'bus_2', 'bus_3']].plot()\n",
    "testing_data['max_u_regressor_sparse']['gb']['real'][['bus_30', 'bus_1', 'bus_2', 'bus_3']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min u regression training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression sparse\n"
     ]
    }
   ],
   "source": [
    "# min_u regression sparse\n",
    "if 'min_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_min_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regression_sparse_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_sparse['y_train'].shape[1]\n",
    "    regressor_min_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse', regressor_min_u)\n",
    "else:\n",
    "    print('Loading min_u regression sparse')\n",
    "    regressor_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse')\n",
    "\n",
    "testing_data['min_u_regressor_sparse'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    testing_data['min_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_sparse'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression focused\n"
     ]
    }
   ],
   "source": [
    "# min_u regression focused\n",
    "if 'min_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_focused['y_train'].shape[1]\n",
    "    regressor_min_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused', regressor_min_u_focused)\n",
    "else:\n",
    "    print('Loading min_u regression focused')\n",
    "    regressor_min_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused')\n",
    "\n",
    "testing_data['min_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    testing_data['min_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_focused'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u filtered regression\n"
     ]
    }
   ],
   "source": [
    "# min u regression filtered\n",
    "if 'min_u_filtered_regressor.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression filtered')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_filtered = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_gradient_boost_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_xgboost_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_support_vector_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_mlp_regression_filtered_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_filtered['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_filtered['y_train'].shape[1]\n",
    "    regressor_min_u_filtered.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_filtered_regressor', regressor_min_u_filtered)\n",
    "else: \n",
    "    print('Loading min_u filtered regression')\n",
    "    regressor_min_u_filtered = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_filtered_regressor')\n",
    "\n",
    "testing_data['min_u_filtered_regressor'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_filtered.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_filtered['y_test'].columns)\n",
    "    testing_data['min_u_filtered_regressor'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_filtered_regressor'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_filtered_regressor'][model]['real'] = deepcopy(data_min_u_sparse['y_test'][utils.cols_with_positive_values(prediction)].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression balanced\n"
     ]
    }
   ],
   "source": [
    "# min u regression balanced\n",
    "if 'min_u_regressor_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression balanced')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_balanced = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_gradient_boost_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_xgboost_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_support_vector_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_mlp_regression_balanced_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_balanced['y_train'].shape[1]\n",
    "    regressor_min_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_balanced', regressor_min_u_balanced)\n",
    "else: \n",
    "    print('Loading min_u regression balanced')\n",
    "    regressor_min_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_balanced')\n",
    "\n",
    "testing_data['min_u_regressor_balanced'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    testing_data['min_u_regressor_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_balanced'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u classification\n"
     ]
    }
   ],
   "source": [
    "# min_u classification\n",
    "if 'min_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_gradient_boost_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_xgboost_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_support_vector_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_mlp_sparse_classifier_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_bool['y_train'].shape[1]\n",
    "    classifier_min_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier', classifier_min_u)\n",
    "else: \n",
    "    print('Loading min_u classification')\n",
    "    classifier_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier')\n",
    "\n",
    "testing_data['min_u_classifier'] = {}\n",
    "for model, strategy in zip(class_models, classifier_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_bool)\n",
    "    testing_data['min_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_classifier'][model]['real'] = deepcopy(data_min_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u classification balanced\n"
     ]
    }
   ],
   "source": [
    "# min u classification balanced\n",
    "if 'min_u_classifier_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification balanced')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_gradient_boost_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_xgboost_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_support_vector_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_mlp_balanced_classifier_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_bool_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_bool_balanced['y_train'].shape[1]\n",
    "    classifier_min_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier_balanced', classifier_min_u_balanced)\n",
    "else: \n",
    "    print('Loading min_u classification balanced')\n",
    "    classifier_min_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier_balanced')\n",
    "\n",
    "testing_data['min_u_classifier_balanced'] = {}\n",
    "for model, strategy in zip(class_models, classifier_min_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_bool)\n",
    "    testing_data['min_u_classifier_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_classifier_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_classifier_balanced'][model]['real'] = deepcopy(data_min_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "In this section the results of the training and testing are presented and compared. The main objectives of this experience is to compare the performance of the regression models in terms of the hybrid metrics confusion matrix and the hybrid metrics rmse. The comparisons will be the following:\n",
    "- Compare the confusion matrices of the classification models and the regression models evaluate with the hybrid metrics.\n",
    "- Compare the error results of the regression models trained with the focused dataset and the sparse dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_u_regressor_sparse :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_regressor_focused :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_filtered_regressor :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_regressor_balanced :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_classifier :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_classifier_balanced :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_sparse :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_focused :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_filtered_regressor :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_balanced :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_classifier :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_classifier_balanced :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n"
     ]
    }
   ],
   "source": [
    "for experience in testing_data.keys():\n",
    "    print(experience,': ', testing_data[experience].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3158 + 1791 = 4949 = 4949.0 possible positive values.\n",
      "92054 + 2481 = 94535 = 94535.0 possible negative values.\n"
     ]
    }
   ],
   "source": [
    "# Testing all models: Function that receives a dict with the real and predicted values, and outputs a dataframe with the results of the metrics.\n",
    "# Accumulate all the classifications for each bus.\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for bus in testing_data['max_u_regressor_sparse']['mlp']['predicted'].columns:\n",
    "    # Compute tp, tn, fp, fn\n",
    "    tp += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 1) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 1))\n",
    "    tn += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 0) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 0))\n",
    "    fp += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 1) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 0))\n",
    "    fn += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 0) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 1))\n",
    "print('{} + {} = {} = {} possible positive values.'.format(tp, fn, tp+fn, testing_data['max_u_regressor_sparse']['mlp']['real'].sum().sum()))\n",
    "print('{} + {} = {} = {} possible negative values.'.format(tn, fp, tn+fp, testing_data['max_u_regressor_sparse']['mlp']['real'].shape[0]*testing_data['max_u_regressor_sparse']['mlp']['real'].shape[1] - testing_data['max_u_regressor_sparse']['mlp']['real'].sum().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n",
      "C:\\Users\\jamil\\AppData\\Local\\Temp\\ipykernel_4676\\1692979963.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append({'bus': bus, 'tp': tp, 'fn': fn, 'fp': fp}, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bus</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bus_8</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bus_9</td>\n",
       "      <td>13</td>\n",
       "      <td>196</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bus_10</td>\n",
       "      <td>57</td>\n",
       "      <td>245</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bus_11</td>\n",
       "      <td>112</td>\n",
       "      <td>299</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bus_12</td>\n",
       "      <td>172</td>\n",
       "      <td>329</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bus_13</td>\n",
       "      <td>434</td>\n",
       "      <td>213</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bus_14</td>\n",
       "      <td>618</td>\n",
       "      <td>92</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bus_15</td>\n",
       "      <td>619</td>\n",
       "      <td>91</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bus_16</td>\n",
       "      <td>563</td>\n",
       "      <td>159</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bus_18</td>\n",
       "      <td>570</td>\n",
       "      <td>153</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bus_32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bus   tp   fn   fp\n",
       "0    bus_8    0   13    0\n",
       "1    bus_9   13  196   18\n",
       "2   bus_10   57  245   49\n",
       "3   bus_11  112  299   83\n",
       "4   bus_12  172  329  132\n",
       "5   bus_13  434  213  308\n",
       "6   bus_14  618   92  508\n",
       "7   bus_15  619   91  519\n",
       "8   bus_16  563  159  434\n",
       "9   bus_18  570  153  430\n",
       "10  bus_32    0    1    0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing all models: Function that receives a dict with the real and predicted values, and outputs a dataframe with the results of the metrics.\n",
    "# Accumulate all the classifications for each bus.\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for bus in testing_data['max_u_regressor_sparse']['mlp']['predicted'].columns:\n",
    "    # Compute tp, tn, fp, fn\n",
    "    tp += sum((testing_data['max_u_regressor_sparse']['gb']['predicted'][bus] == 1) & (testing_data['max_u_regressor_sparse']['gb']['real'][bus] == 1))\n",
    "    tn += sum((testing_data['max_u_regressor_sparse']['gb']['predicted'][bus] == 0) & (testing_data['max_u_regressor_sparse']['gb']['real'][bus] == 0))\n",
    "    fp += sum((testing_data['max_u_regressor_sparse']['gb']['predicted'][bus] == 1) & (testing_data['max_u_regressor_sparse']['gb']['real'][bus] == 0))\n",
    "    fn += sum((testing_data['max_u_regressor_sparse']['gb']['predicted'][bus] == 0) & (testing_data['max_u_regressor_sparse']['gb']['real'][bus] == 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beepy import beep; beep(sound=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: max_u_regressor_sparse, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3151\n",
      "true_negatives_ctr:  297203\n",
      "false_positives_ctr:  5344\n",
      "false_negatives_ctr:  1798\n",
      "3803175167752364985\n",
      "Experiment: max_u_regressor_sparse, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3410\n",
      "true_negatives_ctr:  299857\n",
      "false_positives_ctr:  2690\n",
      "false_negatives_ctr:  1539\n",
      "2752818789825106800\n",
      "Experiment: max_u_regressor_sparse, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4550\n",
      "true_negatives_ctr:  292244\n",
      "false_positives_ctr:  10303\n",
      "false_negatives_ctr:  399\n",
      "6508226007841622337\n",
      "Experiment: max_u_regressor_sparse, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4615\n",
      "true_negatives_ctr:  275913\n",
      "false_positives_ctr:  26634\n",
      "false_negatives_ctr:  334\n",
      "12925400211095992809\n",
      "Experiment: max_u_regressor_sparse, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4948\n",
      "true_negatives_ctr:  217055\n",
      "false_positives_ctr:  85492\n",
      "false_negatives_ctr:  1\n",
      "29392914664141297920\n",
      "Experiment: max_u_regressor_focused, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4321\n",
      "true_negatives_ctr:  297379\n",
      "false_positives_ctr:  5168\n",
      "false_negatives_ctr:  628\n",
      "4234062035962222569\n",
      "Experiment: max_u_regressor_focused, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4523\n",
      "true_negatives_ctr:  249361\n",
      "false_positives_ctr:  53186\n",
      "false_negatives_ctr:  426\n",
      "21583590147476487249\n",
      "Experiment: max_u_regressor_focused, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4660\n",
      "true_negatives_ctr:  179741\n",
      "false_positives_ctr:  122806\n",
      "false_negatives_ctr:  289\n",
      "34359714271387409940\n",
      "Experiment: max_u_regressor_focused, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4940\n",
      "true_negatives_ctr:  249296\n",
      "false_positives_ctr:  53251\n",
      "false_negatives_ctr:  9\n",
      "21721865183700422265\n",
      "Experiment: max_u_regressor_focused, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3714\n",
      "true_negatives_ctr:  204398\n",
      "false_positives_ctr:  98149\n",
      "false_negatives_ctr:  1235\n",
      "31363143043396705737\n",
      "Experiment: max_u_filtered_regressor, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3151\n",
      "true_negatives_ctr:  89191\n",
      "false_positives_ctr:  5344\n",
      "false_negatives_ctr:  1798\n",
      "361628256521776825\n",
      "Experiment: max_u_filtered_regressor, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3356\n",
      "true_negatives_ctr:  91872\n",
      "false_positives_ctr:  2663\n",
      "false_negatives_ctr:  1593\n",
      "263198515836827025\n",
      "Experiment: max_u_filtered_regressor, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4949\n",
      "true_negatives_ctr:  128\n",
      "false_positives_ctr:  94407\n",
      "false_negatives_ctr:  0\n",
      "5949961434565120\n",
      "Experiment: max_u_filtered_regressor, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4443\n",
      "true_negatives_ctr:  46628\n",
      "false_positives_ctr:  47907\n",
      "false_negatives_ctr:  506\n",
      "1154412620097103500\n",
      "Experiment: max_u_filtered_regressor, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4949\n",
      "true_negatives_ctr:  513\n",
      "false_positives_ctr:  94022\n",
      "false_negatives_ctr:  0\n",
      "23753926363986945\n",
      "Experiment: max_u_regressor_balanced, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4521\n",
      "true_negatives_ctr:  280815\n",
      "false_positives_ctr:  21732\n",
      "false_negatives_ctr:  428\n",
      "11055311020666760337\n",
      "Experiment: max_u_regressor_balanced, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4090\n",
      "true_negatives_ctr:  297475\n",
      "false_positives_ctr:  5072\n",
      "false_negatives_ctr:  859\n",
      "4092638102722559124\n",
      "Experiment: max_u_regressor_balanced, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4448\n",
      "true_negatives_ctr:  293409\n",
      "false_positives_ctr:  9138\n",
      "false_negatives_ctr:  501\n",
      "5978831001189609780\n",
      "Experiment: max_u_regressor_balanced, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4222\n",
      "true_negatives_ctr:  287934\n",
      "false_positives_ctr:  14613\n",
      "false_negatives_ctr:  727\n",
      "8140742936328958305\n",
      "Experiment: max_u_regressor_balanced, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4948\n",
      "true_negatives_ctr:  213161\n",
      "false_positives_ctr:  89386\n",
      "false_negatives_ctr:  1\n",
      "30108446030196623124\n",
      "Experiment: min_u_regressor_sparse, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  2553\n",
      "true_negatives_ctr:  297508\n",
      "false_positives_ctr:  3966\n",
      "false_negatives_ctr:  3469\n",
      "3562090133984546964\n",
      "Experiment: min_u_regressor_sparse, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5039\n",
      "true_negatives_ctr:  294582\n",
      "false_positives_ctr:  6892\n",
      "false_negatives_ctr:  983\n",
      "6402070686261354420\n",
      "Experiment: min_u_regressor_sparse, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4781\n",
      "true_negatives_ctr:  294780\n",
      "false_positives_ctr:  6694\n",
      "false_negatives_ctr:  1241\n",
      "6166884719777037300\n",
      "Experiment: min_u_regressor_sparse, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5502\n",
      "true_negatives_ctr:  281219\n",
      "false_positives_ctr:  20255\n",
      "false_negatives_ctr:  520\n",
      "13174461152311957044\n",
      "Experiment: min_u_regressor_sparse, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  6013\n",
      "true_negatives_ctr:  232129\n",
      "false_positives_ctr:  69345\n",
      "false_negatives_ctr:  9\n",
      "31758955930231216912\n",
      "Experiment: min_u_regressor_focused, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5877\n",
      "true_negatives_ctr:  244952\n",
      "false_positives_ctr:  56522\n",
      "false_negatives_ctr:  145\n",
      "27765547379161324884\n",
      "Experiment: min_u_regressor_focused, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5592\n",
      "true_negatives_ctr:  259564\n",
      "false_positives_ctr:  41910\n",
      "false_negatives_ctr:  430\n",
      "22421560500974862864\n",
      "Experiment: min_u_regressor_focused, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5628\n",
      "true_negatives_ctr:  252109\n",
      "false_positives_ctr:  49365\n",
      "false_negatives_ctr:  394\n",
      "25209519554749125012\n",
      "Experiment: min_u_regressor_focused, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5975\n",
      "true_negatives_ctr:  253411\n",
      "false_positives_ctr:  48063\n",
      "false_negatives_ctr:  47\n",
      "24865424909283840912\n",
      "Experiment: min_u_regressor_focused, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4078\n",
      "true_negatives_ctr:  222792\n",
      "false_positives_ctr:  78682\n",
      "false_negatives_ctr:  1944\n",
      "33766320874884142080\n",
      "Experiment: min_u_filtered_regressor, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  2553\n",
      "true_negatives_ctr:  80452\n",
      "false_positives_ctr:  3966\n",
      "false_negatives_ctr:  3469\n",
      "278116939284510804\n",
      "Experiment: min_u_filtered_regressor, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4993\n",
      "true_negatives_ctr:  77816\n",
      "false_positives_ctr:  6602\n",
      "false_negatives_ctr:  1029\n",
      "464751414722598900\n",
      "Experiment: min_u_filtered_regressor, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4936\n",
      "true_negatives_ctr:  78434\n",
      "false_positives_ctr:  5984\n",
      "false_negatives_ctr:  1086\n",
      "441443188214246400\n",
      "Experiment: min_u_filtered_regressor, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5369\n",
      "true_negatives_ctr:  66433\n",
      "false_positives_ctr:  17985\n",
      "false_negatives_ctr:  653\n",
      "796469195782443024\n",
      "Experiment: min_u_filtered_regressor, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4712\n",
      "true_negatives_ctr:  31210\n",
      "false_positives_ctr:  35240\n",
      "false_negatives_ctr:  1190\n",
      "507665587777920000\n",
      "Experiment: min_u_regressor_balanced, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5117\n",
      "true_negatives_ctr:  282366\n",
      "false_positives_ctr:  19108\n",
      "false_negatives_ctr:  905\n",
      "12458234917891809300\n",
      "Experiment: min_u_regressor_balanced, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4997\n",
      "true_negatives_ctr:  292064\n",
      "false_positives_ctr:  9410\n",
      "false_negatives_ctr:  1025\n",
      "7665909532803367444\n",
      "Experiment: min_u_regressor_balanced, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5316\n",
      "true_negatives_ctr:  289858\n",
      "false_positives_ctr:  11616\n",
      "false_negatives_ctr:  706\n",
      "8931834755719537344\n",
      "Experiment: min_u_regressor_balanced, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5366\n",
      "true_negatives_ctr:  283756\n",
      "false_positives_ctr:  17718\n",
      "false_negatives_ctr:  656\n",
      "11919268318002316224\n",
      "Experiment: min_u_regressor_balanced, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  6015\n",
      "true_negatives_ctr:  226077\n",
      "false_positives_ctr:  75397\n",
      "false_negatives_ctr:  7\n",
      "33415569463756268224\n"
     ]
    }
   ],
   "source": [
    "from numpy import sqrt \n",
    "# Build a multi-index dataframe with the results of the metrics. The first index is the testing_data.keys(), the second index are the tp, tn, fp, fn, and the columns are the models.\n",
    "columns = ['tp', 'tn', 'fp', 'fn', '(hybrid)accuracy', '(hybrid)precision', '(hybrid)recall', '(hybrid)f1']\n",
    "index = pd.MultiIndex.from_product([testing_data.keys(), ['lr', 'gb', 'xgb', 'svr', 'mlp']], names=['experiment', 'class'])\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "classifier_experiments =[experiment for experiment in testing_data.keys() if 'classifier' in experiment.split('_')] # TODO confirm this\n",
    "regressor_experiments = [experiment for experiment in testing_data.keys() if 'regressor' in experiment.split('_')]\n",
    "# Classifier experiments\n",
    "class_metrics = metrics.Metrics()\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for experiment in classifier_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        for bus in testing_data[experiment][model]['predicted'].columns:\n",
    "            try:\n",
    "                tp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "                tn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "            except: \n",
    "                print('In the experiment ', experiment, ' and model ', model, ' there was a problem with bus: ', bus)\n",
    "                if not testing_data[experiment][model]['real'][bus].any():\n",
    "                    print('Bus {} has no positive data points. Just ignore the little shit.'.format(bus))    \n",
    "        df.loc[(experiment, model), 'tp'] = tp\n",
    "        df.loc[(experiment, model), 'tn'] = tn\n",
    "        df.loc[(experiment, model), 'fp'] = fp\n",
    "        df.loc[(experiment, model), 'fn'] = fn\n",
    "        #print('Experiment: {}, model: {}, tp: {}, tn: {}, fp: {}, fn: {}'.format(experiment, model, tp, tn, fp, fn))\n",
    "        recall = class_metrics.compute_recall(tp, fn)\n",
    "        precision = class_metrics.compute_precision(tp, fp)\n",
    "        f1 = class_metrics.compute_f1(recall, precision)\n",
    "        accuracy = class_metrics.compute_accuracy(tp, tn, fp, fn)\n",
    "        mcc = class_metrics.compute_mcc(tp, tn, fp, fn)\n",
    "        df.loc[(experiment, model), '(hybrid)accuracy'] = accuracy\n",
    "        df.loc[(experiment, model), '(hybrid)precision'] = precision\n",
    "        df.loc[(experiment, model), '(hybrid)recall'] = recall\n",
    "        df.loc[(experiment, model), '(hybrid)f1'] = f1\n",
    "        df.loc[(experiment, model), '(hybrid)mcc'] = mcc\n",
    "        # print('Experiment: {}, model: {}, accuracy: {}, precision: {}, recall: {}, f1: {}'.format(experiment, model, accuracy, precision, recall, f1))\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0 \n",
    "# Regressor experiments\n",
    "_threshold = lambda experiment: max_u_threshold / data_max_u_sparse['scaler']['y'] if 'max_u' in experiment else min_u_threshold/ data_min_u_sparse['scaler']['y']\n",
    "# _threshold = lambda experiment: max_u_threshold if 'max_u' in experiment else min_u_threshold\n",
    "for experiment in regressor_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        # try:\n",
    "        threshold = _threshold(experiment)\n",
    "        print('Experiment: {}, model: {}, threshold: {}'.format(experiment, model, threshold))\n",
    "        hybrid_metrics = metrics.Metrics()\n",
    "        hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted'], testing_data[experiment][model]['real'], threshold=threshold)\n",
    "        df.loc[(experiment, model), 'tp'] = hybrid_metrics.true_positives_ctr\n",
    "        df.loc[(experiment, model), 'tn'] = hybrid_metrics.true_negatives_ctr\n",
    "        df.loc[(experiment, model), 'fp'] = hybrid_metrics.false_positives_ctr\n",
    "        df.loc[(experiment, model), 'fn'] = hybrid_metrics.false_negatives_ctr\n",
    "        df.loc[(experiment, model), '(hybrid)accuracy'] = hybrid_metrics.hybrid_accuracy\n",
    "        df.loc[(experiment, model), '(hybrid)precision'] = hybrid_metrics.hybrid_precision\n",
    "        df.loc[(experiment, model), '(hybrid)recall'] = hybrid_metrics.hybrid_recall\n",
    "        df.loc[(experiment, model), '(hybrid)f1'] = hybrid_metrics.hybrid_f1\n",
    "        df.loc[(experiment, model), '(hybrid)mcc'] = hybrid_metrics.hybrid_mcc\n",
    "        # print('Experiment: {}, model: {}, tp: {}, tn: {}, fp: {}, fn: {}'.format(experiment, model, hybrid_metrics.true_positives_ctr, hybrid_metrics.true_negatives_ctr, hybrid_metrics.false_positives_ctr, hybrid_metrics.false_negatives_ctr))\n",
    "        # print('Experiment: {}, model: {}, accuracy: {}, precision: {}, recall: {}, f1: {}'.format(experiment, model, hybrid_metrics.hybrid_accuracy_rmse, hybrid_metrics.hybrid_precision_rmse, hybrid_metrics.hybrid_recall_rmse, hybrid_metrics.hybrid_f1_rmse))\n",
    "        # except(Exception) as e:\n",
    "        #     print('In the experiment ', experiment, ' and model ', model, ' there was a problem')\n",
    "        #     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('results_db1_mcc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562243</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.016844</td>\n",
       "      <td>0.068940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4321</td>\n",
       "      <td>297379</td>\n",
       "      <td>5168</td>\n",
       "      <td>628</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.540358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4523</td>\n",
       "      <td>249361</td>\n",
       "      <td>53186</td>\n",
       "      <td>426</td>\n",
       "      <td>0.79822</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.878914</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.187375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4660</td>\n",
       "      <td>179741</td>\n",
       "      <td>122806</td>\n",
       "      <td>289</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.919546</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.105429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4940</td>\n",
       "      <td>249296</td>\n",
       "      <td>53251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.225088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3714</td>\n",
       "      <td>204398</td>\n",
       "      <td>98149</td>\n",
       "      <td>1235</td>\n",
       "      <td>0.635756</td>\n",
       "      <td>0.023866</td>\n",
       "      <td>0.631137</td>\n",
       "      <td>0.045992</td>\n",
       "      <td>0.064838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>513</td>\n",
       "      <td>94022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015264</td>\n",
       "      <td>0.004556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4521</td>\n",
       "      <td>280815</td>\n",
       "      <td>21732</td>\n",
       "      <td>428</td>\n",
       "      <td>0.917912</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.314492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4090</td>\n",
       "      <td>297475</td>\n",
       "      <td>5072</td>\n",
       "      <td>859</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.35234</td>\n",
       "      <td>0.759724</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>0.508297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4448</td>\n",
       "      <td>293409</td>\n",
       "      <td>9138</td>\n",
       "      <td>501</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.25097</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.452522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4222</td>\n",
       "      <td>287934</td>\n",
       "      <td>14613</td>\n",
       "      <td>727</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.798145</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.357587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>213161</td>\n",
       "      <td>89386</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545816</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.016041</td>\n",
       "      <td>0.066263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3900</td>\n",
       "      <td>58970</td>\n",
       "      <td>35565</td>\n",
       "      <td>1049</td>\n",
       "      <td>0.631961</td>\n",
       "      <td>0.098822</td>\n",
       "      <td>0.788038</td>\n",
       "      <td>0.17562</td>\n",
       "      <td>0.183029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3499</td>\n",
       "      <td>91026</td>\n",
       "      <td>3509</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0.585264</td>\n",
       "      <td>0.569179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3158</td>\n",
       "      <td>92054</td>\n",
       "      <td>2481</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.957058</td>\n",
       "      <td>0.560028</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>0.575312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3956</td>\n",
       "      <td>89928</td>\n",
       "      <td>4607</td>\n",
       "      <td>993</td>\n",
       "      <td>0.94371</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>0.581876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4047</td>\n",
       "      <td>58332</td>\n",
       "      <td>36203</td>\n",
       "      <td>902</td>\n",
       "      <td>0.627025</td>\n",
       "      <td>0.100547</td>\n",
       "      <td>0.817741</td>\n",
       "      <td>0.179075</td>\n",
       "      <td>0.192601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6013</td>\n",
       "      <td>232129</td>\n",
       "      <td>69345</td>\n",
       "      <td>9</td>\n",
       "      <td>0.629996</td>\n",
       "      <td>0.00939</td>\n",
       "      <td>0.992413</td>\n",
       "      <td>0.018603</td>\n",
       "      <td>0.076194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5877</td>\n",
       "      <td>244952</td>\n",
       "      <td>56522</td>\n",
       "      <td>145</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.223576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5592</td>\n",
       "      <td>259564</td>\n",
       "      <td>41910</td>\n",
       "      <td>430</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.908282</td>\n",
       "      <td>0.160995</td>\n",
       "      <td>0.254038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5628</td>\n",
       "      <td>252109</td>\n",
       "      <td>49365</td>\n",
       "      <td>394</td>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.228193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5975</td>\n",
       "      <td>253411</td>\n",
       "      <td>48063</td>\n",
       "      <td>47</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.262651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4078</td>\n",
       "      <td>222792</td>\n",
       "      <td>78682</td>\n",
       "      <td>1944</td>\n",
       "      <td>0.702677</td>\n",
       "      <td>0.035257</td>\n",
       "      <td>0.580554</td>\n",
       "      <td>0.066476</td>\n",
       "      <td>0.083337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4712</td>\n",
       "      <td>31210</td>\n",
       "      <td>35240</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.181608</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.395188</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>-0.192029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5117</td>\n",
       "      <td>282366</td>\n",
       "      <td>19108</td>\n",
       "      <td>905</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.165926</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.345050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4997</td>\n",
       "      <td>292064</td>\n",
       "      <td>9410</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.284526</td>\n",
       "      <td>0.77814</td>\n",
       "      <td>0.41669</td>\n",
       "      <td>0.456403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5316</td>\n",
       "      <td>289858</td>\n",
       "      <td>11616</td>\n",
       "      <td>706</td>\n",
       "      <td>0.954371</td>\n",
       "      <td>0.255966</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.393042</td>\n",
       "      <td>0.450693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5366</td>\n",
       "      <td>283756</td>\n",
       "      <td>17718</td>\n",
       "      <td>656</td>\n",
       "      <td>0.933244</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.391941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6015</td>\n",
       "      <td>226077</td>\n",
       "      <td>75397</td>\n",
       "      <td>7</td>\n",
       "      <td>0.601228</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.993897</td>\n",
       "      <td>0.016537</td>\n",
       "      <td>0.070218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5318</td>\n",
       "      <td>50201</td>\n",
       "      <td>34217</td>\n",
       "      <td>704</td>\n",
       "      <td>0.613877</td>\n",
       "      <td>0.134514</td>\n",
       "      <td>0.883095</td>\n",
       "      <td>0.233466</td>\n",
       "      <td>0.240123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4379</td>\n",
       "      <td>77799</td>\n",
       "      <td>6619</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.398163</td>\n",
       "      <td>0.727167</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.494868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4395</td>\n",
       "      <td>77766</td>\n",
       "      <td>6652</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.908459</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>0.729824</td>\n",
       "      <td>0.514969</td>\n",
       "      <td>0.495647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4931</td>\n",
       "      <td>79390</td>\n",
       "      <td>5028</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.49513</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.604686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5309</td>\n",
       "      <td>46569</td>\n",
       "      <td>37849</td>\n",
       "      <td>713</td>\n",
       "      <td>0.573618</td>\n",
       "      <td>0.123013</td>\n",
       "      <td>0.881601</td>\n",
       "      <td>0.215901</td>\n",
       "      <td>0.216245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                                \n",
       "max_u_regressor_sparse    lr     3151  297203    5344  1798         0.973939   \n",
       "                          gb     3410  299857    2690  1539          0.98396   \n",
       "                          xgb    4550  292244   10303   399         0.960463   \n",
       "                          svr    4615  275913   26634   334         0.904389   \n",
       "                          mlp    4948  217055   85492     1         0.562243   \n",
       "max_u_regressor_focused   lr     4321  297379    5168   628         0.977467   \n",
       "                          gb     4523  249361   53186   426          0.79822   \n",
       "                          xgb    4660  179741  122806   289         0.554576   \n",
       "                          svr    4940  249296   53251     9         0.808736   \n",
       "                          mlp    3714  204398   98149  1235         0.635756   \n",
       "max_u_filtered_regressor  lr     3151   89191    5344  1798         0.918805   \n",
       "                          gb     3356   91872    2663  1593         0.949925   \n",
       "                          xgb    4949     128   94407     0         0.037666   \n",
       "                          svr    4443   46628   47907   506         0.481777   \n",
       "                          mlp    4949     513   94022     0         0.010349   \n",
       "max_u_regressor_balanced  lr     4521  280815   21732   428         0.917912   \n",
       "                          gb     4090  297475    5072   859         0.977647   \n",
       "                          xgb    4448  293409    9138   501         0.963717   \n",
       "                          svr    4222  287934   14613   727         0.944365   \n",
       "                          mlp    4948  213161   89386     1         0.545816   \n",
       "max_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     2487   92303    2232  2462         0.952817   \n",
       "                          xgb    1817   93214    1321  3132         0.955239   \n",
       "                          svr       0   94535       0  4949         0.950253   \n",
       "                          mlp    3900   58970   35565  1049         0.631961   \n",
       "max_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     3499   91026    3509  1450         0.950153   \n",
       "                          xgb    3158   92054    2481  1791         0.957058   \n",
       "                          svr    3956   89928    4607   993          0.94371   \n",
       "                          mlp    4047   58332   36203   902         0.627025   \n",
       "min_u_regressor_sparse    lr     2553  297508    3966  3469         0.972468   \n",
       "                          gb     5039  294582    6892   983         0.970974   \n",
       "                          xgb    4781  294780    6694  1241         0.970684   \n",
       "                          svr    5502  281219   20255   520         0.925053   \n",
       "                          mlp    6013  232129   69345     9         0.629996   \n",
       "min_u_regressor_focused   lr     5877  244952   56522   145         0.780846   \n",
       "                          gb     5592  259564   41910   430         0.839482   \n",
       "                          xgb    5628  252109   49365   394         0.808055   \n",
       "                          svr    5975  253411   48063    47         0.822388   \n",
       "                          mlp    4078  222792   78682  1944         0.702677   \n",
       "min_u_filtered_regressor  lr     2553   80452    3966  3469         0.905889   \n",
       "                          gb     4993   77816    6602  1029         0.903749   \n",
       "                          xgb    4936   78434    5984  1086         0.911141   \n",
       "                          svr    5369   66433   17985   653         0.770305   \n",
       "                          mlp    4712   31210   35240  1190         0.181608   \n",
       "min_u_regressor_balanced  lr     5117  282366   19108   905         0.926901   \n",
       "                          gb     4997  292064    9410  1025         0.961439   \n",
       "                          xgb    5316  289858   11616   706         0.954371   \n",
       "                          svr    5366  283756   17718   656         0.933244   \n",
       "                          mlp    6015  226077   75397     7         0.601228   \n",
       "min_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4068   81151    3267  1954         0.942271   \n",
       "                          xgb    4167   80534    3884  1855         0.936544   \n",
       "                          svr    2965   82965    1453  3057         0.950133   \n",
       "                          mlp    5318   50201   34217   704         0.613877   \n",
       "min_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4379   77799    6619  1643         0.908647   \n",
       "                          xgb    4395   77766    6652  1627         0.908459   \n",
       "                          svr    4931   79390    5028  1091         0.932342   \n",
       "                          mlp    5309   46569   37849   713         0.573618   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_regressor_sparse    lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.441493       0.567722   0.496713   \n",
       "                          xgb            0.230752       0.882031   0.365804   \n",
       "                          svr            0.107401       0.898987   0.191878   \n",
       "                          mlp            0.008494       0.999275   0.016844   \n",
       "max_u_regressor_focused   lr             0.366413       0.822844   0.507041   \n",
       "                          gb             0.053925       0.878914   0.101616   \n",
       "                          xgb            0.025552       0.919546   0.049723   \n",
       "                          svr            0.063073       0.997519   0.118643   \n",
       "                          mlp            0.023866       0.631137   0.045992   \n",
       "max_u_filtered_regressor  lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.439197       0.552025    0.48919   \n",
       "                          xgb            0.036546            1.0   0.070515   \n",
       "                          svr            0.060259       0.842986   0.112478   \n",
       "                          mlp            0.007691            1.0   0.015264   \n",
       "max_u_regressor_balanced  lr                0.126       0.877757   0.220366   \n",
       "                          gb              0.35234       0.759724   0.481414   \n",
       "                          xgb             0.25097       0.857354   0.388281   \n",
       "                          svr            0.174752       0.798145   0.286726   \n",
       "                          mlp            0.008085       0.999274   0.016041   \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.527018       0.502526   0.514481   \n",
       "                          xgb            0.579031       0.367145   0.449363   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.098822       0.788038    0.17562   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.499287       0.707012   0.585264   \n",
       "                          xgb            0.560028       0.638109   0.596524   \n",
       "                          svr            0.461988       0.799353   0.585554   \n",
       "                          mlp            0.100547       0.817741   0.179075   \n",
       "min_u_regressor_sparse    lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.353983       0.787945   0.488506   \n",
       "                          xgb            0.345599       0.731315   0.469381   \n",
       "                          svr            0.174263       0.890969    0.29151   \n",
       "                          mlp             0.00939       0.992413   0.018603   \n",
       "min_u_regressor_focused   lr             0.067654       0.968548   0.126474   \n",
       "                          gb             0.088325       0.908282   0.160995   \n",
       "                          xgb            0.073954        0.91519   0.136849   \n",
       "                          svr            0.085393       0.990249   0.157228   \n",
       "                          mlp            0.035257       0.580554   0.066476   \n",
       "min_u_filtered_regressor  lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.360775       0.778289   0.493014   \n",
       "                          xgb            0.382714        0.76811    0.51088   \n",
       "                          svr            0.186868       0.861772   0.307136   \n",
       "                          mlp            0.015304       0.395188   0.029467   \n",
       "min_u_regressor_balanced  lr             0.165926       0.804743   0.275126   \n",
       "                          gb             0.284526        0.77814    0.41669   \n",
       "                          xgb            0.255966       0.846198   0.393042   \n",
       "                          svr            0.194107         0.8676   0.317238   \n",
       "                          mlp            0.008338       0.993897   0.016537   \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.554601       0.675523   0.609119   \n",
       "                          xgb            0.517575       0.691963   0.592198   \n",
       "                          svr            0.671118       0.492361   0.568008   \n",
       "                          mlp            0.134514       0.883095   0.233466   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.398163       0.727167   0.514571   \n",
       "                          xgb            0.397846       0.729824   0.514969   \n",
       "                          svr             0.49513       0.818831   0.617108   \n",
       "                          mlp            0.123013       0.881601   0.215901   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "max_u_regressor_sparse    lr        0.346102  \n",
       "                          gb        0.492687  \n",
       "                          xgb       0.439649  \n",
       "                          svr       0.291796  \n",
       "                          mlp       0.068940  \n",
       "max_u_regressor_focused   lr        0.540358  \n",
       "                          gb        0.187375  \n",
       "                          xgb       0.105429  \n",
       "                          svr       0.225088  \n",
       "                          mlp       0.064838  \n",
       "max_u_filtered_regressor  lr        0.318793  \n",
       "                          gb        0.466570  \n",
       "                          xgb       0.006640  \n",
       "                          svr       0.120496  \n",
       "                          mlp       0.004556  \n",
       "max_u_regressor_balanced  lr        0.314492  \n",
       "                          gb        0.508297  \n",
       "                          xgb       0.452522  \n",
       "                          svr       0.357587  \n",
       "                          mlp       0.066263  \n",
       "max_u_classifier          lr             NaN  \n",
       "                          gb        0.489852  \n",
       "                          xgb       0.439336  \n",
       "                          svr      -1.000000  \n",
       "                          mlp       0.183029  \n",
       "max_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.569179  \n",
       "                          xgb       0.575312  \n",
       "                          svr       0.581876  \n",
       "                          mlp       0.192601  \n",
       "min_u_regressor_sparse    lr        0.297390  \n",
       "                          gb        0.516571  \n",
       "                          xgb       0.490517  \n",
       "                          svr       0.374989  \n",
       "                          mlp       0.076194  \n",
       "min_u_regressor_focused   lr        0.223576  \n",
       "                          gb        0.254038  \n",
       "                          xgb       0.228193  \n",
       "                          svr       0.262651  \n",
       "                          mlp       0.083337  \n",
       "min_u_filtered_regressor  lr        0.260936  \n",
       "                          gb        0.488250  \n",
       "                          xgb       0.502496  \n",
       "                          svr       0.331681  \n",
       "                          mlp      -0.192029  \n",
       "min_u_regressor_balanced  lr        0.345050  \n",
       "                          gb        0.456403  \n",
       "                          xgb       0.450693  \n",
       "                          svr       0.391941  \n",
       "                          mlp       0.070218  \n",
       "min_u_classifier          lr             NaN  \n",
       "                          gb        0.581558  \n",
       "                          xgb       0.565496  \n",
       "                          svr       0.549541  \n",
       "                          mlp       0.240123  \n",
       "min_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.494868  \n",
       "                          xgb       0.495647  \n",
       "                          svr       0.604686  \n",
       "                          mlp       0.216245  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>possible_positives</th>\n",
       "      <th>possible_negatives</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5902</td>\n",
       "      <td>66450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                possible_positives possible_negatives\n",
       "experiment                class                                      \n",
       "max_u_regressor_sparse    lr                  4949             302547\n",
       "                          gb                  4949             302547\n",
       "                          xgb                 4949             302547\n",
       "                          svr                 4949             302547\n",
       "                          mlp                 4949             302547\n",
       "max_u_regressor_focused   lr                  4949             302547\n",
       "                          gb                  4949             302547\n",
       "                          xgb                 4949             302547\n",
       "                          svr                 4949             302547\n",
       "                          mlp                 4949             302547\n",
       "max_u_filtered_regressor  lr                  4949              94535\n",
       "                          gb                  4949              94535\n",
       "                          xgb                 4949              94535\n",
       "                          svr                 4949              94535\n",
       "                          mlp                 4949              94535\n",
       "max_u_regressor_balanced  lr                  4949             302547\n",
       "                          gb                  4949             302547\n",
       "                          xgb                 4949             302547\n",
       "                          svr                 4949             302547\n",
       "                          mlp                 4949             302547\n",
       "max_u_classifier          lr                   NaN                NaN\n",
       "                          gb                  4949              94535\n",
       "                          xgb                 4949              94535\n",
       "                          svr                 4949              94535\n",
       "                          mlp                 4949              94535\n",
       "max_u_classifier_balanced lr                   NaN                NaN\n",
       "                          gb                  4949              94535\n",
       "                          xgb                 4949              94535\n",
       "                          svr                 4949              94535\n",
       "                          mlp                 4949              94535\n",
       "min_u_regressor_sparse    lr                  6022             301474\n",
       "                          gb                  6022             301474\n",
       "                          xgb                 6022             301474\n",
       "                          svr                 6022             301474\n",
       "                          mlp                 6022             301474\n",
       "min_u_regressor_focused   lr                  6022             301474\n",
       "                          gb                  6022             301474\n",
       "                          xgb                 6022             301474\n",
       "                          svr                 6022             301474\n",
       "                          mlp                 6022             301474\n",
       "min_u_filtered_regressor  lr                  6022              84418\n",
       "                          gb                  6022              84418\n",
       "                          xgb                 6022              84418\n",
       "                          svr                 6022              84418\n",
       "                          mlp                 5902              66450\n",
       "min_u_regressor_balanced  lr                  6022             301474\n",
       "                          gb                  6022             301474\n",
       "                          xgb                 6022             301474\n",
       "                          svr                 6022             301474\n",
       "                          mlp                 6022             301474\n",
       "min_u_classifier          lr                   NaN                NaN\n",
       "                          gb                  6022              84418\n",
       "                          xgb                 6022              84418\n",
       "                          svr                 6022              84418\n",
       "                          mlp                 6022              84418\n",
       "min_u_classifier_balanced lr                   NaN                NaN\n",
       "                          gb                  6022              84418\n",
       "                          xgb                 6022              84418\n",
       "                          svr                 6022              84418\n",
       "                          mlp                 6022              84418"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirmation_df = pd.DataFrame()\n",
    "confirmation_df['possible_positives'] = df['tp'] + df['fn']\n",
    "confirmation_df['possible_negatives'] = df['fp'] + df['tn']\n",
    "confirmation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscale everything\n",
    "testing_data['max_u_regressor_sparse'][model]['predicted'] = testing_data['max_u_regressor_sparse'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_sparse'][model]['real'] = testing_data['max_u_regressor_sparse'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_focused'][model]['predicted'] = testing_data['max_u_regressor_focused'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_focused'][model]['real'] = testing_data['max_u_regressor_focused'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_filtered_regressor'][model]['predicted'] = testing_data['max_u_filtered_regressor'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_filtered_regressor'][model]['real'] = testing_data['max_u_filtered_regressor'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_balanced'][model]['predicted'] = testing_data['max_u_regressor_balanced'][model]['predicted'] * data_max_u_balanced['scaler']['y']\n",
    "testing_data['max_u_regressor_balanced'][model]['real'] = testing_data['max_u_regressor_balanced'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_sparse'][model]['predicted'] = testing_data['min_u_regressor_sparse'][model]['predicted'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_sparse'][model]['real'] = testing_data['min_u_regressor_sparse'][model]['real'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_focused'][model]['predicted'] = testing_data['min_u_regressor_focused'][model]['predicted'] * data_min_u_focused['scaler']['y']\n",
    "testing_data['min_u_regressor_focused'][model]['real'] = testing_data['min_u_regressor_focused'][model]['real'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_filtered_regressor'][model]['predicted'] = testing_data['min_u_filtered_regressor'][model]['predicted'] * data_min_u_sparse['scaler']['y'] \n",
    "testing_data['min_u_filtered_regressor'][model]['real'] = testing_data['min_u_filtered_regressor'][model]['real'][utils.cols_with_positive_values(prediction)] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_balanced'][model]['predicted'] = testing_data['min_u_regressor_balanced'][model]['predicted'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_balanced'][model]['real'] = testing_data['min_u_regressor_balanced'][model]['real'] * data_min_u_sparse['scaler']['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to evaluate all the results obtained above. This benchmarking has the objective of obtaining the answer following questions:\n",
    "- What is the optimum number of rows for the training data set? What is the respective model?\n",
    "    - sparse reg. vs balanced reg. vs focused reg.\n",
    "- What is the optimum number present busses in regresison?\n",
    "    - sparse reg. vs filtered reg.\n",
    "- Regression vs Classification\n",
    "    - filtered reg. vs sparse class.\n",
    "- What is the optimum number of rows in class?\n",
    "    - sparse class. vs balanced class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum proportion of P/N rows for the training data set? What is the respective model?\n",
    "In order to understand the optinum number of rows for the training set of the regression data set the data sets used will be:\n",
    "\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Maximum Voltage Constraints|Balanced Regression|6971|34|\n",
    "|Maximum Voltage Constraints|Focused Regression|3486|34|\n",
    "|Minimum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Minimum Voltage Constraints|Balanced Regression|13917|34|\n",
    "|Minimum Voltage Constraints|Focused Regression|6958|34|\n",
    "\n",
    "The **Sparse Regression data set** is generated directly from the power flow results. The important moments are those where the constraints are violated, so the output feature contains null values for when there is no constraint, and positive value for when there is a constraint. The positive values represent the amplitude of the constraint violation. It can be expressed as follows:\n",
    "$$\n",
    "    \\begin{align}\n",
    "        \\text{Target} &= \\begin{cases}\n",
    "            0 & \\text{if} \\; \\text{constraint} \\; \\text{is not violated} \\\\\n",
    "            \\text{amplitude of constraint} & \\text{if} \\; \\text{constraint} \\; \\text{is violated} \\\\\n",
    "        \\end{cases}\n",
    "    \\end{align}\n",
    "$$\n",
    "In our case, the constraints are being considered as the following:\n",
    "- Minimal voltage on bus: $v_{bus} < 0.95 \\text{ [pu]}$ (constraint is violated if the voltage is below $0.95 \\text{ [pu]} $)\n",
    "- Maximal voltage on bus: $v_{bus} > 1.05 \\text{ [pu]}$ (constraint is violated if the voltage is above $1.05 \\text{ [pu]} $)\n",
    "- Maximal current on line: $i_{line} > 1 \\text{ [kA]}$ (constraint is violated if the current is above $1 \\text{ [kA]} $)\n",
    "<!-- Summarize the information in the bullet points above, in the form of a latex table. -->\n",
    "| Constraint | Description | Target |\n",
    "|------------|-------------|--------|\n",
    "| Minimal voltage on bus | $v_{bus} < 0.95 \\text{ [pu]}$ | $v_{bus} - 0.95 \\text{ [pu]}$ |\n",
    "| Maximal voltage on bus | $v_{bus} > 1.05 \\text{ [pu]}$ | $1.05 \\text{ [pu]} - v_{bus}$ |\n",
    "| Maximal current on line | $i_{line} > 1 \\text{ [kA]}$ | $i_{line} - 1 \\text{ [kA]}$ |\n",
    "    \n",
    "The **Balanced Regression** data set is created from the **Sparse Regression data set**. It is created by taking all the rows that containt at least one constraint violation and then taking the same number of rows that do not contain any constraint violation. Finally, the **Focused Regression data set** is created by taking all the rows that contain at least one constraint violation.\n",
    "\n",
    "Since these data sets have the same number of possible negative and possible positives, all the metrics can be used to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4521</td>\n",
       "      <td>280815</td>\n",
       "      <td>21732</td>\n",
       "      <td>428</td>\n",
       "      <td>0.917912</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.314492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4090</td>\n",
       "      <td>297475</td>\n",
       "      <td>5072</td>\n",
       "      <td>859</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.35234</td>\n",
       "      <td>0.759724</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>0.508297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4448</td>\n",
       "      <td>293409</td>\n",
       "      <td>9138</td>\n",
       "      <td>501</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.25097</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.452522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4222</td>\n",
       "      <td>287934</td>\n",
       "      <td>14613</td>\n",
       "      <td>727</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.798145</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.357587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>213184</td>\n",
       "      <td>89363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.066274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4321</td>\n",
       "      <td>297379</td>\n",
       "      <td>5168</td>\n",
       "      <td>628</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.540358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4523</td>\n",
       "      <td>249361</td>\n",
       "      <td>53186</td>\n",
       "      <td>426</td>\n",
       "      <td>0.79822</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.878914</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.187375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4660</td>\n",
       "      <td>179741</td>\n",
       "      <td>122806</td>\n",
       "      <td>289</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.919546</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.105429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4940</td>\n",
       "      <td>249296</td>\n",
       "      <td>53251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.225088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3713</td>\n",
       "      <td>204413</td>\n",
       "      <td>98134</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.635806</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.631136</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.064861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                                \n",
       "max_u_regressor_sparse   lr     3151  297203    5344  1798         0.973939   \n",
       "                         gb     3410  299857    2690  1539          0.98396   \n",
       "                         xgb    4550  292244   10303   399         0.960463   \n",
       "                         svr    4615  275913   26634   334         0.904389   \n",
       "                         mlp    4948  217055   85492     1         0.562262   \n",
       "max_u_regressor_balanced lr     4521  280815   21732   428         0.917912   \n",
       "                         gb     4090  297475    5072   859         0.977647   \n",
       "                         xgb    4448  293409    9138   501         0.963717   \n",
       "                         svr    4222  287934   14613   727         0.944365   \n",
       "                         mlp    4948  213184   89363     1         0.545878   \n",
       "max_u_regressor_focused  lr     4321  297379    5168   628         0.977467   \n",
       "                         gb     4523  249361   53186   426          0.79822   \n",
       "                         xgb    4660  179741  122806   289         0.554576   \n",
       "                         svr    4940  249296   53251     9         0.808736   \n",
       "                         mlp    3713  204413   98134  1236         0.635806   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.441493       0.567722   0.496713   \n",
       "                         xgb            0.230752       0.882031   0.365804   \n",
       "                         svr            0.107401       0.898987   0.191878   \n",
       "                         mlp            0.008497       0.999275    0.01685   \n",
       "max_u_regressor_balanced lr                0.126       0.877757   0.220366   \n",
       "                         gb              0.35234       0.759724   0.481414   \n",
       "                         xgb             0.25097       0.857354   0.388281   \n",
       "                         svr            0.174752       0.798145   0.286726   \n",
       "                         mlp            0.008087       0.999274   0.016044   \n",
       "max_u_regressor_focused  lr             0.366413       0.822844   0.507041   \n",
       "                         gb             0.053925       0.878914   0.101616   \n",
       "                         xgb            0.025552       0.919546   0.049723   \n",
       "                         svr            0.063073       0.997519   0.118643   \n",
       "                         mlp            0.023876       0.631136   0.046011   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_regressor_sparse   lr        0.346102  \n",
       "                         gb        0.492687  \n",
       "                         xgb       0.439649  \n",
       "                         svr       0.291796  \n",
       "                         mlp       0.068953  \n",
       "max_u_regressor_balanced lr        0.314492  \n",
       "                         gb        0.508297  \n",
       "                         xgb       0.452522  \n",
       "                         svr       0.357587  \n",
       "                         mlp       0.066274  \n",
       "max_u_regressor_focused  lr        0.540358  \n",
       "                         gb        0.187375  \n",
       "                         xgb       0.105429  \n",
       "                         svr       0.225088  \n",
       "                         mlp       0.064861  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_regressor_sparse', 'max_u_regressor_balanced', 'max_u_regressor_focused']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best alternative is to use the focused data set with a the linear regression model, because it presents a the best values for F1 and MCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5117</td>\n",
       "      <td>282366</td>\n",
       "      <td>19108</td>\n",
       "      <td>905</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.165926</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.345050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4997</td>\n",
       "      <td>292064</td>\n",
       "      <td>9410</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.284526</td>\n",
       "      <td>0.77814</td>\n",
       "      <td>0.41669</td>\n",
       "      <td>0.456403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5316</td>\n",
       "      <td>289858</td>\n",
       "      <td>11616</td>\n",
       "      <td>706</td>\n",
       "      <td>0.954371</td>\n",
       "      <td>0.255966</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.393042</td>\n",
       "      <td>0.450693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5366</td>\n",
       "      <td>283756</td>\n",
       "      <td>17718</td>\n",
       "      <td>656</td>\n",
       "      <td>0.933244</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.391941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6015</td>\n",
       "      <td>226077</td>\n",
       "      <td>75397</td>\n",
       "      <td>7</td>\n",
       "      <td>0.601244</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.993896</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.070213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5877</td>\n",
       "      <td>244952</td>\n",
       "      <td>56522</td>\n",
       "      <td>145</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.223576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5592</td>\n",
       "      <td>259564</td>\n",
       "      <td>41910</td>\n",
       "      <td>430</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.908282</td>\n",
       "      <td>0.160995</td>\n",
       "      <td>0.254038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5628</td>\n",
       "      <td>252109</td>\n",
       "      <td>49365</td>\n",
       "      <td>394</td>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.228193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5975</td>\n",
       "      <td>253411</td>\n",
       "      <td>48063</td>\n",
       "      <td>47</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.262651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4106</td>\n",
       "      <td>222759</td>\n",
       "      <td>78715</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.702687</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.585727</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.084777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr     2553  297508   3966  3469         0.972468   \n",
       "                         gb     5039  294582   6892   983         0.970974   \n",
       "                         xgb    4781  294780   6694  1241         0.970684   \n",
       "                         svr    5502  281219  20255   520         0.925053   \n",
       "                         mlp    6014  232123  69351     8         0.629952   \n",
       "min_u_regressor_balanced lr     5117  282366  19108   905         0.926901   \n",
       "                         gb     4997  292064   9410  1025         0.961439   \n",
       "                         xgb    5316  289858  11616   706         0.954371   \n",
       "                         svr    5366  283756  17718   656         0.933244   \n",
       "                         mlp    6015  226077  75397     7         0.601244   \n",
       "min_u_regressor_focused  lr     5877  244952  56522   145         0.780846   \n",
       "                         gb     5592  259564  41910   430         0.839482   \n",
       "                         xgb    5628  252109  49365   394         0.808055   \n",
       "                         svr    5975  253411  48063    47         0.822388   \n",
       "                         mlp    4106  222759  78715  1916         0.702687   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.353983       0.787945   0.488506   \n",
       "                         xgb            0.345599       0.731315   0.469381   \n",
       "                         svr            0.174263       0.890969    0.29151   \n",
       "                         mlp            0.009394       0.993227   0.018612   \n",
       "min_u_regressor_balanced lr             0.165926       0.804743   0.275126   \n",
       "                         gb             0.284526        0.77814    0.41669   \n",
       "                         xgb            0.255966       0.846198   0.393042   \n",
       "                         svr            0.194107         0.8676   0.317238   \n",
       "                         mlp            0.008336       0.993896   0.016534   \n",
       "min_u_regressor_focused  lr             0.067654       0.968548   0.126474   \n",
       "                         gb             0.088325       0.908282   0.160995   \n",
       "                         xgb            0.073954        0.91519   0.136849   \n",
       "                         svr            0.085393       0.990249   0.157228   \n",
       "                         mlp            0.035524       0.585727   0.066985   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_regressor_sparse   lr        0.297390  \n",
       "                         gb        0.516571  \n",
       "                         xgb       0.490517  \n",
       "                         svr       0.374989  \n",
       "                         mlp       0.076279  \n",
       "min_u_regressor_balanced lr        0.345050  \n",
       "                         gb        0.456403  \n",
       "                         xgb       0.450693  \n",
       "                         svr       0.391941  \n",
       "                         mlp       0.070213  \n",
       "min_u_regressor_focused  lr        0.223576  \n",
       "                         gb        0.254038  \n",
       "                         xgb       0.228193  \n",
       "                         svr       0.262651  \n",
       "                         mlp       0.084777  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_regressor_sparse', 'min_u_regressor_balanced', 'min_u_regressor_focused']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best sparse, with gradient boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum number present busses in regresison?\n",
    "In order to understand the optinum number of busses for the training set of the regression data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Maximum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Minimum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Minimum Voltage Constraints|Filtered Regression|45216|10|\n",
    "\n",
    "The **Filtered Regression data set** is created from the Sparse Regression data set, but only keeping the columns that contain at least one time step with a constraint violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr     3151  297203   5344  1798         0.973939   \n",
       "                         gb     3410  299857   2690  1539          0.98396   \n",
       "                         xgb    4550  292244  10303   399         0.960463   \n",
       "                         svr    4615  275913  26634   334         0.904389   \n",
       "                         mlp    4948  217055  85492     1         0.562262   \n",
       "max_u_filtered_regressor lr     3151   89191   5344  1798         0.918805   \n",
       "                         gb     3356   91872   2663  1593         0.949925   \n",
       "                         xgb    4949     128  94407     0         0.037666   \n",
       "                         svr    4443   46628  47907   506         0.481777   \n",
       "                         mlp    4949     549  93986     0         0.010538   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.441493       0.567722   0.496713   \n",
       "                         xgb            0.230752       0.882031   0.365804   \n",
       "                         svr            0.107401       0.898987   0.191878   \n",
       "                         mlp            0.008497       0.999275    0.01685   \n",
       "max_u_filtered_regressor lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.439197       0.552025    0.48919   \n",
       "                         xgb            0.036546            1.0   0.070515   \n",
       "                         svr            0.060259       0.842986   0.112478   \n",
       "                         mlp            0.007693            1.0   0.015269   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_regressor_sparse   lr        0.346102  \n",
       "                         gb        0.492687  \n",
       "                         xgb       0.439649  \n",
       "                         svr       0.291796  \n",
       "                         mlp       0.068953  \n",
       "max_u_filtered_regressor lr        0.318793  \n",
       "                         gb        0.466570  \n",
       "                         xgb       0.006640  \n",
       "                         svr       0.120496  \n",
       "                         mlp       0.004715  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_regressor_sparse', 'max_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse, with GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr     2553  297508   3966  3469         0.972468   \n",
       "                         gb     5039  294582   6892   983         0.970974   \n",
       "                         xgb    4781  294780   6694  1241         0.970684   \n",
       "                         svr    5502  281219  20255   520         0.925053   \n",
       "                         mlp    6014  232123  69351     8         0.629952   \n",
       "min_u_filtered_regressor lr     2553   80452   3966  3469         0.905889   \n",
       "                         gb     4993   77816   6602  1029         0.903749   \n",
       "                         xgb    4936   78434   5984  1086         0.911141   \n",
       "                         svr    5369   66433  17985   653         0.770305   \n",
       "                         mlp    4709   31253  35197  1193         0.181759   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.353983       0.787945   0.488506   \n",
       "                         xgb            0.345599       0.731315   0.469381   \n",
       "                         svr            0.174263       0.890969    0.29151   \n",
       "                         mlp            0.009394       0.993227   0.018612   \n",
       "min_u_filtered_regressor lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.360775       0.778289   0.493014   \n",
       "                         xgb            0.382714        0.76811    0.51088   \n",
       "                         svr            0.186868       0.861772   0.307136   \n",
       "                         mlp            0.015308       0.393679    0.02947   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_regressor_sparse   lr        0.297390  \n",
       "                         gb        0.516571  \n",
       "                         xgb       0.490517  \n",
       "                         svr       0.374989  \n",
       "                         mlp       0.076279  \n",
       "min_u_filtered_regressor lr        0.260936  \n",
       "                         gb        0.488250  \n",
       "                         xgb       0.502496  \n",
       "                         svr       0.331681  \n",
       "                         mlp      -0.192864  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_regressor_sparse', 'min_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse, with GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression vs Classification\n",
    "In order to understand the optinum number of busses for the training set of the regression data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Maximum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Minimum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Minimum Voltage Constraints|Sparse Classification|45216|10|\n",
    "\n",
    "The **Sparse Classification data set** is created from the Sparse Regression data set, but instead of having the target feature as the amplitude of the constraint violation, it is a binary feature that indicates if there is a constraint violation or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                              \n",
       "max_u_classifier         lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                         gb     2487  92303   2232  2462         0.952817   \n",
       "                         xgb    1817  93214   1321  3132         0.955239   \n",
       "                         svr       0  94535      0  4949         0.950253   \n",
       "                         mlp    3902  58964  35571  1047         0.631921   \n",
       "max_u_filtered_regressor lr     3151  89191   5344  1798         0.918805   \n",
       "                         gb     3356  91872   2663  1593         0.949925   \n",
       "                         xgb    4949    128  94407     0         0.037666   \n",
       "                         svr    4443  46628  47907   506         0.481777   \n",
       "                         mlp    4949    549  93986     0         0.010538   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_classifier         lr                  NaN            NaN        NaN   \n",
       "                         gb             0.527018       0.502526   0.514481   \n",
       "                         xgb            0.579031       0.367145   0.449363   \n",
       "                         svr                   0            0.0          0   \n",
       "                         mlp            0.098852       0.788442   0.175679   \n",
       "max_u_filtered_regressor lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.439197       0.552025    0.48919   \n",
       "                         xgb            0.036546            1.0   0.070515   \n",
       "                         svr            0.060259       0.842986   0.112478   \n",
       "                         mlp            0.007693            1.0   0.015269   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_classifier         lr             NaN  \n",
       "                         gb        0.489852  \n",
       "                         xgb       0.439336  \n",
       "                         svr      -1.000000  \n",
       "                         mlp       0.183174  \n",
       "max_u_filtered_regressor lr        0.318793  \n",
       "                         gb        0.466570  \n",
       "                         xgb       0.006640  \n",
       "                         svr       0.120496  \n",
       "                         mlp       0.004715  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_classifier', 'max_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_u_filtered regressor with the gradient boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                              \n",
       "min_u_classifier         lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                         gb     4068  81151   3267  1954         0.942271   \n",
       "                         xgb    4167  80534   3884  1855         0.936544   \n",
       "                         svr    2965  82965   1453  3057         0.950133   \n",
       "                         mlp    5320  50125  34293   702         0.613058   \n",
       "min_u_filtered_regressor lr     2553  80452   3966  3469         0.905889   \n",
       "                         gb     4993  77816   6602  1029         0.903749   \n",
       "                         xgb    4936  78434   5984  1086         0.911141   \n",
       "                         svr    5369  66433  17985   653         0.770305   \n",
       "                         mlp    4709  31253  35197  1193         0.181759   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_classifier         lr                  NaN            NaN        NaN   \n",
       "                         gb             0.554601       0.675523   0.609119   \n",
       "                         xgb            0.517575       0.691963   0.592198   \n",
       "                         svr            0.671118       0.492361   0.568008   \n",
       "                         mlp            0.134299       0.883427   0.233154   \n",
       "min_u_filtered_regressor lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.360775       0.778289   0.493014   \n",
       "                         xgb            0.382714        0.76811    0.51088   \n",
       "                         svr            0.186868       0.861772   0.307136   \n",
       "                         mlp            0.015308       0.393679    0.02947   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_classifier         lr             NaN  \n",
       "                         gb        0.581558  \n",
       "                         xgb       0.565496  \n",
       "                         svr       0.549541  \n",
       "                         mlp       0.239785  \n",
       "min_u_filtered_regressor lr        0.260936  \n",
       "                         gb        0.488250  \n",
       "                         xgb       0.502496  \n",
       "                         svr       0.331681  \n",
       "                         mlp      -0.192864  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_classifier', 'min_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_u_classifier with the gradient boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum number of rows in class?\n",
    "In order to understand the optinum number of rows for the training set of the classification data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Maximum Voltage Constraints|Balanced Classification|6971|10|\n",
    "|Minimum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Minimum Voltage Constraints|Balanced Classification|13917|10|\n",
    "<!-- Summarize the information in the table above, in a table in latex format  -->\n",
    "The **Balanced Classification data set** is created from the Sparse Classification data set. It is created by taking all the rows that containt at least one constraint violation and then taking the same number of rows that do not contain any constraint violation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3499</td>\n",
       "      <td>91026</td>\n",
       "      <td>3509</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0.585264</td>\n",
       "      <td>0.569179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3158</td>\n",
       "      <td>92054</td>\n",
       "      <td>2481</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.957058</td>\n",
       "      <td>0.560028</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>0.575312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3956</td>\n",
       "      <td>89928</td>\n",
       "      <td>4607</td>\n",
       "      <td>993</td>\n",
       "      <td>0.94371</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>0.581876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4041</td>\n",
       "      <td>58329</td>\n",
       "      <td>36206</td>\n",
       "      <td>908</td>\n",
       "      <td>0.626935</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.816529</td>\n",
       "      <td>0.178821</td>\n",
       "      <td>0.192052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                              \n",
       "max_u_classifier          lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     2487  92303   2232  2462         0.952817   \n",
       "                          xgb    1817  93214   1321  3132         0.955239   \n",
       "                          svr       0  94535      0  4949         0.950253   \n",
       "                          mlp    3902  58964  35571  1047         0.631921   \n",
       "max_u_classifier_balanced lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     3499  91026   3509  1450         0.950153   \n",
       "                          xgb    3158  92054   2481  1791         0.957058   \n",
       "                          svr    3956  89928   4607   993          0.94371   \n",
       "                          mlp    4041  58329  36206   908         0.626935   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.527018       0.502526   0.514481   \n",
       "                          xgb            0.579031       0.367145   0.449363   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.098852       0.788442   0.175679   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.499287       0.707012   0.585264   \n",
       "                          xgb            0.560028       0.638109   0.596524   \n",
       "                          svr            0.461988       0.799353   0.585554   \n",
       "                          mlp            0.100405       0.816529   0.178821   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "max_u_classifier          lr             NaN  \n",
       "                          gb        0.489852  \n",
       "                          xgb       0.439336  \n",
       "                          svr      -1.000000  \n",
       "                          mlp       0.183174  \n",
       "max_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.569179  \n",
       "                          xgb       0.575312  \n",
       "                          svr       0.581876  \n",
       "                          mlp       0.192052  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_classifier', 'max_u_classifier_balanced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier balanced with xgb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4379</td>\n",
       "      <td>77799</td>\n",
       "      <td>6619</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.398163</td>\n",
       "      <td>0.727167</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.494868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4395</td>\n",
       "      <td>77766</td>\n",
       "      <td>6652</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.908459</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>0.729824</td>\n",
       "      <td>0.514969</td>\n",
       "      <td>0.495647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4931</td>\n",
       "      <td>79390</td>\n",
       "      <td>5028</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.49513</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.604686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5328</td>\n",
       "      <td>46466</td>\n",
       "      <td>37952</td>\n",
       "      <td>694</td>\n",
       "      <td>0.572689</td>\n",
       "      <td>0.123105</td>\n",
       "      <td>0.884756</td>\n",
       "      <td>0.216137</td>\n",
       "      <td>0.217185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                              \n",
       "min_u_classifier          lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     4068  81151   3267  1954         0.942271   \n",
       "                          xgb    4167  80534   3884  1855         0.936544   \n",
       "                          svr    2965  82965   1453  3057         0.950133   \n",
       "                          mlp    5320  50125  34293   702         0.613058   \n",
       "min_u_classifier_balanced lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     4379  77799   6619  1643         0.908647   \n",
       "                          xgb    4395  77766   6652  1627         0.908459   \n",
       "                          svr    4931  79390   5028  1091         0.932342   \n",
       "                          mlp    5328  46466  37952   694         0.572689   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.554601       0.675523   0.609119   \n",
       "                          xgb            0.517575       0.691963   0.592198   \n",
       "                          svr            0.671118       0.492361   0.568008   \n",
       "                          mlp            0.134299       0.883427   0.233154   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.398163       0.727167   0.514571   \n",
       "                          xgb            0.397846       0.729824   0.514969   \n",
       "                          svr             0.49513       0.818831   0.617108   \n",
       "                          mlp            0.123105       0.884756   0.216137   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "min_u_classifier          lr             NaN  \n",
       "                          gb        0.581558  \n",
       "                          xgb       0.565496  \n",
       "                          svr       0.549541  \n",
       "                          mlp       0.239785  \n",
       "min_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.494868  \n",
       "                          xgb       0.495647  \n",
       "                          svr       0.604686  \n",
       "                          mlp       0.217185  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_classifier', 'min_u_classifier_balanced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier balanced with svr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "In order to understand how good our predictions really are, we can compare it to a random classifier. [source](https://inside.getyourguide.com/blog/2020/9/30/what-makes-a-good-f1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "      <th>q</th>\n",
       "      <th>f1_coin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4321</td>\n",
       "      <td>297379</td>\n",
       "      <td>5168</td>\n",
       "      <td>628</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.540358</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4523</td>\n",
       "      <td>249361</td>\n",
       "      <td>53186</td>\n",
       "      <td>426</td>\n",
       "      <td>0.79822</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.878914</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4660</td>\n",
       "      <td>179741</td>\n",
       "      <td>122806</td>\n",
       "      <td>289</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.919546</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.105429</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4940</td>\n",
       "      <td>249296</td>\n",
       "      <td>53251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.225088</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3713</td>\n",
       "      <td>204413</td>\n",
       "      <td>98134</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.635806</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.631136</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.064861</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4521</td>\n",
       "      <td>280815</td>\n",
       "      <td>21732</td>\n",
       "      <td>428</td>\n",
       "      <td>0.917912</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.314492</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4090</td>\n",
       "      <td>297475</td>\n",
       "      <td>5072</td>\n",
       "      <td>859</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.35234</td>\n",
       "      <td>0.759724</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4448</td>\n",
       "      <td>293409</td>\n",
       "      <td>9138</td>\n",
       "      <td>501</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.25097</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.452522</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4222</td>\n",
       "      <td>287934</td>\n",
       "      <td>14613</td>\n",
       "      <td>727</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.798145</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.357587</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>213184</td>\n",
       "      <td>89363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.066274</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3499</td>\n",
       "      <td>91026</td>\n",
       "      <td>3509</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0.585264</td>\n",
       "      <td>0.569179</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3158</td>\n",
       "      <td>92054</td>\n",
       "      <td>2481</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.957058</td>\n",
       "      <td>0.560028</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>0.575312</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3956</td>\n",
       "      <td>89928</td>\n",
       "      <td>4607</td>\n",
       "      <td>993</td>\n",
       "      <td>0.94371</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>0.581876</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4041</td>\n",
       "      <td>58329</td>\n",
       "      <td>36206</td>\n",
       "      <td>908</td>\n",
       "      <td>0.626935</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.816529</td>\n",
       "      <td>0.178821</td>\n",
       "      <td>0.192052</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5877</td>\n",
       "      <td>244952</td>\n",
       "      <td>56522</td>\n",
       "      <td>145</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.223576</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5592</td>\n",
       "      <td>259564</td>\n",
       "      <td>41910</td>\n",
       "      <td>430</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.908282</td>\n",
       "      <td>0.160995</td>\n",
       "      <td>0.254038</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5628</td>\n",
       "      <td>252109</td>\n",
       "      <td>49365</td>\n",
       "      <td>394</td>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.228193</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5975</td>\n",
       "      <td>253411</td>\n",
       "      <td>48063</td>\n",
       "      <td>47</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.262651</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4106</td>\n",
       "      <td>222759</td>\n",
       "      <td>78715</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.702687</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.585727</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.084777</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "      <td>0.081573</td>\n",
       "      <td>0.150842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5117</td>\n",
       "      <td>282366</td>\n",
       "      <td>19108</td>\n",
       "      <td>905</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.165926</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.345050</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4997</td>\n",
       "      <td>292064</td>\n",
       "      <td>9410</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.284526</td>\n",
       "      <td>0.77814</td>\n",
       "      <td>0.41669</td>\n",
       "      <td>0.456403</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5316</td>\n",
       "      <td>289858</td>\n",
       "      <td>11616</td>\n",
       "      <td>706</td>\n",
       "      <td>0.954371</td>\n",
       "      <td>0.255966</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.393042</td>\n",
       "      <td>0.450693</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5366</td>\n",
       "      <td>283756</td>\n",
       "      <td>17718</td>\n",
       "      <td>656</td>\n",
       "      <td>0.933244</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.391941</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6015</td>\n",
       "      <td>226077</td>\n",
       "      <td>75397</td>\n",
       "      <td>7</td>\n",
       "      <td>0.601244</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.993896</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.070213</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4379</td>\n",
       "      <td>77799</td>\n",
       "      <td>6619</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.398163</td>\n",
       "      <td>0.727167</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.494868</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4395</td>\n",
       "      <td>77766</td>\n",
       "      <td>6652</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.908459</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>0.729824</td>\n",
       "      <td>0.514969</td>\n",
       "      <td>0.495647</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4931</td>\n",
       "      <td>79390</td>\n",
       "      <td>5028</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.49513</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.604686</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5328</td>\n",
       "      <td>46466</td>\n",
       "      <td>37952</td>\n",
       "      <td>694</td>\n",
       "      <td>0.572689</td>\n",
       "      <td>0.123105</td>\n",
       "      <td>0.884756</td>\n",
       "      <td>0.216137</td>\n",
       "      <td>0.217185</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                                \n",
       "max_u_regressor_sparse    lr     3151  297203    5344  1798         0.973939   \n",
       "                          gb     3410  299857    2690  1539          0.98396   \n",
       "                          xgb    4550  292244   10303   399         0.960463   \n",
       "                          svr    4615  275913   26634   334         0.904389   \n",
       "                          mlp    4948  217055   85492     1         0.562262   \n",
       "max_u_regressor_focused   lr     4321  297379    5168   628         0.977467   \n",
       "                          gb     4523  249361   53186   426          0.79822   \n",
       "                          xgb    4660  179741  122806   289         0.554576   \n",
       "                          svr    4940  249296   53251     9         0.808736   \n",
       "                          mlp    3713  204413   98134  1236         0.635806   \n",
       "max_u_filtered_regressor  lr     3151   89191    5344  1798         0.918805   \n",
       "                          gb     3356   91872    2663  1593         0.949925   \n",
       "                          xgb    4949     128   94407     0         0.037666   \n",
       "                          svr    4443   46628   47907   506         0.481777   \n",
       "                          mlp    4949     549   93986     0         0.010538   \n",
       "max_u_regressor_balanced  lr     4521  280815   21732   428         0.917912   \n",
       "                          gb     4090  297475    5072   859         0.977647   \n",
       "                          xgb    4448  293409    9138   501         0.963717   \n",
       "                          svr    4222  287934   14613   727         0.944365   \n",
       "                          mlp    4948  213184   89363     1         0.545878   \n",
       "max_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     2487   92303    2232  2462         0.952817   \n",
       "                          xgb    1817   93214    1321  3132         0.955239   \n",
       "                          svr       0   94535       0  4949         0.950253   \n",
       "                          mlp    3902   58964   35571  1047         0.631921   \n",
       "max_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     3499   91026    3509  1450         0.950153   \n",
       "                          xgb    3158   92054    2481  1791         0.957058   \n",
       "                          svr    3956   89928    4607   993          0.94371   \n",
       "                          mlp    4041   58329   36206   908         0.626935   \n",
       "min_u_regressor_sparse    lr     2553  297508    3966  3469         0.972468   \n",
       "                          gb     5039  294582    6892   983         0.970974   \n",
       "                          xgb    4781  294780    6694  1241         0.970684   \n",
       "                          svr    5502  281219   20255   520         0.925053   \n",
       "                          mlp    6014  232123   69351     8         0.629952   \n",
       "min_u_regressor_focused   lr     5877  244952   56522   145         0.780846   \n",
       "                          gb     5592  259564   41910   430         0.839482   \n",
       "                          xgb    5628  252109   49365   394         0.808055   \n",
       "                          svr    5975  253411   48063    47         0.822388   \n",
       "                          mlp    4106  222759   78715  1916         0.702687   \n",
       "min_u_filtered_regressor  lr     2553   80452    3966  3469         0.905889   \n",
       "                          gb     4993   77816    6602  1029         0.903749   \n",
       "                          xgb    4936   78434    5984  1086         0.911141   \n",
       "                          svr    5369   66433   17985   653         0.770305   \n",
       "                          mlp    4709   31253   35197  1193         0.181759   \n",
       "min_u_regressor_balanced  lr     5117  282366   19108   905         0.926901   \n",
       "                          gb     4997  292064    9410  1025         0.961439   \n",
       "                          xgb    5316  289858   11616   706         0.954371   \n",
       "                          svr    5366  283756   17718   656         0.933244   \n",
       "                          mlp    6015  226077   75397     7         0.601244   \n",
       "min_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4068   81151    3267  1954         0.942271   \n",
       "                          xgb    4167   80534    3884  1855         0.936544   \n",
       "                          svr    2965   82965    1453  3057         0.950133   \n",
       "                          mlp    5320   50125   34293   702         0.613058   \n",
       "min_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4379   77799    6619  1643         0.908647   \n",
       "                          xgb    4395   77766    6652  1627         0.908459   \n",
       "                          svr    4931   79390    5028  1091         0.932342   \n",
       "                          mlp    5328   46466   37952   694         0.572689   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_regressor_sparse    lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.441493       0.567722   0.496713   \n",
       "                          xgb            0.230752       0.882031   0.365804   \n",
       "                          svr            0.107401       0.898987   0.191878   \n",
       "                          mlp            0.008497       0.999275    0.01685   \n",
       "max_u_regressor_focused   lr             0.366413       0.822844   0.507041   \n",
       "                          gb             0.053925       0.878914   0.101616   \n",
       "                          xgb            0.025552       0.919546   0.049723   \n",
       "                          svr            0.063073       0.997519   0.118643   \n",
       "                          mlp            0.023876       0.631136   0.046011   \n",
       "max_u_filtered_regressor  lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.439197       0.552025    0.48919   \n",
       "                          xgb            0.036546            1.0   0.070515   \n",
       "                          svr            0.060259       0.842986   0.112478   \n",
       "                          mlp            0.007693            1.0   0.015269   \n",
       "max_u_regressor_balanced  lr                0.126       0.877757   0.220366   \n",
       "                          gb              0.35234       0.759724   0.481414   \n",
       "                          xgb             0.25097       0.857354   0.388281   \n",
       "                          svr            0.174752       0.798145   0.286726   \n",
       "                          mlp            0.008087       0.999274   0.016044   \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.527018       0.502526   0.514481   \n",
       "                          xgb            0.579031       0.367145   0.449363   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.098852       0.788442   0.175679   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.499287       0.707012   0.585264   \n",
       "                          xgb            0.560028       0.638109   0.596524   \n",
       "                          svr            0.461988       0.799353   0.585554   \n",
       "                          mlp            0.100405       0.816529   0.178821   \n",
       "min_u_regressor_sparse    lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.353983       0.787945   0.488506   \n",
       "                          xgb            0.345599       0.731315   0.469381   \n",
       "                          svr            0.174263       0.890969    0.29151   \n",
       "                          mlp            0.009394       0.993227   0.018612   \n",
       "min_u_regressor_focused   lr             0.067654       0.968548   0.126474   \n",
       "                          gb             0.088325       0.908282   0.160995   \n",
       "                          xgb            0.073954        0.91519   0.136849   \n",
       "                          svr            0.085393       0.990249   0.157228   \n",
       "                          mlp            0.035524       0.585727   0.066985   \n",
       "min_u_filtered_regressor  lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.360775       0.778289   0.493014   \n",
       "                          xgb            0.382714        0.76811    0.51088   \n",
       "                          svr            0.186868       0.861772   0.307136   \n",
       "                          mlp            0.015308       0.393679    0.02947   \n",
       "min_u_regressor_balanced  lr             0.165926       0.804743   0.275126   \n",
       "                          gb             0.284526        0.77814    0.41669   \n",
       "                          xgb            0.255966       0.846198   0.393042   \n",
       "                          svr            0.194107         0.8676   0.317238   \n",
       "                          mlp            0.008336       0.993896   0.016534   \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.554601       0.675523   0.609119   \n",
       "                          xgb            0.517575       0.691963   0.592198   \n",
       "                          svr            0.671118       0.492361   0.568008   \n",
       "                          mlp            0.134299       0.883427   0.233154   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.398163       0.727167   0.514571   \n",
       "                          xgb            0.397846       0.729824   0.514969   \n",
       "                          svr             0.49513       0.818831   0.617108   \n",
       "                          mlp            0.123105       0.884756   0.216137   \n",
       "\n",
       "                                 (hybrid)mcc         q   f1_coin  \n",
       "experiment                class                                   \n",
       "max_u_regressor_sparse    lr        0.346102  0.016095  0.031679  \n",
       "                          gb        0.492687  0.016095  0.031679  \n",
       "                          xgb       0.439649  0.016095  0.031679  \n",
       "                          svr       0.291796  0.016095  0.031679  \n",
       "                          mlp       0.068953  0.016095  0.031679  \n",
       "max_u_regressor_focused   lr        0.540358  0.016095  0.031679  \n",
       "                          gb        0.187375  0.016095  0.031679  \n",
       "                          xgb       0.105429  0.016095  0.031679  \n",
       "                          svr       0.225088  0.016095  0.031679  \n",
       "                          mlp       0.064861  0.016095  0.031679  \n",
       "max_u_filtered_regressor  lr        0.318793  0.049747  0.094778  \n",
       "                          gb        0.466570  0.049747  0.094778  \n",
       "                          xgb       0.006640  0.049747  0.094778  \n",
       "                          svr       0.120496  0.049747  0.094778  \n",
       "                          mlp       0.004715  0.049747  0.094778  \n",
       "max_u_regressor_balanced  lr        0.314492  0.016095  0.031679  \n",
       "                          gb        0.508297  0.016095  0.031679  \n",
       "                          xgb       0.452522  0.016095  0.031679  \n",
       "                          svr       0.357587  0.016095  0.031679  \n",
       "                          mlp       0.066274  0.016095  0.031679  \n",
       "max_u_classifier          lr             NaN       NaN       NaN  \n",
       "                          gb        0.489852  0.049747  0.094778  \n",
       "                          xgb       0.439336  0.049747  0.094778  \n",
       "                          svr      -1.000000  0.049747  0.094778  \n",
       "                          mlp       0.183174  0.049747  0.094778  \n",
       "max_u_classifier_balanced lr             NaN       NaN       NaN  \n",
       "                          gb        0.569179  0.049747  0.094778  \n",
       "                          xgb       0.575312  0.049747  0.094778  \n",
       "                          svr       0.581876  0.049747  0.094778  \n",
       "                          mlp       0.192052  0.049747  0.094778  \n",
       "min_u_regressor_sparse    lr        0.297390  0.019584  0.038416  \n",
       "                          gb        0.516571  0.019584  0.038416  \n",
       "                          xgb       0.490517  0.019584  0.038416  \n",
       "                          svr       0.374989  0.019584  0.038416  \n",
       "                          mlp       0.076279  0.019584  0.038416  \n",
       "min_u_regressor_focused   lr        0.223576  0.019584  0.038416  \n",
       "                          gb        0.254038  0.019584  0.038416  \n",
       "                          xgb       0.228193  0.019584  0.038416  \n",
       "                          svr       0.262651  0.019584  0.038416  \n",
       "                          mlp       0.084777  0.019584  0.038416  \n",
       "min_u_filtered_regressor  lr        0.260936  0.066586  0.124857  \n",
       "                          gb        0.488250  0.066586  0.124857  \n",
       "                          xgb       0.502496  0.066586  0.124857  \n",
       "                          svr       0.331681  0.066586  0.124857  \n",
       "                          mlp      -0.192864  0.081573  0.150842  \n",
       "min_u_regressor_balanced  lr        0.345050  0.019584  0.038416  \n",
       "                          gb        0.456403  0.019584  0.038416  \n",
       "                          xgb       0.450693  0.019584  0.038416  \n",
       "                          svr       0.391941  0.019584  0.038416  \n",
       "                          mlp       0.070213  0.019584  0.038416  \n",
       "min_u_classifier          lr             NaN       NaN       NaN  \n",
       "                          gb        0.581558  0.066586  0.124857  \n",
       "                          xgb       0.565496  0.066586  0.124857  \n",
       "                          svr       0.549541  0.066586  0.124857  \n",
       "                          mlp       0.239785  0.066586  0.124857  \n",
       "min_u_classifier_balanced lr             NaN       NaN       NaN  \n",
       "                          gb        0.494868  0.066586  0.124857  \n",
       "                          xgb       0.495647  0.066586  0.124857  \n",
       "                          svr       0.604686  0.066586  0.124857  \n",
       "                          mlp       0.217185  0.066586  0.124857  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['q'] =  (df['tp'] + df['fn']) / (df['fp'] + df['tn'] + df['tp'] + df['fn'])\n",
    "df['f1_coin'] = (2*df['q'])/(df['q']+1)\n",
    "# write df to csv in this directory, with the name dataset_benchmark.csv\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5328"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[('min_u_classifier_balanced', 'mlp'), 'tp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: max_u_regressor_sparse, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  1432\n",
      "true_negatives_ctr:  0\n",
      "false_positives_ctr:  16656\n",
      "false_negatives_ctr:  0\n",
      "0\n",
      "hybrid_metrics.true_positives_ctr:  1432\n",
      "hybrid_metrics.true_negatives_ctr:  0\n",
      "hybrid_metrics.false_positives_ctr:  16656\n",
      "hybrid_metrics.false_negatives_ctr:  0\n",
      "\n",
      "\n",
      "hybrid_true_positives_rmse 483.64282925858015\n",
      "hybrid_true_negatives_rmse 0\n",
      "hybrid_false_positives_rmse 33308.75967554767\n",
      "hybrid_false_negatives_rmse 0\n",
      "\n",
      "\n",
      "true_positives_rmse 0.6622605940931703\n",
      "true_negatives_rmse 0\n",
      "false_positives_rmse 0.9998054560247163\n",
      "false_negatives_rmse 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Metrics' object has no attribute 'hybrid_accuracy_rmse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\jupyter_notebooks\\datasets_benchmark.ipynb Cell 77\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfalse_negatives_rmse\u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39mfalse_negatives_rmse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhybrid_metrics.hybrid_accuracy_rmse: \u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39;49mhybrid_accuracy_rmse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhybrid_metrics.hybrid_precision_rmse: \u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39mhybrid_precision_rmse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhybrid_metrics.hybrid_recall_rmse: \u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39mhybrid_recall_rmse)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Metrics' object has no attribute 'hybrid_accuracy_rmse'"
     ]
    }
   ],
   "source": [
    "threshold = _threshold(experiment)\n",
    "experiment = 'max_u_regressor_sparse'\n",
    "model = 'mlp' \n",
    "threshold = _threshold(experiment)\n",
    "print('Experiment: {}, model: {}, threshold: {}'.format(experiment, model, threshold))\n",
    "hybrid_metrics = metrics.Metrics()\n",
    "hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted'][['bus_15', 'bus_16']], testing_data[experiment][model]['real'][['bus_15', 'bus_16']], threshold=threshold)\n",
    "print('hybrid_metrics.true_positives_ctr: ', hybrid_metrics.true_positives_ctr)\n",
    "print('hybrid_metrics.true_negatives_ctr: ', hybrid_metrics.true_negatives_ctr)\n",
    "print('hybrid_metrics.false_positives_ctr: ', hybrid_metrics.false_positives_ctr)\n",
    "print('hybrid_metrics.false_negatives_ctr: ', hybrid_metrics.false_negatives_ctr)\n",
    "print('\\n')\n",
    "print('hybrid_true_positives_rmse', hybrid_metrics.hybrid_true_positives_rmse)\n",
    "print('hybrid_true_negatives_rmse', hybrid_metrics.hybrid_true_negatives_rmse)\n",
    "print('hybrid_false_positives_rmse', hybrid_metrics.hybrid_false_positives_rmse)\n",
    "print('hybrid_false_negatives_rmse', hybrid_metrics.hybrid_false_negatives_rmse)\n",
    "print('\\n')\n",
    "print('true_positives_rmse', hybrid_metrics.true_positives_rmse)\n",
    "print('true_negatives_rmse', hybrid_metrics.true_negatives_rmse)\n",
    "print('false_positives_rmse', hybrid_metrics.false_positives_rmse)\n",
    "print('false_negatives_rmse', hybrid_metrics.false_negatives_rmse)\n",
    "print('\\n')\n",
    "print('hybrid_metrics.hybrid_accuracy_rmse: ', hybrid_metrics.hybrid_accuracy_rmse)\n",
    "print('hybrid_metrics.hybrid_precision_rmse: ', hybrid_metrics.hybrid_precision_rmse)\n",
    "print('hybrid_metrics.hybrid_recall_rmse: ', hybrid_metrics.hybrid_recall_rmse)\n",
    "print('hybrid_metrics.hybrid_f1_rmse: ', hybrid_metrics.hybrid_f1_rmse)\n",
    "print('hybrid_metrics.hybrid_mcc_rmse: ', hybrid_metrics.hybrid_mcc_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure size of the plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 10))\n",
    "testing_data['max_u_classifier']['mlp']['predicted']['bus_16'].plot()\n",
    "#testing_data['max_u_classifier']['mlp']['real']['bus_16'].plot()\n",
    "\n",
    "# plot a line with the threshold\n",
    "_threshold = lambda experiment: max_u_threshold / data_max_u_balanced['scaler']['y'] if 'max_u' in experiment else min_u_threshold/ data_min_u_balanced['scaler']['y']\n",
    "threshold = _threshold('max_u_regressor_sparse')\n",
    "plt.axhline(y=threshold, color='r', linestyle='-')\n",
    "# Add legend\n",
    "plt.legend(['predicted', 'real', 'threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data['max_u_regressor_sparse']['mlp']['predicted'].apply(lambda x: x.apply(lambda y: min(1.0, max(0.0, y))))['bus_1'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data['max_u_classifier']['mlp']['predicted'].astype('float64')['bus_16'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn df to numpy array\n",
    "testing_data['max_u_classifier']['gb']['predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment: min_u_classifier, model: gb, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier, model: xgb, max: 1, min: 0\n",
      "experiment: min_u_classifier, model: svr, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier_balanced, model: gb, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier_balanced, model: xgb, max: 1, min: 0\n",
      "experiment: min_u_classifier_balanced, model: svr, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier_balanced, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: lr, max: 0.13619870924844507, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: gb, max: 0.3810799686594865, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: xgb, max: 0.3127909302711487, min: 0.024557016789913177\n",
      "experiment: max_u_regressor_sparse, model: svr, max: 0.4946822431673944, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: lr, max: 0.6501631250830311, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: gb, max: 0.42120136723128043, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: xgb, max: 0.42610928416252136, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: svr, max: 0.46197486433850854, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: mlp, max: 0.577883243560791, min: 0.0\n",
      "experiment: max_u_filtered_regressor, model: lr, max: 0.12660268004533026, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: lr, max: 0.4010267617457135, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: gb, max: 0.7517199729659615, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: xgb, max: 0.5393862724304199, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: svr, max: 0.787608227817534, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: lr, max: 0.5855579684553072, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: gb, max: 0.5932988934689641, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: xgb, max: 0.5121873617172241, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: svr, max: 0.6045885499738398, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: mlp, max: 0.34603604674339294, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: lr, max: 0.34171831351797666, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: gb, max: 0.5165846932947002, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: xgb, max: 0.4210992753505707, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: svr, max: 0.6300204477633999, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: mlp, max: 1.0, min: 0.0\n"
     ]
    }
   ],
   "source": [
    "classifier_experiments =[experiment for experiment in testing_data.keys() if 'classifier' in experiment.split('_')] # TODO confirm this\n",
    "regressor_experiments = [experiment for experiment in testing_data.keys() if 'regressor' in experiment.split('_')]\n",
    "# Classifier experiments\n",
    "for experiment in classifier_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        try:\n",
    "            print('experiment: {}, model: {}, max: {}, min: {}'.format(experiment, model, testing_data[experiment][model]['predicted'].max().max(), testing_data[experiment][model]['predicted'].min().min()))\n",
    "        except:\n",
    "            print('experiment {} model {} failed'.format(experiment, model))\n",
    "for experiment in regressor_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        try:\n",
    "            print('experiment: {}, model: {}, max: {}, min: {}'.format(experiment, model, testing_data[experiment][model]['predicted'].max().max(), testing_data[experiment][model]['predicted'].min().min()))\n",
    "        except:\n",
    "            print('experiment {} model {} failed'.format(experiment, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "7\n",
      "8\n",
      "6\n",
      "3\n",
      "8\n",
      "7\n",
      "8\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from numpy import random\n",
    "from beepy import beep\n",
    "from time import sleep\n",
    "for i in range(10):\n",
    "    # generate random int between 0 and 10\n",
    "    value = random.randint(0, 10)\n",
    "    # make program wait for value seconds\n",
    "    print(value)\n",
    "    sleep(value)\n",
    "    beep(value)\n",
    "    sleep(3)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "beep(9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe4baa4d27e3b73db55d4bb4674105e8dd41faaf9e559c3cc8381041ce15293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
