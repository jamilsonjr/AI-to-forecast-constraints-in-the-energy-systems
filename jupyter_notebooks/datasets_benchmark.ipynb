{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of this Article** \n",
    "- Loading best hyperparameters for each model\n",
    "- Model training\n",
    "- Results discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best hyperparameters for each model\n",
    "\n",
    "As explained in another notebook, the hyperparameters for each model were tunnned using the Optuna library. For each dataset and model, the hyperparameters have different values. The values for each hyperparameters are seen bellow.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hyperparameters dataset.\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse hyper params:\n",
      "\n",
      "params_gradient_boost_regression_sparse_max_u.csv :\n",
      "            params                  value\n",
      "0   n_estimators                    544\n",
      "1  learning_rate    0.36423151911958196\n",
      "2           loss          squared_error\n",
      "3          value  0.0064745090355284845\n",
      "params_gradient_boost_regression_sparse_min_u.csv :\n",
      "            params               value\n",
      "0   n_estimators                  22\n",
      "1  learning_rate  0.8296843568407096\n",
      "2           loss      absolute_error\n",
      "3          value                 0.0\n",
      "params_support_vector_regression_sparse_max_u.csv :\n",
      "     params                   value\n",
      "0  kernel                    poly\n",
      "1       C  0.00018807624871896921\n",
      "2  degree                       5\n",
      "3   gamma      0.8511446423066539\n",
      "4   value      0.4008346176510517\n",
      "params_support_vector_regression_sparse_min_u.csv :\n",
      "     params                   value\n",
      "0  kernel                    poly\n",
      "1       C  3.4084813417139984e-06\n",
      "2  degree                       2\n",
      "3   gamma  7.5582957595600045e-06\n",
      "4   value      0.2592248866377364\n",
      "params_xgboost_regression_sparse_max_u.csv :\n",
      "               params                  value\n",
      "0           booster               gblinear\n",
      "1            lambda  4.195122525977499e-07\n",
      "2             alpha     0.1001382333795902\n",
      "3         subsample     0.9941075848643193\n",
      "4  colsample_bytree     0.7713666161545742\n",
      "5             value                    0.0\n",
      "params_xgboost_regression_sparse_min_u.csv :\n",
      "               params                value\n",
      "0           booster             gblinear\n",
      "1            lambda  0.05222241453451214\n",
      "2             alpha   0.4796424371172093\n",
      "3         subsample   0.8991281740894908\n",
      "4  colsample_bytree   0.9143759295062182\n",
      "5             value                  0.0\n",
      "Focused hyper params:\n",
      "\n",
      "params_gradient_boost_regression_focused_max_u.csv :\n",
      "           params                 value\n",
      "0   n_estimators                    25\n",
      "1  learning_rate    0.2724645522088135\n",
      "2           loss         squared_error\n",
      "3          value  0.004506710347566452\n",
      "params_gradient_boost_regression_focused_min_u.csv :\n",
      "           params                value\n",
      "0   n_estimators                   74\n",
      "1  learning_rate   0.8511834961992796\n",
      "2           loss        squared_error\n",
      "3          value  0.00514602580023137\n",
      "params_support_vector_regression_focused_max_u.csv :\n",
      "    params                 value\n",
      "0  kernel                  poly\n",
      "1       C  0.005584880493571942\n",
      "2  degree                     2\n",
      "3   gamma    0.8532257247043119\n",
      "4   value    0.2999199774846511\n",
      "params_support_vector_regression_focused_min_u.csv :\n",
      "    params                value\n",
      "0  kernel                  rbf\n",
      "1       C  0.23459004141044545\n",
      "2  degree                    5\n",
      "3   gamma   0.9827535390703468\n",
      "4   value  0.19794213653821938\n",
      "params_xgboost_regression_focused_max_u.csv :\n",
      "               params                   value\n",
      "0            booster                  gbtree\n",
      "1             lambda   4.288055780512365e-06\n",
      "2              alpha  7.5629056802818344e-06\n",
      "3          subsample       0.923150683853891\n",
      "4   colsample_bytree     0.29590462079459834\n",
      "5          max_depth                       9\n",
      "6   min_child_weight                       7\n",
      "7                eta     0.04974261878678785\n",
      "8              gamma  2.4006274373913765e-06\n",
      "9        grow_policy               lossguide\n",
      "10             value    0.004746721767657069\n",
      "params_xgboost_regression_focused_min_u.csv :\n",
      "               params                   value\n",
      "0            booster                  gbtree\n",
      "1             lambda   0.0022873748876265547\n",
      "2              alpha  4.7080182859143866e-07\n",
      "3          subsample      0.8208513399117434\n",
      "4   colsample_bytree      0.3880421550437328\n",
      "5          max_depth                       7\n",
      "6   min_child_weight                       6\n",
      "7                eta     0.04780943557478916\n",
      "8              gamma   0.0032619783528789396\n",
      "9        grow_policy               depthwise\n",
      "10             value   0.0047686450341566855\n",
      "Boolean hyper params:\n",
      "\n",
      "params_gradient_boost_classifier_max_u.csv :\n",
      "           params              value\n",
      "0   n_estimators                 38\n",
      "1  learning_rate  0.466137255116544\n",
      "2           loss        exponential\n",
      "3          value  0.622128598655833\n",
      "params_gradient_boost_classifier_min_u.csv :\n",
      "           params                value\n",
      "0   n_estimators                  991\n",
      "1  learning_rate  0.30604705738285287\n",
      "2           loss          exponential\n",
      "3          value   0.6332760671336064\n",
      "params_support_vector_classifier_max_u.csv :\n",
      "    params               value\n",
      "0  kernel                poly\n",
      "1       C  0.5283498165839644\n",
      "2  degree                   4\n",
      "3   gamma  0.9996926592406632\n",
      "4   value   0.368779841709756\n",
      "params_support_vector_classifier_min_u.csv :\n",
      "    params                value\n",
      "0  kernel                 poly\n",
      "1       C  0.18387180132926847\n",
      "2  degree                    5\n",
      "3   gamma   0.9548296680596685\n",
      "4   value   0.3742098077264465\n",
      "params_xgboost_classifier_max_u.csv :\n",
      "           params                value\n",
      "0           loss          exponential\n",
      "1  learning_rate  0.08363472795701299\n",
      "2   n_estimators                   80\n",
      "3      subsample   0.3056030047028318\n",
      "4      max_depth                    5\n",
      "5          value    0.415922217007392\n",
      "params_xgboost_classifier_min_u.csv :\n",
      "           params                value\n",
      "0           loss             deviance\n",
      "1  learning_rate   0.6311975807171595\n",
      "2   n_estimators                   81\n",
      "3      subsample    0.981589184229811\n",
      "4      max_depth                   10\n",
      "5          value  0.45011534919770996\n"
     ]
    }
   ],
   "source": [
    "sparse_hyper_params = {}\n",
    "focused_hyper_params = {}\n",
    "boolean_hyper_params = {}\n",
    "for file in os.listdir('hyper_params_results'):\n",
    "    if file.endswith('.csv') and 'sparse' in file.split('_') and 'classifier' not in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'focused' in file.split('_') and 'classifier' not in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        focused_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        boolean_hyper_params[file] = df\n",
    "print('Sparse hyper params:\\n')\n",
    "for key in sparse_hyper_params.keys():\n",
    "    print(key, ':\\n ',sparse_hyper_params[key])\n",
    "print('Focused hyper params:\\n')\n",
    "for key in focused_hyper_params.keys():\n",
    "    print(key, ':\\n',focused_hyper_params[key])\n",
    "print('Boolean hyper params:\\n')\n",
    "for key in boolean_hyper_params.keys():\n",
    "    print(key, ':\\n',boolean_hyper_params[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 544,\n",
       " 'learning_rate': 0.36423151911958196,\n",
       " 'loss': 'squared_error'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "def get_hyper_params_from_df(df):\n",
    "    output = {}\n",
    "    for row in df.iterrows():\n",
    "        if row[1]['params'] != 'value':\n",
    "            try:\n",
    "                output[row[1]['params']] = ast.literal_eval(row[1]['value'])\n",
    "            except :\n",
    "                output[row[1]['params']] = row[1]['value']\n",
    "    return output\n",
    "get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_max_u.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from thesis_package import aimodels as my_ai, utils, metrics\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression data sparse\n",
    "y_max_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv').drop(columns=['timestamps'])\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_max_u_sparse)\n",
    "data_max_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_max_u_sparse, scaling=True)\n",
    "data_max_u_scaled_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_min_u_sparse)\n",
    "data_min_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_min_u_sparse, scaling=True)\n",
    "data_min_u_scaled_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data focused\n",
    "y_max_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_bal_constr.csv')\n",
    "exogenous_data_focused_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_bal.csv').drop(columns=['date'])\n",
    "y_min_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_bal_constr.csv')\n",
    "exogenous_data_focused_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_bal.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data_focused_max_u, y_max_u_focused)\n",
    "data_max_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data_focused_max_u, y_max_u_focused, scaling=True)\n",
    "data_max_u_scaled_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data_focused_min_u, y_min_u_focused)\n",
    "data_min_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data_focused_min_u, y_min_u_focused, scaling=True)\n",
    "data_min_u_scaled_focused = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data\n",
    "y_max_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_max_u = y_max_u[utils.cols_with_positive_values(y_max_u)]\n",
    "y_min_u = y_min_u[utils.cols_with_positive_values(y_min_u)]\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_max_u)\n",
    "data_max_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_max_u, scaling=True)\n",
    "data_max_u_bool_scaled = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_min_u)\n",
    "data_min_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_min_u, scaling=True)\n",
    "data_min_u_bool_scaled = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "In this section the models will be trained with the hyperparameters loaded above. All the models will be stored in the same `Context` object for later evaluation. The `Context` object is a class that stores all the models and their respective hyperparameters. The `Context` object is defined in the `aimodels.py` file. The `Context` object is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params_gradient_boost_regression_sparse_max_u.csv', 'params_gradient_boost_regression_sparse_min_u.csv', 'params_support_vector_regression_sparse_max_u.csv', 'params_support_vector_regression_sparse_min_u.csv', 'params_xgboost_regression_sparse_max_u.csv', 'params_xgboost_regression_sparse_min_u.csv'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_hyper_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression sparse\n"
     ]
    }
   ],
   "source": [
    "# max_u regression sparse\n",
    "if 'max_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_max_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_max_u.csv']) \n",
    "    regressor_max_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_scaled_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse', regressor_max_u)\n",
    "else:\n",
    "    print('Loading max_u regression sparse') \n",
    "    regressor_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse')\n",
    "models = ['lr', 'gb', 'xgb', 'svr']\n",
    "testing_data = {'max_u_regressor_sparse': {}}\n",
    "for model, strategy in zip(models, regressor_max_u.strategies):\n",
    "    if model != 'svr':\n",
    "        prediction = strategy.predict(data=data_max_u_sparse)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_max_u_sparse['y_test'].columns)\n",
    "        testing_data['max_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['max_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['max_u_regressor_sparse'][model]['real'] = deepcopy(data_max_u_sparse['y_test'])\n",
    "    else:\n",
    "        prediction = strategy.predict(data=data_max_u_scaled_sparse)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_max_u_scaled_sparse['y_test'].columns)\n",
    "        testing_data['max_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['max_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['max_u_regressor_sparse'][model]['real'] = deepcopy(data_max_u_scaled_sparse['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression focused\n"
     ]
    }
   ],
   "source": [
    "# max_u regression focused\n",
    "if 'max_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_max_u.csv']) \n",
    "    regressor_max_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_scaled_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_focused', regressor_max_u_focused)\n",
    "else: \n",
    "    print('Loading max_u regression focused')\n",
    "    regressor_max_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\\\max_u_regressor_focused')\n",
    "\n",
    "models = ['lr', 'gb', 'xgb', 'svr']\n",
    "testing_data['max_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(models, regressor_max_u_focused.strategies):\n",
    "    if model != 'svr':\n",
    "        prediction = strategy.predict(data=data_max_u_focused)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_max_u_focused['y_test'].columns)\n",
    "        testing_data['max_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['max_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['max_u_regressor_focused'][model]['real'] = deepcopy(data_max_u_focused['y_test'])\n",
    "    else:\n",
    "        prediction = strategy.predict(data=data_max_u_scaled_focused)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_max_u_scaled_focused['y_test'].columns)\n",
    "        testing_data['max_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['max_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['max_u_regressor_focused'][model]['real'] = deepcopy(data_max_u_scaled_focused['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u classification\n"
     ]
    }
   ],
   "source": [
    "# max_u classification\n",
    "if 'max_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_gradient_boost_classifier_max_u.csv'])\n",
    "    classifier_max_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_xgboost_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_support_vector_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool_scaled)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier', classifier_max_u)\n",
    "else: \n",
    "    print('Loading max_u classification')\n",
    "    classifier_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier')\n",
    "models = ['gb', 'xgb', 'svr']\n",
    "testing_data['max_u_classifier'] = {}\n",
    "for model, strategy in zip(models, classifier_max_u.strategies):\n",
    "    if model != 'svr':\n",
    "        prediction = strategy.predict(data=data_max_u_bool)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_max_u_bool['y_test'].columns)\n",
    "        testing_data['max_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['max_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['max_u_classifier'][model]['real'] = deepcopy(data_max_u_bool['y_test'])\n",
    "    else:\n",
    "        prediction = strategy.predict(data=data_max_u_bool_scaled)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_max_u_bool_scaled['y_test'].columns)\n",
    "        testing_data['max_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['max_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['max_u_classifier'][model]['real'] = deepcopy(data_max_u_bool_scaled['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min u regression training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression sparse\n"
     ]
    }
   ],
   "source": [
    "# min_u regression sparse\n",
    "if 'min_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_min_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_scaled_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse', regressor_min_u)\n",
    "else:\n",
    "    print('Loading min_u regression sparse')\n",
    "    regressor_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse')\n",
    "    \n",
    "models = ['lr', 'gb', 'xgb', 'svr']\n",
    "testing_data['min_u_regressor_sparse'] = {}\n",
    "for model, strategy in zip(models, regressor_min_u.strategies):\n",
    "    if model != 'svr':\n",
    "        prediction = strategy.predict(data=data_min_u_sparse)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_min_u_sparse['y_test'].columns)\n",
    "        testing_data['min_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['min_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['min_u_regressor_sparse'][model]['real'] = deepcopy(data_min_u_sparse['y_test'])\n",
    "    else:\n",
    "        prediction = strategy.predict(data=data_min_u_scaled_sparse)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_min_u_scaled_sparse['y_test'].columns)\n",
    "        testing_data['min_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['min_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['min_u_regressor_sparse'][model]['real'] = deepcopy(data_min_u_scaled_sparse['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression focused\n"
     ]
    }
   ],
   "source": [
    "# min_u regression focused\n",
    "if 'min_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_scaled_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused', regressor_min_u_focused)\n",
    "else:\n",
    "    print('Loading min_u regression focused')\n",
    "    regressor_min_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused')\n",
    "models = ['lr', 'gb', 'xgb', 'svr']\n",
    "testing_data['min_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(models, regressor_min_u_focused.strategies):\n",
    "    if model != 'svr':\n",
    "        prediction = strategy.predict(data=data_min_u_focused)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_min_u_focused['y_test'].columns)\n",
    "        testing_data['min_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['min_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['min_u_regressor_focused'][model]['real'] = deepcopy(data_min_u_focused['y_test'])\n",
    "    else:\n",
    "        prediction = strategy.predict(data=data_min_u_scaled_focused)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_min_u_scaled_focused['y_test'].columns)\n",
    "        testing_data['min_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['min_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['min_u_regressor_focused'][model]['real'] = deepcopy(data_min_u_scaled_focused['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u classification\n"
     ]
    }
   ],
   "source": [
    "# min_u classification\n",
    "if 'min_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_gradient_boost_classifier_max_u.csv'])\n",
    "    classifier_min_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_xgboost_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_support_vector_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool_scaled)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier', classifier_min_u)\n",
    "else: \n",
    "    print('Loading min_u classification')\n",
    "    classifier_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier')\n",
    "models = ['gb', 'xgb', 'svr']\n",
    "testing_data['min_u_classifier'] = {}\n",
    "for model, strategy in zip(models, classifier_min_u.strategies):\n",
    "    if model != 'svr':\n",
    "        prediction = strategy.predict(data=data_min_u_bool)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_min_u_bool['y_test'].columns)\n",
    "        testing_data['min_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['min_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['min_u_classifier'][model]['real'] = deepcopy(data_min_u_bool['y_test'])\n",
    "    else:\n",
    "        prediction = strategy.predict(data=data_min_u_bool_scaled)\n",
    "        prediction = pd.DataFrame(prediction, columns=data_min_u_bool_scaled['y_test'].columns)\n",
    "        testing_data['min_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "        testing_data['min_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "        testing_data['min_u_classifier'][model]['real'] = deepcopy(data_min_u_bool_scaled['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Discussion\n",
    "In this section the results of the training and testing are presented and compared. The main objectives of this experience is to compare the performance of the regression models in terms of the hybrid metrics confusion matrix and the hybrid metrics rmse. The comparisons will be the following:\n",
    "- Compare the confusion matrices of the classification models and the regression models evaluate with the hybrid metrics.\n",
    "- Compare the error results of the regression models trained with the focused dataset and the sparse dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with bus:  bus_7\n"
     ]
    }
   ],
   "source": [
    "# Testing all models: Function that receives a dict with the real and predicted values, and outputs a dataframe with the results of the metrics.\n",
    "# Build confusion matrix with sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Accumulate all the classifications for each bus.\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for bus in testing_data['max_u_classifier']['gb']['predicted'].columns:\n",
    "    try:\n",
    "        _tp, _tn, _fp, _fn = confusion_matrix(testing_data['max_u_classifier']['gb']['real'][bus], testing_data['max_u_classifier']['gb']['predicted'][bus]).ravel()\n",
    "        tp += _tp; tn += _tn; fp += _fp; fn += _fn\n",
    "    except: \n",
    "        print('Problem with bus: ', bus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the experiment  max_u_classifier  and model  gb  there was a problem with bus:  bus_7\n",
      "Bus bus_7 has no positive data points. Just ignore the little shit.\n",
      "In the experiment  max_u_classifier  and model  xgb  there was a problem with bus:  bus_7\n",
      "Bus bus_7 has no positive data points. Just ignore the little shit.\n",
      "In the experiment  max_u_classifier  and model  svr  there was a problem with bus:  bus_7\n",
      "Bus bus_7 has no positive data points. Just ignore the little shit.\n"
     ]
    }
   ],
   "source": [
    "# Build a multi-index dataframe with the results of the metrics. The first index is the testing_data.keys(), the second index are the tp, tn, fp, fn, and the columns are the models.\n",
    "columns = ['tp', 'tn', 'fp', 'fn', 'accuracy', 'precision', 'recall', 'f1']\n",
    "index = pd.MultiIndex.from_product([testing_data.keys(), ['lr', 'gb', 'xgb', 'svr']], names=['experiment', 'class'])\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "classifier_experiments =[experiment for experiment in testing_data.keys() if 'classifier' in experiment.split('_')]\n",
    "regressor_experiments = [experiment for experiment in testing_data.keys() if 'regressor' in experiment.split('_')]\n",
    "# Classifier experiments\n",
    "for experiment in classifier_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        for bus in testing_data[experiment][model]['predicted'].columns:\n",
    "            try:\n",
    "                _tp, _tn, _fp, _fn = confusion_matrix(testing_data[experiment][model]['real'][bus], testing_data[experiment][model]['predicted'][bus]).ravel()\n",
    "                tp += _tp; tn += _tn; fp += _fp; fn += _fn\n",
    "            except: \n",
    "                print('In the experiment ', experiment, ' and model ', model, ' there was a problem with bus: ', bus)\n",
    "                if not testing_data[experiment][model]['real'][bus].any():\n",
    "                    print('Bus {} has no positive data points. Just ignore the little shit.'.format(bus))    \n",
    "        df.loc[(experiment, model), 'tp'] = tp\n",
    "        df.loc[(experiment, model), 'tn'] = tn\n",
    "        df.loc[(experiment, model), 'fp'] = fp\n",
    "        df.loc[(experiment, model), 'fn'] = fn\n",
    "        accuracy = (tp + tn ) / (tp + tn + fp + fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        df.loc[(experiment, model), 'accuracy'] = accuracy\n",
    "        df.loc[(experiment, model), 'precision'] = precision\n",
    "        df.loc[(experiment, model), 'recall'] = recall\n",
    "        df.loc[(experiment, model), 'f1'] = f1\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "# Regressor experiments.\n",
    "for experiment in regressor_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        test_data = testing_data[experiment][model]['real']\n",
    "        threshold = test_data.loc[:, test_data.max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "        hybrid_metrics = metrics.Metrics()\n",
    "        hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted'], testing_data[experiment][model]['real'], threshold=threshold)\n",
    "        df.loc[(experiment, model), 'tp'] = hybrid_metrics.true_positives_ctr\n",
    "        df.loc[(experiment, model), 'tn'] = hybrid_metrics.true_negatives_ctr\n",
    "        df.loc[(experiment, model), 'fp'] = hybrid_metrics.false_positives_ctr\n",
    "        df.loc[(experiment, model), 'fn'] = hybrid_metrics.false_negatives_ctr\n",
    "        df.loc[(experiment, model), 'accuracy'] = hybrid_metrics.accuracy\n",
    "        df.loc[(experiment, model), 'precision'] = hybrid_metrics.precision\n",
    "        df.loc[(experiment, model), 'recall'] = hybrid_metrics.recall\n",
    "        df.loc[(experiment, model), 'f1'] = hybrid_metrics.f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3339</td>\n",
       "      <td>295690</td>\n",
       "      <td>6770</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.972465</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.663026</td>\n",
       "      <td>0.440938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4038</td>\n",
       "      <td>298628</td>\n",
       "      <td>3832</td>\n",
       "      <td>998</td>\n",
       "      <td>0.984292</td>\n",
       "      <td>0.513088</td>\n",
       "      <td>0.801827</td>\n",
       "      <td>0.625755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>2632</td>\n",
       "      <td>121757</td>\n",
       "      <td>180703</td>\n",
       "      <td>2404</td>\n",
       "      <td>0.404522</td>\n",
       "      <td>0.014356</td>\n",
       "      <td>0.522637</td>\n",
       "      <td>0.027945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3153</td>\n",
       "      <td>300590</td>\n",
       "      <td>1992</td>\n",
       "      <td>1761</td>\n",
       "      <td>0.987795</td>\n",
       "      <td>0.612828</td>\n",
       "      <td>0.641636</td>\n",
       "      <td>0.626901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4937</td>\n",
       "      <td>19939</td>\n",
       "      <td>1569</td>\n",
       "      <td>75</td>\n",
       "      <td>0.938009</td>\n",
       "      <td>0.758838</td>\n",
       "      <td>0.985036</td>\n",
       "      <td>0.857267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4776</td>\n",
       "      <td>20369</td>\n",
       "      <td>1139</td>\n",
       "      <td>236</td>\n",
       "      <td>0.948152</td>\n",
       "      <td>0.807439</td>\n",
       "      <td>0.952913</td>\n",
       "      <td>0.874165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5012</td>\n",
       "      <td>0</td>\n",
       "      <td>21508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188989</td>\n",
       "      <td>0.188989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4142</td>\n",
       "      <td>20212</td>\n",
       "      <td>1411</td>\n",
       "      <td>755</td>\n",
       "      <td>0.918326</td>\n",
       "      <td>0.745903</td>\n",
       "      <td>0.845824</td>\n",
       "      <td>0.792727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>101661</td>\n",
       "      <td>1272</td>\n",
       "      <td>2494</td>\n",
       "      <td>3101</td>\n",
       "      <td>0.948446</td>\n",
       "      <td>0.976055</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.973219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>101837</td>\n",
       "      <td>1096</td>\n",
       "      <td>2633</td>\n",
       "      <td>2962</td>\n",
       "      <td>0.948446</td>\n",
       "      <td>0.974797</td>\n",
       "      <td>0.971736</td>\n",
       "      <td>0.973264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>101938</td>\n",
       "      <td>995</td>\n",
       "      <td>2848</td>\n",
       "      <td>2747</td>\n",
       "      <td>0.948446</td>\n",
       "      <td>0.972821</td>\n",
       "      <td>0.973759</td>\n",
       "      <td>0.97329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>1423</td>\n",
       "      <td>299915</td>\n",
       "      <td>1563</td>\n",
       "      <td>4595</td>\n",
       "      <td>0.979974</td>\n",
       "      <td>0.476557</td>\n",
       "      <td>0.236457</td>\n",
       "      <td>0.316082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0</td>\n",
       "      <td>301478</td>\n",
       "      <td>0</td>\n",
       "      <td>6018</td>\n",
       "      <td>0.980429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5934</td>\n",
       "      <td>62984</td>\n",
       "      <td>238494</td>\n",
       "      <td>84</td>\n",
       "      <td>0.224126</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.047387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5462</td>\n",
       "      <td>224118</td>\n",
       "      <td>77894</td>\n",
       "      <td>22</td>\n",
       "      <td>0.746611</td>\n",
       "      <td>0.065526</td>\n",
       "      <td>0.995988</td>\n",
       "      <td>0.122963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>6130</td>\n",
       "      <td>51991</td>\n",
       "      <td>2320</td>\n",
       "      <td>2323</td>\n",
       "      <td>0.926024</td>\n",
       "      <td>0.725444</td>\n",
       "      <td>0.725186</td>\n",
       "      <td>0.725315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6087</td>\n",
       "      <td>52657</td>\n",
       "      <td>1654</td>\n",
       "      <td>2366</td>\n",
       "      <td>0.935951</td>\n",
       "      <td>0.786333</td>\n",
       "      <td>0.720099</td>\n",
       "      <td>0.75176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>8453</td>\n",
       "      <td>0</td>\n",
       "      <td>54311</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134679</td>\n",
       "      <td>0.134679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.237387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6898</td>\n",
       "      <td>50914</td>\n",
       "      <td>4035</td>\n",
       "      <td>917</td>\n",
       "      <td>0.921101</td>\n",
       "      <td>0.630934</td>\n",
       "      <td>0.882662</td>\n",
       "      <td>0.735865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>89752</td>\n",
       "      <td>1457</td>\n",
       "      <td>4456</td>\n",
       "      <td>3819</td>\n",
       "      <td>0.916821</td>\n",
       "      <td>0.9527</td>\n",
       "      <td>0.959186</td>\n",
       "      <td>0.955932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>89320</td>\n",
       "      <td>1889</td>\n",
       "      <td>4146</td>\n",
       "      <td>4129</td>\n",
       "      <td>0.916821</td>\n",
       "      <td>0.955642</td>\n",
       "      <td>0.955815</td>\n",
       "      <td>0.955729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>85595</td>\n",
       "      <td>5614</td>\n",
       "      <td>1714</td>\n",
       "      <td>6561</td>\n",
       "      <td>0.916821</td>\n",
       "      <td>0.980369</td>\n",
       "      <td>0.928806</td>\n",
       "      <td>0.953891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp      tn      fp    fn  accuracy  \\\n",
       "experiment              class                                           \n",
       "max_u_regressor_sparse  lr       3339  295690    6770  1697  0.972465   \n",
       "                        gb       4038  298628    3832   998  0.984292   \n",
       "                        xgb      2632  121757  180703  2404  0.404522   \n",
       "                        svr      3153  300590    1992  1761  0.987795   \n",
       "max_u_regressor_focused lr       4937   19939    1569    75  0.938009   \n",
       "                        gb       4776   20369    1139   236  0.948152   \n",
       "                        xgb      5012       0   21508     0  0.188989   \n",
       "                        svr      4142   20212    1411   755  0.918326   \n",
       "max_u_classifier        lr        NaN     NaN     NaN   NaN       NaN   \n",
       "                        gb     101661    1272    2494  3101  0.948446   \n",
       "                        xgb    101837    1096    2633  2962  0.948446   \n",
       "                        svr    101938     995    2848  2747  0.948446   \n",
       "min_u_regressor_sparse  lr       1423  299915    1563  4595  0.979974   \n",
       "                        gb          0  301478       0  6018  0.980429   \n",
       "                        xgb      5934   62984  238494    84  0.224126   \n",
       "                        svr      5462  224118   77894    22  0.746611   \n",
       "min_u_regressor_focused lr       6130   51991    2320  2323  0.926024   \n",
       "                        gb       6087   52657    1654  2366  0.935951   \n",
       "                        xgb      8453       0   54311     0  0.134679   \n",
       "                        svr      6898   50914    4035   917  0.921101   \n",
       "min_u_classifier        lr        NaN     NaN     NaN   NaN       NaN   \n",
       "                        gb      89752    1457    4456  3819  0.916821   \n",
       "                        xgb     89320    1889    4146  4129  0.916821   \n",
       "                        svr     85595    5614    1714  6561  0.916821   \n",
       "\n",
       "                              precision    recall        f1  \n",
       "experiment              class                                \n",
       "max_u_regressor_sparse  lr       0.3303  0.663026  0.440938  \n",
       "                        gb     0.513088  0.801827  0.625755  \n",
       "                        xgb    0.014356  0.522637  0.027945  \n",
       "                        svr    0.612828  0.641636  0.626901  \n",
       "max_u_regressor_focused lr     0.758838  0.985036  0.857267  \n",
       "                        gb     0.807439  0.952913  0.874165  \n",
       "                        xgb    0.188989       1.0  0.317899  \n",
       "                        svr    0.745903  0.845824  0.792727  \n",
       "max_u_classifier        lr          NaN       NaN       NaN  \n",
       "                        gb     0.976055    0.9704  0.973219  \n",
       "                        xgb    0.974797  0.971736  0.973264  \n",
       "                        svr    0.972821  0.973759   0.97329  \n",
       "min_u_regressor_sparse  lr     0.476557  0.236457  0.316082  \n",
       "                        gb            0       0.0         0  \n",
       "                        xgb    0.024277  0.986042  0.047387  \n",
       "                        svr    0.065526  0.995988  0.122963  \n",
       "min_u_regressor_focused lr     0.725444  0.725186  0.725315  \n",
       "                        gb     0.786333  0.720099   0.75176  \n",
       "                        xgb    0.134679       1.0  0.237387  \n",
       "                        svr    0.630934  0.882662  0.735865  \n",
       "min_u_classifier        lr          NaN       NaN       NaN  \n",
       "                        gb       0.9527  0.959186  0.955932  \n",
       "                        xgb    0.955642  0.955815  0.955729  \n",
       "                        svr    0.980369  0.928806  0.953891  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe4baa4d27e3b73db55d4bb4674105e8dd41faaf9e559c3cc8381041ce15293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
