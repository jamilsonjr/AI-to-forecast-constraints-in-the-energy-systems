{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of this Article** \n",
    "- Loading best hyperparameters for each model\n",
    "- Model training\n",
    "- Results discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best hyperparameters for each model\n",
    "\n",
    "TODO... explain that this is the second try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hyperparameters dataset.\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse hyper params:\n",
      "\n",
      "params_gradient_boost_regression_sparse_max_u.csv :\n",
      "            params                value\n",
      "0   n_estimators                   13\n",
      "1  learning_rate  0.17764936153906563\n",
      "2           loss        squared_error\n",
      "3          value   0.5528979104909191\n",
      "params_gradient_boost_regression_sparse_min_u.csv :\n",
      "            params                value\n",
      "0   n_estimators                  151\n",
      "1  learning_rate  0.10018058609990134\n",
      "2           loss        squared_error\n",
      "3          value   0.5607221182696422\n",
      "params_mlp_regressor_sparse_max_u.csv :\n",
      "          params                 value\n",
      "0  hidden_size                    19\n",
      "1     n_layers                     3\n",
      "2      dropout    0.4415292238988939\n",
      "3   activation                  relu\n",
      "4    optimizer                   sgd\n",
      "5           lr  0.003549282320247246\n",
      "6       epochs                    30\n",
      "7   batch_size                    16\n",
      "8   classifier                 False\n",
      "9        value    1.5483470399373407\n",
      "params_mlp_regressor_sparse_min_u.csv :\n",
      "          params                  value\n",
      "0  hidden_size                     57\n",
      "1     n_layers                      2\n",
      "2      dropout     0.4962090212097388\n",
      "3   activation                sigmoid\n",
      "4    optimizer                    sgd\n",
      "5           lr  0.0007518807270370491\n",
      "6       epochs                     81\n",
      "7   batch_size                     32\n",
      "8   classifier                  False\n",
      "9        value     124.92202478545231\n",
      "params_support_vector_regression_sparse_max_u.csv :\n",
      "     params                 value\n",
      "0  kernel                   rbf\n",
      "1       C  0.022436909301419707\n",
      "2  degree                     1\n",
      "3   gamma    0.8962604691772639\n",
      "4   value   0.42052882987664747\n",
      "params_support_vector_regression_sparse_min_u.csv :\n",
      "     params                value\n",
      "0  kernel                  rbf\n",
      "1       C  0.07420599506532788\n",
      "2  degree                    2\n",
      "3   gamma   0.9633643757492328\n",
      "4   value   0.5020651136575333\n",
      "params_xgboost_regression_sparse_max_u.csv :\n",
      "                params                   value\n",
      "0            booster                  gbtree\n",
      "1             lambda   5.782747652090873e-06\n",
      "2              alpha    0.012308367933724952\n",
      "3          subsample      0.6225067185220082\n",
      "4   colsample_bytree      0.8488305767001761\n",
      "5          max_depth                       7\n",
      "6   min_child_weight                       3\n",
      "7                eta     0.02113381538367604\n",
      "8              gamma  1.3723417484849897e-08\n",
      "9        grow_policy               lossguide\n",
      "10             value      0.5518040130536346\n",
      "params_xgboost_regression_sparse_min_u.csv :\n",
      "                params                   value\n",
      "0            booster                    dart\n",
      "1             lambda     0.31985959177956824\n",
      "2              alpha  3.7623127675934423e-07\n",
      "3          subsample      0.4083379688615113\n",
      "4   colsample_bytree      0.9910601387196718\n",
      "5          max_depth                       5\n",
      "6   min_child_weight                       8\n",
      "7                eta     0.14775510540149925\n",
      "8              gamma   0.0022715829398750258\n",
      "9        grow_policy               depthwise\n",
      "10       sample_type                weighted\n",
      "11    normalize_type                    tree\n",
      "12         rate_drop  2.9835982780187868e-06\n",
      "13         skip_drop    0.009744089480552023\n",
      "14             value      0.5629411047598317\n",
      "Focused hyper params:\n",
      "\n",
      "params_gradient_boost_regression_focused_max_u.csv :\n",
      "           params                value\n",
      "0   n_estimators                   10\n",
      "1  learning_rate  0.10144664021941828\n",
      "2           loss        squared_error\n",
      "3          value   0.0773945040090285\n",
      "params_gradient_boost_regression_focused_min_u.csv :\n",
      "           params                value\n",
      "0   n_estimators                   30\n",
      "1  learning_rate  0.13719104718081254\n",
      "2           loss        squared_error\n",
      "3          value  0.04942396630494839\n",
      "params_mlp_regressor_focused_max_u.csv :\n",
      "         params                  value\n",
      "0  hidden_size                     34\n",
      "1     n_layers                      3\n",
      "2      dropout    0.08036356457000618\n",
      "3   activation                   relu\n",
      "4    optimizer                    sgd\n",
      "5           lr  0.0002685191505675321\n",
      "6       epochs                     43\n",
      "7   batch_size                     64\n",
      "8   classifier                  False\n",
      "9        value     0.1617882534101509\n",
      "params_mlp_regressor_focused_min_u.csv :\n",
      "         params                   value\n",
      "0  hidden_size                      80\n",
      "1     n_layers                       3\n",
      "2      dropout     0.08520638219479518\n",
      "3   activation                    relu\n",
      "4    optimizer                     sgd\n",
      "5           lr  6.0293232128668264e-05\n",
      "6       epochs                      42\n",
      "7   batch_size                       8\n",
      "8   classifier                   False\n",
      "9        value      0.1043009418012103\n",
      "params_support_vector_regression_focused_max_u.csv :\n",
      "    params                 value\n",
      "0  kernel                  poly\n",
      "1       C  0.018404139496246343\n",
      "2  degree                     2\n",
      "3   gamma   0.42588631166241975\n",
      "4   value   0.08019984465657237\n",
      "params_support_vector_regression_focused_min_u.csv :\n",
      "    params                value\n",
      "0  kernel                  rbf\n",
      "1       C   0.8790622098913237\n",
      "2  degree                    2\n",
      "3   gamma  0.35975955062018733\n",
      "4   value  0.04751631380477192\n",
      "params_xgboost_regression_focused_max_u.csv :\n",
      "              params                   value\n",
      "0           booster                gblinear\n",
      "1            lambda  0.00013877247253661892\n",
      "2             alpha    0.005279267376072027\n",
      "3         subsample      0.8184308604987783\n",
      "4  colsample_bytree     0.30923426777896207\n",
      "5             value     0.07202090466196524\n",
      "params_xgboost_regression_focused_min_u.csv :\n",
      "              params                  value\n",
      "0           booster               gblinear\n",
      "1            lambda  9.527948761085565e-08\n",
      "2             alpha   4.07820829801347e-07\n",
      "3         subsample     0.8088586056670691\n",
      "4  colsample_bytree     0.7795435215677236\n",
      "5             value    0.04860042403331934\n",
      "Boolean hyper params:\n",
      "\n",
      "params_gradient_boost_classifier_max_u.csv :\n",
      "           params               value\n",
      "0   n_estimators                 986\n",
      "1  learning_rate  0.4044031036864314\n",
      "2           loss            deviance\n",
      "3          value  0.5176270103312387\n",
      "params_gradient_boost_classifier_min_u.csv :\n",
      "           params                value\n",
      "0   n_estimators                   25\n",
      "1  learning_rate  0.26687757947348434\n",
      "2           loss             log_loss\n",
      "3          value   0.6121851200937317\n",
      "params_mlp_classifier_max_u.csv :\n",
      "         params                  value\n",
      "0  hidden_size                     69\n",
      "1     n_layers                      1\n",
      "2      dropout    0.22628939853329905\n",
      "3   activation                   tanh\n",
      "4    optimizer                   adam\n",
      "5           lr  0.0026741772486018607\n",
      "6       epochs                     93\n",
      "7   batch_size                      2\n",
      "8   classifier                   True\n",
      "9        value    0.16464042860086545\n",
      "params_mlp_classifier_min_u.csv :\n",
      "         params                  value\n",
      "0  hidden_size                     76\n",
      "1     n_layers                      2\n",
      "2      dropout    0.07881331134802505\n",
      "3   activation                   relu\n",
      "4    optimizer                   adam\n",
      "5           lr  0.0032979855565955056\n",
      "6       epochs                     20\n",
      "7   batch_size                     16\n",
      "8   classifier                   True\n",
      "9        value    0.20475454736989956\n",
      "params_support_vector_classifier_max_u.csv :\n",
      "    params                value\n",
      "0  kernel                 poly\n",
      "1       C   0.1925050495631466\n",
      "2  degree                    3\n",
      "3   gamma   0.7842438720239481\n",
      "4   value  0.29964455634485454\n",
      "params_support_vector_classifier_min_u.csv :\n",
      "    params                  value\n",
      "0  kernel                   poly\n",
      "1       C   0.000133583886435618\n",
      "2  degree                      2\n",
      "3   gamma  0.0004938586327866807\n",
      "4   value                    0.0\n",
      "params_xgboost_classifier_max_u.csv :\n",
      "           params                value\n",
      "0           loss             deviance\n",
      "1  learning_rate   0.7092160592789676\n",
      "2   n_estimators                   71\n",
      "3      subsample  0.08947014223147053\n",
      "4      max_depth                    4\n",
      "5          value    0.381870266927326\n",
      "params_xgboost_classifier_min_u.csv :\n",
      "           params                 value\n",
      "0           loss           exponential\n",
      "1  learning_rate  0.021531729860856535\n",
      "2   n_estimators                    85\n",
      "3      subsample   0.31351075725974775\n",
      "4      max_depth                     5\n",
      "5          value   0.44327403443439695\n"
     ]
    }
   ],
   "source": [
    "sparse_hyper_params = {}\n",
    "focused_hyper_params = {}\n",
    "boolean_hyper_params = {}\n",
    "for file in os.listdir('hyper_params_results'):\n",
    "    if file.endswith('.csv') and 'sparse' in file.split('_') and 'classifier' not in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'focused' in file.split('_') and 'classifier' not in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        focused_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        boolean_hyper_params[file] = df\n",
    "print('Sparse hyper params:\\n')\n",
    "for key in sparse_hyper_params.keys():\n",
    "    print(key, ':\\n ',sparse_hyper_params[key])\n",
    "print('Focused hyper params:\\n')\n",
    "for key in focused_hyper_params.keys():\n",
    "    print(key, ':\\n',focused_hyper_params[key])\n",
    "print('Boolean hyper params:\\n')\n",
    "for key in boolean_hyper_params.keys():\n",
    "    print(key, ':\\n',boolean_hyper_params[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 34,\n",
       " 'n_layers': 3,\n",
       " 'dropout': 0.08036356457000618,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'sgd',\n",
       " 'lr': 0.0002685191505675321,\n",
       " 'epochs': 43,\n",
       " 'batch_size': 64,\n",
       " 'classifier': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "def get_hyper_params_from_df(df):\n",
    "    output = {}\n",
    "    for row in df.iterrows():\n",
    "        if row[1]['params'] != 'value':\n",
    "            try:\n",
    "                output[row[1]['params']] = ast.literal_eval(row[1]['value'])\n",
    "            except :\n",
    "                output[row[1]['params']] = row[1]['value']\n",
    "    return output\n",
    "get_hyper_params_from_df(focused_hyper_params['params_mlp_regressor_focused_max_u.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from thesis_package import aimodels as my_ai, utils, metrics\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression data sparse\n",
    "y_max_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv').drop(columns=['timestamps'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_sparse, test_size=0.2, scaling=True)\n",
    "data_max_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_sparse, test_size=0.2, scaling=True)\n",
    "data_min_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data focused\n",
    "y_max_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_bal_constr.csv')\n",
    "exogenous_data_focused_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_bal.csv').drop(columns=['date'])\n",
    "y_min_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_bal_constr.csv')\n",
    "exogenous_data_focused_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_bal.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_max_u, y_max_u_focused, test_size=0.2, scaling=True)\n",
    "data_max_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_min_u, y_min_u_focused, test_size=0.2, scaling=True)\n",
    "data_min_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data\n",
    "y_max_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_max_u_bool = y_max_u_bool[utils.cols_with_positive_values(y_max_u_bool)]\n",
    "y_min_u_bool = y_min_u_bool[utils.cols_with_positive_values(y_min_u_bool)]\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_bool, test_size=0.2, scaling=True)\n",
    "data_max_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_bool, test_size=0.2, scaling=True)\n",
    "data_min_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a quick sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count in classifiation data max_u : 22236\n",
      "Positive count in regression data max_u with threshold 0.001591058368850724 : 22236\n",
      "Positive count in classifiation data min_u : 35462\n",
      "Positive count in regression data min_u with threshold 0.0020242378560612192 : 35462\n"
     ]
    }
   ],
   "source": [
    "def check_positive_count(reg_data, class_data, threshold, experiment='max_u'):\n",
    "    print('Positive count in classifiation data', experiment, ':', class_data.sum().sum())\n",
    "    print('Positive count in regression data', experiment, 'with threshold', threshold, ':', reg_data[reg_data > threshold].count().sum())\n",
    "\n",
    "def get_threshold(target_data):\n",
    "    X_train, X_test, y_train, y_test = utils.split_and_suffle(exogenous_data, target_data)\n",
    "    threshold = y_test.loc[:, y_test.max(axis=0) != 0].max(axis=0).mean() * 0.10\n",
    "    return threshold\n",
    "    \n",
    "check_positive_count(y_max_u_sparse, y_max_u_bool, get_threshold(y_max_u_sparse), experiment='max_u')\n",
    "check_positive_count(y_min_u_sparse, y_min_u_bool, get_threshold(y_min_u_sparse), experiment='min_u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "In this section the models will be trained with the hyperparameters loaded above. All the models will be stored in the same `Context` object for later evaluation. The `Context` object is a class that stores all the models and their respective hyperparameters. The `Context` object is defined in the `aimodels.py` file. The `Context` object is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['lr', 'gb', 'xgb', 'svr', 'mlp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params_gradient_boost_regression_sparse_max_u.csv', 'params_gradient_boost_regression_sparse_min_u.csv', 'params_mlp_regressor_sparse_max_u.csv', 'params_mlp_regressor_sparse_min_u.csv', 'params_support_vector_regression_sparse_max_u.csv', 'params_support_vector_regression_sparse_min_u.csv', 'params_xgboost_regression_sparse_max_u.csv', 'params_xgboost_regression_sparse_min_u.csv'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_hyper_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression sparse\n"
     ]
    }
   ],
   "source": [
    "# max_u regression sparse\n",
    "if 'max_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_max_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_max_u.csv']) \n",
    "    regressor_max_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regressor_sparse_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_sparse['y_train'].shape[1]\n",
    "    regressor_max_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse', regressor_max_u)\n",
    "else:\n",
    "    print('Loading max_u regression sparse') \n",
    "    regressor_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse')\n",
    "\n",
    "testing_data = {'max_u_regressor_sparse': {}}\n",
    "for model, strategy in zip(models, regressor_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_sparse['y_test'].columns)\n",
    "    testing_data['max_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_sparse'][model]['real'] = deepcopy(data_max_u_sparse['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training max_u regression focused\n",
      "[16:07:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:07:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvXUlEQVR4nO3dd5iU5bnH8e+9lbL0sigdRBCkCCtFUEBFwYYao6LBLqJYsEVNUY8mUU88CgoGULElgqKi2IPK0kGKFAWpgjSpIiy93OePeUkmm62wM7O78/tc11w78zzvO3Pvc8H89q2PuTsiIiLZJcS6ABERKZ4UECIikiMFhIiI5EgBISIiOVJAiIhIjhQQIiKSIwWEyDEys+ZmNtvMLIY1uJmdkEvfhWb2VrRrkpJPASGllpmtMrOzo/BRjwNPe3BRUfC5e8wsK+wxJAp15MjdPwRamFmrWNUgJZMCQuQYmNlxQHfg/WxdF7p7Wtjj9uhX9x9GAf1iXIOUMAoIiStmlmpmg8xsffAYZGapQV91M/vIzLab2TYzm2xmCUHfA2a2zsx2mtkSMzsreMsewFx331vAz7/OzKaa2RAz+8XMvg97L8zseDMbF3z+cjO7Oawv0cx+Z2YrgjrmmFndsLc/28yWBfUPzbbLKxM4/+hGTeJVUqwLEImy3wMdgTaAAx8AfwD+CNwLrAVqBMt2BNzMmgK3A6e6+3ozawAkBsu0BJYUsoYOwDtAdeBS4D0za+ju24DRwLfA8UAzYLyZrXD3r4B7gD7AecBSoBWwO+x9LwBOBSoCc4APgc+CvsVAAzOr6O47ClmvxCltQUi8uRp4zN03uftm4H+AvkHfAeA4oL67H3D3ycFxhUNAKtDczJLdfZW7rwjWqQzszOFz3g/+kj/yuDmsbxMwKPiMtwgFzPnB1kBn4AF33+vu84CXgGuC9W4C/uDuSzxkvrtvDXvfJ919u7v/CEwgFIJHHKmxciHGSuKcAkLizfHA6rDXq4M2gL8Cy4F/mtlKM3sQwN2XAwOBR4FNZjbazI6s8zNQIYfPudjdK4c9XgzrW3fkgHa2Go4Htrn7zmx9tYPndYEV5O6nsOe7gbSw10dq3J7H+iL/QQEh8WY9UD/sdb2gDXff6e73unsj4CLgniPHB9z9TXfvEqzrwFPB+guAEwtZQ+1sxweO1LAeqGpmFbL1rQuerwEaF/KzjjgJWKXdS1IYCggp7ZLNrMyRB6Gzef5gZjXMrDrwMPB3ADO7wMxOCL68fyG0a+mwmTU1szODg9l7gT3A4eD9xwNtg/cuqJrAnWaWbGa/JvTl/Ym7rwGmAU8E9bYCbjxSH6HdTY+bWRMLaWVm1Qr4mV2BTwtRo4gCQkq9Twh9oR95lAFmE/rLfyEwF/hTsGwT4AsgC5gOvODuEwgdf3gS2EJoN05N4CEAd98IfAX0zva5H2a7DmJsWN/M4LO2AH8GLgs7ltAHaEBoa2Is8Ii7fxH0PQO8DfwT2AG8DJQt4Dj0AYYXcFkRAEwTBokcGzNrDrwGtPd8/kOZ2XXATcHuqqgwswuBvu5+ebQ+U0oHneYqcozcfRGh00uLpeBK6g9jXYeUPNrFJCIiOdIuJhERyZG2IEREJEel6hhE9erVvUGDBrn279q1i/Lly0evoBJG45M3jU/+NEZ5K47jM2fOnC3uXiOnvlIVEA0aNGD27Nm59mdmZtKtW7foFVTCaHzypvHJn8Yob8VxfMxsdW592sUkIiI5UkCIiEiOFBAiIpIjBYSIiORIASEiIjlSQIiISI4UECIikiMFBLB4ww42/LKHA4cO579wAS3flMXIKT/wy54DRfaeIiLRVKoulDsa7s6lL0xjz4FDmEHVcinUqJBKzYplSK+QSs2KqTSqnkbHxtWoXTnvW+/vPXCIT7/dwKiZa/h61TYAxs1fzxs3tqdCmeRo/DoiIkUm7gMC4Pk+p7Bp5z427tjLpp372Lwz9HPpTzvZnLWPQ4dDNzSsV7UcnRpVo2PjqnRqVJ1alUKTiC35aSejvv6R9+auZcfegzSoVo4HezWjRloqD7y7gOtfmcVrN7SnfKqGW0RKjrj/xjIzzm6enmv/ocPO0o07mb5iK9NXbuXTbzfw1uw1ADSsXp4KZZJYsPYXUhITOPfkWvRpX5eODauRkBCacrhsSiJ3jPqGG16dxavXt6dsSmJUfi8RkWMV9wGRn8QE46TjKnLScRW5oUtDDh12Fm/YwYyVW5m+Yiubs/bxh/NP4tK2dahaPuW/1j+v5XEcOHSYu9+ax82vz+alazMok6yQEJHiTwFRSIkJxsm1K3Fy7UrcdHqjAq3Tu01tDhxy7n9nPre8MYcR17QjNUkhISLFm85iipLL2tXhiUtaMnHpZgb8Yy77DxbdGVMiIpGggIiiK9vX4/GLT+aLxZu4Y9TcIj2tVkSkqCkgoqxvx/o8fEFzPv9uI1cMn873P+2IdUkiIjlSQMTADV0a8uwVrflhyy7Of24KT3yymN37D8a6LBGR/6CAiJFLTqnDV/d247K2dRg+aSU9npnEF4s2xrosEZF/UUDEUJXyKTx1WSvG9O9E+dREbnp9Nv1en8367XtiXZqIiAKiODi1QVU+vvN0HuzVjEnLNnP2MxN5/stlbN+9P9aliUgci1hAmFlTM5sX9thhZgNzWfZUMztoZpeFtV1rZsuCx7WRqrO4SE5MoH/Xxoy/uyudT6jO/41fSscnvuT3YxeyfFNWrMsTkTgUsQvl3H0J0AbAzBKBdcDY7MsFfU8B/wxrqwo8AmQADswxs3Hu/nOk6i0u6lYtx4vXZPD9Tzt4ZcoqxsxZyz9m/ki3pjW4sUtDupxQHTOLdZkiEgeitYvpLGCFu6/Ooe8O4F1gU1jbucB4d98WhMJ4oGfkyyw+mtWqyFOXtWLag2dy99kn8u26HfR9+WvOHTSJ9+auxd1jXaKIlHIWjS8aMxsJzHX3IdnaawNvAt2BkcBH7v6Omd0HlHH3PwXL/RHY4+5P5/De/YB+AOnp6e1Gjx6dax1ZWVmkpaUV0W8VXQcOOzM3HOTzVQdZs/MwFzZO5tITkot0a6Ikj080aHzypzHKW3Ecn+7du89x94yc+iJ+LyYzSwEuAh7KoXsQ8IC7Hz7aLzp3HwGMAMjIyPBu3brlumxmZiZ59Rd3PYDfHXYeem8hb81eQ9269bj/3KZFFhIlfXwiTeOTP41R3kra+ETjZn29CG095HSSfwYwOviCqw6cZ2YHCR2v6Ba2XB0gM7JllgwJCcYTl7YkIcF4IXMFhw47D/ZqpuMSIlLkohEQfYBROXW4e8Mjz83sVUK7mN4PDlL/xcyqBN3nkPMWSFxKSDD+fPHJJCbA8EkrOXTY+f35JykkRKRIRTQgzKw8oT0jt4S19Qdw92G5refu28zscWBW0PSYu2+LZK0lTUKC8Xjvk0k046UpP3DInYcvaK6QEJEiE9GAcPddQLVsbTkGg7tfl+31SEIHriUXZsajF7UgIcF4ZeoqDh92Hr2ohUJCRIqEJgwq4cyMhy9oTlKC8eLk0JbEYxed/K8pT0VEjpYCohQwM3533kkkJBjDJ65k6cYsnr6sNfWqlYt1aSJSguleTKWEmfFgz2b89bJWLF6/g56DJ/HG9NBuJxGRo6GAKEXMjF9n1OXzu8+gXf0q/PGD7+g7ciZrf94d69JEpARSQJRCx1cuy+s3tOeJS1sy78ft9Bw0mdFf/6jbc4hIoSggSikzo0/7enw28Axa1q7Eg+8t5NpXZrFpx95YlyYiJYQCopSrW7Uc/7ipA4/3bsGsH7bxq2HTWLNNu5xEJH8KiDiQkGD07dSA0f06snPvQX49bLrmmBCRfCkg4kjrupUZ3a8jBw8f5orh01m8YUesSxKRYkwBEWea1arI27d0IiUpgStHzGDemu2xLklEiikFRBxqVCONt2/pRKWyyVz94gxmrNwa65JEpBhSQMSpulXLMaZ/J46rXJZrR35N5pJN+a8kInFFARHH0iuW4a1+HWlcI42bX5/NZz8cYMlPO3X1tYgAuhdT3KuWlsqofh256bVZjF7yM6OXTKJCahKt61bmlHqhR5u6VahaPiXWpYpIlCkghEplk3n7lk689ckEkmudyDdrfuabH7f/a8Y6gGa1KnBPjxPp0TxdtxMXiRMKCAFCV17XKp9At3Z1+FW7OgDs3n+QhWt/Ye6P23lnzhr6vTGHDg2r8vvzT6JVncqxLVhEIk7HICRX5VKS6NCoGrd2a8znA8/g8YtPZvmmLC4aMpW735rHuu17Yl2iiESQAkIKJCkxgb4d65N5fzdu69aYTxZu4MynM/nfz75n594DsS5PRCIgYgFhZk3NbF7YY4eZDcy2TG8zWxD0zzazLmF9h8LWHRepOqVwKpRJ5rc9m/HVfd04r+VxvJC5gq5/zWTQF0vZvHNfrMsTkSIUsWMQ7r4EaANgZonAOmBstsW+BMa5u5tZK+BtoFnQt8fd20SqPjk2tSuX5dkr2nBD54Y8M34Jg75YxgsTVnBB6+O4/rSGtKxTKdYlisgxitZB6rOAFe6+OrzR3cPvGFce0An4JUzLOpV45fr2rNycxevTVzNm9hrem7uOjPpVuK5zA85tUYvkRO3JFCmJLBqTyJjZSGCuuw/Joe8S4AmgJnC+u08P2g8C84CDwJPu/n4u790P6AeQnp7ebvTo0bnWkZWVRVpa2jH9LqVZUYzP7gPO5HUH+WL1ATbvcaqWMfo0S+HUWiX/hDn9+8mfxihvxXF8unfvPsfdM3LsdPeIPoAUYAuQns9yZwBfhL2uHfxsBKwCGuf3We3atfO8TJgwIc/+eFeU43Pw0GEf/91PfuHzk73+Ax/5s+OX+OHDh4vs/WNB/37ypzHKW3EcH2C25/KdGo1t/16Eth425rWQu08CGplZ9eD1uuDnSiATOCXCdUoRSkwwzm6ezpj+nbi0bW0GfbGMO0Z9w94Dh2JdmogUUDQCog8wKqcOMzvBgstyzawtkApsNbMqZpYatFcHOgOLolCrFLHUpET+79etebBXMz5euIHLh09no6Y9FSkRIhoQZlYe6AG8F9bW38z6By9/BXxrZvOAocAVwSbPScBsM5sPTCB0DEIBUUKZGf27NmZE34zgQrspLFz7S6zLEpF8RDQg3H2Xu1dz91/C2oa5+7Dg+VPu3sLd27h7J3efErRPc/eW7t46+PlyJOuU6OjRPJ13bz2NpIQEfj18Gh8v2BDrkkQkDzr/UKLqpOMq8v6AzrQ4vhID3pzLs+OX6vbiIsWUAkKirkaFVN68uQO/aluHwV8u47pXZ7Ft1/5YlyUi2SggJCZSkxJ5+tet+PMlJzNjxVYueG6y5scWKWYUEBIzZsbVHerzzq2dMDN+PWwar09fdeQ6GBGJMQWExFyrOpX5+M4unN6kBg9/8B13jZ7Hrn0HY12WSNxTQEixULlcCi9dk8H95zblowXr6T10Kss37Yx1WSJxTQEhxUZCgjGg+wm8cWMHft61n16DJ3Pv2/NZtH5HrEsTiUsKCCl2Op9QnU/uOp2rO9Tn0283cN5zk7nqxRl89f1GnRIrEkUKCCmW0iuW4dGLWjD9wbN4qFczftiyixtenc3Zz07k7zNWs2e/7ukkEmkKCCnWKpVL5paujZn02+4MvrINaalJ/OH9bzntyS8ZM3uNzngSiSAFhJQIyYkJ9G5Tmw8GdGZM/040qVmB+99ZwI2vzeanX3TzP5FIUEBIiWJmnNqgKqP7deSRC5szbcUWznl2Iu/MWautCZEipoCQEikhwbi+c0M+u+sMmtaqwH1j5nPTa7N1K3GRIqSAkBKtQfXyjO7XiT9e0JypK7bQ45mJvDdXWxMiRUEBISVeYoJxY5eGfHrXGZyYXoF73p7P7W9+w869B2JdmkiJpoCQUqNh9fK8dUsnftuzKZ999xMXDZnK4g26yE7kaCkgpFRJTDBu63YCb97UgV37DnLx0Km8PXtNrMsSKZEUEFIqdWhUjY/vPJ129avw23cWcP+Y+bq4TqSQIhYQZtbUzOaFPXaY2cBsy/Q2swVB/2wz6xLWd62ZLQse10aqTim9alRI5Y0bO3DHmScwZs5aLnlhKis3Z8W6LJESI2IB4e5Lgrmm2wDtgN3A2GyLfQm0Dpa5AXgJwMyqAo8AHYD2wCNmViVStUrplZhg3HtOU165/lR+2rGXi4ZM5aMF62NdlkiJEK1dTGcBK9x9dXiju2f5v89HLA8ceX4uMN7dt7n7z8B4oGeUapVSqHvTmnx85+k0SU/j9je/4cF3F7B7v+acEMmLReN8cTMbCcx19yE59F0CPAHUBM539+lmdh9Qxt3/FCzzR2CPuz+dw/r9gH4A6enp7UaPHp1rHVlZWaSlpRXFr1QqxcP4HDzsjF12gE9+OECt8satrVOpVzGxQOvGw/gcK41R3orj+HTv3n2Ou2fk1BfxgDCzFGA90MLdN+ax3BnAw+5+dmECIlxGRobPnj071/7MzEy6det2FL9FfIin8ZmybAt3vz2PX/Yc4PfnncQ1nepjZnmuE0/jc7Q0RnkrjuNjZrkGRDR2MfUitPWQazgAuPskoJGZVQfWAXXDuusEbSJFokuT6nx21+l0blyNR8Z9x82vz2bbrv2xLkukWIlGQPQBRuXUYWYnWPBnm5m1BVKBrcDnwDlmViU4OH1O0CZSZKqlpTLyulN5+ILmTFq6hV6DJzFtxZZYlyVSbEQ0IMysPNADeC+srb+Z9Q9e/gr41szmAUOBKzxkG/A4MCt4PBa0iRQpM+OGLg1577bTKJ+SxFUvzuTBdxewfbe2JkSSIvnm7r4LqJatbVjY86eAp3JZdyQwMpL1iRxxcu1KfHRnFwZ9sYyXp/zA+EUb+f35J3HJKbXzPTYhUlrpSmqRQLmUJH533kl8dEcX6lUrxz1vz+fql2ayQhfXSZxSQIhkc9JxFXm3/2n8+ZKT+XbdL/QaNJlnxy9l/yHdQlziS0R3MYmUVAkJxtUd6nNO81r86eNFDP5yGenljDJ1N3PGiTViXZ5IVGgLQiQPNSqkMvjKU/j7jR0AuGbk19z2jzms374nxpWJRJ4CQqQAujSpzp+6lOX+c5vy1febOOv/JvK3zBXsP3g41qWJRIwCQqSAkhOMAd1PYPzdXTm9SXWe+ux7eg2exNTlunZCSicFhEgh1a1ajhHXZPDKdady8LBz9UszGfDmXDbt3Bvr0kSKlAJC5Ch1b1aTzweewT09TuSLRRs5b/BkJi7dHOuyRIqMAkLkGJRJTuTOs5rw0R1dqFY+lWtHfs2Tn37PgUM6NiElnwJCpAg0Sa/AB7d3pk/7egybuILLh09nzbbdsS5L5JgoIESKSJnkRJ64tCVDrjqF5RuzOP+5yXz27YZYlyVy1BQQIkXsglbH8/Gdp9Owenn6/30uf3z/W/YeOBTrskQKTQEhEgH1qpVjTP/TuPn0hrwxYzUXD53K0o07Y12WSKEoIEQiJCUpgd+f35xXrjuVLVn7uPD5KbwxYzXRmOZXpCgoIEQirHuzmnx61xl0bFSNP77/LTe/PoetWftiXZZIvhQQIlFQo0Iqr/xr9rrN9Bw8mcnLdM2EFG8FCggzK29mCcHzE83sIjNLjmxpIqVLQkJo9rr3B3Smctlk+r78NX/+eBH7DuoAthRPBd2CmASUMbPawD+BvsCrkSpKpDRrfnxFPryjC3071ufFyT9w6QvTWKlJiaQYKmhAmLvvBi4FXnD3XwMt8lzBrKmZzQt77DCzgdmWudrMFpjZQjObZmatw/pWBe3zzGx2IX8vkWKtTHIij198Mi9ek8G67Xu48PkpjP1mbazLEvkPBQ4IM+sEXA18HLQl5rWCuy9x9zbu3gZoB+wGxmZb7Aegq7u3BB4HRmTr7x68R0YB6xQpUXo0T+fTu06nxfGVuPut+dw/Zj679x+MdVkiQMEDYiDwEDDW3b8zs0bAhEJ8zlnACndfHd7o7tPc/efg5QygTiHeU6RUOK5SWd68uQN3nnkC78xdy0VDpvL9TztiXZYIVthzsoOD1WnuXuB/wWY2Epjr7kPyWOY+oJm73xS8/gH4GXBguLtn37o4sl4/oB9Aenp6u9GjR+daR1ZWFmlpaQUtO+5ofPIWjfFZtPUQwxfsY/cB56pmKXSrm4SZRfQzi5L+DeWtOI5P9+7d5+S6l8bd830AbwIVgfLAImAtcH8B100BtgDpeSzTHVgMVAtrqx38rAnMB87I77PatWvneZkwYUKe/fFO45O3aI3P5p17ve/LM73+Ax/5bX+f41uz9kXlc4uC/g3lrTiODzDbc/lOLegupuYe2mK4GPgUaEjoTKaC6EVo62FjTp1m1gp4Cejt7lvDgmtd8HMToWMX7Qv4eSIlWvW0VF697lQe7NWMz7/7ibOfmcjYb9bqCmyJuoIGRHJw3cPFwDh3P0Bo109B9AFG5dRhZvWA94C+7r40rL28mVU48hw4B/i2gJ8nUuIlJBj9uzbm4ztPp361ctz91nyuGfk1q7fuinVpEkcKGhDDgVWEdjFNMrP6QL7HIIIv9x6EQuBIW38z6x+8fBioBryQ7XTWdGCKmc0HvgY+dvfPClirSKnRtFYF3u1/Go/3bsG8H7dzzrOTeCFzuSYkkqhIKshC7v4c8FxY02oz616A9XYRCoDwtmFhz28CbsphvZVA6+ztIvEoIcHo26kBPZrX4tFx3/G/ny1h3Lz1PHFpS06pVyXW5UkpVtBbbVQys2fMbHbw+D9CWxMiEiW1KpVhWN92jOjbju27D3Dp36bx6Ljv2LVP101IZBR0F9NIYCdwefDYAbwSqaJEJHfntKjF+HvOoG/H+rw6bRXnDprElGVbYl2WlEIFDYjG7v6Iu68MHv8DNIpkYSKSuwplknms98m8fUsnkhMT+M3LM3nw3QXs2Hsg1qVJKVLQgNhjZl2OvDCzzsCeyJQkIgXVvmFVPr3rdG7p2oi3Z6+hxzMT+WJRjmeUixRaQQOiPzA0uIHeKmAIcEvEqhKRAiuTnMhDvU5i7G2dqVw2hZten82do75h2679sS5NSrgCBYS7z3f31kAroJW7nwKcGdHKRKRQWtetzId3dGHg2U349NsNnDtoElOX69iEHL1CzSjn7jv83/dguicC9YjIMUhJSmDg2SfywYAuVCyTxG9enslfP/9e103IUTmWKUdLzh3EROLMkUmJLm9Xl6ETVnDF8Oms2bY71mVJCXMsAaEbw4gUY+VSknjqslY81+cUlm7M4rznJvPJwg2xLktKkDwDwsx2BjPBZX/sBI6PUo0icgwuan08n9x5Oo1qpHHbP+byu7EL2XtA82BL/vIMCHev4O4Vc3hUcPcC3aZDRGKvXrVyjLmlE7d0bcSbM3/kwuen8O26X2JdlhRzx7KLSURKkJSkBB7qdRKv39CeHXsPcPHQqQz6YqkOYEuuFBAiceaME2vwz4FdubD18Qz6YhmXvDCVpRt3xrosKYYUECJxqFK5ZJ69og3DftOWDdv3csFzUxg+cQWHDuvcE/k3BYRIHOt58nF8fvcZnNmsJk98+j2XD5/OD1s0KZGEKCBE4lz1tFT+9pu2DLqiDcs27qTX4Em8O2dtrMuSYkABISKYGRefUpt/3t2VNnUrc++Y+Tz0nk6HjXcRCwgzaxpMI3rkscPMBmZb5mozW2BmC81smpm1DuvraWZLzGy5mT0YqTpF5N9qVSrD32/swK3dGjPq6x/59TBdgR3PIhYQ7r7E3du4exugHbAbGJttsR+Aru7eEngcGAFgZonAUKAX0BzoY2bNI1WriPxbUmICD/RsxovXZLBq6y4ueH4KX32vW4jHo2jtYjoLWOHuq8Mb3X2au/8cvJwB1AmetweWB5MT7QdGA72jVKuIAD2ap/PRHV2oXbksN7w6m6c/X6KznOJMtALiSmBUPsvcCHwaPK8NrAnrWxu0iUgU1a9WnvduO40rMuoyZMJyrhk5k80798W6LIkSc4/sXwRmlgKsB1q4e47bqWbWHXgB6OLuW83sMqCnu98U9PcFOrj77Tms2w/oB5Cent5u9OjRudaSlZVFWlrasf5KpZbGJ2/xPj6T1h7gjUX7KZME17VIpV36f99tJ97HKD/FcXy6d+8+x90zcuqLxv2UegFz8wiHVsBLQC933xo0rwPqhi1WJ2j7L+4+guDYRUZGhnfr1i3XQjIzM8mrP95pfPIW7+PTDbhy407ufmsez3+zg1+1rcEjFzWnYpnkfy0T72OUn5I2PtHYxdSHXHYvmVk94D2gr7svDeuaBTQxs4bBFsiVwLiIVyoieToxvQJjb+vMHWeewNhv1tJr0GSmrdCsdaVVRAPCzMoDPQiFwJG2/mbWP3j5MFANeCE4FXY2gLsfBG4HPgcWA2+7+3eRrFVECiYlKYF7z2nKO7eeRkpSAle9OJPHP1qkayZKoYjuYnL3XYQCILxtWNjzm4Cbcln3E+CTSNYnIkevbb0qfHxnF5789HtenvIDE5du5qrGh+gW68KkyOhKahE5auVSknis98m8fkN7svYe5PHpe3nkg2/ZsfdArEuTIqCAEJFjdsaJNfjnPWdwZr0kXp+xmrP+byIfzl9PpM+SlMhSQIhIkahYJpm+zVP5YEBn0iumcseob7hm5Nes0t1hSywFhIgUqVZ1KvPBgC48emFzvvlxO+cMmsTgL5ax76AOYpc0CggRKXKJCcZ1nRvy5b1dOad5Os9+sZTzBk/mu/WaB7skUUCISMSkVyzDkKva8toN7cnad5BLhk7j1ak/6NhECaGAEJGI63piDT696wxOb1KdRz9cxM2vz+HnXftjXZbkQwEhIlFRtXwKL12bwcMXNGfi0k30GjyZGSu35r+ixIwCQkSixsy4oUtDxt7WmbIpiVz14gyeHb+Ug4cOx7o0yYECQkSi7uTalfjwji5c3KY2g79cxlUvzmT1Vp0OW9woIEQkJtJSk3jmijY8c3lrFm3YwTnPTmLohOUc0NZEsaGAEJGYurRtHb68tytnNqvJXz9fwgXPTWHO6p/zX1EiTgEhIjGXXrEMf/tNO166JoOdew9w2bBp/H7sQn7Zo3s6xZICQkSKjbObp/PPe7py/WkNGfX1j5z9zEQ+XrBB103EiAJCRIqVtNQkHr6wOR8M6ELNCqkMeHMufV6cwdwftdsp2hQQIlIstaxTiQ8GdOZ/LmrB8k1ZXPrCNPq9PpulG3fGurS4oYAQkWIrKTGBa09rwMT7u3NvjxOZvmIrPQdN4t6357P2592xLq/UU0CISLFXPjWJO85qwqTfduem0xvx4YL1nPn0RB4d9x1bs/bFurxSK2IBYWZNg3mmjzx2mNnAbMs0M7PpZrbPzO7L1rfKzBaGz1UtIvGtSvkUfnfeSWTe141L29bm9emrOHfQJCZ8vynWpZVKEQsId1/i7m3cvQ3QDtgNjM222DbgTuDpXN6me/AeGZGqU0RKnuMrl+XJX7Xi07vOoHpaKte/OotHx33H3gOac6IoRWsX01nACndfHd7o7pvcfRagk51FpNCa1qrA+wM6c33nBrw6bRUXD53Kkp90ELuoWDTOLzazkcBcdx+SS/+jQJa7Px3W9gPwM+DAcHcfkcu6/YB+AOnp6e1Gjx6dax1ZWVmkpaUd7a9R6ml88qbxyV8sx2jB5oO8tHAfuw/ClU1TOKteEmYWk1pyUxz/DXXv3n1ObntpIh4QZpYCrAdauPvGXJZ5lP8OiNruvs7MagLjgTvcfVJen5WRkeGzZ+d+uCIzM5Nu3boV/peIExqfvGl88hfrMdq8cx+/fWc+E5Zs5sxmNfnfy1pRPS01ZvVkF+vxyYmZ5RoQ0djF1IvQ1kOO4ZAbd18X/NxE6NhF+wjUJiKlSI0KqYy87lQevbA5U5ZvoeegSUxYogPYRysaAdEHGFWYFcysvJlVOPIcOAf4NgK1iUgpYxaaD3vc7Z2pVj6V61/RAeyjFdGACL7cewDvhbX1N7P+wfNaZrYWuAf4g5mtNbOKQDowxczmA18DH7v7Z5GsVURKl2a1KvLB7Z257rTQAezeQ3QAu7CSIvnm7r4LqJatbVjY85+AOjmsugNoHcnaRKT0K5OcyKMXtaBr0xrcP2Y+Fw6Zwu96NePa0xoUuwPYxZGupBaRUq9705p8NvAMOjeuxqMfLuL6V2exeaeuwM6PAkJE4kL1tNAB7Md6t2D6iq30GjyJKcu2xLqsYk0BISJxw8y4plMDPryjC1XKpdB35Eye+3IZhw9rvomcKCBEJO6cmF6BD27vzMVtavPM+KVc9+ostu3aH+uyih0FhIjEpXIpSTxzeWv+cklLZqzYyvnPTdakRNkoIEQkbpkZV3Wox3u3nUZSonH5sOmMnPKDpjgNKCBEJO6dXLsSH91+Ot2a1uSxjxYx4M257Nyre4gqIEREgErlknnxmnY81KsZn3+3kcv+Nj3uZ61TQIiIBMyMW7o25rXr27P+lz1cPHQa38TxcQkFhIhINl2aVGfsbadRNiWBK0fM4OMFG2JdUkwoIEREcnBCzQq8f1tnTq5diQFvzmXohOVxd/BaASEikotqaan846YO9G5zPH/9fAn3jVnA/oOHY11W1ET0Zn0iIiVdmeREBl3RhkbV03j2i6Ws+Xk3w3/TjirlU2JdWsRpC0JEJB9mxl1nN2HwlW2Y9+N2Ln5hKss3lf5bhysgREQKqHeb2ozq15Fd+w5yydBppX62OgWEiEghtKtfhQ9u70LdquW48dVZvDR5Zak9eK2AEBEppNqVy/LOrZ04p3kt/vTxYn77zgL2HSx9U5oqIEREjkK5lCReuLotd57VhDFz1nL1izPZklW6JiGKWECYWVMzmxf22GFmA7Mt08zMppvZPjO7L1tfTzNbYmbLzezBSNUpInK0EhKMe3qcyPN9TmHhul/oPWQqi9bviHVZRSZiAeHuS9y9jbu3AdoBu4Gx2RbbBtwJPB3eaGaJwFCgF9Ac6GNmzSNVq4jIsbiw9fGM6d+Jg4cPc+nfpvLWrB9LxXGJaO1iOgtY4e6rwxvdfZO7zwKy3zaxPbDc3Ve6+35gNNA7OqWKiBReqzqV+fD2LrStV4UH3l3InaPnsaOE3xE2WhfKXQmMKsTytYE1Ya/XAh1yWtDM+gH9ANLT08nMzMz1TbOysvLsj3can7xpfPKnMYKbTnCOS0hm7IL1zFi6gVvbpNKoUiJQ8sYn4gFhZinARcBDkXh/dx8BjADIyMjwbt265bpsZmYmefXHO41P3jQ++dMYhZzZHfqs2sZdo+fxl5l7eaBnM27s0pBJkyaWqPGJxi6mXsBcd99YiHXWAXXDXtcJ2kRESoSMBlX5+M4unHVSTf78yWJueG0WO/aVrOMS0QiIPhRu9xLALKCJmTUMtkCuBMYVeWUiIhFUuVwKw37Tjsd7t2Daiq08PG0Pc1aXnPklIhoQZlYe6AG8F9bW38z6B89rmdla4B7gD2a21swquvtB4Hbgc2Ax8La7fxfJWkVEIsHM6NupAe/f1pnkBOjz4gze/6Zk7BCJ6DEId98FVMvWNizs+U+Edh/ltO4nwCeRrE9EJFqaH1+RhzuV5e8/lGHgW/NYunEn953TlIQEi3VpudKV1CIiUVIhxXjjxg70aV+XFzJX0P/vc9i172Csy8qVAkJEJIpSkhL4yyUt+eMFzfli8UYuGzadddv3xLqsHCkgRESizMy4sUtDXr7uVNZu203vIVOK5cFrBYSISIx0b1qTsQNOo1xKEn1GzGDc/PWxLuk/KCBERGLohJoV+GBAZ9rUrcydo75h5JQfYl3SvyggRERirEr5FF6/sT3ntkjnsY8W8eSn3xeLm/0pIEREioEyyYm8cHU7rupQj2ETV3DvmPkcOHQ4pjVF62Z9IiKSj8QE488Xn0x6hTI8+8VStu3azwtXt6VcSmy+qrUFISJSjJgZd53dhL9c0pJJSzfT58WZbNu1Pya1KCBERIqhqzrU42+/acf3G3Zw2d+msWbb7qjXoIAQESmmzm1Ri7/f1IEtWfu4cMgUvvq+MDfFPnYKCBGRYuzUBlX54PYuHF+pLDe8OpsnPl0ctYPXCggRkWKuYfXyvHfbaVzVoR7DJ66kz4gZbPgl8rfnUECIiJQAZZIT+cslLRl8ZRsWb9jB+c9NIXPJpoh+pgJCRKQE6d2mNuPu6ELNCqlc98os/vr59xyM0C4nBYSISAnTuEYa7w/ozJWn1mXohBVc/dLMiNw2XBfKiYiUQGWSE3nyV63o0KgqM1Zso1xKYpF/hgJCRKQEu+SUOlxySo4Tcx6ziO1iMrOmZjYv7LHDzAZmW8bM7DkzW25mC8ysbVjfobB1x0WqThERyVnEtiDcfQnQBsDMEoF1wNhsi/UCmgSPDsDfgp8Ae9y9TaTqExGRvEXrIPVZwAp3X52tvTfwuofMACqb2XFRqklERPIQrWMQVwKjcmivDawJe702aNsAlDGz2cBB4El3fz+nNzazfkA/gPT0dDIzM3MtIisrK8/+eKfxyZvGJ38ao7yVtPGJeECYWQpwEfBQIVet7+7rzKwR8JWZLXT3FdkXcvcRwAiAjIwM79atW65vmJmZSV798U7jkzeNT/40RnkraeMTjV1MvYC57p7TXabWAXXDXtcJ2nD3Iz9XApnAKZEtU0REwkUjIPqQ8+4lgHHANcHZTB2BX9x9g5lVMbNUADOrDnQGFkWhVhERCUR0F5OZlQd6ALeEtfUHcPdhwCfAecByYDdwfbDYScBwMztMKMSedHcFhIhIFFlxmBi7qJjZZiD7mVLhqgNbolROSaTxyZvGJ38ao7wVx/Gp7+41cuooVQGRHzOb7e4Zsa6juNL45E3jkz+NUd5K2vjoZn0iIpIjBYSIiOQo3gJiRKwLKOY0PnnT+ORPY5S3EjU+cXUMQkRECi7etiBERKSAFBAiIpKjuAgIM+tpZkuCeScejHU9xYGZjTSzTWb2bVhbVTMbb2bLgp9VYlljLJlZXTObYGaLzOw7M7sraNcYAWZWxsy+NrP5wfj8T9De0MxmBv/X3gruxRbXzCzRzL4xs4+C1yVmjEp9QARzUQwldE+o5kAfM2se26qKhVeBntnaHgS+dPcmwJfB63h1ELjX3ZsDHYEBwb8bjVHIPuBMd29NaN6XnsHtcp4CnnX3E4CfgRtjV2KxcRewOOx1iRmjUh8QQHtgubuvdPf9wGhC81DENXefBGzL1twbeC14/hpwcTRrKk7cfYO7zw2e7yT0H7w2GiMAgjlcsoKXycHDgTOBd4L2uB2fI8ysDnA+8FLw2ihBYxQPAZHbnBPy39LdfUPw/CcgPZbFFBdm1oDQ3YRnojH6l2DXyTxgEzAeWAFsd/eDwSL6vwaDgN8Ch4PX1ShBYxQPASFHwUPnP8f9OdBmlga8Cwx09x3hffE+Ru5+KJgWuA6hLfVmsa2oeDGzC4BN7j4n1rUcrWjNKBdLuc45If9lo5kdF9xy/ThCfxnGLTNLJhQO/3D394JmjVE27r7dzCYAnQhNG5wU/IUc7//XOgMXmdl5QBmgIjCYEjRG8bAFMQtoEpw5kEJo+tNxMa6puBoHXBs8vxb4IIa1xFSwr/hlYLG7PxPWpTECzKyGmVUOnpcldFv/xcAE4LJgsbgdHwB3f8jd67h7A0LfO1+5+9WUoDGKiyupgwQfBCQCI939z7GtKPbMbBTQjdDthzcCjwDvA28D9QjdNv1yd89+IDsumFkXYDKwkH/vP/4doeMQcT9GZtaK0AHWREJ/aL7t7o8FUwSPBqoC3wC/cfd9sau0eDCzbsB97n5BSRqjuAgIEREpvHjYxSQiIkdBASEiIjlSQIiISI4UECIikiMFhIiI5EgBIVIIZnbIzOaFPYrsZn1m1iD87roisRYPV1KLFKU9we0lREo9bUGIFAEzW2Vm/2tmC4N5Ek4I2huY2VdmtsDMvjSzekF7upmNDeZTmG9mpwVvlWhmLwZzLPwzuEpZJCYUECKFUzbbLqYrwvp+cfeWwBBCV+4DPA+85u6tgH8AzwXtzwETg/kU2gLfBe1NgKHu3gLYDvwqor+NSB50JbVIIZhZlrun5dC+itAEOiuDm/z95O7VzGwLcJy7HwjaN7h7dTPbDNQJv8VCcFvx8cFkRJjZA0Cyu/8pCr+ayH/RFoRI0fFcnhdG+D15DqHjhBJDCgiRonNF2M/pwfNphO7kCXA1oRsAQmi60lvhXxPvVIpWkSIFpb9ORAqnbDCL2hGfufuRU12rmNkCQlsBfYK2O4BXzOx+YDNwfdB+FzDCzG4ktKVwK7ABkWJExyBEikBwDCLD3bfEuhaRoqJdTCIikiNtQYiISI60BSEiIjlSQIiISI4UECIikiMFhIiI5EgBISIiOfp/OrnfVnaLn/AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_u regression focused\n",
    "if 'max_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_max_u.csv']) \n",
    "    regressor_max_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regressor_focused_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_focused['y_train'].shape[1]\n",
    "    regressor_max_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_focused', regressor_max_u_focused)\n",
    "else: \n",
    "    print('Loading max_u regression focused')\n",
    "    regressor_max_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\\\max_u_regressor_focused')\n",
    "\n",
    "testing_data['max_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(models, regressor_max_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_sparse['y_test'].columns)\n",
    "    testing_data['max_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_focused'][model]['real'] = deepcopy(data_max_u_sparse['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training max_u classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:28:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:28:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:28:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:28:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:28:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:28:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:28:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:28:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_u classification\n",
    "if 'max_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_gradient_boost_classifier_max_u.csv'])\n",
    "    classifier_max_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_xgboost_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_support_vector_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_mlp_classifier_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_bool['y_train'].shape[1]\n",
    "    regressor_max_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier', classifier_max_u)\n",
    "else: \n",
    "    print('Loading max_u classification')\n",
    "    classifier_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier')\n",
    "\n",
    "testing_data['max_u_classifier'] = {}\n",
    "for model, strategy in zip(models, classifier_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_bool)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_bool['y_test'].columns)\n",
    "    testing_data['max_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_classifier'][model]['real'] = deepcopy(data_max_u_bool['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min u regression training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training min_u regression sparse\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsUElEQVR4nO3deXyV5Zn/8c+Vfd8IhECAsMqiiIKgRS24otNi27FVp+PUTpWZaWlrZ2qrM61tre102k6rrc5v6jhWp9NKHVstWlpXUOsKKKjsEdmXkAAJgZD1+v1xntBDPGAO5ORJcr7v1+t5nfNs53zJOeTKfd/PYu6OiIhIZylhBxARkd5JBUJERGJSgRARkZhUIEREJCYVCBERiUkFQkREYlKBEDlJZjbRzJaZmYWYwc1szDHWfdjMft3TmaTvU4GQfsvMNpnZRT3wVt8GfujBSUXB+zaaWUPUdFcP5IjJ3R8DJpnZ5LAySN+kAiFyEsysHJgNPNpp1YfdPS9qmt/z6Y7yIDAv5AzSx6hASFIxs0wzu8PMdgTTHWaWGawrNbPHzWy/me01sxfMLCVY91Uz225mB8xsnZldGLzkxcDr7n64i+9/nZm9aGZ3mVmdma2Nei3MbIiZLQzev8rMbohal2pm/2xm7wQ5lpvZsKiXv8jMNgT57+7U5bUE+IsT+6lJskoLO4BID/sX4GxgCuDA74CvAV8H/gnYBgwMtj0bcDM7BZgPnOXuO8ysEkgNtjkNWBdnhhnAw0Ap8DHgt2Y20t33AguAt4EhwHjgKTN7x92fBf4RuAa4HFgPTAYORb3uh4CzgAJgOfAY8Mdg3Rqg0swK3L0+zrySpNSCkGTzSeA2d6929z3At4Brg3UtQDkwwt1b3P2FYFyhDcgEJppZurtvcvd3gn2KgAMx3ufR4C/5jumGqHXVwB3Be/yaSIH5i6A1MBP4qrsfdvcVwL3A3wT7XQ98zd3XecRKd6+Net3vuft+d98CLCZSBDt0ZCyK42clSU4FQpLNEGBz1PzmYBnAD4Aq4Ekz22hmNwO4exVwI/BNoNrMFphZxz77gPwY7/MRdy+Kmv4rat32jgHtThmGAHvd/UCndUOD58OAdzi2XVHPDwF5UfMdGfcfZ3+Ro6hASLLZAYyImh8eLMPdD7j7P7n7KGAu8I8d4wPu/it3PzfY14F/C/Z/ExgXZ4ahncYHOjLsAErMLL/Tuu3B863A6Djfq8MEYJO6lyQeKhDS36WbWVbHRORonq+Z2UAzKwVuBf4XwMw+ZGZjgl/edUS6ltrN7BQzuyAYzD4MNALtwes/BZwZvHZXDQK+YGbpZvZxIr+8F7n7VuAl4F+DvJOBz3TkI9Ld9G0zG2sRk81sQBff84PAH+LIKKICIf3eIiK/0DumLGAZkb/83wJeB24Pth0LPA00AC8D/+Hui4mMP3wPqCHSjTMIuAXA3XcDzwJXdHrfxzqdB/FI1LpXg/eqAb4DXBk1lnANUEmkNfEI8A13fzpY9yPgIeBJoB74byC7iz+Ha4CfdXFbEQBMNwwSOTlmNhF4AJju7/MfysyuA64Puqt6hJl9GLjW3T/RU+8p/YMOcxU5Se6+msjhpb1ScCb1Y2HnkL5HXUwiIhKTuphERCQmtSBERCSmfjMGUVpa6pWVlV3e/uDBg+Tm5iYu0AlSrvgoV3yUKz7JkGv58uU17j4w5kp37xfT1KlTPR6LFy+Oa/ueolzxUa74KFd8kiEXsMyP8XtVXUwiIhKTCoSIiMSkAiEiIjGpQIiISEwqECIiEpMKhIiIxKQCISIiMSV9gag71MKdT2/grW11YUcREelV+s2Z1CfKUuDHT68nLdU4raIw7DgiIr1G0rcgCrLSqSjOZu2uWPedFxFJXklfIADGD85n7U7dqldEJJoKBDB+cAEbaw7S1NoWdhQRkV5DBQIYX55PW7tTVd0QdhQRkV5DBYJICwJg7U6NQ4iIdFCBACoH5JCZlsLaXRqHEBHpkNACYWZzzGydmVWZ2c0x1v/YzFYE03oz2x+1ri1q3cJE5kxLTWFsWZ6OZBIRiZKw8yDMLBW4G7gY2AYsNbOF7r66Yxt3/1LU9p8Hzoh6iUZ3n5KofJ2NH1zAknV7eurtRER6vUS2IKYDVe6+0d2bgQXAFcfZ/hrgwQTmOa7xg/OpaWiipqEprAgiIr2KRe44l4AXNrsSmOPu1wfz1wIz3H1+jG1HAK8AFe7eFixrBVYArcD33P3RGPvNA+YBlJWVTV2wYEGX8zU0NJCXl3dkfnVtG99fepivnJXFxAGpXX6d7tY5V2+hXPFRrvgoV3y6M9fs2bOXu/u0mCuPdS/Sk52AK4F7o+avBe46xrZfBX7aadnQ4HEUsAkYfbz3O9l7Uu85cNhHfPVx/6/n34nrdbpbMtwDtzspV3yUKz7JkIuQ7km9HRgWNV8RLIvlajp1L7n79uBxI7CEo8cnul1pXialeZkaqBYRCSSyQCwFxprZSDPLIFIE3nM0kpmNB4qBl6OWFZtZZvC8FJgJrO68b3ebUJ6vQ11FRAIJKxDu3grMB54A1gAPufsqM7vNzOZGbXo1sCBo6nSYACwzs5XAYiJjEAkvEOMH57N+dwOtbe2JfisRkV4voZf7dvdFwKJOy27tNP/NGPu9BJyWyGyxjB9cQHNrO5tqDzFmUO8bmBIR6Uk6kzrKKYPzAdTNJCKCCsRRxgzKIzXFdE0mERFUII6SlZ7KqNJctSBERFCBeI/x5QWsUQtCREQForPxg/PZvr+R+sMtYUcREQmVCkQn4zsGqtWKEJEkpwLRyWlDCwF4c9v+cIOIiIRMBaKTQQVZDC7I4s1tdWFHEREJlQpEDJMrCnlruwqEiCQ3FYgYJlcU8m7NQeoaNVAtIslLBSKGyRVFALytVoSIJDEViBg6BqpXaqBaRJKYCkQMxbkZDC/J4S0NVItIElOBOIbTKgp1JJOIJDUViGM4vaKQ7fsbqWloCjuKiEgoVCCOoWOgWt1MIpKsVCCO4dShhZhpoFpEkpcKxDHkZaYxemCeWhAikrRUII5j8tBCVm6r4+jbZYuIJAcViOOYXFFITUMTu+oPhx1FRKTHqUAcx2nBQPXKrepmEpHkowJxHJOGFJCWYrr0t4gkJRWI48hKT2VcWb6u7CoiSUkF4n1MDs6o1kC1iCQbFYj3MWVYEXWNLbyz52DYUUREepQKxPuYVlkCwLJNe0NOIiLSs1Qg3sfogbmU5GawdNO+sKOIiPSohBYIM5tjZuvMrMrMbo6x/sdmtiKY1pvZ/qh1nzKzDcH0qUTmPB4zY9qIYpZtVgtCRJJLWqJe2MxSgbuBi4FtwFIzW+juqzu2cfcvRW3/eeCM4HkJ8A1gGuDA8mDfUP6MP6uyhCdX76a6/jCDCrLCiCAi0uMS2YKYDlS5+0Z3bwYWAFccZ/trgAeD55cCT7n73qAoPAXMSWDW45pWWQzAss3qZhKR5GGJOnzTzK4E5rj79cH8tcAMd58fY9sRwCtAhbu3mdmXgSx3vz1Y/3Wg0d1/2Gm/ecA8gLKysqkLFizocr6Ghgby8vK6tG1ru/PZpw/xwWFpfHJCZpff40TEk6snKVd8lCs+yhWf7sw1e/bs5e4+Lda6hHUxxelq4GF3b4tnJ3e/B7gHYNq0aT5r1qwu77tkyRLi2f7MqpfZ2dTKrFnnxRMxbvHm6inKFR/lio9yxaenciWyi2k7MCxqviJYFsvV/Ll7Kd59e8T0yhJW76inoak1zBgiIj0mkQViKTDWzEaaWQaRIrCw80ZmNh4oBl6OWvwEcImZFZtZMXBJsCw00ypLaHd4Y4vGIUQkOSSsQLh7KzCfyC/2NcBD7r7KzG4zs7lRm14NLPCowRB33wt8m0iRWQrcFiwLzRnDi0gxdD6EiCSNhI5BuPsiYFGnZbd2mv/mMfa9D7gvYeHilJ+VzoTyAp1RLSJJQ2dSx+GsyhLe2LKflrb2sKOIiCScCkQczqosobGljdU76sOOIiKScCoQceg4YW6puplEJAmoQMShrCCL4SU5KhAikhRUIOI0fWQJr767l7Z23UBIRPo3FYg4nTe2lP2HWli1Q7chFZH+TQUiTjPHlALwwoaakJOIiCSWCkScSvMymTSkgOfX7wk7iohIQqlAnIDzxg7k9S37dF0mEenXVCBOwPljS2lpc17dWBt2FBGRhFGBOAFTK4vJSk/ROISI9GsqECcgMy2Vs0cN4PkNGocQkf5LBeIEnTd2IBv3HGTbvkNhRxERSQgViBN0/tjI4a5/UjeTiPRTKhAnaMygPMoLszQOISL9lgrECTIzzhtbyp+qanTZDRHpl1QgTsJ5YwdS19jCW9t12Q0R6X9UIE7CzDGlmKGzqkWkX1KBOAkluRlMrijimTW7w44iItLtVCBO0qWTyli5rY7t+xvDjiIi0q1UIE7SnEmDAXhy1a6Qk4iIdC8ViJM0amAep5Tl88e3VSBEpH9RgegGl546mKWb9lLT0BR2FBGRbqMC0Q3mTBpMu8NTqzVYLSL9hwpEN5hQns/wkhx1M4lIv6IC0Q3MjMtOHcxL79RQ19gSdhwRkW6hAtFNLj11MC1tzuK11WFHERHpFgktEGY2x8zWmVmVmd18jG0+YWarzWyVmf0qanmbma0IpoWJzNkdplQUUVaQyR/e3hl2FBGRbpGWqBc2s1TgbuBiYBuw1MwWuvvqqG3GArcAM919n5kNinqJRnefkqh83S0lxbh00mAeWraVQ82t5GQk7EcrItIjEtmCmA5UuftGd28GFgBXdNrmBuBud98H4O59un9mzqTBHG5p57l1ujaTiPR9iSwQQ4GtUfPbgmXRxgHjzOxFM3vFzOZErcsys2XB8o8kMGe3mT6yhNK8TB5dsT3sKCIiJ83cE3MvAzO7Epjj7tcH89cCM9x9ftQ2jwMtwCeACuB54DR3329mQ919u5mNAp4FLnT3dzq9xzxgHkBZWdnUBQsWdDlfQ0MDeXl5J/VvjOXBtU08vbmVO2fnkJdhce+fqFwnS7nio1zxUa74dGeu2bNnL3f3aTFXuntCJuAc4Imo+VuAWzpt85/Ap6PmnwHOivFa9wNXHu/9pk6d6vFYvHhxXNt31eoddT7iq4/7/S++e0L7JyrXyVKu+ChXfJQrPt2ZC1jmx/i9msgupqXAWDMbaWYZwNVA56ORHgVmAZhZKZEup41mVmxmmVHLZwKr6QMmlBcwsbyA37y+LewoIiInJWEFwt1bgfnAE8Aa4CF3X2Vmt5nZ3GCzJ4BaM1sNLAZucvdaYAKwzMxWBsu/51FHP/V2fzm1gje31bFh94Gwo4iInLCEHovp7ouARZ2W3Rr13IF/DKbobV4CTktktkS6YsoQvrtoDQ+/vo1bLpsQdhwRkROiM6kToDQvk1njBvLoG9tpa0/MQQAiIommApEgfzm1gt31TfypqibsKCIiJ0QFIkEunDCIwux0frNcg9Ui0jd1qUCYWa6ZpQTPx5nZXDNLT2y0vi0zLZUPn17OE6t2UX9YV3gVkb6nqy2I54mc2TwUeBK4lsi5CXIcH586jKbWdh55XWdWi0jf09UCYe5+CPgY8B/u/nFgUuJi9Q+nDytiyrAiHnhpE+0arBaRPqbLBcLMzgE+Cfw+WJaamEj9y6dnVrKx5iDPbdAF/ESkb+lqgbiRyKUyHglOdhtF5AQ2eR+XnVrOoPxMfv7iprCjiIjEpUsFwt2fc/e57v5vwWB1jbt/IcHZ+oWMtBSuPXsEz6/fQ1V1Q9hxRES6rKtHMf3KzArMLBd4G1htZjclNlr/8VczhpORlsL9L70bdhQRkS7rahfTRHevBz4C/AEYSeRIJumCAXmZzD19CL9Zvp26Rh3yKiJ9Q1cLRHpw3sNHgIXu3gLosJw4fHpmJY0tbTy0dOv7bywi0gt0tUD8DNgE5ALPm9kIoD5RofqjSUMKmT6yhAde3kRrW3vYcURE3ldXB6l/4u5D3f3y4B4Tm4HZCc7W71x/7ki27Wvkdyt2hB1FROR9dXWQutDMfhTcI3qZmf07kdaExOHiiWVMLC/gp89uUCtCRHq9rnYx3QccIHLv6E8Q6V76eaJC9Vdmxo0XjWVT7SEeVStCRHq5rhaI0e7+DXffGEzfAkYlMlh/dfHEMiYNUStCRHq/rhaIRjM7t2PGzGYCjYmJ1L9FWhHj2Fx7iEfe0EX8RKT36uotR/8e+B8zKwzm9wGfSkyk/u+iCYM4dWgBdy2u4qNnDCUtVbflEJHep6tHMa1099OBycBkdz8DuCChyfoxM+PGC9WKEJHeLa4/Xd29PjijGuAfE5AnaVw4YRCnDS3kzmc2cLilLew4IiLvcTJ9G9ZtKZKQmXHzZePZtq+R//6TrtEkIr3PyRQIXWrjJM0cU8rFE8u4e3EV1fWHw44jInKU4xYIMztgZvUxpgPAkB7K2K/9y+UTaG1zvv/EurCjiIgc5bgFwt3z3b0gxpTv7l09AkqOo7I0l0+fW8nDy7excuv+sOOIiByh4yt7gfmzx1Cal8ltj6/GXT13ItI7qED0AvlZ6dx06TiWb97HKzt1RJOI9A4qEL3ElVOHcdrQQh5c28S+g81hxxERSWyBMLM5ZrbOzKrM7OZjbPMJM1ttZqvM7FdRyz9lZhuCqd+ftZ2aYnz/yskcbIFvPrYq7DgiIokrEGaWCtwNXAZMBK4xs4mdthkL3ALMdPdJwI3B8hLgG8AMYDrwDTMrTlTW3mJCeQFzR6fzuxU7eGLVrrDjiEiSS2QLYjpQFVz9tRlYAFzRaZsbgLvdfR+Au1cHyy8FnnL3vcG6p4A5Cczaa/zFqHQmlBfwL4+8zf5D6moSkfBYoo6aMbMrgTnufn0wfy0ww93nR23zKLAemAmkAt909z+a2ZeBLHe/Pdju60Cju/+w03vMA+YBlJWVTV2wYEGX8zU0NJCXl3cS/8LEaGhooLY9m9tePsyM8jTmTc4MOxLQu39eytV1yhWfZMg1e/bs5e4+Lda6sM9lSAPGArOACiL3uz6tqzu7+z3APQDTpk3zWbNmdfmNlyxZQjzb95QlS5bwoVmzqM1ez0+e2cB1F57OJZMGhx2rV/+8lKvrlCs+yZ4rkV1M24FhUfMVwbJo24CF7t7i7u8SaU2M7eK+/dr82WOYNKSAr/zmTXbW6dYbItLzElkglgJjzWykmWUAVwMLO23zKJHWA2ZWCowDNgJPAJeYWXEwOH1JsCxpZKSl8NNrzqC5tZ0vPrhCd58TkR6XsALh7q3AfCK/2NcAD7n7KjO7zczmBps9AdSa2WpgMXCTu9e6+17g20SKzFLgtmBZUhk1MI/vfPRUXtu0l588WxV2HBFJMgkdg3D3RcCiTstujXruRO4r8Z57S7j7fcB9iczXF3z0jAperKrlp89u4OxRJXxgdGnYkUQkSehM6j7gW3MnMbI0lxsXrGDPgaaw44hIklCB6ANyM9O4+6/OpP5wC/N+sUx3oBORHqEC0UdMKC/gjqum8MaW/Xzl4Td11VcRSTgViD5kzqnlfGXOKSxcuYM7n9kQdhwR6efCPlFO4vQPHxzNxj0HuePpDYwszeWKKUPDjiQi/ZQKRB9jZnz3o6exZe8hbnr4TQblZ3HO6AFhxxKRfkhdTH1QRloK91w7lRElOdzwP8t4a1td2JFEpB9SgeijinIy+MVnZlCUk86nfv4aVdUNYUcSkX5GBaIPG1yYxS8+M4MUg7/571fZvl/XbBKR7qMC0ceNLM3lgb+dzoGmVv763lfZVXc47Egi0k+oQPQDk4YUcv+nz2LPgSauuudltSREpFuoQPQTU0eU8D+fmc7ehmau+tnLbN17KOxIItLHqUD0I2cOL+aXN8ygvrGFq+95hc21B8OOJCJ9mApEPzO5oohf3XA2B5tbufI/X2bVDh0CKyInRgWiHzp1aCEP/d05pKUYV/3sFV6sqgk7koj0QSoQ/dS4snx++9kPMLQom+t+/hq/W5FUd2wVkW6gAtGPlRdm89Dfn8PUEcV8ccEK7l5cpavAikiXqUD0c4XZ6Tzwt9O5YsoQfvDEOr6wYAWNzbqfhIi8P12sLwlkpqVyx1VTGD+4gO8/sZZ3axq459ppDCnKDjuaiPRiakEkCTPjH2aN5t6/mcammkPMvetPvPSOBq9F5NhUIJLMhRPKePRzH6AgO52/vvdV7nh6PW3tGpcQkfdSgUhCYwbl89j8c/nIlKHc8fQGPnnvK+yu1zWcRORoKhBJKjczjR9dNYUffvx0Vm6t4/I7X+DJVbvCjiUivYgKRJK7cmoFj31+JoMLs5j3i+V85eGVHDjcEnYsEekFVCCEMYPyeeSzM/nc7NE8vHwbl935Aq9urA07loiETAVCgMhtTG+6dDz/9/fnkJpiXHXPK3zt0beoV2tCJGmpQMhRpo4o4Q9fPI/rzx3Jr17dwiU/ep6nVu8OO5aIhCChBcLM5pjZOjOrMrObY6y/zsz2mNmKYLo+al1b1PKFicwpR8vJSONrH5rII5+dSVFOOjf8zzJ++sZhtu3TPSZEkknCCoSZpQJ3A5cBE4FrzGxijE1/7e5TguneqOWNUcvnJiqnHNvpw4p47PPnctOlp/BWTRsX/vtz3PH0eg636FIdIskgkS2I6UCVu29092ZgAXBFAt9PEiA9NYXPzR7Dv56bzUUTy7jj6Q1c9KPn+P2bO3XhP5F+zhL1n9zMrgTmuPv1wfy1wAx3nx+1zXXAvwJ7gPXAl9x9a7CuFVgBtALfc/dHY7zHPGAeQFlZ2dQFCxZ0OV9DQwN5eXkn8k9LqN6ea01tG79c08S2BmdUYQpXnZLBKSWpoefqbZQrPsoVn+7MNXv27OXuPi3mSndPyARcCdwbNX8tcFenbQYAmcHzvwOejVo3NHgcBWwCRh/v/aZOnerxWLx4cVzb95S+kKu1rd1/vXSLz/jO0z7iq4/7Z+5f6mt31oeeqzdRrvgoV3y6MxewzI/xezWRXUzbgWFR8xXBsiPcvdbdm4LZe4GpUeu2B48bgSXAGQnMKnFITTE+MW0Yi788i5suPYVXN9Yy587nmf+r16mqPhB2PBHpJoksEEuBsWY20swygKuBo45GMrPyqNm5wJpgebGZZQbPS4GZwOoEZpUTkJ2Ryudmj+GFr87mc7PGsHhtNRf/+HluXPAGG3arUIj0dQm7H4S7t5rZfOAJIBW4z91XmdltRJo0C4EvmNlcIuMMe4Hrgt0nAD8zs3YiRex77q4C0UsV5WTw5UtP4W/PHck9z2/kgZc28eiKHVwysYzPzh7DlGFFYUcUkROQ0BsGufsiYFGnZbdGPb8FuCXGfi8BpyUym3S/ktwMbr5sPH93/ijuf2kT97+0iSdXv8gHRg9g3vmj+OC4gZhZ2DFFpIt0JrV0u+LcDL508ThevPkC/vny8byzp4Hrfr6UOXe8wP8t20pTq86jEOkLVCAkYfIy05h3/mhe+MoF/PvHT8cMbnr4TWZ+bzE/emq97kEh0svpntSScBlpKfzl1Ao+duZQXthQw89ffJefPruB/1hcxWWnlXPt2SM4q7JY3U8ivYwKhPQYM+P8cQM5f9xANtUc5BevbOahZVt5bOUORg/M5Zrpw/nYmRWU5GaEHVVEUBeThKSyNJevf2gir/7zhfzgyskUZqdz++/XcPZ3n+Gzv1zOM2t209LWHnZMkaSmFoSEKicjjY9PG8bHpw1j7a56Fry2lYUrd7DorV2U5mUw9/ShfOzMoUwaUqAuKJEepgIhvcb4wQV8c+4k/vnyCTy3fg+/Wb6NX7yyiftefJcxg/L46BlDuWLKECqKc8KOKpIUVCCk18lIS+HiiWVcPLGM/Yea+f1bO3n0je384Il1/OCJdZwxvIi/OK2cy08rf/8XE5ETpgIhvVpRTgafnDGCT84Ywda9h3jszR38/s2d3P77Ndz++zWMKUphQ8pGLp00mOED1LIQ6U4qENJnDCvJ4bOzxvDZWWPYuKeBRW/t5P9eqeI7i9bwnUVrmFhewCWTyrhoQpnGLES6gQqE9EmjBuYx/4KxnJqyndGTp/PHt3fxx1W7uPOZDdzx9AbKC7O4YPwgLpwwiHNGlZKdEd49K0T6KhUI6fOGleRww/mjuOH8UdQ0NLF4bTVPr9nNI29s55evbiEzLYVzRg/ggvGDOH/sQEYMyFHrQqQLVCCkXynNyzxy2GxTaxuvbtzL4nXVLF5bza2/WwXAsJJszhs7kPPGlHLO6AEU5ejEPJFYVCCk38pMSz1y5vY3PjyJd2sO8qcNe3h+Qw0LV+zgV69uwQxOHVLIB8YMYOboUqZVFpOTof8WIqACIUlkZGkuI0tzufacSlra2lm5dT8vVtXyYlUN9/3pXX723EbSUozThxVx9qgSzh41gDOHF5Obqf8mkpz0zZeklJ6awrTKEqZVlvDFi8ZysKmVZZv38crGWl5+p5b/fG4jdy9+h9QU49ShhcwYWcK0EcVMHVHMgLzMsOOL9AgVCBEgNzOND44byAfHDQSgoamV5Zv38dq7tbz27l7uf3ET9zy/EYi0RM4cXsyZI4o4c3gx48rySU3RoLf0PyoQIjHkdSoYh1vaeGt7Hcs372PZpn0sXlfNb17fdmTb04cVcnpFEVOGFekWq9JvqECIdEFWeipnVZZwVmUJfBDcnS17D/H6ln28vnk/b2zdxz3Pb6S13QEoyTKmbVnG5IpCJlcUcerQQl3GXPocFQiRE2BmjBiQy4gBuXz0jAog0spYtaOON7bs5+nX17OhuoEnV+8+ss+QwiwmDilk0pCCyDS0kCGFWTonQ3otFQiRbpKVnsrUESVMHVHCmLYtzJo1i7rGFt7eXseqHXW8vb2eVTvqeGbtbjzS0KAoJ52J5QVMODLlM3ZQPhlpulWLhE8FQiSBCrPTmTmmlJljSo8sO9TcypqdB1i9s57VO+pYvaOe/31lM02tkRskpaUYowbmMq4sn1PK8jllcD7jyvIZVpKjwXDpUSoQIj0sJyONqcEhsx3a2p13aw6yZmc9a3bWs353Ayu37efxN3ce2SYrPYWxg/IZW5YXeRyUx7iyfIYWZ6twSEKoQIj0AqkpxphBeYwZlMeHTx9yZHlDUytV1Q2s33WAdbsPsH73AV6qquW3r28/sk1mWgojS3MZMyiP0QPzGDUw98ijzgqXk6Fvj0gvlpeZFvPQ2brGFqqqG9iw+wDv7GmgqjrS4vj9WzuPjG8AlBdmHTmDfGRpLg3VrQzb08Cw4hyNc8j7UoEQ6YMKs9Pf000FkSOpNtUeZOOeg7xT3cDGmoO8W3OQx9/cSV1jCwB3vP4cKQYVxTmMGJBD5YBcRgzIYXhJDiMG5DK8JEeXRxdABUKkX8lKT2X84ALGDy54z7q9B5v57ZMvUDz8FDbVRgrH5tpDPLp1OwcOtx617cD8TEaU5DCsJIeK4myGFedQURJ5LC/MIi1VrY9kkNACYWZzgDuBVOBed/9ep/XXAT8AOjpU73L3e4N1nwK+Fiy/3d0fSGRWkf6uJDeDMcWpzJpacdRyd2f/oRY21R5ky95DbN17iM21h9iy9xCvvbuX361opD2q2yo1xSgvzKKiOJuK4hyGFmUztDibiuBxcGEWmWlqgfQHCSsQZpYK3A1cDGwDlprZQndf3WnTX7v7/E77lgDfAKYBDiwP9t2XqLwiycrMKM7NoDg3gzOGF79nfUtbOzv3H2brvkjx2Lavka37Io9/2lDD7gOHjxr3MIOBeZkMKcpmaFE25YVZDCnKZkhRFoMLI/OleZk68qoPSGQLYjpQ5e4bAcxsAXAF0LlAxHIp8JS77w32fQqYAzyYoKwicgzpqSkMH5DD8AE5Mdc3t7azs66R7fsa2b4/mPY1srPuMGt21vP0mt1HzvHokJZiDMrPZHBhFoMLs2itb2JDykbKCrMoL8xicEEWgwoy1RIJmXl06e/OFza7Epjj7tcH89cCM6JbC0EX078Ce4D1wJfcfauZfRnIcvfbg+2+DjS6+w87vcc8YB5AWVnZ1AULFnQ5X0NDA3l5eSfxL0wM5YqPcsUnjFzuzoEW2He4nb2HnX2HPeqxnX1Nzt7Gdprb39uiyEuH4qwUijItMmUZxR3Pg/mCDCMtQa2RZPgcZ8+evdzdp8VaF/Yg9WPAg+7eZGZ/BzwAXNDVnd39HuAegGnTpvmsWbO6/MZLliwhnu17inLFR7ni01tzLV68mDPPPpfd9YfZWXeY3XWH2V1/mF31kcfqA02sqztMzY6mo8ZDINKlVZKTwcD8TAbmZzIoP+vI84H5mZTmZTAwL5PSvEyKctLjuvZVb/159VSuRBaI7cCwqPkK/jwYDYC710bN3gt8P2rfWZ32XdLtCUWkVzAzCrPTKcxOZ1xZ/jG3a21rp6ahmeoDh6mub6L6QFPk+YEmquub2NPQxDvVNdQ0NNPc1v6e/dNTjZLcDErzMhmQ9+fiMSAvgwG5kcfSYF5X301sgVgKjDWzkUR+4V8N/FX0BmZW7u4d1xKYC6wJnj8BfNfMOkbMLgFuSWBWEekD0lJTjoxbHI+7U9/YSvWBw+xpaKKmoZmaA03UNESm2oZmahqaeKe6gT0NTTS3vreYAGSnQdnSxZTkZjAgL5MBwWD+gNxIAemYinMijzkZqf3q6rwJKxDu3mpm84n8sk8F7nP3VWZ2G7DM3RcCXzCzuUArsBe4Lth3r5l9m0iRAbitY8BaROT9mBmFOekU5qQz9jgtEogUk4PNbdQcaKL2YKR41B5sprahiRVrN5JdXMTeg01s3XuIFVv3s+9g85H7fnSWkZZCSU6kiBTnpFOcmxGZD54X5aRTlBMpKMXB84KstF5bVBI6BuHui4BFnZbdGvX8Fo7RMnD3+4D7EplPRMTMyMtMIy8zjcrS3KPWLUnZzqxZZxy1zN2pP9zK3oPN7D3YzL7gsfZgM/sPNbPvUDN7D7aw71Aza3bWs+9gM/sbWzjW8UCpKZHutaKcdIqy0ynOyaAwJ52i7I6Ckn6k+y2yXQYHmp3WtvaEn7AY9iC1iEifEj1eMrJTQTmWtnanrjFSNPYfagkKSeRx/6FgeWNkflf9YdbuOkBdYwsNTa3HftFn/0B+ZhoF2emcMbyIu/7qzG76F/6ZCoSISIKlptiR8Yp4tLS1U9fYwv5DLdQ1tlDX2ExdYwvLVq5hYMWIYFkLgwuOPyZzolQgRER6qfTUFEqDQ3SjFddVMWvWuIS/v664JSIiMalAiIhITCoQIiISkwqEiIjEpAIhIiIxqUCIiEhMKhAiIhKTCoSIiMSUsBsG9TQz2wNsjmOXUqAmQXFOhnLFR7nio1zxSYZcI9x9YKwV/aZAxMvMlh3rLkphUq74KFd8lCs+yZ5LXUwiIhKTCoSIiMSUzAXinrADHINyxUe54qNc8UnqXEk7BiEiIseXzC0IERE5DhUIERGJKekKhJnNMbN1ZlZlZjeHnOU+M6s2s7ejlpWY2VNmtiF4LO7hTMPMbLGZrTazVWb2xV6SK8vMXjOzlUGubwXLR5rZq8Hn+Wszi++WXd2XL9XM3jCzx3tZrk1m9paZrTCzZcGyUD/LIEORmT1sZmvNbI2ZnRN2LjM7Jfg5dUz1ZnZj2LmCbF8Kvvdvm9mDwf+HhH/HkqpAmFkqcDdwGTARuMbMJoYY6X5gTqdlNwPPuPtY4Jlgvie1Av/k7hOBs4HPBT+jsHM1ARe4++nAFGCOmZ0N/BvwY3cfA+wDPtPDuTp8EVgTNd9bcgHMdvcpUcfNh/1ZAtwJ/NHdxwOnE/nZhZrL3dcFP6cpwFTgEPBI2LnMbCjwBWCau58KpAJX0xPfMXdPmgk4B3giav4W4JaQM1UCb0fNrwPKg+flwLqQ8/0OuLg35QJygNeBGUTOJk2L9fn2YJ4KIr84LgAeB6w35AreexNQ2mlZqJ8lUAi8S3CQTG/J1SnLJcCLvSEXMBTYCpQQuU3048ClPfEdS6oWBH/+QXfYFizrTcrcfWfwfBdQFlYQM6sEzgBe7Q25gm6cFUA18BTwDrDf3VuDTcL6PO8AvgK0B/MDekkuAAeeNLPlZjYvWBb2ZzkS2AP8POiWu9fMcntBrmhXAw8Gz0PN5e7bgR8CW4CdQB2wnB74jiVbgehTPPKnQSjHIZtZHvAb4EZ3r+8Nudy9zSPN/wpgOjC+pzN0ZmYfAqrdfXnYWY7hXHc/k0i36ufM7PzolSF9lmnAmcD/c/czgIN06rYJ+bufAcwF/q/zujByBWMeVxAprEOAXN7bNZ0QyVYgtgPDouYrgmW9yW4zKwcIHqt7OoCZpRMpDr9099/2llwd3H0/sJhIs7rIzNKCVWF8njOBuWa2CVhApJvpzl6QCzjy1yfuXk2kP3064X+W24Bt7v5qMP8wkYIRdq4OlwGvu/vuYD7sXBcB77r7HndvAX5L5HuX8O9YshWIpcDYYPQ/g0gzcmHImTpbCHwqeP4pImMAPcbMDPhvYI27/6gX5RpoZkXB82wi4yJriBSKK8PK5e63uHuFu1cS+T496+6fDDsXgJnlmll+x3Mi/epvE/Jn6e67gK1mdkqw6EJgddi5olzDn7uXIPxcW4CzzSwn+P/Z8fNK/HcsrEGgsCbgcmA9kf7rfwk5y4NE+hRbiPxV9Rki/dfPABuAp4GSHs50LpEm9JvAimC6vBfkmgy8EeR6G7g1WD4KeA2oItIlkBni5zkLeLy35AoyrAymVR3f97A/yyDDFGBZ8Hk+ChT3kly5QC1QGLWsN+T6FrA2+O7/Asjsie+YLrUhIiIxJVsXk4iIdJEKhIiIxKQCISIiMalAiIhITCoQIiISkwqESBzMrK3TFT+77cJtZlZpUVf2FQlb2vtvIiJRGj1yuQ+Rfk8tCJFuENx34fvBvRdeM7MxwfJKM3vWzN40s2fMbHiwvMzMHgnub7HSzD4QvFSqmf1XcO3/J4OzxkVCoQIhEp/sTl1MV0Wtq3P304C7iFzhFeCnwAPuPhn4JfCTYPlPgOc8cn+LM4mc6QwwFrjb3ScB+4G/TOi/RuQ4dCa1SBzMrMHd82Is30TkhkYbg4sd7nL3AWZWQ+ReAi3B8p3uXmpme4AKd2+Keo1K4CmP3JgGM/sqkO7ut/fAP03kPdSCEOk+fozn8WiKet6GxgklRCoQIt3nqqjHl4PnLxG5yivAJ4EXgufPAP8AR26EVNhTIUW6Sn+diMQnO7irXYc/unvHoa7FZvYmkVbANcGyzxO5c9pNRO6i9ulg+ReBe8zsM0RaCv9A5Mq+Ir2GxiBEukEwBjHN3WvCziLSXdTFJCIiMakFISIiMakFISIiMalAiIhITCoQIiISkwqEiIjEpAIhIiIx/X9Juh20g9tWcgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min_u regression sparse\n",
    "if 'min_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_min_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regressor_sparse_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_sparse['y_train'].shape[1]\n",
    "    regressor_max_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_min_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse', regressor_min_u)\n",
    "else:\n",
    "    print('Loading min_u regression sparse')\n",
    "    regressor_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse')\n",
    "\n",
    "testing_data['min_u_regressor_sparse'] = {}\n",
    "for model, strategy in zip(models, regressor_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_sparse['y_test'].columns)\n",
    "    testing_data['min_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_sparse'][model]['real'] = deepcopy(data_min_u_sparse['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training min_u regression focused\n",
      "[17:13:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:13:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min_u regression focused\n",
    "if 'min_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regressor_focused_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_focused['y_train'].shape[1]\n",
    "    regressor_max_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_min_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused', regressor_min_u_focused)\n",
    "else:\n",
    "    print('Loading min_u regression focused')\n",
    "    regressor_min_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused')\n",
    "\n",
    "testing_data['min_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(models, regressor_min_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_sparse['y_test'].columns)\n",
    "    testing_data['min_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_focused'][model]['real'] = deepcopy(data_min_u_sparse['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training min_u classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:34:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:34:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:34:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:34:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:34:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:34:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:34:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:35:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min_u classification\n",
    "if 'min_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_gradient_boost_classifier_max_u.csv'])\n",
    "    classifier_min_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_xgboost_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_support_vector_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier', classifier_min_u)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_mlp_classifier_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_bool['y_train'].shape[1]\n",
    "    regressor_max_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_min_u_bool)\n",
    "else: \n",
    "    print('Loading min_u classification')\n",
    "    classifier_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier')\n",
    "\n",
    "testing_data['min_u_classifier'] = {}\n",
    "for model, strategy in zip(models, classifier_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_bool)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_bool['y_test'].columns)\n",
    "    testing_data['min_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_classifier'][model]['real'] = deepcopy(data_min_u_bool['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Discussion\n",
    "In this section the results of the training and testing are presented and compared. The main objectives of this experience is to compare the performance of the regression models in terms of the hybrid metrics confusion matrix and the hybrid metrics rmse. The comparisons will be the following:\n",
    "- Compare the confusion matrices of the classification models and the regression models evaluate with the hybrid metrics.\n",
    "- Compare the error results of the regression models trained with the focused dataset and the sparse dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1906 + 3130 = 5036 = 5036.0\n"
     ]
    }
   ],
   "source": [
    "# Testing all models: Function that receives a dict with the real and predicted values, and outputs a dataframe with the results of the metrics.\n",
    "# Accumulate all the classifications for each bus.\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for bus in testing_data['max_u_classifier']['gb']['predicted'].columns:\n",
    "    # Compute tp, tn, fp, fn\n",
    "    tp += sum((testing_data['max_u_classifier']['gb']['predicted'][bus] == 1) & (testing_data['max_u_classifier']['gb']['real'][bus] == 1))\n",
    "    tn += sum((testing_data['max_u_classifier']['gb']['predicted'][bus] == 0) & (testing_data['max_u_classifier']['gb']['real'][bus] == 0))\n",
    "    fp += sum((testing_data['max_u_classifier']['gb']['predicted'][bus] == 1) & (testing_data['max_u_classifier']['gb']['real'][bus] == 0))\n",
    "    fn += sum((testing_data['max_u_classifier']['gb']['predicted'][bus] == 0) & (testing_data['max_u_classifier']['gb']['real'][bus] == 1))\n",
    "    # try:\n",
    "    #     _tp, _tn, _fp, _fn = confusion_matrix(testing_data['max_u_classifier']['gb']['real'][bus], testing_data['max_u_classifier']['gb']['predicted'][bus]).ravel()\n",
    "    #     tp += _tp; tn += _tn; fp += _fp; fn += _fn\n",
    "    # except: \n",
    "    #     print('Problem with bus: ', bus)\n",
    "print('{} + {} = {} = {}'.format(tp, fn, tp+fn, testing_data['max_u_classifier']['gb']['real'].sum().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a multi-index dataframe with the results of the metrics. The first index is the testing_data.keys(), the second index are the tp, tn, fp, fn, and the columns are the models.\n",
    "columns = ['tp', 'tn', 'fp', 'fn', '(hybrid)accuracy', '(hybrid)precision', '(hybrid)recall', '(hybrid)f1']\n",
    "index = pd.MultiIndex.from_product([testing_data.keys(), ['lr', 'gb', 'xgb', 'svr']], names=['experiment', 'class'])\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "classifier_experiments =[experiment for experiment in testing_data.keys() if 'classifier' in experiment.split('_')]\n",
    "regressor_experiments = [experiment for experiment in testing_data.keys() if 'regressor' in experiment.split('_')]\n",
    "# Classifier experiments\n",
    "for experiment in classifier_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        for bus in testing_data[experiment][model]['predicted'].columns:\n",
    "            try:\n",
    "                tp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "                tn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "            except: \n",
    "                print('In the experiment ', experiment, ' and model ', model, ' there was a problem with bus: ', bus)\n",
    "                if not testing_data[experiment][model]['real'][bus].any():\n",
    "                    print('Bus {} has no positive data points. Just ignore the little shit.'.format(bus))    \n",
    "        df.loc[(experiment, model), 'tp'] = tp\n",
    "        df.loc[(experiment, model), 'tn'] = tn\n",
    "        df.loc[(experiment, model), 'fp'] = fp\n",
    "        df.loc[(experiment, model), 'fn'] = fn\n",
    "        if (tp + tn + fp + fn) != 0:\n",
    "            accuracy = (tp + tn ) / (tp + tn + fp + fn)\n",
    "        else: \n",
    "            accuracy = 0\n",
    "        if (tp + fp) != 0:\n",
    "            precision = tp / (tp + fp)\n",
    "        else:\n",
    "            precision = 0\n",
    "        if (tp + fn) != 0:\n",
    "            recall = tp / (tp + fn)\n",
    "        else:\n",
    "            recall = 0\n",
    "        if (precision + recall) != 0:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "        df.loc[(experiment, model), '(hybrid)accuracy'] = accuracy\n",
    "        df.loc[(experiment, model), '(hybrid)precision'] = precision\n",
    "        df.loc[(experiment, model), '(hybrid)recall'] = recall\n",
    "        df.loc[(experiment, model), '(hybrid)f1'] = f1\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0 \n",
    "# Regressor experiments.\n",
    "for experiment in regressor_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        test_data = testing_data[experiment][model]['real']\n",
    "        threshold = test_data.loc[:, test_data.max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "        hybrid_metrics = metrics.Metrics()\n",
    "        hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted'], testing_data[experiment][model]['real'], threshold=threshold)\n",
    "        df.loc[(experiment, model), 'tp'] = hybrid_metrics.true_positives_ctr\n",
    "        df.loc[(experiment, model), 'tn'] = hybrid_metrics.true_negatives_ctr\n",
    "        df.loc[(experiment, model), 'fp'] = hybrid_metrics.false_positives_ctr\n",
    "        df.loc[(experiment, model), 'fn'] = hybrid_metrics.false_negatives_ctr\n",
    "        df.loc[(experiment, model), '(hybrid)accuracy'] = hybrid_metrics.hybrid_accuracy\n",
    "        df.loc[(experiment, model), '(hybrid)precision'] = hybrid_metrics.hybrid_precision\n",
    "        df.loc[(experiment, model), '(hybrid)recall'] = hybrid_metrics.hybrid_recall\n",
    "        df.loc[(experiment, model), '(hybrid)f1'] = hybrid_metrics.hybrid_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>736</td>\n",
       "      <td>302365</td>\n",
       "      <td>217</td>\n",
       "      <td>4178</td>\n",
       "      <td>0.991394</td>\n",
       "      <td>0.68233</td>\n",
       "      <td>0.148467</td>\n",
       "      <td>0.243871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2956</td>\n",
       "      <td>300543</td>\n",
       "      <td>2039</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.990292</td>\n",
       "      <td>0.520878</td>\n",
       "      <td>0.58928</td>\n",
       "      <td>0.552972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3433</td>\n",
       "      <td>299312</td>\n",
       "      <td>3270</td>\n",
       "      <td>1481</td>\n",
       "      <td>0.987202</td>\n",
       "      <td>0.457789</td>\n",
       "      <td>0.683091</td>\n",
       "      <td>0.548194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3272</td>\n",
       "      <td>298018</td>\n",
       "      <td>4564</td>\n",
       "      <td>1642</td>\n",
       "      <td>0.981964</td>\n",
       "      <td>0.318792</td>\n",
       "      <td>0.620103</td>\n",
       "      <td>0.421099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4903</td>\n",
       "      <td>222815</td>\n",
       "      <td>79767</td>\n",
       "      <td>11</td>\n",
       "      <td>0.447775</td>\n",
       "      <td>0.064603</td>\n",
       "      <td>0.999257</td>\n",
       "      <td>0.12136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>3824</td>\n",
       "      <td>299186</td>\n",
       "      <td>3396</td>\n",
       "      <td>1090</td>\n",
       "      <td>0.965336</td>\n",
       "      <td>0.522715</td>\n",
       "      <td>0.81896</td>\n",
       "      <td>0.638132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4392</td>\n",
       "      <td>251328</td>\n",
       "      <td>51254</td>\n",
       "      <td>522</td>\n",
       "      <td>0.861056</td>\n",
       "      <td>0.071804</td>\n",
       "      <td>0.904144</td>\n",
       "      <td>0.133041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4589</td>\n",
       "      <td>239447</td>\n",
       "      <td>63135</td>\n",
       "      <td>325</td>\n",
       "      <td>0.836931</td>\n",
       "      <td>0.067747</td>\n",
       "      <td>0.943935</td>\n",
       "      <td>0.12642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4252</td>\n",
       "      <td>277358</td>\n",
       "      <td>25224</td>\n",
       "      <td>662</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.121167</td>\n",
       "      <td>0.866381</td>\n",
       "      <td>0.212601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4518</td>\n",
       "      <td>228455</td>\n",
       "      <td>74127</td>\n",
       "      <td>396</td>\n",
       "      <td>0.829597</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>0.94416</td>\n",
       "      <td>0.136715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>2439</td>\n",
       "      <td>83464</td>\n",
       "      <td>1940</td>\n",
       "      <td>2597</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.556976</td>\n",
       "      <td>0.484313</td>\n",
       "      <td>0.518109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>1906</td>\n",
       "      <td>83260</td>\n",
       "      <td>2144</td>\n",
       "      <td>3130</td>\n",
       "      <td>0.941685</td>\n",
       "      <td>0.470617</td>\n",
       "      <td>0.378475</td>\n",
       "      <td>0.419547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1516</td>\n",
       "      <td>84934</td>\n",
       "      <td>470</td>\n",
       "      <td>3520</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.763343</td>\n",
       "      <td>0.301033</td>\n",
       "      <td>0.431786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>932</td>\n",
       "      <td>301454</td>\n",
       "      <td>558</td>\n",
       "      <td>4552</td>\n",
       "      <td>0.987205</td>\n",
       "      <td>0.54083</td>\n",
       "      <td>0.151247</td>\n",
       "      <td>0.236387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4369</td>\n",
       "      <td>296641</td>\n",
       "      <td>5371</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.981985</td>\n",
       "      <td>0.430003</td>\n",
       "      <td>0.805767</td>\n",
       "      <td>0.560755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3939</td>\n",
       "      <td>297572</td>\n",
       "      <td>4440</td>\n",
       "      <td>1545</td>\n",
       "      <td>0.98377</td>\n",
       "      <td>0.455714</td>\n",
       "      <td>0.730443</td>\n",
       "      <td>0.561263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4764</td>\n",
       "      <td>293962</td>\n",
       "      <td>8050</td>\n",
       "      <td>720</td>\n",
       "      <td>0.97408</td>\n",
       "      <td>0.353947</td>\n",
       "      <td>0.863269</td>\n",
       "      <td>0.50205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5429</td>\n",
       "      <td>240971</td>\n",
       "      <td>61041</td>\n",
       "      <td>55</td>\n",
       "      <td>0.844695</td>\n",
       "      <td>0.091969</td>\n",
       "      <td>0.993235</td>\n",
       "      <td>0.16835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5113</td>\n",
       "      <td>259435</td>\n",
       "      <td>42577</td>\n",
       "      <td>371</td>\n",
       "      <td>0.885003</td>\n",
       "      <td>0.113267</td>\n",
       "      <td>0.939922</td>\n",
       "      <td>0.202171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5174</td>\n",
       "      <td>249903</td>\n",
       "      <td>52109</td>\n",
       "      <td>310</td>\n",
       "      <td>0.865197</td>\n",
       "      <td>0.09874</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.178874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5229</td>\n",
       "      <td>269317</td>\n",
       "      <td>32695</td>\n",
       "      <td>255</td>\n",
       "      <td>0.908627</td>\n",
       "      <td>0.14016</td>\n",
       "      <td>0.957879</td>\n",
       "      <td>0.244539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>3257</td>\n",
       "      <td>80400</td>\n",
       "      <td>4022</td>\n",
       "      <td>2761</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.447452</td>\n",
       "      <td>0.54121</td>\n",
       "      <td>0.489885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3723</td>\n",
       "      <td>82270</td>\n",
       "      <td>2152</td>\n",
       "      <td>2295</td>\n",
       "      <td>0.950829</td>\n",
       "      <td>0.633702</td>\n",
       "      <td>0.618644</td>\n",
       "      <td>0.626083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0</td>\n",
       "      <td>84422</td>\n",
       "      <td>0</td>\n",
       "      <td>6018</td>\n",
       "      <td>0.933459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment              class                                               \n",
       "max_u_regressor_sparse  lr      736  302365    217  4178         0.991394   \n",
       "                        gb     2956  300543   2039  1958         0.990292   \n",
       "                        xgb    3433  299312   3270  1481         0.987202   \n",
       "                        svr    3272  298018   4564  1642         0.981964   \n",
       "                        mlp    4903  222815  79767    11         0.447775   \n",
       "max_u_regressor_focused lr     3824  299186   3396  1090         0.965336   \n",
       "                        gb     4392  251328  51254   522         0.861056   \n",
       "                        xgb    4589  239447  63135   325         0.836931   \n",
       "                        svr    4252  277358  25224   662         0.919038   \n",
       "                        mlp    4518  228455  74127   396         0.829597   \n",
       "max_u_classifier        lr     2439   83464   1940  2597         0.949834   \n",
       "                        gb     1906   83260   2144  3130         0.941685   \n",
       "                        xgb    1516   84934    470  3520         0.955882   \n",
       "                        svr     NaN     NaN    NaN   NaN              NaN   \n",
       "                        mlp     NaN     NaN    NaN   NaN              NaN   \n",
       "min_u_regressor_sparse  lr      932  301454    558  4552         0.987205   \n",
       "                        gb     4369  296641   5371  1115         0.981985   \n",
       "                        xgb    3939  297572   4440  1545          0.98377   \n",
       "                        svr    4764  293962   8050   720          0.97408   \n",
       "                        mlp     NaN     NaN    NaN   NaN              NaN   \n",
       "min_u_regressor_focused lr     5429  240971  61041    55         0.844695   \n",
       "                        gb     5113  259435  42577   371         0.885003   \n",
       "                        xgb    5174  249903  52109   310         0.865197   \n",
       "                        svr    5229  269317  32695   255         0.908627   \n",
       "                        mlp     NaN     NaN    NaN   NaN              NaN   \n",
       "min_u_classifier        lr     3257   80400   4022  2761            0.925   \n",
       "                        gb     3723   82270   2152  2295         0.950829   \n",
       "                        xgb       0   84422      0  6018         0.933459   \n",
       "                        svr     NaN     NaN    NaN   NaN              NaN   \n",
       "                        mlp     NaN     NaN    NaN   NaN              NaN   \n",
       "\n",
       "                              (hybrid)precision (hybrid)recall (hybrid)f1  \n",
       "experiment              class                                              \n",
       "max_u_regressor_sparse  lr              0.68233       0.148467   0.243871  \n",
       "                        gb             0.520878        0.58928   0.552972  \n",
       "                        xgb            0.457789       0.683091   0.548194  \n",
       "                        svr            0.318792       0.620103   0.421099  \n",
       "                        mlp            0.064603       0.999257    0.12136  \n",
       "max_u_regressor_focused lr             0.522715        0.81896   0.638132  \n",
       "                        gb             0.071804       0.904144   0.133041  \n",
       "                        xgb            0.067747       0.943935    0.12642  \n",
       "                        svr            0.121167       0.866381   0.212601  \n",
       "                        mlp            0.073693        0.94416   0.136715  \n",
       "max_u_classifier        lr             0.556976       0.484313   0.518109  \n",
       "                        gb             0.470617       0.378475   0.419547  \n",
       "                        xgb            0.763343       0.301033   0.431786  \n",
       "                        svr                 NaN            NaN        NaN  \n",
       "                        mlp                 NaN            NaN        NaN  \n",
       "min_u_regressor_sparse  lr              0.54083       0.151247   0.236387  \n",
       "                        gb             0.430003       0.805767   0.560755  \n",
       "                        xgb            0.455714       0.730443   0.561263  \n",
       "                        svr            0.353947       0.863269    0.50205  \n",
       "                        mlp                 NaN            NaN        NaN  \n",
       "min_u_regressor_focused lr             0.091969       0.993235    0.16835  \n",
       "                        gb             0.113267       0.939922   0.202171  \n",
       "                        xgb             0.09874       0.949275   0.178874  \n",
       "                        svr             0.14016       0.957879   0.244539  \n",
       "                        mlp                 NaN            NaN        NaN  \n",
       "min_u_classifier        lr             0.447452        0.54121   0.489885  \n",
       "                        gb             0.633702       0.618644   0.626083  \n",
       "                        xgb                   0            0.0          0  \n",
       "                        svr                 NaN            NaN        NaN  \n",
       "                        mlp                 NaN            NaN        NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The real values are the same\n",
    "test = testing_data['max_u_regressor_sparse']['gb']['real'] == testing_data['max_u_regressor_sparse']['lr']['real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\jupyter_notebooks\\datasets_benchmark.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m testing_data[\u001b[39m'\u001b[39;49m\u001b[39mclassifier\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mkeys()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'classifier'"
     ]
    }
   ],
   "source": [
    "testing_data['classifier'].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe4baa4d27e3b73db55d4bb4674105e8dd41faaf9e559c3cc8381041ce15293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
