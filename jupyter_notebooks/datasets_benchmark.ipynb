{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of this Article** \n",
    "- Loading best hyperparameters for each model\n",
    "- Model training\n",
    "- Results discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best hyperparameters for each model\n",
    "\n",
    "TODO... explain this model bench mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hyperparameters dataset.\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse hyperparameters: 8/8\n",
      "Focused hyperparameters: 8/8\n",
      "Balanced hyperparameters: 8/8\n",
      "Filtered hyperparameters: 8/8\n",
      "Sparse classifier hyperparameters: 8/8\n",
      "Balanced classifier hyperparameters: 8/8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparse_hyper_params = {}\n",
    "focused_hyper_params = {}\n",
    "balanced_hyper_params = {}\n",
    "filtered_hyper_params = {}\n",
    "sparse_class_hyper_params = {}\n",
    "balanced_class_hyper_params = {}\n",
    "for file in os.listdir('hyper_params_results_mcc'):\n",
    "    if file.endswith('.csv') and 'regression_sparse' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'regression_focused' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        focused_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'regression_balanced' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        balanced_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'filtered' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        filtered_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'sparse_classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_class_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'balanced_classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        balanced_class_hyper_params[file] = df\n",
    "print('Sparse hyperparameters: {}/8'.format(len(sparse_hyper_params)))\n",
    "print('Focused hyperparameters: {}/8'.format(len(focused_hyper_params)))\n",
    "print('Balanced hyperparameters: {}/8'.format(len(balanced_hyper_params)))\n",
    "print('Filtered hyperparameters: {}/8'.format(len(filtered_hyper_params)))\n",
    "print('Sparse classifier hyperparameters: {}/8'.format(len(sparse_class_hyper_params)))\n",
    "print('Balanced classifier hyperparameters: {}/8'.format(len(balanced_class_hyper_params)))\n",
    "print('\\n')\n",
    "# print('Sparse hyper params:\\n')\n",
    "# for key in sparse_hyper_params.keys():\n",
    "#     print(key, ':\\n ',sparse_hyper_params[key])\n",
    "# print('Focused hyper params:\\n')\n",
    "# for key in focused_hyper_params.keys():\n",
    "#     print(key, ':\\n',focused_hyper_params[key])\n",
    "# print('Boolean hyper params:\\n')\n",
    "# for key in sparse_class_hyper_params.keys():\n",
    "#     print(key, ':\\n',sparse_class_hyper_params[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 34,\n",
       " 'n_layers': 3,\n",
       " 'dropout': 0.0030412321477918842,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'sgd',\n",
       " 'lr': 9.741292351005151e-05,\n",
       " 'epochs': 55,\n",
       " 'batch_size': 8,\n",
       " 'classifier': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "def get_hyper_params_from_df(df):\n",
    "    output = {}\n",
    "    for row in df.iterrows():\n",
    "        if row[1]['params'] != 'value':\n",
    "            try:\n",
    "                output[row[1]['params']] = ast.literal_eval(row[1]['value'])\n",
    "            except :\n",
    "                output[row[1]['params']] = row[1]['value']\n",
    "    return output\n",
    "get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_max_u.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..');from thesis_package import aimodels as my_ai, utils, metrics\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression data sparse\n",
    "y_max_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv').drop(columns=['timestamps'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_sparse, test_size=0.2, scaling=True)\n",
    "data_max_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_sparse, test_size=0.2, scaling=True)\n",
    "data_min_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data sparse\n",
    "y_max_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_sparse_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_sparse_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_max_u_bool = y_max_u_bool[utils.cols_with_positive_values(y_max_u_bool)]\n",
    "y_min_u_bool = y_min_u_bool[utils.cols_with_positive_values(y_min_u_bool)]\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_bool, test_size=0.2, scaling=True)\n",
    "data_max_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_bool, test_size=0.2, scaling=True)\n",
    "data_min_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered data\n",
    "y_max_u_filtered = deepcopy(y_max_u_sparse[utils.cols_with_positive_values(y_max_u_bool)])\n",
    "y_min_u_filtered = deepcopy(y_min_u_sparse[utils.cols_with_positive_values(y_min_u_bool)])\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_filtered, test_size=0.2, scaling=True)\n",
    "data_max_u_filtered = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_filtered, test_size=0.2, scaling=True)\n",
    "data_min_u_filtered = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification data size:  (9044, 11)\n",
      "Regression data size:  (9044, 11)\n",
      "Positive in classification data:  4949.0\n",
      "Positive in regression data:  4949\n",
      "Theshhold:  0.0016733255333549746\n",
      "\n",
      "\n",
      "Classification data size:  (9044, 10)\n",
      "Regression data size:  (9044, 10)\n",
      "Positive in classification data:  6022.0\n",
      "Positive in regression data:  6022\n",
      "Theshhold:  0.002022118621573741\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the classiciation testing data and the filtered testing data\n",
    "print('Classification data size: ', data_max_u_bool['y_test'].shape)\n",
    "print('Regression data size: ', data_max_u_filtered['y_test'].shape)\n",
    "print('Positive in classification data: ', utils.count_positives_class(data_max_u_bool['y_test']))\n",
    "#unscaled_y_test = pd.DataFrame(data_max_u_filtered['scaler']['y'].inverse_transform(data_max_u_filtered['y_test']), columns=data_max_u_filtered['y_test'].columns)\n",
    "unscaled_y_test = data_max_u_filtered['y_test'] * data_max_u_sparse['scaler']['y']\n",
    "print('Positive in regression data: ', utils.count_positives_reg(unscaled_y_test, utils.compute_threshold(y_max_u_sparse)))\n",
    "print('Theshhold: ', utils.compute_threshold(y_max_u_sparse))\n",
    "# Same for min_u\n",
    "print('\\n')\n",
    "print('Classification data size: ', data_min_u_bool['y_test'].shape)\n",
    "print('Regression data size: ', data_min_u_filtered['y_test'].shape)\n",
    "print('Positive in classification data: ', utils.count_positives_class(data_min_u_bool['y_test']))\n",
    "#unscaled_y_test = pd.DataFrame(data_min_u_filtered['scaler']['y'].inverse_transform(data_min_u_filtered['y_test']), columns=data_min_u_filtered['y_test'].columns)\n",
    "unscaled_y_test = data_min_u_filtered['y_test'] * data_min_u_sparse['scaler']['y']\n",
    "print('Positive in regression data: ', utils.count_positives_reg(unscaled_y_test, utils.compute_threshold(y_min_u_sparse)))\n",
    "print('Theshhold: ', utils.compute_threshold(y_min_u_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data focused\n",
    "y_max_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_focused_constr.csv')\n",
    "exogenous_data_focused_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_focused.csv').drop(columns=['date'])\n",
    "y_min_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_focused_constr.csv')\n",
    "exogenous_data_focused_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_focused.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_max_u, y_max_u_focused, test_size=0.2, scaling=True)\n",
    "data_max_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_min_u, y_min_u_focused, test_size=0.2, scaling=True)\n",
    "data_min_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data balanced\n",
    "y_max_u_balanced = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_constr.csv')\n",
    "exogenous_data_balanced_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "y_min_u_balanced = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_constr.csv')\n",
    "exogenous_data_balanced_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_max_u, y_max_u_balanced, test_size=0.2, scaling=True)\n",
    "data_max_u_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_min_u, y_min_u_balanced, test_size=0.2, scaling=True)\n",
    "data_min_u_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data balanced\n",
    "y_max_u_balanced_class = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_bool_constr.csv')\n",
    "exogenous_data_balanced_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "y_min_u_balanced_class = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_bool_constr.csv')\n",
    "exogenous_data_balanced_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "y_max_u_balanced_class = y_max_u_balanced_class[utils.cols_with_positive_values(y_max_u_balanced_class)]\n",
    "y_min_u_balanced_class = y_min_u_balanced_class[utils.cols_with_positive_values(y_min_u_balanced_class)]\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_max_u, y_max_u_balanced_class, test_size=0.2, scaling=True)\n",
    "data_max_u_bool_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_min_u, y_min_u_balanced_class, test_size=0.2, scaling=True)\n",
    "data_min_u_bool_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a quick sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count in classification data max_u : 4949.0\n",
      "Positive count in regression data max_u with threshold 0.0016733255333549746 : 4949\n",
      "\n",
      "\n",
      "Positive count in classification data min_u : 6022.0\n",
      "Positive count in regression data min_u with threshold 0.002022118621573741 : 6022\n",
      "\n",
      "\n",
      "Negative count in classification data max_u : 94535.0\n",
      "Negative count in regression data max_u with threshold 0.0016733255333549746 : 94535\n",
      "\n",
      "\n",
      "Negative count in classification data min_u : 84418.0\n",
      "Negative count in regression data min_u with threshold 0.002022118621573741 : 84418\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.check_positive_count(data_max_u_filtered['y_test']* data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')\n",
    "utils.check_positive_count(data_min_u_filtered['y_test']* data_min_u_filtered['scaler']['y'], data_min_u_bool['y_test'], utils.compute_threshold(y_min_u_sparse), experiment='min_u')\n",
    "utils.check_negative_count(data_max_u_filtered['y_test']* data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')\n",
    "utils.check_negative_count(data_min_u_filtered['y_test']* data_min_u_filtered['scaler']['y'], data_min_u_bool['y_test'], utils.compute_threshold(y_min_u_sparse), experiment='min_u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count in classification data max_u : 4949.0\n",
      "Positive count in regression data max_u with threshold 0.0016733255333549746 : 4949\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.check_positive_count(data_max_u_filtered['y_test'] * data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "In this section the models will be trained with the hyperparameters loaded above. All the models will be stored in the same `Context` object for later evaluation. The `Context` object is a class that stores all the models and their respective hyperparameters. The `Context` object is defined in the `aimodels.py` file. The `Context` object is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_models = ['lr', 'gb', 'xgb', 'svr', 'mlp']\n",
    "class_models =  ['gb', 'xgb', 'svr', 'mlp']\n",
    "max_u_threshold = utils.compute_threshold(y_max_u_sparse)\n",
    "min_u_threshold = utils.compute_threshold(y_min_u_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params_gradient_boost_regression_sparse_max_u.csv', 'params_gradient_boost_regression_sparse_min_u.csv', 'params_mlp_regression_sparse_max_u.csv', 'params_mlp_regression_sparse_min_u.csv', 'params_support_vector_regression_sparse_max_u.csv', 'params_support_vector_regression_sparse_min_u.csv', 'params_xgboost_regression_sparse_max_u.csv', 'params_xgboost_regression_sparse_min_u.csv'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_hyper_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training max_u regression sparse\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_u regression sparse\n",
    "if 'max_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_max_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_max_u.csv']) \n",
    "    regressor_max_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regression_sparse_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_sparse['y_train'].shape[1]\n",
    "    regressor_max_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse', regressor_max_u)\n",
    "else:\n",
    "    print('Loading max_u regression sparse') \n",
    "    regressor_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse')\n",
    "\n",
    "testing_data = {'max_u_regressor_sparse': {}}\n",
    "for model, strategy in zip(reg_models, regressor_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_sparse['y_test'].columns)\n",
    "    testing_data['max_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_sparse'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ext_grid</th>\n",
       "      <th>bus_1</th>\n",
       "      <th>bus_2</th>\n",
       "      <th>bus_3</th>\n",
       "      <th>bus_4</th>\n",
       "      <th>bus_5</th>\n",
       "      <th>bus_6</th>\n",
       "      <th>bus_7</th>\n",
       "      <th>bus_8</th>\n",
       "      <th>bus_9</th>\n",
       "      <th>...</th>\n",
       "      <th>bus_30</th>\n",
       "      <th>bus_31</th>\n",
       "      <th>bus_17</th>\n",
       "      <th>bus_21</th>\n",
       "      <th>bus_24</th>\n",
       "      <th>bus_18</th>\n",
       "      <th>bus_23</th>\n",
       "      <th>bus_27</th>\n",
       "      <th>bus_32</th>\n",
       "      <th>bus_33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9040</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.959050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9041</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9044 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ext_grid  bus_1  bus_2  bus_3  bus_4  bus_5  bus_6  bus_7     bus_8  \\\n",
       "0          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  1.000000   \n",
       "1          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.991541   \n",
       "2          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  1.000000   \n",
       "3          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.965330   \n",
       "4          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.957302   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...       ...   \n",
       "9039       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.750065   \n",
       "9040       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.959050   \n",
       "9041       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  1.000000   \n",
       "9042       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.589455   \n",
       "9043       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.979599   \n",
       "\n",
       "      bus_9  ...  bus_30  bus_31  bus_17  bus_21  bus_24  bus_18  bus_23  \\\n",
       "0       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "1       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "2       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "3       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "4       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "...     ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9039    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "9040    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "9041    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "9042    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "9043    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "\n",
       "      bus_27  bus_32  bus_33  \n",
       "0        0.0     0.0     0.0  \n",
       "1        0.0     0.0     0.0  \n",
       "2        0.0     0.0     0.0  \n",
       "3        0.0     0.0     0.0  \n",
       "4        0.0     0.0     0.0  \n",
       "...      ...     ...     ...  \n",
       "9039     0.0     0.0     0.0  \n",
       "9040     0.0     0.0     0.0  \n",
       "9041     0.0     0.0     0.0  \n",
       "9042     0.0     0.0     0.0  \n",
       "9043     0.0     0.0     0.0  \n",
       "\n",
       "[9044 rows x 34 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# figure size of the plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "testing_data['max_u_regressor_sparse']['mlp']['predicted']['bus_1'].plot()\n",
    "testing_data['max_u_regressor_sparse']['mlp']['real']['bus_1'].plot()\n",
    "# plot a line with the threshold\n",
    "# Add legend\n",
    "plt.legend(['predicted', 'real'])\n",
    "testing_data['max_u_regressor_sparse']['mlp']['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_positives_ctr:  5528\n",
      "true_negatives_ctr:  217049\n",
      "false_positives_ctr:  7\n",
      "false_negatives_ctr:  84912\n",
      "32809591956366086400\n"
     ]
    }
   ],
   "source": [
    "metric = metrics.Metrics()\n",
    "metric.get_prediction_scores(testing_data['max_u_regressor_sparse']['mlp']['real'], testing_data['max_u_regressor_sparse']['mlp']['predicted'], max_u_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training max_u regression focused\n",
      "[10:35:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:35:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_u regression focused\n",
    "if 'max_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_max_u.csv']) \n",
    "    regressor_max_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_focused['y_train'].shape[1]\n",
    "    regressor_max_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_focused', regressor_max_u_focused)\n",
    "else: \n",
    "    print('Loading max_u regression focused')\n",
    "    regressor_max_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\\\max_u_regressor_focused')\n",
    "\n",
    "testing_data['max_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    testing_data['max_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_focused'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training max_u regression filtered\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_u regression filtered\n",
    "if 'max_u_filtered_regressor.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression filtered')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_filtered = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_gradient_boost_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_xgboost_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_support_vector_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_mlp_regression_filtered_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_filtered['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_filtered['y_train'].shape[1]\n",
    "    regressor_max_u_filtered.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_filtered_regressor', regressor_max_u_filtered)\n",
    "else: \n",
    "    print('Loading max_u filtered regression')\n",
    "    regressor_max_u_filtered = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_filtered_regressor')\n",
    "\n",
    "testing_data['max_u_filtered_regressor'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_filtered.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_filtered['y_test'].columns)\n",
    "    testing_data['max_u_filtered_regressor'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_filtered_regressor'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_filtered_regressor'][model]['real'] = deepcopy(data_max_u_sparse['y_test'][utils.cols_with_positive_values(prediction)].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9044, 11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy = regressor_max_u_filtered.strategies[0]\n",
    "prediction = strategy.predict(data=data_max_u_sparse)\n",
    "prediction.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training max_u regression balanced\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max u regression balanced\n",
    "if 'max_u_regressor_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression balanced')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_balanced = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_gradient_boost_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_xgboost_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_support_vector_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_mlp_regression_balanced_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_balanced['y_train'].shape[1]\n",
    "    regressor_max_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_balanced', regressor_max_u_balanced)\n",
    "else: \n",
    "    print('Loading max_u regression balanced')\n",
    "    regressor_max_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_balanced')\n",
    "\n",
    "testing_data['max_u_regressor_balanced'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    testing_data['max_u_regressor_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_balanced'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training max_u classification\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_u classification\n",
    "if 'max_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_gradient_boost_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_xgboost_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_support_vector_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_mlp_sparse_classifier_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_bool['y_train'].shape[1]\n",
    "    classifier_max_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier', classifier_max_u)\n",
    "else: \n",
    "    print('Loading max_u classification')\n",
    "    classifier_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier')\n",
    "\n",
    "testing_data['max_u_classifier'] = {}\n",
    "for model, strategy in zip(class_models, classifier_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_bool)\n",
    "    testing_data['max_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_classifier'][model]['real'] = deepcopy(data_max_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_data['max_u_classifier']['xgb']['predicted']['bus_15'].plot()\n",
    "testing_data['max_u_classifier']['xgb']['real']['bus_15'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training max_u classification balanced\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_u classification balanced\n",
    "if 'max_u_classifier_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification balanced')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_gradient_boost_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_xgboost_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_support_vector_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_mlp_balanced_classifier_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_bool_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_bool_balanced['y_train'].shape[1]\n",
    "    classifier_max_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier_balanced', classifier_max_u_balanced)\n",
    "else: \n",
    "    print('Loading max_u classification balanced')\n",
    "    classifier_max_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier_balanced')\n",
    "\n",
    "testing_data['max_u_classifier_balanced'] = {}\n",
    "for model, strategy in zip(class_models, classifier_max_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_bool)\n",
    "    testing_data['max_u_classifier_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_classifier_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_classifier_balanced'][model]['real'] = deepcopy(data_max_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<thesis_package.aimodels.GradientBoostClassifierStrategy at 0x228859fcd90>,\n",
       " <thesis_package.aimodels.XGBoostClassifierStrategy at 0x228859fceb0>,\n",
       " <thesis_package.aimodels.SupportVectorClassifierStrategy at 0x2287f2a8640>,\n",
       " <thesis_package.aimodels.MultilayerPerceptronStrategy at 0x22865cdb550>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_max_u_balanced.strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min u regression training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training min_u regression sparse\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAp8UlEQVR4nO3deZhcZZn38e/d+5pO0kkqezpLNxIIAokEEDBBwQgOoEYHVEQFIrzEwWGcVxgdxsFtcGbQV8EFEURHJuICRAibkAAiWwJhyQLphIQkkH2tdHpL3+8f53Sn0lR3ulN9qrq7fp/rOled5amqu4uifjnnPOc55u6IiIi0l5PpAkREpHdSQIiISFIKCBERSUoBISIiSSkgREQkKQWEiIgkpYAQSZGZTTazxWZmGazBzWxSB9v+zsx+l+6apO9TQEi/ZWZrzexDaXirbwH/5eFFReH77jezeMJ0cxrqSMrd/wwcY2bHZaoG6ZsUECIpMLMRwEzg3nab/s7dyxKmuemv7hD/C8zJcA3SxyggJKuYWaGZ/dDM3g6nH5pZYbhtiJndb2a7zGyHmT1lZjnhtq+Z2UYz22tmr5vZB8OXPAt40d3ru/j+nzezp83sZjPbbWYrE14LMxtpZvPD9681s8sTtuWa2b+Y2eqwjiVmNibh5T9kZqvC+m9pd8hrEXDukX1qkq3yMl2ASJp9HTgZOB5w4D7gG8C/Av8EbACGhm1PBtzMjgLmAu9z97fNrArIDdtMAV7vZg3TgT8AQ4CPA38ys/HuvgOYB7wGjATeAzxqZqvd/XHgGuAi4BzgDeA4oC7hdT8KvA8YACwB/gw8FG5bAVSZ2QB339PNeiVLaQ9Css1ngBvcfYu7bwX+Hbg43NYEjADGuXuTuz8Vnlc4ABQCk80s393Xuvvq8DkDgb1J3ufe8F/yrdPlCdu2AD8M3+N3BAFzbrg38H7ga+5e7+5LgduAz4XPuwz4hru/7oGX3X17wuv+h7vvcve3gIUEIdiqtcaB3fisJMspICTbjATWJSyvC9cB/CdQCzxiZmvM7FoAd68FvgJ8E9hiZvPMrPU5O4HyJO9zgbsPTJh+kbBtY+sJ7XY1jAR2uPvedttGhfNjgNV0bFPCfB1QlrDcWuOuTp4vcggFhGSbt4FxCctjw3W4+153/yd3nwCcB1zTen7A3e9y99PC5zpwY/j8V4CabtYwqt35gdYa3gYGm1l5u20bw/n1wMRuvlero4G1Orwk3aGAkP4u38yKWieC3jzfMLOhZjYEuB74HwAz+6iZTQp/vHcTHFpqMbOjzOzM8GR2PbAfaAlf/1HgxPC1u2oY8A9mlm9mnyT48V7g7uuBvwHfC+s9Dri0tT6Cw03fMrNqCxxnZpVdfM8PAA92o0YRBYT0ewsIftBbpyJgMcG//F8FXgS+HbatBv4CxIFngJ+4+0KC8w//AWwjOIwzDLgOwN03A48D57d73z+3uw7inoRtz4XvtQ34DjA74VzCRUAVwd7EPcC/uftfwm03AXcDjwB7gF8CxV38HC4Cft7FtiIAmG4YJJIaM5sM3Amc5If5H8rMPg9cFh6uSgsz+zvgYnf/VLreU/oHdXMVSZG7LyfoXtorhVdS/znTdUjfo0NMIiKSlA4xiYhIUtqDEBGRpPrNOYghQ4Z4VVVVpsvo0L59+ygtLc10GR1SfalRfalRfalJpb4lS5Zsc/ehSTe6e2QTMItgGIFa4NpO2n2C4OKjaeHyWQRjybwaPp55uPeaOnWq92YLFy7MdAmdUn2pUX2pUX2pSaU+YLF38Lsa2R6EmeUCt4Q/9huAF8xsvgc9PhLblQNXE/QNb7WNYLjkt83sWOBhDg43ICIiaRDlOYiTgFp3X+PujQSjVLa/mAiCm63cSHCFKgDu/pK7vx0uLgOKW4dkFhGR9IisF5OZzQZmuftl4fLFwHRPuHGKmZ0IfN3dP2Fmi4CvuvviJK9zhbu/685gZjaH8CYosVhs6rx58yL5W3pCPB6nrKzs8A0zRPWlRvWlRvWlJpX6Zs6cucTdpyXd2NGxp1QnYDZwW8LyxcDNCcs5BDcxqQqXFxGeg0hocwzB6JUTD/d+OgeRGtWXGtWXGtWXmqjOQUR5iGkjwfDErUZzcFRKCIYfPhZYZGZrCW7OMt/MpgGY2WiCsWg+5wfH3hcRkTSJMiBeAKrNbLyZFQAXAvNbN7r7bncf4u5V7l4FPAuc5+6LzWwg8ABBz6enI6xRREQ6EFlAuHszwW0aHya43eHd7r7MzG4ws/MO8/S5wCTgejNbGk7DoqpVRETeLdIL5dx9AcFwy4nrru+g7YyE+W9zcAjmSG3ctZ95z7/FJ6eOYWxlSTreUkSkT8j6oTb27G/ix4/X8tL6nZkuRUSkV8n6gJgwtJTcHGPV5nimSxER6VWyPiAK83IZV1nCG5v3Hr6xiEgWyfqAAKgZVs6qLdqDEBFJpIAAamJlrNu+j/qmA5kuRUSk11BAANWxcloc1mzdl+lSRER6DQUEUBMrB2DVFp2HEBFppYAAqoaUkJtjOlEtIpJAAUHQk6mqsoQ31NVVRKSNAiJUEytnlfYgRETaKCBC1bFy1u2oU08mEZGQAiJUEyvDHVZv1WEmERFQQLRp68mk8xAiIoACok1VZSl56skkItJGAREqyMth/JBS9WQSEQkpIBJUx8p0sZyISEgBkaB6WDlv7ahjf6N6MomIKCAS1MTK1ZNJRCSkgEhQEysD0IlqEREUEIeoGlJKfq7p3hAiIiggDpGfG/Rk0pAbIiIKiHepjpWrq6uICAqId6kZVs76nerJJCKigGinOhyTqVbnIUQkyykg2lFPJhGRgAKinXGVQU+mN3RFtYhkOQVEO/m5OUwYUkatTlSLSJZTQCRRHSvTHoSIZD0FRBI1sXLW79hPXWNzpksREckYBUQSrSeq1ZNJRLKZAiKJScOCu8vpgjkRyWYKiCSqKksoyM3RkBsiktUUEEnk5eYwYWiproUQkawWaUCY2Swze93Mas3s2k7afcLM3MymhcuVZrbQzOJmdnOUNXakOlauUV1FJKtFFhBmlgvcAnwEmAxcZGaTk7QrB64GnktYXQ/8K/DVqOo7nJphZWzYuZ99DerJJCLZKco9iJOAWndf4+6NwDzg/CTtvgXcSBAKALj7Pnf/a+K6dKuOBSeq1ZNJRLJVlAExClifsLwhXNfGzE4Exrj7AxHWcUQ0JpOIZLu8TL2xmeUANwGfT+E15gBzAGKxGIsWLeqR2gAOtDh5OfDY4hUMja9O+fXi8XiP1tfTVF9qVF9qVF9qoqovyoDYCIxJWB4drmtVDhwLLDIzgOHAfDM7z90Xd+UN3P1W4FaAadOm+YwZM3qg7IMmvfIk9YVFzJhxUsqvtWjRInq6vp6k+lKj+lKj+lITVX1RHmJ6Aag2s/FmVgBcCMxv3ejuu919iLtXuXsV8CzQ5XBIh5pYOat0sZyIZKnIAsLdm4G5wMPACuBud19mZjeY2XmHe76ZrSU8BGVmG5L1gIpaTayMjbv2E1dPJhHJQpGeg3D3BcCCduuu76DtjHbLVZEV1kWJPZmOHzMws8WIiKSZrqTuRE2sdUwm9WQSkeyjgOjE2MElFOZpTCYRyU4KiE7k5hgTh5ZpVFcRyUoKiMOoiZVpD0JEspIC4jCqY+W8vbuevfVNmS5FRCStFBCHUT0sGHJDI7uKSLZRQBxGa0+mWp2HEJEso4A4jDFhTyZ1dRWRbKOAOIzcHGPSsDLe0CEmEckyCoguCMZk0h6EiGQXBUQXVMfKeGd3PXvUk0lEsogCoguqhwUnqjWyq4hkEwVEF7TeXU6HmUQkmyggumDMoBKK8nM05IaIZBUFRBfkhD2ZVm3RHoSIZA8FRBfVDNPd5UQkuygguqg6Vs6mPfXs3q+eTCKSHRQQXdR6orpWh5lEJEsoILro4N3ldJhJRLKDAqKLRg0spjg/V2MyiUjWUEB0UVtPJu1BiEiWUEB0Q3VMXV1FJHsoILqhJlbO5j0N6skkIllBAdENGnJDRLKJAqIbWgftU08mEckGCohuGDWwmJIC9WQSkeyggOgGjckkItlEAdFN1cPKdYhJRLKCAqKbamJlbN3bwK66xkyXIiISKQVEN7UOubFqi/YiRKR/U0B0U3XY1VUnqkWkv1NAdNOogcWUFuRqyA0R6fcUEN1kZkyKlWsPQkT6PQXEEagZVqaeTCLS70UaEGY2y8xeN7NaM7u2k3afMDM3s2kJ664Ln/e6mX04yjq7qzpWxrZ4Azv3qSeTiPRfkQWEmeUCtwAfASYDF5nZ5CTtyoGrgecS1k0GLgSOAWYBPwlfr1eobrt5kA4ziUj/FeUexElArbuvcfdGYB5wfpJ23wJuBOoT1p0PzHP3Bnd/E6gNX69XUFdXEckGeRG+9ihgfcLyBmB6YgMzOxEY4+4PmNk/t3vus+2eO6r9G5jZHGAOQCwWY9GiRT1T+WG4O0W5sPDFlYyuf7NLz4nH42mr70iovtSovtSovtREVV+UAdEpM8sBbgI+f6Sv4e63ArcCTJs2zWfMmNEjtXXFe5Y/TV1eLjNmnNyl9osWLSKd9XWX6kuN6kuN6ktNVPVFeYhpIzAmYXl0uK5VOXAssMjM1gInA/PDE9WHe27G1ejuciLSz0UZEC8A1WY23swKCE46z2/d6O673X2Iu1e5exXBIaXz3H1x2O5CMys0s/FANfB8hLV2W02snG3xRnaoJ5OI9FORBYS7NwNzgYeBFcDd7r7MzG4ws/MO89xlwN3AcuAh4Cp3PxBVrUdCPZlEpL+L9ByEuy8AFrRbd30HbWe0W/4O8J3IiktR9bCDtx89eUJlhqsREel5upL6CI2oKKK8ME9dXUWk31JAHKFgTKYyHWISkX5LAZGCmmHlGtVVRPotBUQKqmNlbN/XyPZ4Q6ZLERHpcQqIFNS09WTSXoSI9D8KiBQcHJNJ5yFEpP/pUkCYWWk4NAZmVmNm55lZfrSl9X6xAYWUF+bpRLWI9Etd3YN4Eigys1HAI8DFwK+iKqqvMDOqY2U6US0i/VJXA8LcvQ74OPATd/8kwb0asl5NrFzXQohIv9TlgDCzU4DPAA+E63rNDXwyqTpWzo59jWxTTyYR6We6GhBfAa4D7gnHU5oALIysqj6kJhYMubHinT0ZrkREpGd1aSwmd38CeALa7uOwzd3/IcrC+ooTxg6ivCiP3z77FqdXD810OSIiPaarvZjuMrMBZlYKvAYsb3cHuKxVVpjHF06t4qFlm9SbSUT6la4eYprs7nuAC4AHgfEEPZkE+ML7x1NSkMtPFtZmuhQRkR7T1YDID697uACY7+5NgEdWVR8zqLSAz0wfy/yX32bd9n2ZLkdEpEd0NSB+DqwFSoEnzWwcoLOyCS4/fQJ5uTn87InVmS5FRKRHdCkg3P1H7j7K3c/xwDpgZsS19SnDBhTxqWmj+cOSDbyze3+myxERSVlXT1JXmNlNZrY4nP6bYG9CEnzpjIm4w8+fWJPpUkREUtbVQ0y3A3uBT4XTHuCOqIrqq8YMLuGCE0Yx74W3dOGciPR5XQ2Iie7+b+6+Jpz+HZgQZWF91ZUzJtLQ3MIv//pmpksREUlJVwNiv5md1rpgZu8HdKA9iYlDyzhnygh+88w6dtc1ZbocEZEj1tWAuAK4xczWmtla4GbgS5FV1cddNWMS8YZm7nxmbaZLERE5Yl3txfSyu78XOA44zt1PAM6MtLI+bPLIAXzo6GHc/vSb7GtoznQ5IiJHpFt3lHP3PeEV1QDXRFBPv3HVzEnsqmvit8+ty3QpIiJHJJVbjlqPVdEPnTB2EO+fVMkvnnqT+qYDmS5HRKTbUgkIDbVxGFfNnMTWvQ38fvH6TJciItJtnQaEme01sz1Jpr3AyDTV2GedMqGSE8cO5GdPrKG5RXkqIn1LpwHh7uXuPiDJVO7uXbqXRDYzM758ZjUbd+3nmbd1slpE+pZUDjFJF8w4aijHjBzA/WuaOKC9CBHpQxQQETMzrpo5ic11zoJX38l0OSIiXaaASINZxwxnRKlxy8Ja3LUXISJ9gwIiDXJyjI9OyGflpr08tmJLpssREekSBUSanDwijzGDi/mx9iJEpI+INCDMbJaZvW5mtWZ2bZLtV5jZq2a21Mz+amaTw/UFZnZHuO1lM5sRZZ3pkJtjXPGBiby8fhdP127PdDkiIocVWUCYWS5wC/ARYDJwUWsAJLjL3ae4+/HA94GbwvWXA7j7FOAs4L/NrM/v7cyeOprYgEJuXrgq06WIiBxWlD+6JwG14f0jGoF5wPmJDRLGdYLgDnWtx14mA4+HbbYAu4BpEdaaFoV5uVx++gSeXbODJet2ZLocEZFOWVTHw81sNjDL3S8Lly8Gprv73HbtriIY+K8AONPdV5nZHII9h4uAMcBLwKXu/sd2z50DzAGIxWJT582bF8nf0hPi8ThlZWU0NDtffaKO8QNzuWZqUabLatNaX2+l+lKj+lLTn+ubOXPmEndP/g9wd49kAmYDtyUsXwzc3En7TwN3hvN5wA+ApcB9wALggs7eb+rUqd6bLVy4sG3+5sdX+biv3e+vbtiVuYLaSayvN1J9qVF9qenP9QGLvYPf1SgPMW0k+Nd/q9Hhuo7MAy4AcPdmd/9Hdz/e3c8HBgJvRFRn2l18yjjKi/K4ZWFtpksREelQlAHxAlBtZuPNrAC4EJif2MDMqhMWzwVWhetLzKw0nD8LaHb35RHWmlYDivK55JQqHlq2idotezNdjohIUpEFhLs3A3OBh4EVwN3uvszMbjCz88Jmc81smZktJTgPcUm4fhjwopmtAL5GcHiqX/niaeMpysvlJwtXZ7oUEZGkIh2R1d0XEJw/SFx3fcL81R08by1wVJS1Zdrg0gI+M30sd/xtLV/5UA1jK0syXZKIyCH6/LUFfdnlZ0wg14yfPam9CBHpfRQQGRQbUMQnp43mD4s3sGFnXabLERE5hAIiw674wETyc41Lbn+erXsbMl2OiEgbBUSGjRlcwu2ffx9v76rns7c9x459jZkuSUQEUED0CtMnVPLLS6axdvs+Pnvbc+yqU0iISOYpIHqJUycN4dbPTaN2S5zP3f48e+qbMl2SiGQ5BUQv8oGaofz0syey4p09XHL788QbmjNdkohkMQVEL/PBo2Pc/OkTeXXDbr5wx/PUNSokRCQzFBC90IePGc7/u/AElqzbyaW/Wsz+xgOZLklEspACopc697gR3PSp43n2ze3M+c1i6psUEiKSXgqIXuyCE0bx/U8cx1OrtnHl/yyhoVkhISLpo4Do5T45bQzf/dgUFr6+lat++xKNzS2ZLklEsoQCog/49PSx3HD+MfxlxWaunvcSzQcUEiISPQVEH/G5U6r4xrlH8+Brm7jm7pc50BLNrWJFRFpFOty39KzLTp9A0wHnxodWkpdr/Nfs95KTY5kuS0T6KQVEH3PljIk0HWjhpkffoCA3h+9+bIpCQkQioYDog/7hg9U0HWjhx4/XkpdrfOv8YzFTSIhIz1JA9FHXnFVD44EWfv7EGvJzc7j+o5MVEiLSoxQQfZSZce2s99DY3MIdT69lw879fPdjUxhaXpjp0kSkn1Avpj7MzLj+o5P5+jlH88QbWzn7B0/wwCvvZLosEeknFBB9nJlx+RkTeODLpzF2cAlX3fUic+96kZ268ZCIpEgB0U9Ux8r545Wn8tWza3h42SbO+sGTPLp8c6bLEpE+TAHRj+Tl5jD3zGruu+o0hpYXcvmvF3PN3UvZvV83HxKR7lNA9EOTRw7gvqvez5fPnMR9S9/mwz94kife2JrpskSkj1FA9FMFeTn809lH8acrT6WsKI9Lbn+e6/70qu5SJyJdpoDo5947ZiD3f/k0vnTGBOa98Bazfvgkf1u9LdNliUgfoIDIAkX5uVx3ztH84YpTyMsxPv2L5/jm/GW6U52IdEoBkUWmjhvMg1efwedPreJXf1vLOT96iiXrdmS6LBHppRQQWaa4IJdvnncMd10+ncbmFj75s2f43oIVNDRr+HAROZSG2shSp04cwsP/eAbfeWAFP39yDeUFsK5gNZ89eRwlBfpaiIj2ILJaWWEe3/v4FP545SmMLc/huwtWcvqNC/n5E6upa1RvJ5Fsp4AQpo4bzD+/r5g/XnkKk0cO4HsPruS0Gxfy00Wr2adusSJZSwEhbaaOG8xvLp3OH688lWNHVXDjQys57cbH+cmiWl0/IZKFIg0IM5tlZq+bWa2ZXZtk+xVm9qqZLTWzv5rZ5HB9vpndGW5bYWbXRVmnHGrquEH8+osn8af/cyrvHTOQ7z/0Oqff+Di3LFRQiGSTyALCzHKBW4CPAJOBi1oDIMFd7j7F3Y8Hvg/cFK7/JFDo7lOAqcCXzKwqqloluRPHDuJXXziJe696P8ePGch/Pvw6p4VBsbde4zuJ9HdR7kGcBNS6+xp3bwTmAecnNnD3PQmLpUBrX0sHSs0sDygGGoHEtpJGx48ZyB1hUJw4dlAYFAu5+fFVCgqRfszco+n/bmazgVnuflm4fDEw3d3ntmt3FXANUACc6e6rzCwf+A3wQaAE+Ed3vzXJe8wB5gDEYrGp8+bNi+Rv6QnxeJyysrJMl9Gh7tT35u4D3FvbxMtbD1CaD2ePy+fMsfmUF0R3y9P+9PllgupLTX+ub+bMmUvcfVrSje4eyQTMBm5LWL4YuLmT9p8G7gzn3w/8FsgHhgGvAxM6e7+pU6d6b7Zw4cJMl9CpI6nvlfW7/NJfPe/jvna/T/qXB3zOr1/wR5dt8sbmA72ivnRSfalRfalJpT5gsXfwuxrlFVEbgTEJy6PDdR2ZB/w0nP808JC7NwFbzOxpYBqwJopC5chMGV3BbZe8j9c37eX3i9dz79KNPLxsM0PKCvnYCSOZPXUMRw0vz3SZInKEojwH8QJQbWbjzawAuBCYn9jAzKoTFs8FVoXzbwFnhm1KgZOBlRHWKik4ang53/joZJ657oP84nPTmDpuIHc8vZYP//BJzrv5r/z6mbXsqtMtUEX6msj2INy92czmAg8DucDt7r7MzG4g2KWZD8w1sw8BTcBO4JLw6bcAd5jZMsCAO9z9lahqlZ6Rn5vDWZNjnDU5xvZ4A/cufZvfL17P9fct49v3r+CsyTFmTxvN6ZOGkJerS3BEertIB91x9wXAgnbrrk+Yv7qD58UJurpKH1VZVsilp43n0tPG89rG3fxhyQbuW7qRB159h9iAQj52wmhmTx3NpGG998SfSLbTqGwSuWNHVXDsqAquO+c9LFy5hd8v3sAvnlrDz55YzQljBzJ76mg+cuwIBpcWZLpUEUmggJC0KczLZdaxI5h17Ai27K3n3pc28vvFG/j6Pa/xr/e+xvuqBnP2McM5e3KMMYNLMl2uSNZTQEhGDCsvYs4ZE7n89Am8tnEPjyzfxCPLNvOt+5fzrfuX857h5W1hcczIAZkuVyQrKSAko8yMKaMrmDK6gn86+yjWbd/Ho8s388iyzdz8+Cp+9NgqRlYUMbmimfzR2zhp/GDydYJbJC0UENKrjKss5bLTJ3DZ6RPYHm/gsZVbeHT5Zp5YuZm/3PYcA4ry+ODRQU+pD9QMpbRQX2GRqOj/Lum1KssK+dS0MXxq2hgefmwhNvxoHlm+mcdWbOaelzZSkJfDaZOGcNbkGKdXD2H0IJ23EOlJCgjpEwpzjRnHDOfsY4bTfKCFJet28sjyzTy6fDOPr9wCwOhBxZw8oTKcBiswRFKkgJA+Jy83h+kTKpk+oZJvnHs0q7bEeWb1dp5ds53HVmzmD0s2AAoMkVQpIKRPMzNqYuXUxMq55NQqWlqcVVviPLtGgSGSKgWE9Cs5OcZRw8s5anjywHh85ZZ3Bcb08YM5YewgJgwpJScnuiHLRfoaBYT0a90JjNKCXCaPHMCxoyqYEk4ThpaRq9CQLKWAkKySLDBqt8Z5ZcNuXtu4m1c37mbe8+u5o2ktACUFuUwekRAaoyuYqNCQLKGAkKyWk3PwHMbsqaMBONDirN4a59UNQWC8tnE3v3thPb/621oAivODPY0poyo4ZuQApoyuoLklmjszimSSAkKkndyE0PhEQmis2Rrn1Y0HQ+PuxeupazwQPMeg6qVFTBxaxqRhB6cJQ8so08V80kfpmyvSBbk5RnWsnOpYOR8/8WBovLktzmsb9/CXF5bRVFxG7ZY4j6/ccsgexYiKIiYNK2Pi0DImDitjUhgiQ8oKMNOhKum9FBAiRyg3x5g0rJxJw8oZuHsVM2YE931vOtDCuu111G6Js3prnNVb4tRujfP7xevZF+5xAFQU5zNxaGnbnkZVZSkThpYydnAJRfm5mfqzRNooIER6WH5uTtshpkTuzqY99dRuibdNq7fGeXzlVu5evKGtnRmMrChmwtBSxg8ppaqylPFDSxlfWcroQcW6G5+kjQJCJE3MjBEVxYyoKOb06qGHbNtb38TabXWs2RbnzW37WLttH29u28c9L21kb31zW7u8HGNsZQnjK8PwGFLKhCGljBlcwoiKIoWH9CgFhEgvUF6U3zbseSJ3Z8e+Rt4MAyNxenr1NuqbWtra5uYYwwcUMXpQMaMHlTBqUHE4X8zWuhaaDrRoqHTpFgWESC9mZlSWFVJZVsi0qsGHbGtpcTbvrefNrftYv7OODTv3s3Hnfjbs3M8zq7fxzp56PKH37deeepARFcVBcAwsbguS0YOKGTGwmOEDiigu0LkPOUgBIdJH5eQcPGSVTGNzC5t217NhZx1/efYlyoaNZUMYIM+u2c6mPfW0v3xjQFEeIyqKiVUUMWJAEbGKIoYPKGJERRGxAUUMryhiUEm+el9lCQWESD9VkJfD2MoSxlaW0Lghnxkzjjpke2KAvLO7nk176tmU8LjinT1sizccshfS+rrDw7BofRxWXkhlWQGVpcHjkLJCBpcW6JBWH6eAEMlSiQHSkaYDLWzZ2xAERxgem/fU887uejbvrmfp+l1seq2exgMtSZ9fUZwfBEYYHK0hMqSsIDh0Vho8xhudlhbXYIm9jAJCRDqUn5vDqIHFjBqY/DAWBCfS99Q3sz3ewPZ9jWyPN7At3sj2eCPb9zWwPd7ItnhDOEhiAzvrmpK+Ts7CBQwsKWBQST6DSwsYVFIQPJYWMLgkfCzNP2R9eWGeDndFSAEhIikxMyqK86kozmfC0MO3bz7Qwo66MEDC8Hjh5eVUjhzLjrpGdu5rYse+Rt7aUcfS9bvYWddI04HkY13l5RiDSoNQGVQShMqg0sT5cFsYOINK8hlQlK89lS5SQIhIWuXl5jCsvIhh5UVt64Ir0Y9K2t7diTc0B8FR18jOfY3s2NfIzrrgsXV+Z10Tq7fG2bmuiV11jR0OoJhjtO2pDCopYGBJAQNL8ttCbkBRHhWHLOezq76F+qYDWXeFuwJCRHo1M6O8KJ/yovxOz5ckcnf2NjSzqzVUwmDZWReEx459jeyqC/ZUNuysY9nbTezZ33TIUCjvsughCvNyGFDcLkyK8xlQnE95UR5lhcHjwSm/7bGsMI/ywrw+tfeigBCRfsfMGFAU/Ou/q6ECwUn5Pfub2L2/iT31zewO5xe/vIzYmPEJ24LHrfEGarfG2VvfzN76Zg50Ydj3ssK8MEwOhkhZURAepYUH17fOl4VtD5mK8tLSQ0wBISISys/NabswMdGAnW8wY8akTp/r7tQ3tbC3PgiXeEMze+ubwvBoaguR1uVgezO76hpZv7OOfQ3NxOubO9+LSVCYl9MWFu8pb2TGjCP9qzumgBAR6QFmRnFBLsUFuQwbcOSvc6DFqWsMAiZe38zehua28EicjzccXC6p39Zzf0gCBYSISC+Sm3PwnAsVh28PsGjRokhq0WWOIiKSlAJCRESSijQgzGyWmb1uZrVmdm2S7VeY2atmttTM/mpmk8P1nwnXtU4tZnZ8lLWKiMihIgsIM8sFbgE+AkwGLmoNgAR3ufsUdz8e+D5wE4C7/9bdjw/XXwy86e5Lo6pVRETeLco9iJOAWndf4+6NwDzg/MQG7r4nYbEUSNaJ+KLwuSIikkbm7cfy7akXNpsNzHL3y8Lli4Hp7j63XburgGuAAuBMd1/Vbvtq4Hx3fy3Je8wB5gDEYrGp8+b13hyJx+OUlZUdvmGGqL7UqL7UqL7UpFLfzJkzl7j7tKQb3T2SCZgN3JawfDFwcyftPw3c2W7ddODVrrzf1KlTvTdbuHBhpkvolOpLjepLjepLTSr1AYu9g9/VKA8xbQTGJCyPDtd1ZB5wQbt1FwL/27NliYhIV0R5odwLQLWZjScIhgsJ9hLamFm1HzykdC6wKmFbDvAp4PSuvNmSJUu2mdm6nig8IkOAaC537BmqLzWqLzWqLzWp1Deuow2RBYS7N5vZXOBhIBe43d2XmdkNBLs084G5ZvYhoAnYCVyS8BJnAOvdfU0X368LI9Fnjpkt9o6O8/UCqi81qi81qi81UdUX6VAb7r4AWNBu3fUJ81d38txFwMmRFSciIp3SldQiIpKUAiJ9bs10AYeh+lKj+lKj+lITSX2RXQchIiJ9m/YgREQkKQWEiIgkpYDoIWY2xswWmtlyM1tmZu/qoWVmM8xsd8Iotdcne60Ia1ybMHru4iTbzcx+FI6++4qZnZjG2o5qN4LvHjP7Srs2af/8zOx2M9tiZq8lrBtsZo+a2arwcVAHz70kbLPKzC5J1iai+v7TzFaG/w3vMbOBHTy30+9DhPV908w2Jvx3PKeD53Y6GnSE9f0uoba1Zra0g+em4/NL+ruStu9gR5dYa+r20CIjgBPD+XLgDWByuzYzgPszWONaYEgn288BHgSMoIvxcxmqMxfYBIzL9OdHcD3OicBrCeu+D1wbzl8L3JjkeYOBNeHjoHB+UJrqOxvIC+dvTFZfV74PEdb3TeCrXfgOrAYmEIzT9nL7/5+iqq/d9v8Grs/g55f0dyVd30HtQfQQd3/H3V8M5/cCK4BRma2q284Hfu2BZ4GBZjYiA3V8EFjt7hm/Mt7dnwR2tFt9PnBnOH8n7x4iBuDDwKPuvsPddwKPArPSUZ+7P+LuzeHiswTD3GREB59fVxx2NOie0Fl9ZmYEozlkbLifTn5X0vIdVEBEwMyqgBOA55JsPsXMXjazB83smPRWhgOPmNmScCTc9kYB6xOWN5CZkOtsDK5Mfn6tYu7+Tji/CYgladNbPssvEuwVJnO470OU5oaHwG7v4PBIb/j8Tgc2e7sRphOk9fNr97uSlu+gAqKHmVkZ8EfgK37o/S4AXiQ4bPJe4MfAvWku7zR3P5HgJk5XmdkZaX7/wzKzAuA84PdJNmf683sXD/ble2VfcTP7OtAM/LaDJpn6PvwUmAgcD7xDcBinN7qIzvce0vb5dfa7EuV3UAHRg8wsn+A/4m/d/U/tt7v7HnePh/MLgHwzG5Ku+tx9Y/i4BbiHYDc+UXdH4I3CR4AX3X1z+w2Z/vwSbG499BY+bknSJqOfpZl9Hvgo8JnwB+RduvB9iIS7b3b3A+7eAvyig/fN9OeXB3wc+F1HbdL1+XXwu5KW76ACooeExyt/Caxw95s6aDM8bIeZnUTw+W9PU32lZlbeOk9wIrP9TZjmA5+zwMnA7oTd2HTp8F9tmfz82pnPwYElLwHuS9LmYeBsMxsUHkI5O1wXOTObBfxf4Dx3r+ugTVe+D1HVl3he62MdvG/baNDhXuWFBJ97unwIWOnuG5JtTNfn18nvSnq+g1Gegc+mCTiNYDfvFWBpOJ0DXAFcEbaZCywj6JHxLHBqGuubEL7vy2ENXw/XJ9ZnBPcRXw28CkxL82dYSvCDX5GwLqOfH0FYvUMw4vAG4FKgEniMYHj6vwCDw7bTOPQmWV8EasPpC2msr5bg2HPr9/BnYduRwILOvg9pqu834ffrFYIfuhHt6wuXzyHotbM6nfWF63/V+r1LaJuJz6+j35W0fAc11IaIiCSlQ0wiIpKUAkJERJJSQIiISFIKCBERSUoBISIiSSkgRLrBzA7YoaPO9tgoo2ZWlTiqqEim5WW6AJE+Zr+7H5/pIkTSQXsQIj0gvDfA98P7AzxvZpPC9VVm9ng4MN1jZjY2XB+z4F4NL4fTqeFL5ZrZL8Kx/x8xs+KM/VGS9RQQIt1T3O4Q098nbNvt7lOAm4Efhut+DNzp7scRDJr3o3D9j4AnPBh48ESCq3EBqoFb3P0YYBfwiUj/GpFO6EpqkW4ws7i7lyVZvxY4093XhIOrbXL3SjPbRjCURFO4/h13H2JmW4HR7t6Q8BpVBOP3V4fLXwPy3f3bafjTRN5FexAiPcc7mO+OhoT5A+g8oWSQAkKk5/x9wuMz4fzfCEYiBfgM8FQ4/xhwJYCZ5ZpZRbqKFOkq/etEpHuK7dCb2D/k7q1dXQeZ2SsEewEXheu+DNxhZv8MbAW+EK6/GrjVzC4l2FO4kmBUUZFeQ+cgRHpAeA5imrtvy3QtIj1Fh5hERCQp7UGIiEhS2oMQEZGkFBAiIpKUAkJERJJSQIiISFIKCBERSer/A7zT1+vgNzIOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min_u regression sparse\n",
    "if 'min_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_min_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regression_sparse_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_sparse['y_train'].shape[1]\n",
    "    regressor_min_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse', regressor_min_u)\n",
    "else:\n",
    "    print('Loading min_u regression sparse')\n",
    "    regressor_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse')\n",
    "\n",
    "testing_data['min_u_regressor_sparse'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    testing_data['min_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_sparse'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training min_u regression focused\n",
      "[11:23:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsOElEQVR4nO3dd3hUdfr+8feTAgkECM1Ib2IBpBjA0FRUFJVmWcSCyqrYQGy7uPvbr31X17UgRcHedgUbCiguqFEI1aAIUqQJIhaKBgm9PL8/5uBm2QESzWSSmft1XedyTpvzHA7OzWmfj7k7IiIiB0qIdgEiIlI6KSBERCQsBYSIiISlgBARkbAUECIiEpYCQkREwlJAiPxGZtbMzHLNzKJYg5vZUQeZ19PMxpV0TVL2KSAkZpnZajM7vQQ2dS/wkAcvFQXb3W5m+QWGkSVQR1juPhFobmYto1WDlE0KCJHfwMxqAV2Btw6Y1dPd0woMg0q+uv/yCjAwyjVIGaOAkLhiZuXNbJiZfRsMw8ysfDCvhplNMrM8M/vRzKabWUIwb6iZrTOzLWb2pZmdFnxlN+BTd99RyO1fYWYzzGykmW02s6UFvgszq21mE4LtrzCzqwvMSzSzP5vZyqCOeWZWr8DXn25my4P6Rx1wyesj4Jxf96cm8Sop2gWIlLD/B2QBrQEH3gb+AvwfcCvwDVAzWDYLcDM7BhgEtHP3b82sIZAYLHM88GURazgReB2oAZwHvGlmjdz9R2As8AVQGzgWmGpmK939Q+AW4CLgbGAZ0BLYVuB7ewDtgMrAPGAi8F4wbwnQ0Mwqu/vPRaxX4pTOICTeXALc4+7r3X0DcDfQP5i3G6gFNHD33e4+PbivsBcoDzQzs2R3X+3uK4N10oEtYbbzVvAv+f3D1QXmrQeGBdsYRyhgzgnOBjoBQ919h7vPB54GLgvWuwr4i7t/6SGfu/umAt/7gLvnufvXQDahENxvf43pRfizkjingJB4UxtYU2B8TTAN4B/ACmCKma0ys9sB3H0FcBNwF7DezMaa2f51fgIqhdlOH3dPLzA8VWDeuv03tA+ooTbwo7tvOWBeneBzPWAlB/d9gc/bgLQC4/trzDvE+iL/RQEh8eZboEGB8frBNNx9i7vf6u6NgV7ALfvvD7j7v9y9c7CuA38P1l8AHF3EGuoccH9gfw3fAtXMrNIB89YFn9cCTYq4rf2OA1br8pIUhQJCYl2ymaXsHwg9zfMXM6tpZjWAO4CXAcysh5kdFfx4byZ0aWmfmR1jZqcGN7N3ANuBfcH3TwVOCL67sI4AbjSzZDP7HaEf73fdfS0wE7g/qLclcOX++ghdbrrXzJpaSEszq17IbZ4MTC5CjSIKCIl57xL6Qd8/pAC5hP7lvxD4FLgvWLYp8D6QD8wCHnf3bEL3Hx4ANhK6jHME8CcAd/8B+BDofcB2Jx7wHsT4AvPmBNvaCPwVuKDAvYSLgIaEzibGA3e6+/vBvEeAV4EpwM/AM0BqIf8cLgLGFHJZEQBMHQaJ/DZm1gx4AWjvh/kfysyuAK4KLleVCDPrCfR3974ltU2JDXrMVeQ3cvfFhB4vLZWCN6knRrsOKXt0iUlERMLSJSYREQlLZxAiIhJWzNyDqFGjhjds2LBI62zdupWKFStGpqBSTPsdX7Tf8aWo+z1v3ryN7l4z3LyYCYiGDRuSm5tbpHU++ugjTjnllMgUVIppv+OL9ju+FHW/zWzNwebpEpOIiISlgBARkbAUECIiElbEAiJoS2aumX1uZovM7O4wyzxqZvODYZmZ5RWY92Cw3hIzGx7N/n5FROJRJG9S7wROdfd8M0sGcsxssrvP3r+Au9+8/7OZDQbaBJ87EmoXf38fujmEGhv7KIL1iohIARE7gwg6NMkPRpOD4VBv5V1EqKVNguVSgHKEGkpLBn6IUKkiIhJGRN+kNrNEQl0fHgWMcvehB1muATAbqOvue4NpDxHqQcuAke7+/8KsN5CgI/aMjIzMsWPHFqm+/Px80tLSDr9gjNF+xxftd3wp6n537dp1nru3DTvT3SM+EOrmMBtocZD5Q4ERBcaPAt4h1CNWGqGml7scahuZmZleVNnZ2b983rZzjy/8Js/f+uwb/2DJ9/71pq2+d+++w37HivVbfNzcr33H7j1F3n60FNzveKL9ji/a78IBcv0gv6sl8qKcu+eZWTbQnVCH7AfqB9xQYPxcYLYHl6jMbDLQAZhe3LV9v3kHF4yeybq87Rx4MpWSnEBmg6qcflwG3ZplULdqhf+an7dtF5c9M5d1edsZ9dEK/nTWsZzZ/EjMjL37nN1795GSnIiISFkUsYAws5rA7iAcUoFu/KebxoLLHQtUJXSWsN/XwNVmdj+hS0wnA8MiUWeNtHKcUL8qfdvWo+kRaTSumcbPO3azYn0+y37YQs7yjdw9cTF3T1zMaccewSN9W1OlQjLuzm2vLWD9lh3c2bMZr8z9mmtf/pSG1Suwc88+1m/ZSaIZt515NFd1bkxCgh7CEpGyJZJnELWAF4L7EAnAq+4+yczuIXRKMyFYrh8wNjjV2e914FRCPX458J6H2rQvdkmJCQy/qM3/TG/XsNovn7/auJVJn3/L8A+X0+fxGTx1WVuyl67n/SU/8H89mjGgUyP6ZzVgXO5aPliynmoVy5FRuTxffp/P395dyowVm3i4bytqpJWPxC6IiERExALC3RcQPLZ6wPQ7Dhi/K8wye4FrIlVbUTWqUZHBpzWlQ5PqXPvyPM4dNYPtu/dyZvMMft+pIRAKmktObMAlJzb4ZT135+U5X3PvpMV0HzadXq1q07lpddo3qk5a+ZhpBktEYpR+pYqgbcNqvD2oM9e8lMu2nXt58IJWHOr9PTOjf1YD2jaoyt/eXcLLc9bw7IyvSE40eraszXWnNKFpRqUS3AMRkcJTQBRRnfRUJtzQmd379lE+qXA3oI+rVZmXrjyRHbv3Mm/NT0xd/APjPlnLm5+t44xmGZx3Ql2yGlcjvUK5CFcvIlJ4CohfISHBKJ9Q9KeTUpIT6XRUDTodVYMbT2vK8zO+4vmZq5my+AfMoHntyvRuVYeLT6xPRV2CEpEo069QlFSrWI5bzjiGQac2ZcE3ecxYsYmPl63nr+8u4fGPVnBl50Zc3rEhlVKSo12qiMQpteYaZeWSEmjbsBpDTm/Km9d34o3rOtK6XjoPTVlG14c+5q3P1uEHvqAhIlICFBClTGaDqjw3oD1v39CJOukp3DRuPpc8PYdVG/IPv7KISDFSQJRSreql8+b1nbi3TwsWrttMn1EzmL82L9pliUgcUUCUYokJocdkJw/pQnqFclz69Bzmrfkx2mWJSJxQQJQBdatWYNw1WdSsVJ7+z8xl1spN0S5JROKAAqKMqFUllXEDs6hVJYVLn5nDPRMX8/OO3dEuS0RimAKiDDmicgpvXteJfu3q8dzMrzjtYT3lJCKRo4AoY6pUSOav5x7P2zd0onYVPeUkIpGjgCijWtZNZ/z1nbgveMqp+7DpPPb+cvbt09mEiBQPBUQZlpBgXJrVgA9uPZkzWxzJo+8vY+gbCxQSIlIs1NRGDDiiUgrD+7WmUY2KDP9gOQB/P7+lOikSkd9EAREjzIybT28K8EtI3Nunhbo8FZFfTQERQw4Miewv13NFx4b0z2pIlQpq9E9Eikb3IGKMmXFLt6MZOzCLFnWq8NCUZXR84ANGfricHbv3Rrs8ESlDdAYRo7IaVyercXWWfPczw95fxkNTlvFq7jfc0aMZiXpvQkQKQQER446rVZkx/duSs3wjd01cxFUv5lK5nNFp3TwyG1Tl3DZ1qJ5WPtplikgppEtMcaJz0xpMHtKFBy9oSfPqCSxct5n73llC71Ez9JKdiISlgIgjyYkJ9G1bj2tapZAz9FTGX9+R7bv2csHoWXyupsRF5AAKiDjWpn5VXr+uIxXLJ9Lvydl89OX6aJckIqWIAiLONapRkTeu60ijGhW58oVcXstdG+2SRKSUUEAIR1RKYdw1WXRoXJ0/vL6AER8sVwuxIqKAkJBKKck8e0U7zm1Th4enLuP2Nxayc4/emxCJZ3rMVX5RLimBR/q2ok56KiOzV/DlD1sYfWkmR1ZJiXZpIhIFOoOQ/2Jm3HbmMTxxyQks/2ELPUbkMGeVujgViUcKCAnrrONr8dYNnaicksRFT83mwfeW6pKTSJxRQMhBNc2oxITBnenbth6Pf7SS3iNnsOS7n6NdloiUEAWEHFJa+SQeOL8lz1zelo35u+gzagbvffFdtMsSkRKggJBCOe24DN67qQvNalfmun9+yrM5X0W7JBGJMAWEFFqNtPL866oszmiWwT2TFnPPxMXq3lQkhikgpEhSyyXy+CWZXNGxIc/O+Ioh4+aza8++aJclIhGg9yCkyBITjDt7NuPIKik8MHkpedt2MfrSTCqW118nkVgSsTMIM0sxs7lm9rmZLTKzu8Ms86iZzQ+GZWaWF0zvWmD6fDPbYWZ9IlWrFJ2Zce3JTXjw/JbMWLGRi5+azbq87dEuS0SKUST/ybcTONXd880sGcgxs8nuPnv/Au5+8/7PZjYYaBNMzwZaB9OrASuAKRGsVX6lvu3qUbViOW4a+xndH53GXb2ac94JdTCzaJcmIr9RxM4gPGR/TzTJwXCoO5oXAa+EmX4BMNndtxVziVJMujXLYPKQkzi2ViVufe1zrnv5U/K27Yp2WSLyG1kkW+00s0RgHnAUMMrdhx5kuQbAbKCuu+89YN6HwCPuPinMegOBgQAZGRmZY8eOLVJ9+fn5pKWlFWmdWBCp/d7nznurd/PGst1USzEGtSlPg8qJxb6dX0vHO75ovwuna9eu89y9bdiZ7h7xAUgHsoEWB5k/FBgRZnotYAOQfLhtZGZmelFlZ2cXeZ1YEOn9nrfmRz/xr+/70f/vXX/z07UR3VZR6HjHF+134QC5fpDf1RJ5zNXd84KA6H6QRfoR/vJSX2C8u++OUGkSASfUr8rEwZ1pVS+dm8d9ziNTl6l/CZEyKJJPMdU0s/TgcyrQDVgaZrljgarArDBfc7D7ElLK1axUnn9edSIXZNZl+AfL+ft7XyokRMqYSD7FVAt4IbgPkQC86u6TzOweQqc0E4Ll+gFj/YBfDzNrCNQDPo5gjRJByYkJPHh+S8olJTD645Xs2rOP/+txnJ5wEikjIhYQ7r6A4LHVA6bfccD4XQdZfzVQJxK1SclJSDD+2qcF5ZMSeHbGV6zZtJW7ezenbtUK0S5NRA5DTW1IxJkZd/Roxl/OOY6ZKzfR7ZFpPDltJbv3qokOkdJMASElwsy4qktjpt5yEp2Oqs7f3l3K2Y9NJ3vpet2bECmlFBBSoupWrcBTl7Xlyf6Z7N67jwHPf0L/Z+ay9Ht1RCRS2iggpMSZGWc0P5IpN5/MnT2b8cW3mzlneA53TVjE5u16olmktFBASNSUS0pgQKdGfHTbKVzUvh4vzFrNaQ9/xNvz10W7NBFBASGlQHqFctzX53gmDupM3aoVGDJ2Pn95ayE79+w9/MoiEjEKCCk1WtSpwuvXduCakxrz8uyv6TtmNt+qCXGRqFFASKmSlJjAn84+jtGXnsDK9fn0HJHDJ6t/jHZZInFJASGlUvcWtXh7UCcqpyZzyVNzeH3eN9EuSSTuKCCk1GpSM43x13ekXaOq3Pba59z/7hL27tM7EyIlRQEhpVp6hXI8P6A9l2bVZ8y0VVz9Yi4/79CjsCIlQQEhpV5yYgL39Tmee/u0YNqyDZw7agZfbdwa7bJEYp4CQsqM/lkNePmqE/lx6y56jczhuRlfqT0nkQhSQEiZktW4OhMGdaZ1vXTunriYsx6bzsfLNqg9J5EIUEBImVOvWgVe/H17nr6sLXv27uPyZ+dy3hMz+fei79mnm9gixUYBIWWSmXF6swz+ffNJ3Nu7ORvzd3LNS/M4Y9g0piz6XmcUIsVAASFlWvmkRPp3aEj2rafwWL/WAAx8aR6XP/cJK9bnR7c4kTJOASExISkxgd6t6zB5SBf+r0czPlvzE92HTePp6at0NiHyKykgJKYkJyZwZedGZP/hFE477gjue2cJfx7/hZ52EvkVItYntUg01UgrzxOXZPLQlC95/KOVfP3jVi5uoDMJkaJQQEjMSkgw/tj9WBrVqMifxy9k6TdQvckmshpXj3ZpImWCLjFJzPtd23q8dm1HkhLgoqdm8/f3lrJrjy45iRyOAkLiQut66dzdMZV+7erxxEcruWD0TL7etC3aZYmUagoIiRspScb957Vk9KWZrN64lXNGTOe9L76LdlkipZYCQuJO9xZH8s6NXWhcM41rX/6Uuycu0lNOImEoICQu1atWgdeu6cCATg15bsZqLn92Lj9t3RXtskRKFQWExK1ySQnc2bM5D/+uFblrfqLXqByWfv9ztMsSKTUUEBL3zs+sy7iBWezcvY/zHp/J5IW6LyECCggRANrUr8rEwZ055shKXPfPT3l4ypdqGVbingJCJJBROYWxA7Po27YuIz5cwRXPf8KS73TJSeKXAkKkgPJJifz9/Jbc26cFn635ibMem87AF3P5Yt3maJcmUuIUECIHMDP6ZzUgZ+ipDDmtKbNWbaLXyBxGfrhcl50kriggRA6iSoVkbu52NDNuP5WerWrz0JRlXPViLnnb9DisxAcFhMhhVE5JZtiFrbm3d3OmL9/AOcNz+GT1j9EuSyTiIhYQZpZiZnPN7HMzW2Rmd4dZ5lEzmx8My8wsr8C8+mY2xcyWmNliM2sYqVpFDsfM6N+hIa9d25HEBKPvmFk8MHkpO/fsjXZpIhETyTOIncCp7t4KaA10N7Osggu4+83u3trdWwMjgDcLzH4R+Ie7Hwe0B9ZHsFaRQmldL513h3ShX7t6jP54Jb1HzmDZD1uiXZZIREQsIDxkf6fAycFwqDt8FwGvAJhZMyDJ3acG35Xv7mp6U0qFtPJJ3H9eS565vC0btuyk18gcXv1krbo2lZhjkfxLbWaJwDzgKGCUuw89yHINgNlAXXffa2Z9gKuAXUAj4H3gdnffe8B6A4GBABkZGZljx44tUn35+fmkpaUVaZ1YoP0uPnk79vHkwp0s3rSPrFqJXN68PKlJVqzb+K10vONLUfe7a9eu89y9bdiZ7h7xAUgHsoEWB5k/FBhRYPwCYDPQmFCvd28AVx5qG5mZmV5U2dnZRV4nFmi/i9eevft8xAfLvNHtk7zTAx/4nFWbIrKdX0vHO74Udb+BXD/I72qJPMXk7nlBQHQ/yCL9CC4vBb4B5rv7KnffA7wFnBDJGkV+rcQEY9CpTX+5gX3hk7qBLbEhkk8x1TSz9OBzKtANWBpmuWOBqsCsApM/AdLNrGYwfiqwOFK1ihSHzAZVeffG/9zAPu/xmazckH/4FUVKqUieQdQCss1sAaEf/KnuPsnM7jGzXgWW6weMDU51APDQvYbbgA/MbCFgwFMRrFWkWFQMbmA/dVlbvs3bTo/hOYz75GvdwJYyKSlSX+zuC4A2YabfccD4XQdZfyrQMiLFiURYt2YZTB5yEre8Op+hbyxk1spN3H9eS1LLJUa7NJFCK9QZhJlVNLOE4PPRZtbLzJIjW5pI2XZklRReuvJEbu12NG9//i0XjJ7Jurzt0S5LpNAKe4lpGpBiZnWAKUB/4PlIFSUSKxITjMGnNeWZy9vy9aZt9BqRw8wVG6NdlkihFDYgzEMvqp0HPO7uvwOaR64skdhy6rEZjL+hE1UqJHPx03O4e+Iitu/SU05SuhU6IMysA3AJ8E4wTRdTRYrgqCPSmDS4M5d3aMBzM1Zz9vDpzFvzU7TLEjmowgbETcCfgPHuvsjMGhN6r0FEiqBCuSTu7t2Cf111Irv27KPvmFmM/nil+pmQUqlQAeHuH7t7L3f/e3CzeqO73xjh2kRiVsejajD5pi50b34kD0xeylUv5vLTVvUzIaVLYZ9i+peZVTazisAXwGIz+0NkSxOJbZVTkhl5cRvu7d2cnOUbOWPYNF79ZC17dTYhpURhLzE1c/efgT7AZEIN6PWPVFEi8WJ/PxNvXt+RelVT+eMbC+gxIoeZK/Wkk0RfYQMiOXjvoQ8wwd13c+imu0WkCFrUqcIb13VkxEVt+Hn7bi5+KvSkk9pzkmgqbECMAVYDFYFpQfPcP0eqKJF4ZGb0bFWbD249mSs6NuS5GavpM2omK9arQyKJjsLepB7u7nXc/eyghdg1QNcI1yYSl1KSE7mrV3OeubwtP/y8gx4jcnh6+irdm5ASV9ib1FXM7BEzyw2GhwmdTYhIhJx2XAbvDelCpyY1uO+dJfQdM0utw0qJKuwlpmeBLUDfYPgZeC5SRYlIyBGVU3j68rY8emErVqzP56zHpjN27tfRLkviRGEDoom73xl04LPK3e8m1NubiESYmXFum7pMveUkTmxUjdvfXMjQ1xewY7duYEtkFTYgtptZ5/0jZtYJULOUIiXoiEopPD+gPYO6HsW43LX8bvQs1mzaGu2yJIYVNiCuBUaZ2WozWw2MBK6JWFUiElZignHbmcfw1GVtWb1pK2c/Np1Xc9eqQyKJiMI+xfS5u7ci1IFPS3dvQ6gbUBGJgm7NMnjvppNoUacKf3x9Ade9/Kma6pBiV6QuR9395+CNaoBbIlCPiBRSnfRU/nV1Fn8661g+WPoDZw6bxrRlG6JdlsSQ39IntRVbFSLyqyQmGNec3IS3buhEldRkLnt2LndNWKQb2FIsfktA6KKnSCnRvHYVJg7uzIBODXl+5mq662xCikHSoWaa2RbCB4EBqRGpSER+lZTkRO7s2ZxuzTL4y/gvuOzZufRoWYvTqu2LdmlSRh0yINy9UkkVIiLFo2OTUF8TYz5excjsFUz1faxNXs7VXRqTWk4dQUrh/ZZLTCJSSpVPSuTG05oy9eaTOL5GIo9MXcapD3/E5IXfRbs0KUMUECIxrEH1igxqk8Kr13Sgelo5rvvnp9z/7hI1/CeFooAQiQPtG1Xjzes60T+rAWOmreKK5+aSt03vTcihKSBE4kS5pATu7dOCB847njmrfuTsx6YzZdH30S5LSjEFhEic6de+Pq9e24FKKckMfGkeV73wCWt/3BbtsqQUUkCIxKHW9dKZdGNn/nz2scxcuYkzh03j7fnrol2WlDIKCJE4lZyYwMCTmjD1lpNpXrsyQ8bO509vqhlx+Q8FhEicq5OeyitXZ3H9KU14Ze5a+oyawfIf1A+2KCBEBEhKTOCP3Y/l+QHt2LBlJz1H5vCvOV+rGfE4p4AQkV+ccswRTB7ShXYNq/Hn8Qu57uVP2bxtd7TLkihRQIjIfzmicgovDGjPn88+lveX/MA5I6Yzf21etMuSKFBAiMj/SEgwBp7UhNeu7YA7/G70TJ7J+UqXnOJMxALCzFLMbK6ZfW5mi8zs7jDLPGpm84NhmZnlFZi3t8C8CZGqU0QOrk39qrx7YxdOOeYI7p20mAvHzGaZbmDHjUO25vob7QROdfd8M0sGcsxssrvP3r+Au9+8/7OZDQbaFFh/u7u3jmB9IlIIVSok82T/TF7NXcv9k5dy9mPTubJzI246/Wi1DhvjInYG4SH5wWhyMBzq/PQi4JVI1SMiv56ZcWG7+nx46ymcd0IdxkxbRa+ROXz5vc4mYllE70GYWaKZzQfWA1Pdfc5BlmsANAI+LDA5xcxyzWy2mfWJZJ0iUjjVKpbjwQta8dKV7flp2256jczhlbl6HDZWWUkcWDNLB8YDg939izDzhwJ13X1wgWl13H2dmTUmFBynufvKA9YbCAwEyMjIyBw7dmyR6srPzyctLa2ou1Pmab/jS6T2e/NO58kFO1i0aR/tj0xkQIvypCaVnq7qdbwLp2vXrvPcvW3Yme5eIgNwB3DbQeZ9BnQ8xLrPAxcc6vszMzO9qLKzs4u8TizQfseXSO733r37fOSHy73xn97xkx/80L9YlxexbRWVjnfhALl+kN/VSD7FVDM4c8DMUoFuwNIwyx0LVAVmFZhW1czKB59rAJ2AxZGqVUR+nYQE44auR/HK1Vns2L2Pcx+fyfMzvmKfOiSKCZG8B1ELyDazBcAnhO5BTDKze8ysV4Hl+gFjgyTb7zgg18w+B7KBB9xdASFSSrVvVI13buxMpybVuWviYi55eo6aEI8BEXvM1d0X8N+Pre6ffscB43eFWWYmcHykahOR4lc9rTzPXtGOV3PXcu+kJZw5bBp39GjGhe3qYVZ67k1I4elNahEpNvsfh/33zSfRpn46t7+5kFtf+5ztu9SEeFmkgBCRYlcnPZUXf38iQ05ryvjP1tFn1AxWbsg//IpSqiggRCQiEhOMm7sdzfMD2rN+yw56j5zBe1+oD+yyRAEhIhF18tE1mXRjF5rUrMi1L8/jwfeWsldPOZUJCggRibg66amMu6YD/drV4/GPVnL5s3PZlL8z2mXJYSggRKREpCQn8sD5Lfn7+cczd/WPnDM8h09W/xjtsuQQFBAiUqIubFef8dd3pHxyAv2enM3oj1fqklMppYAQkRLXvHYVJg7uzJnNM3hg8lLOf2ImS7//OdplyQEUECISFZVTkhl18Qk81q81a3/cRo/hOfzj30vZtWdftEuTgAJCRKLGzOjdug7v33IyvVvXYVT2Ss57Qu9MlBYKCBGJuqoVy/Fw31Y82T+Tb37aTo/hOYxVPxNRp4AQkVLjjOZH8t6Q/zTTcd3Ln/LT1l3RLituKSBEpFQ5skoKL195In8661g+WPoD3R+bRs7yjdEuKy4pIESk1ElIMK45uQnjr+9EpZRkLn1mDg9MXsqevbqBXZIUECJSarWoU4WJgzpzUfv6jP54JRc/NYfvN++IdllxQwEhIqVaarlE7j/veIZd2Jovvt3MOcOn8/7iH6JdVlxQQIhImdCnTR0mDOpEzUrluerFXG585TO15xRhCggRKTOOOqISEwZ15ubTj2byF99x+iMfM/Hzb6NdVsxSQIhImVIuKYEhpzflnRu7UL96RQa/8hmDX/mMvG16HLa4KSBEpEw6OqMSb1zbgVu7Hc3khd9x5jA9DlvcFBAiUmYlJSYw+LSmvHVD6HHY/s/OYVT2CvapddhioYAQkTKvRZ0qTBjUiR4ta/OPf3/JNS/PY9tuhcRvlRTtAkREikOFckkM79ea1vXS+du7S5j/FVRrsomsxtWjXVqZpTMIEYkZZsaVnRsxbmAWZtDvydncNWER23btiXZpZZICQkRiTtuG1bi3YypXdGzI8zNXc87wHBZ8kxftssocBYSIxKTyScZdvZrzytVZ7Ny9l/Men8mYj1fqBnYRKCBEJKZ1aFKdyUNOoluzDO6fvJT+z85hzaat0S6rTFBAiEjMq1IhmccvOYH7zzuez9du5oxHp/H4RyvYrdZhD0kBISJxwcy4qH19pt5yEqccU5MH3/uSniNyWPTt5miXVmopIEQkrtSqksqY/m15sn8mm7buos+oGYzKXsFe3Zv4HwoIEYlLZzQ/kik3he5N/OPfX3LhmFmsy9se7bJKFQWEiMStqhXLMeriE3j0wlYs/X4L5wyfzodL1dfEfgoIEYlrZsa5beoyaXBnaldJ5ffP5/LA5KW6gY0CQkQEgIY1KvLm9R1/6d6018gZLPwmvm9gKyBERAIpyaHuTcf0z2RT/k56j8rh/neXsGP33miXFhURCwgzSzGzuWb2uZktMrO7wyzzqJnND4ZlZpZ3wPzKZvaNmY2MVJ0iIgc6s/mRTL3lZC5sV48x01bRc0QOS777OdpllbhInkHsBE5191ZAa6C7mWUVXMDdb3b31u7eGhgBvHnAd9wLTItgjSIiYVVJTeb+81ry4u/bk7d9N71HzuCZnK/iqqmOiAWEh+QHo8nBcKg/2YuAV/aPmFkmkAFMiVSNIiKHc9LRNXlvSBdOOrom905azCVPx09THeYeuTQ0s0RgHnAUMMrdhx5kuQbAbKCuu+81swTgQ+BS4HSgrbsPCrPeQGAgQEZGRubYsWOLVF9+fj5paWlFWicWaL/ji/a7eLg7H3+zh7FLd7HP4fyjy9GtQRIJZsW2jeJQ1P3u2rXrPHdvG3amu0d8ANKBbKDFQeYPBUYUGB8E/DH4fAUw8nDbyMzM9KLKzs4u8jqxQPsdX7TfxevbvG0+4Lm53mDoJP/dEzP927xtEdnOr1XU/QZy/SC/qyXyFJO75wUB0f0gi/SjwOUloAMwyMxWAw8Bl5nZA5GsUUSkMGpVSeWZy9vy8O9a8cW3mznrselMXRybL9dF8immmmaWHnxOBboBS8MsdyxQFZi1f5q7X+Lu9d29IXAb8KK73x6pWkVEisLMOD8z9HJdnfRUrn4xl7smLGLnnth6HDaSZxC1gGwzWwB8Akx190lmdo+Z9SqwXD9gbHCqIyJSZjSumcab13dkQKdQz3XnPzGT1Rtj5wZ2UqS+2N0XAG3CTL/jgPG7DvM9zwPPF2NpIiLFpnxSInf2bE6HxtX5w+sL6DEih7+ddzy9WtWOdmm/md6kFhEpBmc0P5J3h3ThmCMrceMrn3HLuPls2bE72mX9JgoIEZFiUic9lXEDsxhyWlPemr+Osx6bTu7qH6Nd1q+mgBARKUZJiQnc3O1oXru2I2Zw4ZOzGf3xyjL5BrYCQkQkAjIbVOXdG7twZvMMHpi8lIEv5bJ5W9m65KSAEBGJkEopyYy6+ATu7NmMj77cwDkjpjNvTdm55KSAEBGJIDNjQKdGvHptBwD6jpnNsPeXsacMdEikgBARKQEn1K/Ku0O60KtVbYa9v5y+Y2aV+kb/FBAiIiWkckoyj17Ymsf6tWb5+nzOemw6/5rzNaX1PWEFhIhICevdug7/vukkWtdL58/jF3LlC7ls2LIz2mX9DwWEiEgU1E5P5eUrT+TOns2YsWIjZz02jY+XbYh2Wf9FASEiEiUJCaEb2BMGdaZaxXJc/uxc/vrO4lLT6J8CQkQkyo45shITBnXm0qz6PDX9K84ZnsO8NT9FuywFhIhIaZCSnMh9fY7nuQHt2LZzDxeMnsldExaxdeeeqNWkgBARKUW6HnMEU245mcuyGvDCrNWcM3w6n30dnbMJBYSISCmTVj6Ju3u3YOzVWeze61wwehaPvb+8xF+uU0CIiJRSJzauzuSbQi/XPfr+Mvo9OZtv87aX2PYVECIipVjBl+uWfPczZw+fzgdLSqYPbAWEiEgZ0Lt1HSYO7kytKqlc+UIud779BfkRvoGtgBARKSMa10xj/PUduaJjQ16cvYZuj3zMlEXfR2x7CggRkTIkJTmRu3o15/VrO1I5JZmBL83jhn9+GpEOiZKK/RtFRCTiMhtUZdKNnXl6+lds3bmHhAQr9m0oIEREyqjkxASuO6VJxL5fl5hERCQsBYSIiISlgBARkbAUECIiEpYCQkREwlJAiIhIWAoIEREJSwEhIiJhmXvxv54dDWa2AVhTxNVqABsjUE5pp/2OL9rv+FLU/W7g7jXDzYiZgPg1zCzX3dtGu46Spv2OL9rv+FKc+61LTCIiEpYCQkREwor3gHgy2gVEifY7vmi/40ux7Xdc34MQEZGDi/czCBEROQgFhIiIhBWXAWFm3c3sSzNbYWa3R7ueSDGzemaWbWaLzWyRmQ0Jplczs6lmtjz4b9Vo1xoJZpZoZp+Z2aRgvJGZzQmO+zgzKxftGoubmaWb2etmttTMlphZh3g43mZ2c/B3/Asze8XMUmL1eJvZs2a23sy+KDAt7DG2kOHBn8ECMzuhKNuKu4Aws0RgFHAW0Ay4yMyaRbeqiNkD3OruzYAs4IZgX28HPnD3psAHwXgsGgIsKTD+d+BRdz8K+Am4MipVRdZjwHvufizQitD+x/TxNrM6wI1AW3dvASQC/Yjd4/080P2AaQc7xmcBTYNhIPBEUTYUdwEBtAdWuPsqd98FjAV6R7mmiHD379z90+DzFkI/FnUI7e8LwWIvAH2iUmAEmVld4Bzg6WDcgFOB14NFYm6/zawKcBLwDIC773L3POLgeBPqPjnVzJKACsB3xOjxdvdpwI8HTD7YMe4NvOghs4F0M6tV2G3FY0DUAdYWGP8mmBbTzKwh0AaYA2S4+3fBrO+BjGjVFUHDgD8C+4Lx6kCeu+8JxmPxuDcCNgDPBZfWnjazisT48Xb3dcBDwNeEgmEzMI/YP94FHewY/6bfu3gMiLhjZmnAG8BN7v5zwXkees45pp51NrMewHp3nxftWkpYEnAC8IS7twG2csDlpBg93lUJ/Uu5EVAbqMj/XoKJG8V5jOMxINYB9QqM1w2mxSQzSyYUDv909zeDyT/sP80M/rs+WvVFSCegl5mtJnQJ8VRC1+bTg0sQEJvH/RvgG3efE4y/TigwYv14nw585e4b3H038CahvwOxfrwLOtgx/k2/d/EYEJ8ATYMnHMoRupk1Ico1RURw3f0ZYIm7P1Jg1gTg8uDz5cDbJV1bJLn7n9y9rrs3JHR8P3T3S4Bs4IJgsVjc7++BtWZ2TDDpNGAxMX68CV1ayjKzCsHf+f37HdPH+wAHO8YTgMuCp5mygM0FLkUdVly+SW1mZxO6Rp0IPOvuf41uRZFhZp2B6cBC/nMt/s+E7kO8CtQn1ER6X3c/8KZXTDCzU4Db3L2HmTUmdEZRDfgMuNTdd0axvGJnZq0J3ZgvB6wCBhD6h2BMH28zuxu4kNCTe58BVxG61h5zx9vMXgFOIdSs9w/AncBbhDnGQWCOJHTJbRswwN1zC72teAwIERE5vHi8xCQiIoWggBARkbAUECIiEpYCQkREwlJAiIhIWAoIkSIws71mNr/AUGwN35lZw4ItdIpEW9LhFxGRAra7e+toFyFSEnQGIVIMzGy1mT1oZgvNbK6ZHRVMb2hmHwZt8X9gZvWD6RlmNt7MPg+GjsFXJZrZU0HfBlPMLDVqOyVxTwEhUjSpB1xiurDAvM3ufjyhN1eHBdNGAC+4e0vgn8DwYPpw4GN3b0WovaRFwfSmwCh3bw7kAedHdG9EDkFvUosUgZnlu3tamOmrgVPdfVXQQOL37l7dzDYCtdx9dzD9O3evYWYbgLoFm34ImmSfGnT6gpkNBZLd/b4S2DWR/6EzCJHi4wf5XBQF2wrai+4TShQpIESKz4UF/jsr+DyTUIuyAJcQajwRQt1CXge/9J1dpaSKFCks/etEpGhSzWx+gfH33H3/o65VzWwBobOAi4Jpgwn18PYHQr29DQimDwGeNLMrCZ0pXEeoNzSRUkP3IESKQXAPoq27b4x2LSLFRZeYREQkLJ1BiIhIWDqDEBGRsBQQIiISlgJCRETCUkCIiEhYCggREQnr/wPuHCDfs4tuvwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min_u regression focused\n",
    "if 'min_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_focused['y_train'].shape[1]\n",
    "    regressor_min_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused', regressor_min_u_focused)\n",
    "else:\n",
    "    print('Loading min_u regression focused')\n",
    "    regressor_min_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused')\n",
    "\n",
    "testing_data['min_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    testing_data['min_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_focused'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training min_u regression filtered\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min u regression filtered\n",
    "if 'min_u_filtered_regressor.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression filtered')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_filtered = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_gradient_boost_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_xgboost_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_support_vector_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_mlp_regression_filtered_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_filtered['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_filtered['y_train'].shape[1]\n",
    "    regressor_min_u_filtered.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_filtered_regressor', regressor_min_u_filtered)\n",
    "else: \n",
    "    print('Loading min_u filtered regression')\n",
    "    regressor_min_u_filtered = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_filtered_regressor')\n",
    "\n",
    "testing_data['min_u_filtered_regressor'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_filtered.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_filtered['y_test'].columns)\n",
    "    testing_data['min_u_filtered_regressor'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_filtered_regressor'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_filtered_regressor'][model]['real'] = deepcopy(data_min_u_sparse['y_test'][utils.cols_with_positive_values(prediction)].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training min_u regression balanced\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min u regression balanced\n",
    "if 'min_u_regressor_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression balanced')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_balanced = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_gradient_boost_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_xgboost_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_support_vector_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_mlp_regression_balanced_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_balanced['y_train'].shape[1]\n",
    "    regressor_min_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_balanced', regressor_min_u_balanced)\n",
    "else: \n",
    "    print('Loading min_u regression balanced')\n",
    "    regressor_min_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_balanced')\n",
    "\n",
    "testing_data['min_u_regressor_balanced'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    testing_data['min_u_regressor_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_balanced'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training min_u classification\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min_u classification\n",
    "if 'min_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_gradient_boost_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_xgboost_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_support_vector_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_mlp_sparse_classifier_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_bool['y_train'].shape[1]\n",
    "    classifier_min_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier', classifier_min_u)\n",
    "else: \n",
    "    print('Loading min_u classification')\n",
    "    classifier_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier')\n",
    "\n",
    "testing_data['min_u_classifier'] = {}\n",
    "for model, strategy in zip(class_models, classifier_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_bool)\n",
    "    testing_data['min_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_classifier'][model]['real'] = deepcopy(data_min_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<thesis_package.aimodels.GradientBoostClassifierStrategy at 0x22865cf8160>,\n",
       " <thesis_package.aimodels.XGBoostClassifierStrategy at 0x2288bdfae80>,\n",
       " <thesis_package.aimodels.SupportVectorClassifierStrategy at 0x228855d6250>,\n",
       " <thesis_package.aimodels.MultilayerPerceptronStrategy at 0x2287238a400>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_min_u.strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training min_u classification balanced\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min u classification balanced\n",
    "if 'min_u_classifier_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification balanced')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_gradient_boost_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_xgboost_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_support_vector_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_mlp_balanced_classifier_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_bool_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_bool_balanced['y_train'].shape[1]\n",
    "    classifier_min_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier_balanced', classifier_min_u_balanced)\n",
    "else: \n",
    "    print('Loading min_u classification balanced')\n",
    "    classifier_min_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier_balanced')\n",
    "\n",
    "testing_data['min_u_classifier_balanced'] = {}\n",
    "for model, strategy in zip(class_models, classifier_min_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_bool)\n",
    "    testing_data['min_u_classifier_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_classifier_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_classifier_balanced'][model]['real'] = deepcopy(data_min_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "In this section the results of the training and testing are presented and compared. The main objectives of this experience is to compare the performance of the regression models in terms of the hybrid metrics confusion matrix and the hybrid metrics rmse. The comparisons will be the following:\n",
    "- Compare the confusion matrices of the classification models and the regression models evaluate with the hybrid metrics.\n",
    "- Compare the error results of the regression models trained with the focused dataset and the sparse dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_u_regressor_sparse :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_regressor_focused :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_filtered_regressor :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_regressor_balanced :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_classifier :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_classifier_balanced :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_sparse :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_focused :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_filtered_regressor :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_balanced :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_classifier :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_classifier_balanced :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n"
     ]
    }
   ],
   "source": [
    "for experience in testing_data.keys():\n",
    "    print(experience,': ', testing_data[experience].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 + 0 = 0 = 1590.4300280519656 possible positive values.\n",
      "217047 + 77879 = 294926 = 305905.56997194805 possible negative values.\n"
     ]
    }
   ],
   "source": [
    "# Testing all models: Function that receives a dict with the real and predicted values, and outputs a dataframe with the results of the metrics.\n",
    "# Accumulate all the classifications for each bus.\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for bus in testing_data['max_u_regressor_sparse']['mlp']['predicted'].columns:\n",
    "    # Compute tp, tn, fp, fn\n",
    "    tp += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 1) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 1))\n",
    "    tn += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 0) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 0))\n",
    "    fp += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 1) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 0))\n",
    "    fn += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 0) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 1))\n",
    "print('{} + {} = {} = {} possible positive values.'.format(tp, fn, tp+fn, testing_data['max_u_regressor_sparse']['mlp']['real'].sum().sum()))\n",
    "print('{} + {} = {} = {} possible negative values.'.format(tn, fp, tn+fp, testing_data['max_u_regressor_sparse']['mlp']['real'].shape[0]*testing_data['max_u_regressor_sparse']['mlp']['real'].shape[1] - testing_data['max_u_regressor_sparse']['mlp']['real'].sum().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beepy import beep; beep(sound=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: max_u_regressor_sparse, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3151\n",
      "true_negatives_ctr:  297203\n",
      "false_positives_ctr:  5344\n",
      "false_negatives_ctr:  1798\n",
      "3803175167752364985\n",
      "Experiment: max_u_regressor_sparse, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3410\n",
      "true_negatives_ctr:  299857\n",
      "false_positives_ctr:  2690\n",
      "false_negatives_ctr:  1539\n",
      "2752818789825106800\n",
      "Experiment: max_u_regressor_sparse, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4550\n",
      "true_negatives_ctr:  292244\n",
      "false_positives_ctr:  10303\n",
      "false_negatives_ctr:  399\n",
      "6508226007841622337\n",
      "Experiment: max_u_regressor_sparse, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4615\n",
      "true_negatives_ctr:  275913\n",
      "false_positives_ctr:  26634\n",
      "false_negatives_ctr:  334\n",
      "12925400211095992809\n",
      "Experiment: max_u_regressor_sparse, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4948\n",
      "true_negatives_ctr:  217055\n",
      "false_positives_ctr:  85492\n",
      "false_negatives_ctr:  1\n",
      "29392914664141297920\n",
      "Experiment: max_u_regressor_focused, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4321\n",
      "true_negatives_ctr:  297379\n",
      "false_positives_ctr:  5168\n",
      "false_negatives_ctr:  628\n",
      "4234062035962222569\n",
      "Experiment: max_u_regressor_focused, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4523\n",
      "true_negatives_ctr:  249361\n",
      "false_positives_ctr:  53186\n",
      "false_negatives_ctr:  426\n",
      "21583590147476487249\n",
      "Experiment: max_u_regressor_focused, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4660\n",
      "true_negatives_ctr:  179741\n",
      "false_positives_ctr:  122806\n",
      "false_negatives_ctr:  289\n",
      "34359714271387409940\n",
      "Experiment: max_u_regressor_focused, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4940\n",
      "true_negatives_ctr:  249296\n",
      "false_positives_ctr:  53251\n",
      "false_negatives_ctr:  9\n",
      "21721865183700422265\n",
      "Experiment: max_u_regressor_focused, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3713\n",
      "true_negatives_ctr:  204413\n",
      "false_positives_ctr:  98134\n",
      "false_negatives_ctr:  1236\n",
      "31360656654477986409\n",
      "Experiment: max_u_filtered_regressor, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3151\n",
      "true_negatives_ctr:  89191\n",
      "false_positives_ctr:  5344\n",
      "false_negatives_ctr:  1798\n",
      "361628256521776825\n",
      "Experiment: max_u_filtered_regressor, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3356\n",
      "true_negatives_ctr:  91872\n",
      "false_positives_ctr:  2663\n",
      "false_negatives_ctr:  1593\n",
      "263198515836827025\n",
      "Experiment: max_u_filtered_regressor, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4949\n",
      "true_negatives_ctr:  128\n",
      "false_positives_ctr:  94407\n",
      "false_negatives_ctr:  0\n",
      "5949961434565120\n",
      "Experiment: max_u_filtered_regressor, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4443\n",
      "true_negatives_ctr:  46628\n",
      "false_positives_ctr:  47907\n",
      "false_negatives_ctr:  506\n",
      "1154412620097103500\n",
      "Experiment: max_u_filtered_regressor, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4949\n",
      "true_negatives_ctr:  549\n",
      "false_positives_ctr:  93986\n",
      "false_negatives_ctr:  0\n",
      "25411621904145225\n",
      "Experiment: max_u_regressor_balanced, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4521\n",
      "true_negatives_ctr:  280815\n",
      "false_positives_ctr:  21732\n",
      "false_negatives_ctr:  428\n",
      "11055311020666760337\n",
      "Experiment: max_u_regressor_balanced, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4090\n",
      "true_negatives_ctr:  297475\n",
      "false_positives_ctr:  5072\n",
      "false_negatives_ctr:  859\n",
      "4092638102722559124\n",
      "Experiment: max_u_regressor_balanced, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4448\n",
      "true_negatives_ctr:  293409\n",
      "false_positives_ctr:  9138\n",
      "false_negatives_ctr:  501\n",
      "5978831001189609780\n",
      "Experiment: max_u_regressor_balanced, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4222\n",
      "true_negatives_ctr:  287934\n",
      "false_positives_ctr:  14613\n",
      "false_negatives_ctr:  727\n",
      "8140742936328958305\n",
      "Experiment: max_u_regressor_balanced, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4948\n",
      "true_negatives_ctr:  213184\n",
      "false_positives_ctr:  89363\n",
      "false_negatives_ctr:  1\n",
      "30104353037394300105\n",
      "Experiment: min_u_regressor_sparse, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  2553\n",
      "true_negatives_ctr:  297508\n",
      "false_positives_ctr:  3966\n",
      "false_negatives_ctr:  3469\n",
      "3562090133984546964\n",
      "Experiment: min_u_regressor_sparse, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5039\n",
      "true_negatives_ctr:  294582\n",
      "false_positives_ctr:  6892\n",
      "false_negatives_ctr:  983\n",
      "6402070686261354420\n",
      "Experiment: min_u_regressor_sparse, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4781\n",
      "true_negatives_ctr:  294780\n",
      "false_positives_ctr:  6694\n",
      "false_negatives_ctr:  1241\n",
      "6166884719777037300\n",
      "Experiment: min_u_regressor_sparse, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5502\n",
      "true_negatives_ctr:  281219\n",
      "false_positives_ctr:  20255\n",
      "false_negatives_ctr:  520\n",
      "13174461152311957044\n",
      "Experiment: min_u_regressor_sparse, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  6014\n",
      "true_negatives_ctr:  232123\n",
      "false_positives_ctr:  69351\n",
      "false_negatives_ctr:  8\n",
      "31760948254033544820\n",
      "Experiment: min_u_regressor_focused, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5877\n",
      "true_negatives_ctr:  244952\n",
      "false_positives_ctr:  56522\n",
      "false_negatives_ctr:  145\n",
      "27765547379161324884\n",
      "Experiment: min_u_regressor_focused, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5592\n",
      "true_negatives_ctr:  259564\n",
      "false_positives_ctr:  41910\n",
      "false_negatives_ctr:  430\n",
      "22421560500974862864\n",
      "Experiment: min_u_regressor_focused, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5628\n",
      "true_negatives_ctr:  252109\n",
      "false_positives_ctr:  49365\n",
      "false_negatives_ctr:  394\n",
      "25209519554749125012\n",
      "Experiment: min_u_regressor_focused, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5975\n",
      "true_negatives_ctr:  253411\n",
      "false_positives_ctr:  48063\n",
      "false_negatives_ctr:  47\n",
      "24865424909283840912\n",
      "Experiment: min_u_regressor_focused, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4106\n",
      "true_negatives_ctr:  222759\n",
      "false_positives_ctr:  78715\n",
      "false_negatives_ctr:  1916\n",
      "33782037118458198900\n",
      "Experiment: min_u_filtered_regressor, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  2553\n",
      "true_negatives_ctr:  80452\n",
      "false_positives_ctr:  3966\n",
      "false_negatives_ctr:  3469\n",
      "278116939284510804\n",
      "Experiment: min_u_filtered_regressor, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4993\n",
      "true_negatives_ctr:  77816\n",
      "false_positives_ctr:  6602\n",
      "false_negatives_ctr:  1029\n",
      "464751414722598900\n",
      "Experiment: min_u_filtered_regressor, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4936\n",
      "true_negatives_ctr:  78434\n",
      "false_positives_ctr:  5984\n",
      "false_negatives_ctr:  1086\n",
      "441443188214246400\n",
      "Experiment: min_u_filtered_regressor, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5369\n",
      "true_negatives_ctr:  66433\n",
      "false_positives_ctr:  17985\n",
      "false_negatives_ctr:  653\n",
      "796469195782443024\n",
      "Experiment: min_u_filtered_regressor, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4709\n",
      "true_negatives_ctr:  31253\n",
      "false_positives_ctr:  35197\n",
      "false_negatives_ctr:  1193\n",
      "507801000847280400\n",
      "Experiment: min_u_regressor_balanced, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5117\n",
      "true_negatives_ctr:  282366\n",
      "false_positives_ctr:  19108\n",
      "false_negatives_ctr:  905\n",
      "12458234917891809300\n",
      "Experiment: min_u_regressor_balanced, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4997\n",
      "true_negatives_ctr:  292064\n",
      "false_positives_ctr:  9410\n",
      "false_negatives_ctr:  1025\n",
      "7665909532803367444\n",
      "Experiment: min_u_regressor_balanced, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5316\n",
      "true_negatives_ctr:  289858\n",
      "false_positives_ctr:  11616\n",
      "false_negatives_ctr:  706\n",
      "8931834755719537344\n",
      "Experiment: min_u_regressor_balanced, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5366\n",
      "true_negatives_ctr:  283756\n",
      "false_positives_ctr:  17718\n",
      "false_negatives_ctr:  656\n",
      "11919268318002316224\n",
      "Experiment: min_u_regressor_balanced, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  6015\n",
      "true_negatives_ctr:  226077\n",
      "false_positives_ctr:  75397\n",
      "false_negatives_ctr:  7\n",
      "33415569463756268224\n"
     ]
    }
   ],
   "source": [
    "from numpy import sqrt \n",
    "# Build a multi-index dataframe with the results of the metrics. The first index is the testing_data.keys(), the second index are the tp, tn, fp, fn, and the columns are the models.\n",
    "columns = ['tp', 'tn', 'fp', 'fn', '(hybrid)accuracy', '(hybrid)precision', '(hybrid)recall', '(hybrid)f1']\n",
    "index = pd.MultiIndex.from_product([testing_data.keys(), ['lr', 'gb', 'xgb', 'svr', 'mlp']], names=['experiment', 'class'])\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "classifier_experiments =[experiment for experiment in testing_data.keys() if 'classifier' in experiment.split('_')] # TODO confirm this\n",
    "regressor_experiments = [experiment for experiment in testing_data.keys() if 'regressor' in experiment.split('_')]\n",
    "# Classifier experiments\n",
    "class_metrics = metrics.Metrics()\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for experiment in classifier_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        for bus in testing_data[experiment][model]['predicted'].columns:\n",
    "            try:\n",
    "                tp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "                tn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "            except: \n",
    "                print('In the experiment ', experiment, ' and model ', model, ' there was a problem with bus: ', bus)\n",
    "                if not testing_data[experiment][model]['real'][bus].any():\n",
    "                    print('Bus {} has no positive data points. Just ignore the little shit.'.format(bus))    \n",
    "        df.loc[(experiment, model), 'tp'] = tp\n",
    "        df.loc[(experiment, model), 'tn'] = tn\n",
    "        df.loc[(experiment, model), 'fp'] = fp\n",
    "        df.loc[(experiment, model), 'fn'] = fn\n",
    "        #print('Experiment: {}, model: {}, tp: {}, tn: {}, fp: {}, fn: {}'.format(experiment, model, tp, tn, fp, fn))\n",
    "        recall = class_metrics.compute_recall(tp, fn)\n",
    "        precision = class_metrics.compute_precision(tp, fp)\n",
    "        f1 = class_metrics.compute_f1(recall, precision)\n",
    "        accuracy = class_metrics.compute_accuracy(tp, tn, fp, fn)\n",
    "        mcc = class_metrics.compute_mcc(tp, tn, fp, fn)\n",
    "        df.loc[(experiment, model), '(hybrid)accuracy'] = accuracy\n",
    "        df.loc[(experiment, model), '(hybrid)precision'] = precision\n",
    "        df.loc[(experiment, model), '(hybrid)recall'] = recall\n",
    "        df.loc[(experiment, model), '(hybrid)f1'] = f1\n",
    "        df.loc[(experiment, model), '(hybrid)mcc'] = mcc\n",
    "        # print('Experiment: {}, model: {}, accuracy: {}, precision: {}, recall: {}, f1: {}'.format(experiment, model, accuracy, precision, recall, f1))\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0 \n",
    "# Regressor experiments\n",
    "_threshold = lambda experiment: max_u_threshold / data_max_u_balanced['scaler']['y'] if 'max_u' in experiment else min_u_threshold/ data_min_u_balanced['scaler']['y']\n",
    "# _threshold = lambda experiment: max_u_threshold if 'max_u' in experiment else min_u_threshold\n",
    "for experiment in regressor_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        # try:\n",
    "        threshold = _threshold(experiment)\n",
    "        print('Experiment: {}, model: {}, threshold: {}'.format(experiment, model, threshold))\n",
    "        hybrid_metrics = metrics.Metrics()\n",
    "        hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted'], testing_data[experiment][model]['real'], threshold=threshold)\n",
    "        df.loc[(experiment, model), 'tp'] = hybrid_metrics.true_positives_ctr\n",
    "        df.loc[(experiment, model), 'tn'] = hybrid_metrics.true_negatives_ctr\n",
    "        df.loc[(experiment, model), 'fp'] = hybrid_metrics.false_positives_ctr\n",
    "        df.loc[(experiment, model), 'fn'] = hybrid_metrics.false_negatives_ctr\n",
    "        df.loc[(experiment, model), '(hybrid)accuracy'] = hybrid_metrics.hybrid_accuracy\n",
    "        df.loc[(experiment, model), '(hybrid)precision'] = hybrid_metrics.hybrid_precision\n",
    "        df.loc[(experiment, model), '(hybrid)recall'] = hybrid_metrics.hybrid_recall\n",
    "        df.loc[(experiment, model), '(hybrid)f1'] = hybrid_metrics.hybrid_f1\n",
    "        df.loc[(experiment, model), '(hybrid)mcc'] = hybrid_metrics.hybrid_mcc\n",
    "        # print('Experiment: {}, model: {}, tp: {}, tn: {}, fp: {}, fn: {}'.format(experiment, model, hybrid_metrics.true_positives_ctr, hybrid_metrics.true_negatives_ctr, hybrid_metrics.false_positives_ctr, hybrid_metrics.false_negatives_ctr))\n",
    "        # print('Experiment: {}, model: {}, accuracy: {}, precision: {}, recall: {}, f1: {}'.format(experiment, model, hybrid_metrics.hybrid_accuracy_rmse, hybrid_metrics.hybrid_precision_rmse, hybrid_metrics.hybrid_recall_rmse, hybrid_metrics.hybrid_f1_rmse))\n",
    "        # except(Exception) as e:\n",
    "        #     print('In the experiment ', experiment, ' and model ', model, ' there was a problem')\n",
    "        #     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_db1_mcc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4321</td>\n",
       "      <td>297379</td>\n",
       "      <td>5168</td>\n",
       "      <td>628</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.540358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4523</td>\n",
       "      <td>249361</td>\n",
       "      <td>53186</td>\n",
       "      <td>426</td>\n",
       "      <td>0.79822</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.878914</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.187375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4660</td>\n",
       "      <td>179741</td>\n",
       "      <td>122806</td>\n",
       "      <td>289</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.919546</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.105429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4940</td>\n",
       "      <td>249296</td>\n",
       "      <td>53251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.225088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3713</td>\n",
       "      <td>204413</td>\n",
       "      <td>98134</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.635806</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.631136</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.064861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4521</td>\n",
       "      <td>280815</td>\n",
       "      <td>21732</td>\n",
       "      <td>428</td>\n",
       "      <td>0.917912</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.314492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4090</td>\n",
       "      <td>297475</td>\n",
       "      <td>5072</td>\n",
       "      <td>859</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.35234</td>\n",
       "      <td>0.759724</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>0.508297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4448</td>\n",
       "      <td>293409</td>\n",
       "      <td>9138</td>\n",
       "      <td>501</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.25097</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.452522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4222</td>\n",
       "      <td>287934</td>\n",
       "      <td>14613</td>\n",
       "      <td>727</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.798145</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.357587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>213184</td>\n",
       "      <td>89363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.066274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3499</td>\n",
       "      <td>91026</td>\n",
       "      <td>3509</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0.585264</td>\n",
       "      <td>0.569179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3158</td>\n",
       "      <td>92054</td>\n",
       "      <td>2481</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.957058</td>\n",
       "      <td>0.560028</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>0.575312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3956</td>\n",
       "      <td>89928</td>\n",
       "      <td>4607</td>\n",
       "      <td>993</td>\n",
       "      <td>0.94371</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>0.581876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4041</td>\n",
       "      <td>58329</td>\n",
       "      <td>36206</td>\n",
       "      <td>908</td>\n",
       "      <td>0.626935</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.816529</td>\n",
       "      <td>0.178821</td>\n",
       "      <td>0.192052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5877</td>\n",
       "      <td>244952</td>\n",
       "      <td>56522</td>\n",
       "      <td>145</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.223576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5592</td>\n",
       "      <td>259564</td>\n",
       "      <td>41910</td>\n",
       "      <td>430</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.908282</td>\n",
       "      <td>0.160995</td>\n",
       "      <td>0.254038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5628</td>\n",
       "      <td>252109</td>\n",
       "      <td>49365</td>\n",
       "      <td>394</td>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.228193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5975</td>\n",
       "      <td>253411</td>\n",
       "      <td>48063</td>\n",
       "      <td>47</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.262651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4106</td>\n",
       "      <td>222759</td>\n",
       "      <td>78715</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.702687</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.585727</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.084777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5117</td>\n",
       "      <td>282366</td>\n",
       "      <td>19108</td>\n",
       "      <td>905</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.165926</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.345050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4997</td>\n",
       "      <td>292064</td>\n",
       "      <td>9410</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.284526</td>\n",
       "      <td>0.77814</td>\n",
       "      <td>0.41669</td>\n",
       "      <td>0.456403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5316</td>\n",
       "      <td>289858</td>\n",
       "      <td>11616</td>\n",
       "      <td>706</td>\n",
       "      <td>0.954371</td>\n",
       "      <td>0.255966</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.393042</td>\n",
       "      <td>0.450693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5366</td>\n",
       "      <td>283756</td>\n",
       "      <td>17718</td>\n",
       "      <td>656</td>\n",
       "      <td>0.933244</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.391941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6015</td>\n",
       "      <td>226077</td>\n",
       "      <td>75397</td>\n",
       "      <td>7</td>\n",
       "      <td>0.601244</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.993896</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.070213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4379</td>\n",
       "      <td>77799</td>\n",
       "      <td>6619</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.398163</td>\n",
       "      <td>0.727167</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.494868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4395</td>\n",
       "      <td>77766</td>\n",
       "      <td>6652</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.908459</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>0.729824</td>\n",
       "      <td>0.514969</td>\n",
       "      <td>0.495647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4931</td>\n",
       "      <td>79390</td>\n",
       "      <td>5028</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.49513</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.604686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5328</td>\n",
       "      <td>46466</td>\n",
       "      <td>37952</td>\n",
       "      <td>694</td>\n",
       "      <td>0.572689</td>\n",
       "      <td>0.123105</td>\n",
       "      <td>0.884756</td>\n",
       "      <td>0.216137</td>\n",
       "      <td>0.217185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                                \n",
       "max_u_regressor_sparse    lr     3151  297203    5344  1798         0.973939   \n",
       "                          gb     3410  299857    2690  1539          0.98396   \n",
       "                          xgb    4550  292244   10303   399         0.960463   \n",
       "                          svr    4615  275913   26634   334         0.904389   \n",
       "                          mlp    4948  217055   85492     1         0.562262   \n",
       "max_u_regressor_focused   lr     4321  297379    5168   628         0.977467   \n",
       "                          gb     4523  249361   53186   426          0.79822   \n",
       "                          xgb    4660  179741  122806   289         0.554576   \n",
       "                          svr    4940  249296   53251     9         0.808736   \n",
       "                          mlp    3713  204413   98134  1236         0.635806   \n",
       "max_u_filtered_regressor  lr     3151   89191    5344  1798         0.918805   \n",
       "                          gb     3356   91872    2663  1593         0.949925   \n",
       "                          xgb    4949     128   94407     0         0.037666   \n",
       "                          svr    4443   46628   47907   506         0.481777   \n",
       "                          mlp    4949     549   93986     0         0.010538   \n",
       "max_u_regressor_balanced  lr     4521  280815   21732   428         0.917912   \n",
       "                          gb     4090  297475    5072   859         0.977647   \n",
       "                          xgb    4448  293409    9138   501         0.963717   \n",
       "                          svr    4222  287934   14613   727         0.944365   \n",
       "                          mlp    4948  213184   89363     1         0.545878   \n",
       "max_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     2487   92303    2232  2462         0.952817   \n",
       "                          xgb    1817   93214    1321  3132         0.955239   \n",
       "                          svr       0   94535       0  4949         0.950253   \n",
       "                          mlp    3902   58964   35571  1047         0.631921   \n",
       "max_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     3499   91026    3509  1450         0.950153   \n",
       "                          xgb    3158   92054    2481  1791         0.957058   \n",
       "                          svr    3956   89928    4607   993          0.94371   \n",
       "                          mlp    4041   58329   36206   908         0.626935   \n",
       "min_u_regressor_sparse    lr     2553  297508    3966  3469         0.972468   \n",
       "                          gb     5039  294582    6892   983         0.970974   \n",
       "                          xgb    4781  294780    6694  1241         0.970684   \n",
       "                          svr    5502  281219   20255   520         0.925053   \n",
       "                          mlp    6014  232123   69351     8         0.629952   \n",
       "min_u_regressor_focused   lr     5877  244952   56522   145         0.780846   \n",
       "                          gb     5592  259564   41910   430         0.839482   \n",
       "                          xgb    5628  252109   49365   394         0.808055   \n",
       "                          svr    5975  253411   48063    47         0.822388   \n",
       "                          mlp    4106  222759   78715  1916         0.702687   \n",
       "min_u_filtered_regressor  lr     2553   80452    3966  3469         0.905889   \n",
       "                          gb     4993   77816    6602  1029         0.903749   \n",
       "                          xgb    4936   78434    5984  1086         0.911141   \n",
       "                          svr    5369   66433   17985   653         0.770305   \n",
       "                          mlp    4709   31253   35197  1193         0.181759   \n",
       "min_u_regressor_balanced  lr     5117  282366   19108   905         0.926901   \n",
       "                          gb     4997  292064    9410  1025         0.961439   \n",
       "                          xgb    5316  289858   11616   706         0.954371   \n",
       "                          svr    5366  283756   17718   656         0.933244   \n",
       "                          mlp    6015  226077   75397     7         0.601244   \n",
       "min_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4068   81151    3267  1954         0.942271   \n",
       "                          xgb    4167   80534    3884  1855         0.936544   \n",
       "                          svr    2965   82965    1453  3057         0.950133   \n",
       "                          mlp    5320   50125   34293   702         0.613058   \n",
       "min_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4379   77799    6619  1643         0.908647   \n",
       "                          xgb    4395   77766    6652  1627         0.908459   \n",
       "                          svr    4931   79390    5028  1091         0.932342   \n",
       "                          mlp    5328   46466   37952   694         0.572689   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_regressor_sparse    lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.441493       0.567722   0.496713   \n",
       "                          xgb            0.230752       0.882031   0.365804   \n",
       "                          svr            0.107401       0.898987   0.191878   \n",
       "                          mlp            0.008497       0.999275    0.01685   \n",
       "max_u_regressor_focused   lr             0.366413       0.822844   0.507041   \n",
       "                          gb             0.053925       0.878914   0.101616   \n",
       "                          xgb            0.025552       0.919546   0.049723   \n",
       "                          svr            0.063073       0.997519   0.118643   \n",
       "                          mlp            0.023876       0.631136   0.046011   \n",
       "max_u_filtered_regressor  lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.439197       0.552025    0.48919   \n",
       "                          xgb            0.036546            1.0   0.070515   \n",
       "                          svr            0.060259       0.842986   0.112478   \n",
       "                          mlp            0.007693            1.0   0.015269   \n",
       "max_u_regressor_balanced  lr                0.126       0.877757   0.220366   \n",
       "                          gb              0.35234       0.759724   0.481414   \n",
       "                          xgb             0.25097       0.857354   0.388281   \n",
       "                          svr            0.174752       0.798145   0.286726   \n",
       "                          mlp            0.008087       0.999274   0.016044   \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.527018       0.502526   0.514481   \n",
       "                          xgb            0.579031       0.367145   0.449363   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.098852       0.788442   0.175679   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.499287       0.707012   0.585264   \n",
       "                          xgb            0.560028       0.638109   0.596524   \n",
       "                          svr            0.461988       0.799353   0.585554   \n",
       "                          mlp            0.100405       0.816529   0.178821   \n",
       "min_u_regressor_sparse    lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.353983       0.787945   0.488506   \n",
       "                          xgb            0.345599       0.731315   0.469381   \n",
       "                          svr            0.174263       0.890969    0.29151   \n",
       "                          mlp            0.009394       0.993227   0.018612   \n",
       "min_u_regressor_focused   lr             0.067654       0.968548   0.126474   \n",
       "                          gb             0.088325       0.908282   0.160995   \n",
       "                          xgb            0.073954        0.91519   0.136849   \n",
       "                          svr            0.085393       0.990249   0.157228   \n",
       "                          mlp            0.035524       0.585727   0.066985   \n",
       "min_u_filtered_regressor  lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.360775       0.778289   0.493014   \n",
       "                          xgb            0.382714        0.76811    0.51088   \n",
       "                          svr            0.186868       0.861772   0.307136   \n",
       "                          mlp            0.015308       0.393679    0.02947   \n",
       "min_u_regressor_balanced  lr             0.165926       0.804743   0.275126   \n",
       "                          gb             0.284526        0.77814    0.41669   \n",
       "                          xgb            0.255966       0.846198   0.393042   \n",
       "                          svr            0.194107         0.8676   0.317238   \n",
       "                          mlp            0.008336       0.993896   0.016534   \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.554601       0.675523   0.609119   \n",
       "                          xgb            0.517575       0.691963   0.592198   \n",
       "                          svr            0.671118       0.492361   0.568008   \n",
       "                          mlp            0.134299       0.883427   0.233154   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.398163       0.727167   0.514571   \n",
       "                          xgb            0.397846       0.729824   0.514969   \n",
       "                          svr             0.49513       0.818831   0.617108   \n",
       "                          mlp            0.123105       0.884756   0.216137   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "max_u_regressor_sparse    lr        0.346102  \n",
       "                          gb        0.492687  \n",
       "                          xgb       0.439649  \n",
       "                          svr       0.291796  \n",
       "                          mlp       0.068953  \n",
       "max_u_regressor_focused   lr        0.540358  \n",
       "                          gb        0.187375  \n",
       "                          xgb       0.105429  \n",
       "                          svr       0.225088  \n",
       "                          mlp       0.064861  \n",
       "max_u_filtered_regressor  lr        0.318793  \n",
       "                          gb        0.466570  \n",
       "                          xgb       0.006640  \n",
       "                          svr       0.120496  \n",
       "                          mlp       0.004715  \n",
       "max_u_regressor_balanced  lr        0.314492  \n",
       "                          gb        0.508297  \n",
       "                          xgb       0.452522  \n",
       "                          svr       0.357587  \n",
       "                          mlp       0.066274  \n",
       "max_u_classifier          lr             NaN  \n",
       "                          gb        0.489852  \n",
       "                          xgb       0.439336  \n",
       "                          svr      -1.000000  \n",
       "                          mlp       0.183174  \n",
       "max_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.569179  \n",
       "                          xgb       0.575312  \n",
       "                          svr       0.581876  \n",
       "                          mlp       0.192052  \n",
       "min_u_regressor_sparse    lr        0.297390  \n",
       "                          gb        0.516571  \n",
       "                          xgb       0.490517  \n",
       "                          svr       0.374989  \n",
       "                          mlp       0.076279  \n",
       "min_u_regressor_focused   lr        0.223576  \n",
       "                          gb        0.254038  \n",
       "                          xgb       0.228193  \n",
       "                          svr       0.262651  \n",
       "                          mlp       0.084777  \n",
       "min_u_filtered_regressor  lr        0.260936  \n",
       "                          gb        0.488250  \n",
       "                          xgb       0.502496  \n",
       "                          svr       0.331681  \n",
       "                          mlp      -0.192864  \n",
       "min_u_regressor_balanced  lr        0.345050  \n",
       "                          gb        0.456403  \n",
       "                          xgb       0.450693  \n",
       "                          svr       0.391941  \n",
       "                          mlp       0.070213  \n",
       "min_u_classifier          lr             NaN  \n",
       "                          gb        0.581558  \n",
       "                          xgb       0.565496  \n",
       "                          svr       0.549541  \n",
       "                          mlp       0.239785  \n",
       "min_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.494868  \n",
       "                          xgb       0.495647  \n",
       "                          svr       0.604686  \n",
       "                          mlp       0.217185  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>possible_positives</th>\n",
       "      <th>possible_negatives</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5902</td>\n",
       "      <td>66450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                possible_positives possible_negatives\n",
       "experiment                class                                      \n",
       "max_u_regressor_sparse    lr                  4949             302547\n",
       "                          gb                  4949             302547\n",
       "                          xgb                 4949             302547\n",
       "                          svr                 4949             302547\n",
       "                          mlp                 4949             302547\n",
       "max_u_regressor_focused   lr                  4949             302547\n",
       "                          gb                  4949             302547\n",
       "                          xgb                 4949             302547\n",
       "                          svr                 4949             302547\n",
       "                          mlp                 4949             302547\n",
       "max_u_filtered_regressor  lr                  4949              94535\n",
       "                          gb                  4949              94535\n",
       "                          xgb                 4949              94535\n",
       "                          svr                 4949              94535\n",
       "                          mlp                 4949              94535\n",
       "max_u_regressor_balanced  lr                  4949             302547\n",
       "                          gb                  4949             302547\n",
       "                          xgb                 4949             302547\n",
       "                          svr                 4949             302547\n",
       "                          mlp                 4949             302547\n",
       "max_u_classifier          lr                   NaN                NaN\n",
       "                          gb                  4949              94535\n",
       "                          xgb                 4949              94535\n",
       "                          svr                 4949              94535\n",
       "                          mlp                 4949              94535\n",
       "max_u_classifier_balanced lr                   NaN                NaN\n",
       "                          gb                  4949              94535\n",
       "                          xgb                 4949              94535\n",
       "                          svr                 4949              94535\n",
       "                          mlp                 4949              94535\n",
       "min_u_regressor_sparse    lr                  6022             301474\n",
       "                          gb                  6022             301474\n",
       "                          xgb                 6022             301474\n",
       "                          svr                 6022             301474\n",
       "                          mlp                 6022             301474\n",
       "min_u_regressor_focused   lr                  6022             301474\n",
       "                          gb                  6022             301474\n",
       "                          xgb                 6022             301474\n",
       "                          svr                 6022             301474\n",
       "                          mlp                 6022             301474\n",
       "min_u_filtered_regressor  lr                  6022              84418\n",
       "                          gb                  6022              84418\n",
       "                          xgb                 6022              84418\n",
       "                          svr                 6022              84418\n",
       "                          mlp                 5902              66450\n",
       "min_u_regressor_balanced  lr                  6022             301474\n",
       "                          gb                  6022             301474\n",
       "                          xgb                 6022             301474\n",
       "                          svr                 6022             301474\n",
       "                          mlp                 6022             301474\n",
       "min_u_classifier          lr                   NaN                NaN\n",
       "                          gb                  6022              84418\n",
       "                          xgb                 6022              84418\n",
       "                          svr                 6022              84418\n",
       "                          mlp                 6022              84418\n",
       "min_u_classifier_balanced lr                   NaN                NaN\n",
       "                          gb                  6022              84418\n",
       "                          xgb                 6022              84418\n",
       "                          svr                 6022              84418\n",
       "                          mlp                 6022              84418"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirmation_df = pd.DataFrame()\n",
    "confirmation_df['possible_positives'] = df['tp'] + df['fn']\n",
    "confirmation_df['possible_negatives'] = df['fp'] + df['tn']\n",
    "confirmation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscale everything\n",
    "testing_data['max_u_regressor_sparse'][model]['predicted'] = testing_data['max_u_regressor_sparse'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_sparse'][model]['real'] = testing_data['max_u_regressor_sparse'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_focused'][model]['predicted'] = testing_data['max_u_regressor_focused'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_focused'][model]['real'] = testing_data['max_u_regressor_focused'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_filtered_regressor'][model]['predicted'] = testing_data['max_u_filtered_regressor'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_filtered_regressor'][model]['real'] = testing_data['max_u_filtered_regressor'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_balanced'][model]['predicted'] = testing_data['max_u_regressor_balanced'][model]['predicted'] * data_max_u_balanced['scaler']['y']\n",
    "testing_data['max_u_regressor_balanced'][model]['real'] = testing_data['max_u_regressor_balanced'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_sparse'][model]['predicted'] = testing_data['min_u_regressor_sparse'][model]['predicted'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_sparse'][model]['real'] = testing_data['min_u_regressor_sparse'][model]['real'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_focused'][model]['predicted'] = testing_data['min_u_regressor_focused'][model]['predicted'] * data_min_u_focused['scaler']['y']\n",
    "testing_data['min_u_regressor_focused'][model]['real'] = testing_data['min_u_regressor_focused'][model]['real'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_filtered_regressor'][model]['predicted'] = testing_data['min_u_filtered_regressor'][model]['predicted'] * data_min_u_sparse['scaler']['y'] \n",
    "testing_data['min_u_filtered_regressor'][model]['real'] = testing_data['min_u_filtered_regressor'][model]['real'][utils.cols_with_positive_values(prediction)] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_balanced'][model]['predicted'] = testing_data['min_u_regressor_balanced'][model]['predicted'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_balanced'][model]['real'] = testing_data['min_u_regressor_balanced'][model]['real'] * data_min_u_sparse['scaler']['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to evaluate all the results obtained above. This benchmarking has the objective of obtaining the answer following questions:\n",
    "- What is the optimum number of rows for the training data set? What is the respective model?\n",
    "    - sparse reg. vs balanced reg. vs focused reg.\n",
    "- What is the optimum number present busses in regresison?\n",
    "    - sparse reg. vs filtered reg.\n",
    "- Regression vs Classification\n",
    "    - filtered reg. vs sparse class.\n",
    "- What is the optimum number of rows in class?\n",
    "    - sparse class. vs balanced class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum proportion of P/N rows for the training data set? What is the respective model?\n",
    "In order to understand the optinum number of rows for the training set of the regression data set the data sets used will be:\n",
    "\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Maximum Voltage Constraints|Balanced Regression|6971|34|\n",
    "|Maximum Voltage Constraints|Focused Regression|3486|34|\n",
    "|Minimum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Minimum Voltage Constraints|Balanced Regression|13917|34|\n",
    "|Minimum Voltage Constraints|Focused Regression|6958|34|\n",
    "\n",
    "The **Sparse Regression data set** is generated directly from the power flow results. The important moments are those where the constraints are violated, so the output feature contains null values for when there is no constraint, and positive value for when there is a constraint. The positive values represent the amplitude of the constraint violation. It can be expressed as follows:\n",
    "$$\n",
    "    \\begin{align}\n",
    "        \\text{Target} &= \\begin{cases}\n",
    "            0 & \\text{if} \\; \\text{constraint} \\; \\text{is not violated} \\\\\n",
    "            \\text{amplitude of constraint} & \\text{if} \\; \\text{constraint} \\; \\text{is violated} \\\\\n",
    "        \\end{cases}\n",
    "    \\end{align}\n",
    "$$\n",
    "In our case, the constraints are being considered as the following:\n",
    "- Minimal voltage on bus: $v_bus < 0.95 \\text{ [pu]}$ (constraint is violated if the voltage is below $0.95 \\text{ [pu]} $)\n",
    "- Maximal voltage on bus: $v_bus > 1.05 \\text{ [pu]}$ (constraint is violated if the voltage is above $1.05 \\text{ [pu]} $)\n",
    "- Maximal current on line: $i_{line} > 1 \\text{ [kA]}$ (constraint is violated if the current is above $1 \\text{ [kA]} $)\n",
    "\n",
    "The **Balanced Regression** data set is created from the **Sparse Regression data set**. It is created by taking all the rows that containt at least one constraint violation and then taking the same number of rows that do not contain any constraint violation. Finally, the **Focused Regression data set** is created by taking all the rows that contain at least one constraint violation.\n",
    "\n",
    "Since these data sets have the same number of possible negative and possible positives, all the metrics can be used to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4521</td>\n",
       "      <td>280815</td>\n",
       "      <td>21732</td>\n",
       "      <td>428</td>\n",
       "      <td>0.917912</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.314492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4090</td>\n",
       "      <td>297475</td>\n",
       "      <td>5072</td>\n",
       "      <td>859</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.35234</td>\n",
       "      <td>0.759724</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>0.508297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4448</td>\n",
       "      <td>293409</td>\n",
       "      <td>9138</td>\n",
       "      <td>501</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.25097</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.452522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4222</td>\n",
       "      <td>287934</td>\n",
       "      <td>14613</td>\n",
       "      <td>727</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.798145</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.357587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>213184</td>\n",
       "      <td>89363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.066274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4321</td>\n",
       "      <td>297379</td>\n",
       "      <td>5168</td>\n",
       "      <td>628</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.540358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4523</td>\n",
       "      <td>249361</td>\n",
       "      <td>53186</td>\n",
       "      <td>426</td>\n",
       "      <td>0.79822</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.878914</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.187375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4660</td>\n",
       "      <td>179741</td>\n",
       "      <td>122806</td>\n",
       "      <td>289</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.919546</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.105429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4940</td>\n",
       "      <td>249296</td>\n",
       "      <td>53251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.225088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3713</td>\n",
       "      <td>204413</td>\n",
       "      <td>98134</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.635806</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.631136</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.064861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                                \n",
       "max_u_regressor_sparse   lr     3151  297203    5344  1798         0.973939   \n",
       "                         gb     3410  299857    2690  1539          0.98396   \n",
       "                         xgb    4550  292244   10303   399         0.960463   \n",
       "                         svr    4615  275913   26634   334         0.904389   \n",
       "                         mlp    4948  217055   85492     1         0.562262   \n",
       "max_u_regressor_balanced lr     4521  280815   21732   428         0.917912   \n",
       "                         gb     4090  297475    5072   859         0.977647   \n",
       "                         xgb    4448  293409    9138   501         0.963717   \n",
       "                         svr    4222  287934   14613   727         0.944365   \n",
       "                         mlp    4948  213184   89363     1         0.545878   \n",
       "max_u_regressor_focused  lr     4321  297379    5168   628         0.977467   \n",
       "                         gb     4523  249361   53186   426          0.79822   \n",
       "                         xgb    4660  179741  122806   289         0.554576   \n",
       "                         svr    4940  249296   53251     9         0.808736   \n",
       "                         mlp    3713  204413   98134  1236         0.635806   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.441493       0.567722   0.496713   \n",
       "                         xgb            0.230752       0.882031   0.365804   \n",
       "                         svr            0.107401       0.898987   0.191878   \n",
       "                         mlp            0.008497       0.999275    0.01685   \n",
       "max_u_regressor_balanced lr                0.126       0.877757   0.220366   \n",
       "                         gb              0.35234       0.759724   0.481414   \n",
       "                         xgb             0.25097       0.857354   0.388281   \n",
       "                         svr            0.174752       0.798145   0.286726   \n",
       "                         mlp            0.008087       0.999274   0.016044   \n",
       "max_u_regressor_focused  lr             0.366413       0.822844   0.507041   \n",
       "                         gb             0.053925       0.878914   0.101616   \n",
       "                         xgb            0.025552       0.919546   0.049723   \n",
       "                         svr            0.063073       0.997519   0.118643   \n",
       "                         mlp            0.023876       0.631136   0.046011   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_regressor_sparse   lr        0.346102  \n",
       "                         gb        0.492687  \n",
       "                         xgb       0.439649  \n",
       "                         svr       0.291796  \n",
       "                         mlp       0.068953  \n",
       "max_u_regressor_balanced lr        0.314492  \n",
       "                         gb        0.508297  \n",
       "                         xgb       0.452522  \n",
       "                         svr       0.357587  \n",
       "                         mlp       0.066274  \n",
       "max_u_regressor_focused  lr        0.540358  \n",
       "                         gb        0.187375  \n",
       "                         xgb       0.105429  \n",
       "                         svr       0.225088  \n",
       "                         mlp       0.064861  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_regressor_sparse', 'max_u_regressor_balanced', 'max_u_regressor_focused']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best alternative is to use the focused data set with a the linear regression model, because it presents a the best values for F1 and MCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5117</td>\n",
       "      <td>282366</td>\n",
       "      <td>19108</td>\n",
       "      <td>905</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.165926</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.345050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4997</td>\n",
       "      <td>292064</td>\n",
       "      <td>9410</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.284526</td>\n",
       "      <td>0.77814</td>\n",
       "      <td>0.41669</td>\n",
       "      <td>0.456403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5316</td>\n",
       "      <td>289858</td>\n",
       "      <td>11616</td>\n",
       "      <td>706</td>\n",
       "      <td>0.954371</td>\n",
       "      <td>0.255966</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.393042</td>\n",
       "      <td>0.450693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5366</td>\n",
       "      <td>283756</td>\n",
       "      <td>17718</td>\n",
       "      <td>656</td>\n",
       "      <td>0.933244</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.391941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6015</td>\n",
       "      <td>226077</td>\n",
       "      <td>75397</td>\n",
       "      <td>7</td>\n",
       "      <td>0.601244</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.993896</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.070213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5877</td>\n",
       "      <td>244952</td>\n",
       "      <td>56522</td>\n",
       "      <td>145</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.223576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5592</td>\n",
       "      <td>259564</td>\n",
       "      <td>41910</td>\n",
       "      <td>430</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.908282</td>\n",
       "      <td>0.160995</td>\n",
       "      <td>0.254038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5628</td>\n",
       "      <td>252109</td>\n",
       "      <td>49365</td>\n",
       "      <td>394</td>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.228193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5975</td>\n",
       "      <td>253411</td>\n",
       "      <td>48063</td>\n",
       "      <td>47</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.262651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4106</td>\n",
       "      <td>222759</td>\n",
       "      <td>78715</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.702687</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.585727</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.084777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr     2553  297508   3966  3469         0.972468   \n",
       "                         gb     5039  294582   6892   983         0.970974   \n",
       "                         xgb    4781  294780   6694  1241         0.970684   \n",
       "                         svr    5502  281219  20255   520         0.925053   \n",
       "                         mlp    6014  232123  69351     8         0.629952   \n",
       "min_u_regressor_balanced lr     5117  282366  19108   905         0.926901   \n",
       "                         gb     4997  292064   9410  1025         0.961439   \n",
       "                         xgb    5316  289858  11616   706         0.954371   \n",
       "                         svr    5366  283756  17718   656         0.933244   \n",
       "                         mlp    6015  226077  75397     7         0.601244   \n",
       "min_u_regressor_focused  lr     5877  244952  56522   145         0.780846   \n",
       "                         gb     5592  259564  41910   430         0.839482   \n",
       "                         xgb    5628  252109  49365   394         0.808055   \n",
       "                         svr    5975  253411  48063    47         0.822388   \n",
       "                         mlp    4106  222759  78715  1916         0.702687   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.353983       0.787945   0.488506   \n",
       "                         xgb            0.345599       0.731315   0.469381   \n",
       "                         svr            0.174263       0.890969    0.29151   \n",
       "                         mlp            0.009394       0.993227   0.018612   \n",
       "min_u_regressor_balanced lr             0.165926       0.804743   0.275126   \n",
       "                         gb             0.284526        0.77814    0.41669   \n",
       "                         xgb            0.255966       0.846198   0.393042   \n",
       "                         svr            0.194107         0.8676   0.317238   \n",
       "                         mlp            0.008336       0.993896   0.016534   \n",
       "min_u_regressor_focused  lr             0.067654       0.968548   0.126474   \n",
       "                         gb             0.088325       0.908282   0.160995   \n",
       "                         xgb            0.073954        0.91519   0.136849   \n",
       "                         svr            0.085393       0.990249   0.157228   \n",
       "                         mlp            0.035524       0.585727   0.066985   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_regressor_sparse   lr        0.297390  \n",
       "                         gb        0.516571  \n",
       "                         xgb       0.490517  \n",
       "                         svr       0.374989  \n",
       "                         mlp       0.076279  \n",
       "min_u_regressor_balanced lr        0.345050  \n",
       "                         gb        0.456403  \n",
       "                         xgb       0.450693  \n",
       "                         svr       0.391941  \n",
       "                         mlp       0.070213  \n",
       "min_u_regressor_focused  lr        0.223576  \n",
       "                         gb        0.254038  \n",
       "                         xgb       0.228193  \n",
       "                         svr       0.262651  \n",
       "                         mlp       0.084777  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_regressor_sparse', 'min_u_regressor_balanced', 'min_u_regressor_focused']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best sparse, with gradient boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum number present busses in regresison?\n",
    "In order to understand the optinum number of busses for the training set of the regression data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Maximum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Minimum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Minimum Voltage Constraints|Filtered Regression|45216|10|\n",
    "\n",
    "The **Filtered Regression data set** is created from the Sparse Regression data set, but only keeping the columns that contain at least one time step with a constraint violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr     3151  297203   5344  1798         0.973939   \n",
       "                         gb     3410  299857   2690  1539          0.98396   \n",
       "                         xgb    4550  292244  10303   399         0.960463   \n",
       "                         svr    4615  275913  26634   334         0.904389   \n",
       "                         mlp    4948  217055  85492     1         0.562262   \n",
       "max_u_filtered_regressor lr     3151   89191   5344  1798         0.918805   \n",
       "                         gb     3356   91872   2663  1593         0.949925   \n",
       "                         xgb    4949     128  94407     0         0.037666   \n",
       "                         svr    4443   46628  47907   506         0.481777   \n",
       "                         mlp    4949     549  93986     0         0.010538   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.441493       0.567722   0.496713   \n",
       "                         xgb            0.230752       0.882031   0.365804   \n",
       "                         svr            0.107401       0.898987   0.191878   \n",
       "                         mlp            0.008497       0.999275    0.01685   \n",
       "max_u_filtered_regressor lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.439197       0.552025    0.48919   \n",
       "                         xgb            0.036546            1.0   0.070515   \n",
       "                         svr            0.060259       0.842986   0.112478   \n",
       "                         mlp            0.007693            1.0   0.015269   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_regressor_sparse   lr        0.346102  \n",
       "                         gb        0.492687  \n",
       "                         xgb       0.439649  \n",
       "                         svr       0.291796  \n",
       "                         mlp       0.068953  \n",
       "max_u_filtered_regressor lr        0.318793  \n",
       "                         gb        0.466570  \n",
       "                         xgb       0.006640  \n",
       "                         svr       0.120496  \n",
       "                         mlp       0.004715  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_regressor_sparse', 'max_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse, with GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr     2553  297508   3966  3469         0.972468   \n",
       "                         gb     5039  294582   6892   983         0.970974   \n",
       "                         xgb    4781  294780   6694  1241         0.970684   \n",
       "                         svr    5502  281219  20255   520         0.925053   \n",
       "                         mlp    6014  232123  69351     8         0.629952   \n",
       "min_u_filtered_regressor lr     2553   80452   3966  3469         0.905889   \n",
       "                         gb     4993   77816   6602  1029         0.903749   \n",
       "                         xgb    4936   78434   5984  1086         0.911141   \n",
       "                         svr    5369   66433  17985   653         0.770305   \n",
       "                         mlp    4709   31253  35197  1193         0.181759   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.353983       0.787945   0.488506   \n",
       "                         xgb            0.345599       0.731315   0.469381   \n",
       "                         svr            0.174263       0.890969    0.29151   \n",
       "                         mlp            0.009394       0.993227   0.018612   \n",
       "min_u_filtered_regressor lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.360775       0.778289   0.493014   \n",
       "                         xgb            0.382714        0.76811    0.51088   \n",
       "                         svr            0.186868       0.861772   0.307136   \n",
       "                         mlp            0.015308       0.393679    0.02947   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_regressor_sparse   lr        0.297390  \n",
       "                         gb        0.516571  \n",
       "                         xgb       0.490517  \n",
       "                         svr       0.374989  \n",
       "                         mlp       0.076279  \n",
       "min_u_filtered_regressor lr        0.260936  \n",
       "                         gb        0.488250  \n",
       "                         xgb       0.502496  \n",
       "                         svr       0.331681  \n",
       "                         mlp      -0.192864  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_regressor_sparse', 'min_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse, with GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression vs Classification\n",
    "In order to understand the optinum number of busses for the training set of the regression data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Maximum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Minimum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Minimum Voltage Constraints|Sparse Classification|45216|10|\n",
    "\n",
    "The **Sparse Classification data set** is created from the Sparse Regression data set, but instead of having the target feature as the amplitude of the constraint violation, it is a binary feature that indicates if there is a constraint violation or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                              \n",
       "max_u_classifier         lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                         gb     2487  92303   2232  2462         0.952817   \n",
       "                         xgb    1817  93214   1321  3132         0.955239   \n",
       "                         svr       0  94535      0  4949         0.950253   \n",
       "                         mlp    3902  58964  35571  1047         0.631921   \n",
       "max_u_filtered_regressor lr     3151  89191   5344  1798         0.918805   \n",
       "                         gb     3356  91872   2663  1593         0.949925   \n",
       "                         xgb    4949    128  94407     0         0.037666   \n",
       "                         svr    4443  46628  47907   506         0.481777   \n",
       "                         mlp    4949    549  93986     0         0.010538   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_classifier         lr                  NaN            NaN        NaN   \n",
       "                         gb             0.527018       0.502526   0.514481   \n",
       "                         xgb            0.579031       0.367145   0.449363   \n",
       "                         svr                   0            0.0          0   \n",
       "                         mlp            0.098852       0.788442   0.175679   \n",
       "max_u_filtered_regressor lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.439197       0.552025    0.48919   \n",
       "                         xgb            0.036546            1.0   0.070515   \n",
       "                         svr            0.060259       0.842986   0.112478   \n",
       "                         mlp            0.007693            1.0   0.015269   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_classifier         lr             NaN  \n",
       "                         gb        0.489852  \n",
       "                         xgb       0.439336  \n",
       "                         svr      -1.000000  \n",
       "                         mlp       0.183174  \n",
       "max_u_filtered_regressor lr        0.318793  \n",
       "                         gb        0.466570  \n",
       "                         xgb       0.006640  \n",
       "                         svr       0.120496  \n",
       "                         mlp       0.004715  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_classifier', 'max_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_u_filtered regressor with the gradient boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                              \n",
       "min_u_classifier         lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                         gb     4068  81151   3267  1954         0.942271   \n",
       "                         xgb    4167  80534   3884  1855         0.936544   \n",
       "                         svr    2965  82965   1453  3057         0.950133   \n",
       "                         mlp    5320  50125  34293   702         0.613058   \n",
       "min_u_filtered_regressor lr     2553  80452   3966  3469         0.905889   \n",
       "                         gb     4993  77816   6602  1029         0.903749   \n",
       "                         xgb    4936  78434   5984  1086         0.911141   \n",
       "                         svr    5369  66433  17985   653         0.770305   \n",
       "                         mlp    4709  31253  35197  1193         0.181759   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_classifier         lr                  NaN            NaN        NaN   \n",
       "                         gb             0.554601       0.675523   0.609119   \n",
       "                         xgb            0.517575       0.691963   0.592198   \n",
       "                         svr            0.671118       0.492361   0.568008   \n",
       "                         mlp            0.134299       0.883427   0.233154   \n",
       "min_u_filtered_regressor lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.360775       0.778289   0.493014   \n",
       "                         xgb            0.382714        0.76811    0.51088   \n",
       "                         svr            0.186868       0.861772   0.307136   \n",
       "                         mlp            0.015308       0.393679    0.02947   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_classifier         lr             NaN  \n",
       "                         gb        0.581558  \n",
       "                         xgb       0.565496  \n",
       "                         svr       0.549541  \n",
       "                         mlp       0.239785  \n",
       "min_u_filtered_regressor lr        0.260936  \n",
       "                         gb        0.488250  \n",
       "                         xgb       0.502496  \n",
       "                         svr       0.331681  \n",
       "                         mlp      -0.192864  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_classifier', 'min_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_u_classifier with the gradient boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum number of rows in class?\n",
    "In order to understand the optinum number of rows for the training set of the classification data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Maximum Voltage Constraints|Balanced Classification|6971|10|\n",
    "|Minimum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Minimum Voltage Constraints|Balanced Classification|13917|10|\n",
    "\n",
    "The **Balanced Classification data set** is created from the Sparse Classification data set. It is created by taking all the rows that containt at least one constraint violation and then taking the same number of rows that do not contain any constraint violation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3499</td>\n",
       "      <td>91026</td>\n",
       "      <td>3509</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0.585264</td>\n",
       "      <td>0.569179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3158</td>\n",
       "      <td>92054</td>\n",
       "      <td>2481</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.957058</td>\n",
       "      <td>0.560028</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>0.575312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3956</td>\n",
       "      <td>89928</td>\n",
       "      <td>4607</td>\n",
       "      <td>993</td>\n",
       "      <td>0.94371</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>0.581876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4041</td>\n",
       "      <td>58329</td>\n",
       "      <td>36206</td>\n",
       "      <td>908</td>\n",
       "      <td>0.626935</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.816529</td>\n",
       "      <td>0.178821</td>\n",
       "      <td>0.192052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                              \n",
       "max_u_classifier          lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     2487  92303   2232  2462         0.952817   \n",
       "                          xgb    1817  93214   1321  3132         0.955239   \n",
       "                          svr       0  94535      0  4949         0.950253   \n",
       "                          mlp    3902  58964  35571  1047         0.631921   \n",
       "max_u_classifier_balanced lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     3499  91026   3509  1450         0.950153   \n",
       "                          xgb    3158  92054   2481  1791         0.957058   \n",
       "                          svr    3956  89928   4607   993          0.94371   \n",
       "                          mlp    4041  58329  36206   908         0.626935   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.527018       0.502526   0.514481   \n",
       "                          xgb            0.579031       0.367145   0.449363   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.098852       0.788442   0.175679   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.499287       0.707012   0.585264   \n",
       "                          xgb            0.560028       0.638109   0.596524   \n",
       "                          svr            0.461988       0.799353   0.585554   \n",
       "                          mlp            0.100405       0.816529   0.178821   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "max_u_classifier          lr             NaN  \n",
       "                          gb        0.489852  \n",
       "                          xgb       0.439336  \n",
       "                          svr      -1.000000  \n",
       "                          mlp       0.183174  \n",
       "max_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.569179  \n",
       "                          xgb       0.575312  \n",
       "                          svr       0.581876  \n",
       "                          mlp       0.192052  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_classifier', 'max_u_classifier_balanced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier balanced with xgb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4379</td>\n",
       "      <td>77799</td>\n",
       "      <td>6619</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.398163</td>\n",
       "      <td>0.727167</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.494868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4395</td>\n",
       "      <td>77766</td>\n",
       "      <td>6652</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.908459</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>0.729824</td>\n",
       "      <td>0.514969</td>\n",
       "      <td>0.495647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4931</td>\n",
       "      <td>79390</td>\n",
       "      <td>5028</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.49513</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.604686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5328</td>\n",
       "      <td>46466</td>\n",
       "      <td>37952</td>\n",
       "      <td>694</td>\n",
       "      <td>0.572689</td>\n",
       "      <td>0.123105</td>\n",
       "      <td>0.884756</td>\n",
       "      <td>0.216137</td>\n",
       "      <td>0.217185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                              \n",
       "min_u_classifier          lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     4068  81151   3267  1954         0.942271   \n",
       "                          xgb    4167  80534   3884  1855         0.936544   \n",
       "                          svr    2965  82965   1453  3057         0.950133   \n",
       "                          mlp    5320  50125  34293   702         0.613058   \n",
       "min_u_classifier_balanced lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     4379  77799   6619  1643         0.908647   \n",
       "                          xgb    4395  77766   6652  1627         0.908459   \n",
       "                          svr    4931  79390   5028  1091         0.932342   \n",
       "                          mlp    5328  46466  37952   694         0.572689   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.554601       0.675523   0.609119   \n",
       "                          xgb            0.517575       0.691963   0.592198   \n",
       "                          svr            0.671118       0.492361   0.568008   \n",
       "                          mlp            0.134299       0.883427   0.233154   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.398163       0.727167   0.514571   \n",
       "                          xgb            0.397846       0.729824   0.514969   \n",
       "                          svr             0.49513       0.818831   0.617108   \n",
       "                          mlp            0.123105       0.884756   0.216137   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "min_u_classifier          lr             NaN  \n",
       "                          gb        0.581558  \n",
       "                          xgb       0.565496  \n",
       "                          svr       0.549541  \n",
       "                          mlp       0.239785  \n",
       "min_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.494868  \n",
       "                          xgb       0.495647  \n",
       "                          svr       0.604686  \n",
       "                          mlp       0.217185  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_classifier', 'min_u_classifier_balanced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier balanced with svr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "In order to understand how good our predictions really are, we can compare it to a random classifier. [source](https://inside.getyourguide.com/blog/2020/9/30/what-makes-a-good-f1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "      <th>q</th>\n",
       "      <th>f1_coin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4321</td>\n",
       "      <td>297379</td>\n",
       "      <td>5168</td>\n",
       "      <td>628</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.540358</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4523</td>\n",
       "      <td>249361</td>\n",
       "      <td>53186</td>\n",
       "      <td>426</td>\n",
       "      <td>0.79822</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.878914</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4660</td>\n",
       "      <td>179741</td>\n",
       "      <td>122806</td>\n",
       "      <td>289</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.919546</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.105429</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4940</td>\n",
       "      <td>249296</td>\n",
       "      <td>53251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.225088</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3713</td>\n",
       "      <td>204413</td>\n",
       "      <td>98134</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.635806</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.631136</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.064861</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4521</td>\n",
       "      <td>280815</td>\n",
       "      <td>21732</td>\n",
       "      <td>428</td>\n",
       "      <td>0.917912</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.314492</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4090</td>\n",
       "      <td>297475</td>\n",
       "      <td>5072</td>\n",
       "      <td>859</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.35234</td>\n",
       "      <td>0.759724</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4448</td>\n",
       "      <td>293409</td>\n",
       "      <td>9138</td>\n",
       "      <td>501</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.25097</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.452522</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4222</td>\n",
       "      <td>287934</td>\n",
       "      <td>14613</td>\n",
       "      <td>727</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.798145</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.357587</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>213184</td>\n",
       "      <td>89363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.066274</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3499</td>\n",
       "      <td>91026</td>\n",
       "      <td>3509</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0.585264</td>\n",
       "      <td>0.569179</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3158</td>\n",
       "      <td>92054</td>\n",
       "      <td>2481</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.957058</td>\n",
       "      <td>0.560028</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>0.575312</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3956</td>\n",
       "      <td>89928</td>\n",
       "      <td>4607</td>\n",
       "      <td>993</td>\n",
       "      <td>0.94371</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>0.581876</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4041</td>\n",
       "      <td>58329</td>\n",
       "      <td>36206</td>\n",
       "      <td>908</td>\n",
       "      <td>0.626935</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.816529</td>\n",
       "      <td>0.178821</td>\n",
       "      <td>0.192052</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5877</td>\n",
       "      <td>244952</td>\n",
       "      <td>56522</td>\n",
       "      <td>145</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.223576</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5592</td>\n",
       "      <td>259564</td>\n",
       "      <td>41910</td>\n",
       "      <td>430</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.908282</td>\n",
       "      <td>0.160995</td>\n",
       "      <td>0.254038</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5628</td>\n",
       "      <td>252109</td>\n",
       "      <td>49365</td>\n",
       "      <td>394</td>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.228193</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5975</td>\n",
       "      <td>253411</td>\n",
       "      <td>48063</td>\n",
       "      <td>47</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.262651</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4106</td>\n",
       "      <td>222759</td>\n",
       "      <td>78715</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.702687</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.585727</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.084777</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "      <td>0.081573</td>\n",
       "      <td>0.150842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5117</td>\n",
       "      <td>282366</td>\n",
       "      <td>19108</td>\n",
       "      <td>905</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.165926</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.345050</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4997</td>\n",
       "      <td>292064</td>\n",
       "      <td>9410</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.284526</td>\n",
       "      <td>0.77814</td>\n",
       "      <td>0.41669</td>\n",
       "      <td>0.456403</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5316</td>\n",
       "      <td>289858</td>\n",
       "      <td>11616</td>\n",
       "      <td>706</td>\n",
       "      <td>0.954371</td>\n",
       "      <td>0.255966</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.393042</td>\n",
       "      <td>0.450693</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5366</td>\n",
       "      <td>283756</td>\n",
       "      <td>17718</td>\n",
       "      <td>656</td>\n",
       "      <td>0.933244</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.391941</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6015</td>\n",
       "      <td>226077</td>\n",
       "      <td>75397</td>\n",
       "      <td>7</td>\n",
       "      <td>0.601244</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.993896</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.070213</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4379</td>\n",
       "      <td>77799</td>\n",
       "      <td>6619</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.398163</td>\n",
       "      <td>0.727167</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.494868</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4395</td>\n",
       "      <td>77766</td>\n",
       "      <td>6652</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.908459</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>0.729824</td>\n",
       "      <td>0.514969</td>\n",
       "      <td>0.495647</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4931</td>\n",
       "      <td>79390</td>\n",
       "      <td>5028</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.49513</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.604686</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5328</td>\n",
       "      <td>46466</td>\n",
       "      <td>37952</td>\n",
       "      <td>694</td>\n",
       "      <td>0.572689</td>\n",
       "      <td>0.123105</td>\n",
       "      <td>0.884756</td>\n",
       "      <td>0.216137</td>\n",
       "      <td>0.217185</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                                \n",
       "max_u_regressor_sparse    lr     3151  297203    5344  1798         0.973939   \n",
       "                          gb     3410  299857    2690  1539          0.98396   \n",
       "                          xgb    4550  292244   10303   399         0.960463   \n",
       "                          svr    4615  275913   26634   334         0.904389   \n",
       "                          mlp    4948  217055   85492     1         0.562262   \n",
       "max_u_regressor_focused   lr     4321  297379    5168   628         0.977467   \n",
       "                          gb     4523  249361   53186   426          0.79822   \n",
       "                          xgb    4660  179741  122806   289         0.554576   \n",
       "                          svr    4940  249296   53251     9         0.808736   \n",
       "                          mlp    3713  204413   98134  1236         0.635806   \n",
       "max_u_filtered_regressor  lr     3151   89191    5344  1798         0.918805   \n",
       "                          gb     3356   91872    2663  1593         0.949925   \n",
       "                          xgb    4949     128   94407     0         0.037666   \n",
       "                          svr    4443   46628   47907   506         0.481777   \n",
       "                          mlp    4949     549   93986     0         0.010538   \n",
       "max_u_regressor_balanced  lr     4521  280815   21732   428         0.917912   \n",
       "                          gb     4090  297475    5072   859         0.977647   \n",
       "                          xgb    4448  293409    9138   501         0.963717   \n",
       "                          svr    4222  287934   14613   727         0.944365   \n",
       "                          mlp    4948  213184   89363     1         0.545878   \n",
       "max_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     2487   92303    2232  2462         0.952817   \n",
       "                          xgb    1817   93214    1321  3132         0.955239   \n",
       "                          svr       0   94535       0  4949         0.950253   \n",
       "                          mlp    3902   58964   35571  1047         0.631921   \n",
       "max_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     3499   91026    3509  1450         0.950153   \n",
       "                          xgb    3158   92054    2481  1791         0.957058   \n",
       "                          svr    3956   89928    4607   993          0.94371   \n",
       "                          mlp    4041   58329   36206   908         0.626935   \n",
       "min_u_regressor_sparse    lr     2553  297508    3966  3469         0.972468   \n",
       "                          gb     5039  294582    6892   983         0.970974   \n",
       "                          xgb    4781  294780    6694  1241         0.970684   \n",
       "                          svr    5502  281219   20255   520         0.925053   \n",
       "                          mlp    6014  232123   69351     8         0.629952   \n",
       "min_u_regressor_focused   lr     5877  244952   56522   145         0.780846   \n",
       "                          gb     5592  259564   41910   430         0.839482   \n",
       "                          xgb    5628  252109   49365   394         0.808055   \n",
       "                          svr    5975  253411   48063    47         0.822388   \n",
       "                          mlp    4106  222759   78715  1916         0.702687   \n",
       "min_u_filtered_regressor  lr     2553   80452    3966  3469         0.905889   \n",
       "                          gb     4993   77816    6602  1029         0.903749   \n",
       "                          xgb    4936   78434    5984  1086         0.911141   \n",
       "                          svr    5369   66433   17985   653         0.770305   \n",
       "                          mlp    4709   31253   35197  1193         0.181759   \n",
       "min_u_regressor_balanced  lr     5117  282366   19108   905         0.926901   \n",
       "                          gb     4997  292064    9410  1025         0.961439   \n",
       "                          xgb    5316  289858   11616   706         0.954371   \n",
       "                          svr    5366  283756   17718   656         0.933244   \n",
       "                          mlp    6015  226077   75397     7         0.601244   \n",
       "min_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4068   81151    3267  1954         0.942271   \n",
       "                          xgb    4167   80534    3884  1855         0.936544   \n",
       "                          svr    2965   82965    1453  3057         0.950133   \n",
       "                          mlp    5320   50125   34293   702         0.613058   \n",
       "min_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4379   77799    6619  1643         0.908647   \n",
       "                          xgb    4395   77766    6652  1627         0.908459   \n",
       "                          svr    4931   79390    5028  1091         0.932342   \n",
       "                          mlp    5328   46466   37952   694         0.572689   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_regressor_sparse    lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.441493       0.567722   0.496713   \n",
       "                          xgb            0.230752       0.882031   0.365804   \n",
       "                          svr            0.107401       0.898987   0.191878   \n",
       "                          mlp            0.008497       0.999275    0.01685   \n",
       "max_u_regressor_focused   lr             0.366413       0.822844   0.507041   \n",
       "                          gb             0.053925       0.878914   0.101616   \n",
       "                          xgb            0.025552       0.919546   0.049723   \n",
       "                          svr            0.063073       0.997519   0.118643   \n",
       "                          mlp            0.023876       0.631136   0.046011   \n",
       "max_u_filtered_regressor  lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.439197       0.552025    0.48919   \n",
       "                          xgb            0.036546            1.0   0.070515   \n",
       "                          svr            0.060259       0.842986   0.112478   \n",
       "                          mlp            0.007693            1.0   0.015269   \n",
       "max_u_regressor_balanced  lr                0.126       0.877757   0.220366   \n",
       "                          gb              0.35234       0.759724   0.481414   \n",
       "                          xgb             0.25097       0.857354   0.388281   \n",
       "                          svr            0.174752       0.798145   0.286726   \n",
       "                          mlp            0.008087       0.999274   0.016044   \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.527018       0.502526   0.514481   \n",
       "                          xgb            0.579031       0.367145   0.449363   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.098852       0.788442   0.175679   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.499287       0.707012   0.585264   \n",
       "                          xgb            0.560028       0.638109   0.596524   \n",
       "                          svr            0.461988       0.799353   0.585554   \n",
       "                          mlp            0.100405       0.816529   0.178821   \n",
       "min_u_regressor_sparse    lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.353983       0.787945   0.488506   \n",
       "                          xgb            0.345599       0.731315   0.469381   \n",
       "                          svr            0.174263       0.890969    0.29151   \n",
       "                          mlp            0.009394       0.993227   0.018612   \n",
       "min_u_regressor_focused   lr             0.067654       0.968548   0.126474   \n",
       "                          gb             0.088325       0.908282   0.160995   \n",
       "                          xgb            0.073954        0.91519   0.136849   \n",
       "                          svr            0.085393       0.990249   0.157228   \n",
       "                          mlp            0.035524       0.585727   0.066985   \n",
       "min_u_filtered_regressor  lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.360775       0.778289   0.493014   \n",
       "                          xgb            0.382714        0.76811    0.51088   \n",
       "                          svr            0.186868       0.861772   0.307136   \n",
       "                          mlp            0.015308       0.393679    0.02947   \n",
       "min_u_regressor_balanced  lr             0.165926       0.804743   0.275126   \n",
       "                          gb             0.284526        0.77814    0.41669   \n",
       "                          xgb            0.255966       0.846198   0.393042   \n",
       "                          svr            0.194107         0.8676   0.317238   \n",
       "                          mlp            0.008336       0.993896   0.016534   \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.554601       0.675523   0.609119   \n",
       "                          xgb            0.517575       0.691963   0.592198   \n",
       "                          svr            0.671118       0.492361   0.568008   \n",
       "                          mlp            0.134299       0.883427   0.233154   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.398163       0.727167   0.514571   \n",
       "                          xgb            0.397846       0.729824   0.514969   \n",
       "                          svr             0.49513       0.818831   0.617108   \n",
       "                          mlp            0.123105       0.884756   0.216137   \n",
       "\n",
       "                                 (hybrid)mcc         q   f1_coin  \n",
       "experiment                class                                   \n",
       "max_u_regressor_sparse    lr        0.346102  0.016095  0.031679  \n",
       "                          gb        0.492687  0.016095  0.031679  \n",
       "                          xgb       0.439649  0.016095  0.031679  \n",
       "                          svr       0.291796  0.016095  0.031679  \n",
       "                          mlp       0.068953  0.016095  0.031679  \n",
       "max_u_regressor_focused   lr        0.540358  0.016095  0.031679  \n",
       "                          gb        0.187375  0.016095  0.031679  \n",
       "                          xgb       0.105429  0.016095  0.031679  \n",
       "                          svr       0.225088  0.016095  0.031679  \n",
       "                          mlp       0.064861  0.016095  0.031679  \n",
       "max_u_filtered_regressor  lr        0.318793  0.049747  0.094778  \n",
       "                          gb        0.466570  0.049747  0.094778  \n",
       "                          xgb       0.006640  0.049747  0.094778  \n",
       "                          svr       0.120496  0.049747  0.094778  \n",
       "                          mlp       0.004715  0.049747  0.094778  \n",
       "max_u_regressor_balanced  lr        0.314492  0.016095  0.031679  \n",
       "                          gb        0.508297  0.016095  0.031679  \n",
       "                          xgb       0.452522  0.016095  0.031679  \n",
       "                          svr       0.357587  0.016095  0.031679  \n",
       "                          mlp       0.066274  0.016095  0.031679  \n",
       "max_u_classifier          lr             NaN       NaN       NaN  \n",
       "                          gb        0.489852  0.049747  0.094778  \n",
       "                          xgb       0.439336  0.049747  0.094778  \n",
       "                          svr      -1.000000  0.049747  0.094778  \n",
       "                          mlp       0.183174  0.049747  0.094778  \n",
       "max_u_classifier_balanced lr             NaN       NaN       NaN  \n",
       "                          gb        0.569179  0.049747  0.094778  \n",
       "                          xgb       0.575312  0.049747  0.094778  \n",
       "                          svr       0.581876  0.049747  0.094778  \n",
       "                          mlp       0.192052  0.049747  0.094778  \n",
       "min_u_regressor_sparse    lr        0.297390  0.019584  0.038416  \n",
       "                          gb        0.516571  0.019584  0.038416  \n",
       "                          xgb       0.490517  0.019584  0.038416  \n",
       "                          svr       0.374989  0.019584  0.038416  \n",
       "                          mlp       0.076279  0.019584  0.038416  \n",
       "min_u_regressor_focused   lr        0.223576  0.019584  0.038416  \n",
       "                          gb        0.254038  0.019584  0.038416  \n",
       "                          xgb       0.228193  0.019584  0.038416  \n",
       "                          svr       0.262651  0.019584  0.038416  \n",
       "                          mlp       0.084777  0.019584  0.038416  \n",
       "min_u_filtered_regressor  lr        0.260936  0.066586  0.124857  \n",
       "                          gb        0.488250  0.066586  0.124857  \n",
       "                          xgb       0.502496  0.066586  0.124857  \n",
       "                          svr       0.331681  0.066586  0.124857  \n",
       "                          mlp      -0.192864  0.081573  0.150842  \n",
       "min_u_regressor_balanced  lr        0.345050  0.019584  0.038416  \n",
       "                          gb        0.456403  0.019584  0.038416  \n",
       "                          xgb       0.450693  0.019584  0.038416  \n",
       "                          svr       0.391941  0.019584  0.038416  \n",
       "                          mlp       0.070213  0.019584  0.038416  \n",
       "min_u_classifier          lr             NaN       NaN       NaN  \n",
       "                          gb        0.581558  0.066586  0.124857  \n",
       "                          xgb       0.565496  0.066586  0.124857  \n",
       "                          svr       0.549541  0.066586  0.124857  \n",
       "                          mlp       0.239785  0.066586  0.124857  \n",
       "min_u_classifier_balanced lr             NaN       NaN       NaN  \n",
       "                          gb        0.494868  0.066586  0.124857  \n",
       "                          xgb       0.495647  0.066586  0.124857  \n",
       "                          svr       0.604686  0.066586  0.124857  \n",
       "                          mlp       0.217185  0.066586  0.124857  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['q'] =  (df['tp'] + df['fn']) / (df['fp'] + df['tn'] + df['tp'] + df['fn'])\n",
    "df['f1_coin'] = (2*df['q'])/(df['q']+1)\n",
    "# write df to csv in this directory, with the name dataset_benchmark.csv\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5328"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[('min_u_classifier_balanced', 'mlp'), 'tp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: max_u_regressor_sparse, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  1432\n",
      "true_negatives_ctr:  0\n",
      "false_positives_ctr:  16656\n",
      "false_negatives_ctr:  0\n",
      "0\n",
      "hybrid_metrics.true_positives_ctr:  1432\n",
      "hybrid_metrics.true_negatives_ctr:  0\n",
      "hybrid_metrics.false_positives_ctr:  16656\n",
      "hybrid_metrics.false_negatives_ctr:  0\n",
      "\n",
      "\n",
      "hybrid_true_positives_rmse 483.64282925858015\n",
      "hybrid_true_negatives_rmse 0\n",
      "hybrid_false_positives_rmse 33308.75967554767\n",
      "hybrid_false_negatives_rmse 0\n",
      "\n",
      "\n",
      "true_positives_rmse 0.6622605940931703\n",
      "true_negatives_rmse 0\n",
      "false_positives_rmse 0.9998054560247163\n",
      "false_negatives_rmse 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Metrics' object has no attribute 'hybrid_accuracy_rmse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\jupyter_notebooks\\datasets_benchmark.ipynb Cell 77\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfalse_negatives_rmse\u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39mfalse_negatives_rmse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhybrid_metrics.hybrid_accuracy_rmse: \u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39;49mhybrid_accuracy_rmse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhybrid_metrics.hybrid_precision_rmse: \u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39mhybrid_precision_rmse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhybrid_metrics.hybrid_recall_rmse: \u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39mhybrid_recall_rmse)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Metrics' object has no attribute 'hybrid_accuracy_rmse'"
     ]
    }
   ],
   "source": [
    "threshold = _threshold(experiment)\n",
    "experiment = 'max_u_regressor_sparse'\n",
    "model = 'mlp' \n",
    "threshold = _threshold(experiment)\n",
    "print('Experiment: {}, model: {}, threshold: {}'.format(experiment, model, threshold))\n",
    "hybrid_metrics = metrics.Metrics()\n",
    "hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted'][['bus_15', 'bus_16']], testing_data[experiment][model]['real'][['bus_15', 'bus_16']], threshold=threshold)\n",
    "print('hybrid_metrics.true_positives_ctr: ', hybrid_metrics.true_positives_ctr)\n",
    "print('hybrid_metrics.true_negatives_ctr: ', hybrid_metrics.true_negatives_ctr)\n",
    "print('hybrid_metrics.false_positives_ctr: ', hybrid_metrics.false_positives_ctr)\n",
    "print('hybrid_metrics.false_negatives_ctr: ', hybrid_metrics.false_negatives_ctr)\n",
    "print('\\n')\n",
    "print('hybrid_true_positives_rmse', hybrid_metrics.hybrid_true_positives_rmse)\n",
    "print('hybrid_true_negatives_rmse', hybrid_metrics.hybrid_true_negatives_rmse)\n",
    "print('hybrid_false_positives_rmse', hybrid_metrics.hybrid_false_positives_rmse)\n",
    "print('hybrid_false_negatives_rmse', hybrid_metrics.hybrid_false_negatives_rmse)\n",
    "print('\\n')\n",
    "print('true_positives_rmse', hybrid_metrics.true_positives_rmse)\n",
    "print('true_negatives_rmse', hybrid_metrics.true_negatives_rmse)\n",
    "print('false_positives_rmse', hybrid_metrics.false_positives_rmse)\n",
    "print('false_negatives_rmse', hybrid_metrics.false_negatives_rmse)\n",
    "print('\\n')\n",
    "print('hybrid_metrics.hybrid_accuracy_rmse: ', hybrid_metrics.hybrid_accuracy_rmse)\n",
    "print('hybrid_metrics.hybrid_precision_rmse: ', hybrid_metrics.hybrid_precision_rmse)\n",
    "print('hybrid_metrics.hybrid_recall_rmse: ', hybrid_metrics.hybrid_recall_rmse)\n",
    "print('hybrid_metrics.hybrid_f1_rmse: ', hybrid_metrics.hybrid_f1_rmse)\n",
    "print('hybrid_metrics.hybrid_mcc_rmse: ', hybrid_metrics.hybrid_mcc_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure size of the plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 10))\n",
    "testing_data['max_u_classifier']['mlp']['predicted']['bus_16'].plot()\n",
    "#testing_data['max_u_classifier']['mlp']['real']['bus_16'].plot()\n",
    "\n",
    "# plot a line with the threshold\n",
    "_threshold = lambda experiment: max_u_threshold / data_max_u_balanced['scaler']['y'] if 'max_u' in experiment else min_u_threshold/ data_min_u_balanced['scaler']['y']\n",
    "threshold = _threshold('max_u_regressor_sparse')\n",
    "plt.axhline(y=threshold, color='r', linestyle='-')\n",
    "# Add legend\n",
    "plt.legend(['predicted', 'real', 'threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data['max_u_regressor_sparse']['mlp']['predicted'].apply(lambda x: x.apply(lambda y: min(1.0, max(0.0, y))))['bus_1'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data['max_u_classifier']['mlp']['predicted'].astype('float64')['bus_16'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn df to numpy array\n",
    "testing_data['max_u_classifier']['gb']['predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment: min_u_classifier, model: gb, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier, model: xgb, max: 1, min: 0\n",
      "experiment: min_u_classifier, model: svr, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier_balanced, model: gb, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier_balanced, model: xgb, max: 1, min: 0\n",
      "experiment: min_u_classifier_balanced, model: svr, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier_balanced, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: lr, max: 0.13619870924844507, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: gb, max: 0.3810799686594865, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: xgb, max: 0.3127909302711487, min: 0.024557016789913177\n",
      "experiment: max_u_regressor_sparse, model: svr, max: 0.4946822431673944, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: lr, max: 0.6501631250830311, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: gb, max: 0.42120136723128043, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: xgb, max: 0.42610928416252136, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: svr, max: 0.46197486433850854, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: mlp, max: 0.577883243560791, min: 0.0\n",
      "experiment: max_u_filtered_regressor, model: lr, max: 0.12660268004533026, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: lr, max: 0.4010267617457135, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: gb, max: 0.7517199729659615, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: xgb, max: 0.5393862724304199, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: svr, max: 0.787608227817534, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: lr, max: 0.5855579684553072, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: gb, max: 0.5932988934689641, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: xgb, max: 0.5121873617172241, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: svr, max: 0.6045885499738398, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: mlp, max: 0.34603604674339294, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: lr, max: 0.34171831351797666, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: gb, max: 0.5165846932947002, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: xgb, max: 0.4210992753505707, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: svr, max: 0.6300204477633999, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: mlp, max: 1.0, min: 0.0\n"
     ]
    }
   ],
   "source": [
    "classifier_experiments =[experiment for experiment in testing_data.keys() if 'classifier' in experiment.split('_')] # TODO confirm this\n",
    "regressor_experiments = [experiment for experiment in testing_data.keys() if 'regressor' in experiment.split('_')]\n",
    "# Classifier experiments\n",
    "for experiment in classifier_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        try:\n",
    "            print('experiment: {}, model: {}, max: {}, min: {}'.format(experiment, model, testing_data[experiment][model]['predicted'].max().max(), testing_data[experiment][model]['predicted'].min().min()))\n",
    "        except:\n",
    "            print('experiment {} model {} failed'.format(experiment, model))\n",
    "for experiment in regressor_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        try:\n",
    "            print('experiment: {}, model: {}, max: {}, min: {}'.format(experiment, model, testing_data[experiment][model]['predicted'].max().max(), testing_data[experiment][model]['predicted'].min().min()))\n",
    "        except:\n",
    "            print('experiment {} model {} failed'.format(experiment, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe4baa4d27e3b73db55d4bb4674105e8dd41faaf9e559c3cc8381041ce15293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
