{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of this Article** \n",
    "- Loading best hyperparameters for each model\n",
    "- Model training\n",
    "- Results discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best hyperparameters for each model\n",
    "\n",
    "As explained in another notebook, the hyperparameters for each model were tunnned using the Optuna library. For each dataset and model, the hyperparameters have different values. The values for each hyperparameters are seen bellow.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hyperparameters dataset.\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse hyper params:\n",
      "\n",
      "params_gradient_boost_regression_sparse_max_u.csv :\n",
      "            params                  value\n",
      "0   n_estimators                    544\n",
      "1  learning_rate    0.36423151911958196\n",
      "2           loss          squared_error\n",
      "3          value  0.0064745090355284845\n",
      "params_gradient_boost_regression_sparse_min_u.csv :\n",
      "            params               value\n",
      "0   n_estimators                  22\n",
      "1  learning_rate  0.8296843568407096\n",
      "2           loss      absolute_error\n",
      "3          value                 0.0\n",
      "params_support_vector_regression_sparse_max_u.csv :\n",
      "     params                   value\n",
      "0  kernel                    poly\n",
      "1       C  0.00018807624871896921\n",
      "2  degree                       5\n",
      "3   gamma      0.8511446423066539\n",
      "4   value      0.4008346176510517\n",
      "params_support_vector_regression_sparse_min_u.csv :\n",
      "     params                   value\n",
      "0  kernel                    poly\n",
      "1       C  3.4084813417139984e-06\n",
      "2  degree                       2\n",
      "3   gamma  7.5582957595600045e-06\n",
      "4   value      0.2592248866377364\n",
      "params_xgboost_regression_sparse_max_u.csv :\n",
      "               params                  value\n",
      "0           booster               gblinear\n",
      "1            lambda  4.195122525977499e-07\n",
      "2             alpha     0.1001382333795902\n",
      "3         subsample     0.9941075848643193\n",
      "4  colsample_bytree     0.7713666161545742\n",
      "5             value                    0.0\n",
      "params_xgboost_regression_sparse_min_u.csv :\n",
      "               params                value\n",
      "0           booster             gblinear\n",
      "1            lambda  0.05222241453451214\n",
      "2             alpha   0.4796424371172093\n",
      "3         subsample   0.8991281740894908\n",
      "4  colsample_bytree   0.9143759295062182\n",
      "5             value                  0.0\n",
      "Focused hyper params:\n",
      "\n",
      "params_gradient_boost_regression_focused_max_u.csv :\n",
      "           params                 value\n",
      "0   n_estimators                    25\n",
      "1  learning_rate    0.2724645522088135\n",
      "2           loss         squared_error\n",
      "3          value  0.004506710347566452\n",
      "params_gradient_boost_regression_focused_min_u.csv :\n",
      "           params                value\n",
      "0   n_estimators                   74\n",
      "1  learning_rate   0.8511834961992796\n",
      "2           loss        squared_error\n",
      "3          value  0.00514602580023137\n",
      "params_support_vector_regression_focused_max_u.csv :\n",
      "    params                 value\n",
      "0  kernel                  poly\n",
      "1       C  0.005584880493571942\n",
      "2  degree                     2\n",
      "3   gamma    0.8532257247043119\n",
      "4   value    0.2999199774846511\n",
      "params_support_vector_regression_focused_min_u.csv :\n",
      "    params                value\n",
      "0  kernel                  rbf\n",
      "1       C  0.23459004141044545\n",
      "2  degree                    5\n",
      "3   gamma   0.9827535390703468\n",
      "4   value  0.19794213653821938\n",
      "params_xgboost_regression_focused_max_u.csv :\n",
      "               params                   value\n",
      "0            booster                  gbtree\n",
      "1             lambda   4.288055780512365e-06\n",
      "2              alpha  7.5629056802818344e-06\n",
      "3          subsample       0.923150683853891\n",
      "4   colsample_bytree     0.29590462079459834\n",
      "5          max_depth                       9\n",
      "6   min_child_weight                       7\n",
      "7                eta     0.04974261878678785\n",
      "8              gamma  2.4006274373913765e-06\n",
      "9        grow_policy               lossguide\n",
      "10             value    0.004746721767657069\n",
      "params_xgboost_regression_focused_min_u.csv :\n",
      "               params                   value\n",
      "0            booster                  gbtree\n",
      "1             lambda   0.0022873748876265547\n",
      "2              alpha  4.7080182859143866e-07\n",
      "3          subsample      0.8208513399117434\n",
      "4   colsample_bytree      0.3880421550437328\n",
      "5          max_depth                       7\n",
      "6   min_child_weight                       6\n",
      "7                eta     0.04780943557478916\n",
      "8              gamma   0.0032619783528789396\n",
      "9        grow_policy               depthwise\n",
      "10             value   0.0047686450341566855\n",
      "Boolean hyper params:\n",
      "\n",
      "params_gradient_boost_classifier_max_u.csv :\n",
      "           params              value\n",
      "0   n_estimators                 38\n",
      "1  learning_rate  0.466137255116544\n",
      "2           loss        exponential\n",
      "3          value  0.622128598655833\n",
      "params_gradient_boost_classifier_min_u.csv :\n",
      "           params                value\n",
      "0   n_estimators                  991\n",
      "1  learning_rate  0.30604705738285287\n",
      "2           loss          exponential\n",
      "3          value   0.6332760671336064\n",
      "params_support_vector_classifier_max_u.csv :\n",
      "    params               value\n",
      "0  kernel                poly\n",
      "1       C  0.5283498165839644\n",
      "2  degree                   4\n",
      "3   gamma  0.9996926592406632\n",
      "4   value   0.368779841709756\n",
      "params_support_vector_classifier_min_u.csv :\n",
      "    params                value\n",
      "0  kernel                 poly\n",
      "1       C  0.18387180132926847\n",
      "2  degree                    5\n",
      "3   gamma   0.9548296680596685\n",
      "4   value   0.3742098077264465\n",
      "params_xgboost_classifier_max_u.csv :\n",
      "           params                value\n",
      "0           loss          exponential\n",
      "1  learning_rate  0.08363472795701299\n",
      "2   n_estimators                   80\n",
      "3      subsample   0.3056030047028318\n",
      "4      max_depth                    5\n",
      "5          value    0.415922217007392\n",
      "params_xgboost_classifier_min_u.csv :\n",
      "           params                value\n",
      "0           loss             deviance\n",
      "1  learning_rate   0.6311975807171595\n",
      "2   n_estimators                   81\n",
      "3      subsample    0.981589184229811\n",
      "4      max_depth                   10\n",
      "5          value  0.45011534919770996\n"
     ]
    }
   ],
   "source": [
    "sparse_hyper_params = {}\n",
    "focused_hyper_params = {}\n",
    "boolean_hyper_params = {}\n",
    "for file in os.listdir('hyper_params_results'):\n",
    "    if file.endswith('.csv') and 'sparse' in file.split('_') and 'classifier' not in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'focused' in file.split('_') and 'classifier' not in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        focused_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        boolean_hyper_params[file] = df\n",
    "print('Sparse hyper params:\\n')\n",
    "for key in sparse_hyper_params.keys():\n",
    "    print(key, ':\\n ',sparse_hyper_params[key])\n",
    "print('Focused hyper params:\\n')\n",
    "for key in focused_hyper_params.keys():\n",
    "    print(key, ':\\n',focused_hyper_params[key])\n",
    "print('Boolean hyper params:\\n')\n",
    "for key in boolean_hyper_params.keys():\n",
    "    print(key, ':\\n',boolean_hyper_params[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 544,\n",
       " 'learning_rate': 0.36423151911958196,\n",
       " 'loss': 'squared_error'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "def get_hyper_params_from_df(df):\n",
    "    output = {}\n",
    "    for row in df.iterrows():\n",
    "        if row[1]['params'] != 'value':\n",
    "            try:\n",
    "                output[row[1]['params']] = ast.literal_eval(row[1]['value'])\n",
    "            except :\n",
    "                output[row[1]['params']] = row[1]['value']\n",
    "    return output\n",
    "get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_max_u.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from thesis_package import aimodels as my_ai, utils, metrics\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Regression data sparse\n",
    "y_max_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv').drop(columns=['timestamps'])\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_max_u_sparse)\n",
    "data_max_u_sparse = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_max_u_sparse, scaling=True)\n",
    "data_max_u_scaled_sparse = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_min_u_sparse)\n",
    "data_min_u_sparse = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_min_u_sparse, scaling=True)\n",
    "data_min_u_scaled_sparse = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Regresison data focused\n",
    "y_max_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_bal_constr.csv')\n",
    "exogenous_data_focused_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_bal.csv').drop(columns=['date'])\n",
    "y_min_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_bal_constr.csv')\n",
    "exogenous_data_focused_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_bal.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data_focused_max_u, y_max_u_focused)\n",
    "data_max_u_focused = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data_focused_max_u, y_max_u_focused, scaling=True)\n",
    "data_max_u_scaled_focused = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data_focused_min_u, y_min_u_focused)\n",
    "data_min_u_focused = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data_focused_min_u, y_min_u_focused, scaling=True)\n",
    "data_min_u_scaled_focused = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data\n",
    "y_max_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_max_u = y_max_u[utils.cols_with_positive_values(y_max_u)]\n",
    "y_min_u = y_min_u[utils.cols_with_positive_values(y_min_u)]\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_max_u)\n",
    "data_max_u_bool = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_max_u, scaling=True)\n",
    "data_max_u_bool_scaled = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_min_u)\n",
    "data_min_u_bool = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}\n",
    "\n",
    "train_x, test_x, train_y, test_y = utils.split_and_suffle(exogenous_data, y_min_u, scaling=True)\n",
    "data_min_u_bool_scaled = {'X_train': train_x, 'X_test': test_x, 'y_train': train_y, 'y_test': test_y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "In this section the models will be trained with the hyperparameters loaded above. All the models will be stored in the same `Context` object for later evaluation. The `Context` object is a class that stores all the models and their respective hyperparameters. The `Context` object is defined in the `aimodels.py` file. The `Context` object is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params_gradient_boost_regression_sparse_max_u.csv', 'params_gradient_boost_regression_sparse_min_u.csv', 'params_support_vector_regression_sparse_max_u.csv', 'params_support_vector_regression_sparse_min_u.csv', 'params_xgboost_regression_sparse_max_u.csv', 'params_xgboost_regression_sparse_min_u.csv'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_hyper_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# max_u regression sparse\n",
    "if 'max_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    # Linear Regression\n",
    "    regressor_max_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_max_u.csv']) \n",
    "    regressor_max_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_scaled_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_spare', regressor_max_u)\n",
    "else: \n",
    "    regressor_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\\\max_u_regressor_sparse')\n",
    "# Linear Regression\n",
    "prediction_lr_max_u = regressor_max_u.strategies[0].predict(data=data_max_u_sparse)\n",
    "prediction_lr_max_u = pd.DataFrame(prediction_lr_max_u , columns=data_max_u_sparse['y_test'].columns)\n",
    "# Gradient Boost Regression\n",
    "prediction_gb_max_u =  regressor_max_u.strategies[1].predict(data=data_max_u_sparse)\n",
    "prediction_gb_max_u = pd.DataFrame(prediction_gb_max_u, columns=data_max_u_sparse['y_test'].columns)\n",
    "# Extreme GBoost Regression\n",
    "prediction_xgb_max_u =  regressor_max_u.strategies[2].predict(data=data_max_u_sparse)\n",
    "prediction_xgb_max_u = pd.DataFrame(prediction_xgb_max_u, columns=data_max_u_sparse['y_test'].columns)\n",
    "# Support Vector Regression\n",
    "prediction_svr_max_u =  regressor_max_u.strategies[3].predict(data=data_max_u_scaled_sparse)\n",
    "prediction_svr_max_u = pd.DataFrame(prediction_svr_max_u, columns=data_max_u_sparse['y_test'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_u regression focused\n",
    "if 'max_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    # Linear Regression\n",
    "    regressor_max_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u.fit(data=data_max_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_max_u.csv']) \n",
    "    regressor_max_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_scaled_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_focused', regressor_max_u)\n",
    "else: \n",
    "    regressor_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\\\max_u_regressor_focused')\n",
    "# Linear Regression\n",
    "prediction_lr_max_u = regressor_max_u.strategies[0].predict(data=data_max_u_focused)\n",
    "prediction_lr_max_u = pd.DataFrame(prediction_lr_max_u , columns=data_max_u_focused['y_test'].columns)\n",
    "# Gradient Boost Regression\n",
    "prediction_gb_max_u =  regressor_max_u.strategies[1].predict(data=data_max_u_focused)\n",
    "prediction_gb_max_u = pd.DataFrame(prediction_gb_max_u, columns=data_max_u_focused['y_test'].columns)\n",
    "# Extreme GBoost Regression\n",
    "prediction_xgb_max_u =  regressor_max_u.strategies[2].predict(data=data_max_u_focused)\n",
    "prediction_xgb_max_u = pd.DataFrame(prediction_xgb_max_u, columns=data_max_u_focused['y_test'].columns)\n",
    "# Support Vector Regression\n",
    "prediction_svr_max_u =  regressor_max_u.strategies[3].predict(data=data_max_u_scaled_focused)\n",
    "prediction_svr_max_u = pd.DataFrame(prediction_svr_max_u, columns=data_max_u_focused['y_test'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:24:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:24:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max_u classification\n",
    "if 'max_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_gradient_boost_classifier_max_u.csv'])\n",
    "    classifier_max_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_xgboost_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_support_vector_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool_scaled)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier', classifier_max_u)\n",
    "else: \n",
    "    classifier_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier')\n",
    "# Gradient Boost Classifier\n",
    "prediction_gb_max_u = classifier_max_u.strategies[0].predict(data=data_max_u_bool)\n",
    "prediction_gb_max_u = pd.DataFrame(prediction_gb_max_u, columns=data_max_u_bool['y_test'].columns)\n",
    "# Extreme GBoost Classifier\n",
    "prediction_xgb_max_u = classifier_max_u.strategies[1].predict(data=data_max_u_bool)\n",
    "prediction_xgb_max_u = pd.DataFrame(prediction_xgb_max_u, columns=data_max_u_bool['y_test'].columns)\n",
    "# Support Vector Classifier\n",
    "prediction_svr_max_u = classifier_max_u.strategies[2].predict(data=data_max_u_bool_scaled)\n",
    "prediction_svr_max_u = pd.DataFrame(prediction_svr_max_u, columns=data_max_u_bool['y_test'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min u regression training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:02:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:02:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"subsample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# min_u regression sparse\n",
    "if 'min_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    # Linear Regression\n",
    "    regressor_min_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_scaled_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse', regressor_min_u)\n",
    "else:\n",
    "    regressor_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse')\n",
    "# Linear Regression\n",
    "prediction_lr_min_u = regressor_min_u.strategies[0].predict(data=data_min_u_sparse)\n",
    "prediction_lr_min_u = pd.DataFrame(prediction_lr_min_u , columns=data_min_u_sparse['y_test'].columns)\n",
    "# Gradient Boost Regression\n",
    "prediction_gb_min_u =  regressor_min_u.strategies[1].predict(data=data_min_u_sparse)\n",
    "prediction_gb_min_u = pd.DataFrame(prediction_gb_min_u, columns=data_min_u_sparse['y_test'].columns)\n",
    "# Extreme GBoost Regression\n",
    "prediction_xgb_min_u =  regressor_min_u.strategies[2].predict(data=data_min_u_sparse)\n",
    "prediction_xgb_min_u = pd.DataFrame(prediction_xgb_min_u, columns=data_min_u_sparse['y_test'].columns)\n",
    "# Support Vector Regression\n",
    "prediction_svr_min_u =  regressor_min_u.strategies[3].predict(data=data_min_u_scaled_sparse)\n",
    "prediction_svr_min_u = pd.DataFrame(prediction_svr_min_u, columns=data_min_u_sparse['y_test'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_u regression focused\n",
    "if 'min_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    # Linear Regression\n",
    "    regressor_min_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u.fit(data=data_min_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_scaled_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused', regressor_min_u)\n",
    "else:\n",
    "    regressor_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused')\n",
    "# Linear Regression\n",
    "prediction_lr_min_u = regressor_min_u.strategies[0].predict(data=data_min_u_focused)\n",
    "prediction_lr_min_u = pd.DataFrame(prediction_lr_min_u , columns=data_min_u_focused['y_test'].columns)\n",
    "# Gradient Boost Regression\n",
    "prediction_gb_min_u =  regressor_min_u.strategies[1].predict(data=data_min_u_focused)\n",
    "prediction_gb_min_u = pd.DataFrame(prediction_gb_min_u, columns=data_min_u_focused['y_test'].columns)\n",
    "# Extreme GBoost Regression\n",
    "prediction_xgb_min_u =  regressor_min_u.strategies[2].predict(data=data_min_u_focused)\n",
    "prediction_xgb_min_u = pd.DataFrame(prediction_xgb_min_u, columns=data_min_u_focused['y_test'].columns)\n",
    "# Support Vector Regression\n",
    "prediction_svr_min_u =  regressor_min_u.strategies[3].predict(data=data_min_u_scaled_focused)\n",
    "prediction_svr_min_u = pd.DataFrame(prediction_svr_min_u, columns=data_min_u_focused['y_test'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:13:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:13:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"loss\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# min_u classification\n",
    "if 'min_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_gradient_boost_classifier_max_u.csv'])\n",
    "    classifier_min_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_xgboost_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(boolean_hyper_params['params_support_vector_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool_scaled)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier', classifier_min_u)\n",
    "else: \n",
    "    classifier_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\classifier_min_u')\n",
    "# Gradient Boost Classifier\n",
    "prediction_gb_min_u = classifier_min_u.strategies[0].predict(data=data_min_u_bool)\n",
    "prediction_gb_min_u = pd.DataFrame(prediction_gb_min_u, columns=data_min_u_bool['y_test'].columns)\n",
    "# Extreme GBoost Classifier\n",
    "prediction_xgb_min_u = classifier_min_u.strategies[1].predict(data=data_min_u_bool)\n",
    "prediction_xgb_min_u = pd.DataFrame(prediction_xgb_min_u, columns=data_min_u_bool['y_test'].columns)\n",
    "# Support Vector Classifier \n",
    "prediction_svr_min_u = classifier_min_u.strategies[2].predict(data=data_min_u_bool_scaled)\n",
    "prediction_svr_min_u = pd.DataFrame(prediction_svr_min_u, columns=data_min_u_bool['y_test'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Discussion\n",
    "In this section the results of the training and testing are presented and compared. The main objectives of this experience is to compare the performance of the regression models in terms of the hybrid metrics confusion matrix and the hybrid metrics rmse. The comparisons will be the following:\n",
    "- Compare the confusion matrices of the classification models and the regression models evaluate with the hybrid metrics.\n",
    "- Compare the error results of the regression models trained with the focused dataset and the sparse dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = train_y.loc[:, train_y.max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "metric = metrics.Metrics()\n",
    "valid_y = pd.DataFrame(valid_y, columns=y_min_u.columns)\n",
    "metric.get_prediction_scores(prediction, valid_y, threshold=threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe4baa4d27e3b73db55d4bb4674105e8dd41faaf9e559c3cc8381041ce15293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
