{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of this Article** \n",
    "- Loading best hyperparameters for each model\n",
    "- Model training\n",
    "- Results discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best hyperparameters for each model\n",
    "\n",
    "TODO... explain this model bench mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hyperparameters dataset.\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse hyperparameters: 8/8\n",
      "Focused hyperparameters: 8/8\n",
      "Balanced hyperparameters: 8/8\n",
      "Filtered hyperparameters: 8/8\n",
      "Sparse classifier hyperparameters: 8/8\n",
      "Balanced classifier hyperparameters: 8/8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparse_hyper_params = {}\n",
    "focused_hyper_params = {}\n",
    "balanced_hyper_params = {}\n",
    "filtered_hyper_params = {}\n",
    "sparse_class_hyper_params = {}\n",
    "balanced_class_hyper_params = {}\n",
    "for file in os.listdir('hyper_params_results_mcc'):\n",
    "    if file.endswith('.csv') and 'regression_sparse' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'regression_focused' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        focused_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'regression_balanced' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        balanced_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'filtered' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        filtered_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'sparse_classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_class_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'balanced_classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        balanced_class_hyper_params[file] = df\n",
    "print('Sparse hyperparameters: {}/8'.format(len(sparse_hyper_params)))\n",
    "print('Focused hyperparameters: {}/8'.format(len(focused_hyper_params)))\n",
    "print('Balanced hyperparameters: {}/8'.format(len(balanced_hyper_params)))\n",
    "print('Filtered hyperparameters: {}/8'.format(len(filtered_hyper_params)))\n",
    "print('Sparse classifier hyperparameters: {}/8'.format(len(sparse_class_hyper_params)))\n",
    "print('Balanced classifier hyperparameters: {}/8'.format(len(balanced_class_hyper_params)))\n",
    "print('\\n')\n",
    "# print('Sparse hyper params:\\n')\n",
    "# for key in sparse_hyper_params.keys():\n",
    "#     print(key, ':\\n ',sparse_hyper_params[key])\n",
    "# print('Focused hyper params:\\n')\n",
    "# for key in focused_hyper_params.keys():\n",
    "#     print(key, ':\\n',focused_hyper_params[key])\n",
    "# print('Boolean hyper params:\\n')\n",
    "# for key in sparse_class_hyper_params.keys():\n",
    "#     print(key, ':\\n',sparse_class_hyper_params[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 34,\n",
       " 'n_layers': 3,\n",
       " 'dropout': 0.0030412321477918842,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'sgd',\n",
       " 'lr': 9.741292351005151e-05,\n",
       " 'epochs': 55,\n",
       " 'batch_size': 8,\n",
       " 'classifier': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "def get_hyper_params_from_df(df):\n",
    "    output = {}\n",
    "    for row in df.iterrows():\n",
    "        if row[1]['params'] != 'value':\n",
    "            try:\n",
    "                output[row[1]['params']] = ast.literal_eval(row[1]['value'])\n",
    "            except :\n",
    "                output[row[1]['params']] = row[1]['value']\n",
    "    return output\n",
    "get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_max_u.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..');from thesis_package import aimodels as my_ai, utils, metrics\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression data sparse\n",
    "y_max_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv').drop(columns=['timestamps'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_sparse, test_size=0.2, scaling=True)\n",
    "data_max_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_sparse, test_size=0.2, scaling=True)\n",
    "data_min_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data sparse\n",
    "y_max_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_sparse_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_sparse_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_max_u_bool = y_max_u_bool[utils.cols_with_positive_values(y_max_u_bool)]\n",
    "y_min_u_bool = y_min_u_bool[utils.cols_with_positive_values(y_min_u_bool)]\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_bool, test_size=0.2, scaling=True)\n",
    "data_max_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_bool, test_size=0.2, scaling=True)\n",
    "data_min_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered data\n",
    "y_max_u_filtered = deepcopy(y_max_u_sparse[utils.cols_with_positive_values(y_max_u_bool)])\n",
    "y_min_u_filtered = deepcopy(y_min_u_sparse[utils.cols_with_positive_values(y_min_u_bool)])\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_filtered, test_size=0.2, scaling=True)\n",
    "data_max_u_filtered = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_filtered, test_size=0.2, scaling=True)\n",
    "data_min_u_filtered = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification data size:  (9044, 11)\n",
      "Regression data size:  (9044, 11)\n",
      "Positive in classification data:  4949.0\n",
      "Positive in regression data:  4949\n",
      "Theshhold:  0.0016733255333549746\n",
      "\n",
      "\n",
      "Classification data size:  (9044, 10)\n",
      "Regression data size:  (9044, 10)\n",
      "Positive in classification data:  6022.0\n",
      "Positive in regression data:  6022\n",
      "Theshhold:  0.002022118621573741\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the classiciation testing data and the filtered testing data\n",
    "print('Classification data size: ', data_max_u_bool['y_test'].shape)\n",
    "print('Regression data size: ', data_max_u_filtered['y_test'].shape)\n",
    "print('Positive in classification data: ', utils.count_positives_class(data_max_u_bool['y_test']))\n",
    "#unscaled_y_test = pd.DataFrame(data_max_u_filtered['scaler']['y'].inverse_transform(data_max_u_filtered['y_test']), columns=data_max_u_filtered['y_test'].columns)\n",
    "unscaled_y_test = data_max_u_filtered['y_test'] * data_max_u_sparse['scaler']['y']\n",
    "print('Positive in regression data: ', utils.count_positives_reg(unscaled_y_test, utils.compute_threshold(y_max_u_sparse)))\n",
    "print('Theshhold: ', utils.compute_threshold(y_max_u_sparse))\n",
    "# Same for min_u\n",
    "print('\\n')\n",
    "print('Classification data size: ', data_min_u_bool['y_test'].shape)\n",
    "print('Regression data size: ', data_min_u_filtered['y_test'].shape)\n",
    "print('Positive in classification data: ', utils.count_positives_class(data_min_u_bool['y_test']))\n",
    "#unscaled_y_test = pd.DataFrame(data_min_u_filtered['scaler']['y'].inverse_transform(data_min_u_filtered['y_test']), columns=data_min_u_filtered['y_test'].columns)\n",
    "unscaled_y_test = data_min_u_filtered['y_test'] * data_min_u_sparse['scaler']['y']\n",
    "print('Positive in regression data: ', utils.count_positives_reg(unscaled_y_test, utils.compute_threshold(y_min_u_sparse)))\n",
    "print('Theshhold: ', utils.compute_threshold(y_min_u_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data focused\n",
    "y_max_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_focused_constr.csv')\n",
    "exogenous_data_focused_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_focused.csv').drop(columns=['date'])\n",
    "y_min_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_focused_constr.csv')\n",
    "exogenous_data_focused_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_focused.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_max_u, y_max_u_focused, test_size=0.2, scaling=True)\n",
    "data_max_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_min_u, y_min_u_focused, test_size=0.2, scaling=True)\n",
    "data_min_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data balanced\n",
    "y_max_u_balanced = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_constr.csv')\n",
    "exogenous_data_balanced_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "y_min_u_balanced = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_constr.csv')\n",
    "exogenous_data_balanced_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_max_u, y_max_u_balanced, test_size=0.2, scaling=True)\n",
    "data_max_u_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_min_u, y_min_u_balanced, test_size=0.2, scaling=True)\n",
    "data_min_u_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data balanced\n",
    "y_max_u_balanced_class = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_bool_constr.csv')\n",
    "exogenous_data_balanced_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "y_min_u_balanced_class = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_bool_constr.csv')\n",
    "exogenous_data_balanced_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "y_max_u_balanced_class = y_max_u_balanced_class[utils.cols_with_positive_values(y_max_u_balanced_class)]\n",
    "y_min_u_balanced_class = y_min_u_balanced_class[utils.cols_with_positive_values(y_min_u_balanced_class)]\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_max_u, y_max_u_balanced_class, test_size=0.2, scaling=True)\n",
    "data_max_u_bool_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_min_u, y_min_u_balanced_class, test_size=0.2, scaling=True)\n",
    "data_min_u_bool_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a quick sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count in classification data max_u : 4949.0\n",
      "Positive count in regression data max_u with threshold 0.0016733255333549746 : 4949\n",
      "\n",
      "\n",
      "Positive count in classification data min_u : 6022.0\n",
      "Positive count in regression data min_u with threshold 0.002022118621573741 : 6022\n",
      "\n",
      "\n",
      "Negative count in classification data max_u : 94535.0\n",
      "Negative count in regression data max_u with threshold 0.0016733255333549746 : 94535\n",
      "\n",
      "\n",
      "Negative count in classification data min_u : 84418.0\n",
      "Negative count in regression data min_u with threshold 0.002022118621573741 : 84418\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.check_positive_count(data_max_u_filtered['y_test']* data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')\n",
    "utils.check_positive_count(data_min_u_filtered['y_test']* data_min_u_filtered['scaler']['y'], data_min_u_bool['y_test'], utils.compute_threshold(y_min_u_sparse), experiment='min_u')\n",
    "utils.check_negative_count(data_max_u_filtered['y_test']* data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')\n",
    "utils.check_negative_count(data_min_u_filtered['y_test']* data_min_u_filtered['scaler']['y'], data_min_u_bool['y_test'], utils.compute_threshold(y_min_u_sparse), experiment='min_u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count in classification data max_u : 4949.0\n",
      "Positive count in regression data max_u with threshold 0.0016733255333549746 : 4949\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.check_positive_count(data_max_u_filtered['y_test'] * data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "In this section the models will be trained with the hyperparameters loaded above. All the models will be stored in the same `Context` object for later evaluation. The `Context` object is a class that stores all the models and their respective hyperparameters. The `Context` object is defined in the `aimodels.py` file. The `Context` object is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_models = ['lr', 'gb', 'xgb', 'svr', 'mlp']\n",
    "class_models =  ['gb', 'xgb', 'svr', 'mlp']\n",
    "max_u_threshold = utils.compute_threshold(y_max_u_sparse)\n",
    "min_u_threshold = utils.compute_threshold(y_min_u_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params_gradient_boost_regression_sparse_max_u.csv', 'params_gradient_boost_regression_sparse_min_u.csv', 'params_mlp_regression_sparse_max_u.csv', 'params_mlp_regression_sparse_min_u.csv', 'params_support_vector_regression_sparse_max_u.csv', 'params_support_vector_regression_sparse_min_u.csv', 'params_xgboost_regression_sparse_max_u.csv', 'params_xgboost_regression_sparse_min_u.csv'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_hyper_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression sparse\n"
     ]
    }
   ],
   "source": [
    "# max_u regression sparse\n",
    "if 'max_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_max_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_max_u.csv']) \n",
    "    regressor_max_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regression_sparse_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_sparse['y_train'].shape[1]\n",
    "    regressor_max_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse', regressor_max_u)\n",
    "else:\n",
    "    print('Loading max_u regression sparse') \n",
    "    regressor_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse')\n",
    "\n",
    "testing_data = {'max_u_regressor_sparse': {}}\n",
    "for model, strategy in zip(reg_models, regressor_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_sparse['y_test'].columns)\n",
    "    testing_data['max_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_sparse'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ext_grid</th>\n",
       "      <th>bus_1</th>\n",
       "      <th>bus_2</th>\n",
       "      <th>bus_3</th>\n",
       "      <th>bus_4</th>\n",
       "      <th>bus_5</th>\n",
       "      <th>bus_6</th>\n",
       "      <th>bus_7</th>\n",
       "      <th>bus_8</th>\n",
       "      <th>bus_9</th>\n",
       "      <th>...</th>\n",
       "      <th>bus_30</th>\n",
       "      <th>bus_31</th>\n",
       "      <th>bus_17</th>\n",
       "      <th>bus_21</th>\n",
       "      <th>bus_24</th>\n",
       "      <th>bus_18</th>\n",
       "      <th>bus_23</th>\n",
       "      <th>bus_27</th>\n",
       "      <th>bus_32</th>\n",
       "      <th>bus_33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9040</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9041</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975726</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9044 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ext_grid  bus_1  bus_2  bus_3  bus_4  bus_5  bus_6  bus_7     bus_8  \\\n",
       "0          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.861825   \n",
       "1          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.975178   \n",
       "2          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.997191   \n",
       "3          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  1.000000   \n",
       "4          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.763679   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...       ...   \n",
       "9039       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.930680   \n",
       "9040       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.859353   \n",
       "9041       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.975726   \n",
       "9042       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.923673   \n",
       "9043       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.993724   \n",
       "\n",
       "      bus_9  ...  bus_30  bus_31  bus_17  bus_21  bus_24  bus_18  bus_23  \\\n",
       "0       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "1       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "2       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "3       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "4       1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "...     ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9039    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "9040    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "9041    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "9042    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "9043    1.0  ...     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "\n",
       "      bus_27  bus_32  bus_33  \n",
       "0        0.0     0.0     0.0  \n",
       "1        0.0     0.0     0.0  \n",
       "2        0.0     0.0     0.0  \n",
       "3        0.0     0.0     0.0  \n",
       "4        0.0     0.0     0.0  \n",
       "...      ...     ...     ...  \n",
       "9039     0.0     0.0     0.0  \n",
       "9040     0.0     0.0     0.0  \n",
       "9041     0.0     0.0     0.0  \n",
       "9042     0.0     0.0     0.0  \n",
       "9043     0.0     0.0     0.0  \n",
       "\n",
       "[9044 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAHSCAYAAABl3euMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfNklEQVR4nO3df7DddX3n8de7BI1EFiGitQRNZqEQfkXCBZOBWluUHysFVFxFuzJbtzCdsvbHrhq2MwvVdga2rj+Yop2MsKJtRctqG7dbCYiMM5YfXpCp/DRBUwlFCD9EolIEP/vH/ZIN6f00CfckJwmPx0zmnu/n+7nnfO6d+c73zjPf8z3VWgsAAAAATOfnxr0AAAAAAHZc4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF2zxr2A5+KlL31pmz9//riXAQAAALDLuPnmmx9qre276fhOGY/mz5+fycnJcS8DAAAAYJdRVf843bi3rQEAAADQJR4BAAAA0CUeAQAAANC1U97zCAAAAHh++elPf5q1a9fmiSeeGPdSdnqzZ8/OvHnzsvvuu2/RfPEIAAAA2OGtXbs2e+65Z+bPn5+qGvdydlqttTz88MNZu3ZtFixYsEXf421rAAAAwA7viSeeyNy5c4WjGaqqzJ07d6uu4BKPAAAAgJ2CcDQaW/t7FI8AAAAAtrPrrrsup5xySpJkxYoVufDCC7tzf/CDH+TjH//4Vr/GBRdckA996EPPeY3PEI8AAAAARuTpp5/e6u859dRTs2zZsu7+5xqPRkU8AgAAANgCa9asycEHH5x3vvOdWbhwYc4444z8+Mc/zvz58/P+978/ixcvzl/91V9l5cqVWbp0aRYvXpy3vvWtWb9+fZLky1/+cg4++OAsXrw4X/jCFzY876c+9amce+65SZIHHnggb3rTm7Jo0aIsWrQof//3f59ly5blnnvuyatf/eq8973vTZL8yZ/8SY4++ugcccQROf/88zc81x//8R/nF3/xF3Pcccfl7rvvHsnP7dPWAAAAgJ3KH37p9tzxTz8c6XMe8gv/Juf/2qGbnXf33Xfn0ksvzbHHHpvf+I3f2HBF0Ny5c3PLLbfkoYceypvf/OZcc801mTNnTi666KJ8+MMfzvve97785m/+Zq699toccMABedvb3jbt87/nPe/JL//yL+eLX/xinn766axfvz4XXnhhbrvtttx6661JkpUrV2bVqlW56aab0lrLqaeemq997WuZM2dOrrjiitx666156qmnsnjx4hx11FEz/t2IRwAAAABbaP/998+xxx6bJPn1X//1XHzxxUmyIQbdcMMNueOOOzbMefLJJ7N06dLcddddWbBgQQ488MAN37t8+fJ/8fzXXnttPv3pTydJdtttt+y111559NFHnzVn5cqVWblyZY488sgkyfr167Nq1ao8/vjjedOb3pQ99tgjydTb4UZBPAIAAAB2KltyhdC2suknlT2zPWfOnCRJay1veMMb8tnPfvZZ8565amgUWms577zzcs455zxr/KMf/ejIXmNj7nkEAAAAsIW+973v5frrr0+S/OVf/mWOO+64Z+1fsmRJvv71r2f16tVJkh/96Ef59re/nYMPPjhr1qzJPffckyT/Ii494/jjj88nPvGJJFM3337sscey55575vHHH98w58QTT8xll1224V5K9913Xx588MG89rWvzV//9V/nJz/5SR5//PF86UtfGsnPLB4BAAAAbKGDDjool1xySRYuXJhHH300v/Vbv/Ws/fvuu28+9alP5cwzz8wRRxyx4S1rs2fPzvLly/PGN74xixcvzste9rJpn/9jH/tYvvrVr+bwww/PUUcdlTvuuCNz587Nsccem8MOOyzvfe97c8IJJ+Qd73hHli5dmsMPPzxnnHFGHn/88SxevDhve9vbsmjRopx88sk5+uijR/IzV2ttJE+0PU1MTLTJyclxLwMAAADYTu68884sXLhwrGtYs2ZNTjnllNx2221jXccoTPf7rKqbW2sTm8515REAAAAAXeIRAAAAwBaYP3/+LnHV0dYSjwAAAADoEo8AAAAA6BKPAAAAAOgSjwAAAADoEo8AAAAAtoP58+fnoYceGvcytpp4BAAAALCVWmv52c9+Nu5lbBfiEQAAAMAWWLNmTQ466KC8613vymGHHZYPfvCDOfroo3PEEUfk/PPP3zDv9NNPz1FHHZVDDz00y5cvH+OKR2PWuBcAAAAAsFX+blny/W+N9jl//vDk5As3O23VqlW5/PLL88Mf/jBXXnllbrrpprTWcuqpp+ZrX/taXvva1+ayyy7LPvvsk5/85Cc5+uij85a3vCVz584d7Xq3I1ceAQAAAGyhV73qVVmyZElWrlyZlStX5sgjj8zixYtz1113ZdWqVUmSiy++OIsWLcqSJUty7733bhjfWbnyCAAAANi5bMEVQtvKnDlzkkzd8+i8887LOeec86z91113Xa655ppcf/312WOPPfK6170uTzzxxDiWOjKuPAIAAADYSieeeGIuu+yyrF+/Pkly33335cEHH8xjjz2WvffeO3vssUfuuuuu3HDDDWNe6cy58ggAAABgK51wwgm58847s3Tp0iTJi1/84vz5n/95TjrppPzZn/1ZFi5cmIMOOihLliwZ80pnrlpr417DVpuYmGiTk5PjXgYAAACwndx5551ZuHDhuJexy5ju91lVN7fWJjad621rAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAwE5hZ7xv845oa3+P4hEAAACww5s9e3YefvhhAWmGWmt5+OGHM3v27C3+nlnbcD0AAAAAIzFv3rysXbs269atG/dSdnqzZ8/OvHnztni+eAQAAADs8HbfffcsWLBg3Mt4XvK2NQAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6RhKPquqkqrq7qlZX1bJp9r+wqj437L+xquZvsv+VVbW+qv7rKNYDAAAAwGjMOB5V1W5JLklycpJDkpxZVYdsMu3dSR5trR2Q5CNJLtpk/4eT/N1M1wIAAADAaI3iyqNjkqxurX2ntfZkkiuSnLbJnNOSXD48vjLJ8VVVSVJVpyf5bpLbR7AWAAAAAEZoFPFovyT3brS9dhibdk5r7akkjyWZW1UvTvL+JH+4uRepqrOrarKqJtetWzeCZQMAAACwOeO+YfYFST7SWlu/uYmtteWttYnW2sS+++677VcGAAAAQGaN4DnuS7L/RtvzhrHp5qytqllJ9krycJLXJDmjqv5Hkpck+VlVPdFa+9MRrAsAAACAGRpFPPpGkgOrakGmItHbk7xjkzkrkpyV5PokZyS5trXWkvzSMxOq6oIk64UjAAAAgB3HjONRa+2pqjo3yVVJdktyWWvt9qr6QJLJ1tqKJJcm+UxVrU7ySKYCEwAAAAA7uJq6AGjnMjEx0SYnJ8e9DAAAAIBdRlXd3Fqb2HR83DfMBgAAAGAHJh4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQJR4BAAAA0CUeAQAAANAlHgEAAADQNZJ4VFUnVdXdVbW6qpZNs/+FVfW5Yf+NVTV/GH9DVd1cVd8avv7qKNYDAAAAwGjMOB5V1W5JLklycpJDkpxZVYdsMu3dSR5trR2Q5CNJLhrGH0rya621w5OcleQzM10PAAAAAKMziiuPjkmyurX2ndbak0muSHLaJnNOS3L58PjKJMdXVbXWvtla+6dh/PYkL6qqF45gTQAAAACMwCji0X5J7t1oe+0wNu2c1tpTSR5LMneTOW9Jcktr7Z+ne5GqOruqJqtqct26dSNYNgAAAACbs0PcMLuqDs3UW9nO6c1prS1vrU201ib23Xff7bc4AAAAgOexUcSj+5Lsv9H2vGFs2jlVNSvJXkkeHrbnJflikne11u4ZwXoAAAAAGJFRxKNvJDmwqhZU1QuSvD3Jik3mrMjUDbGT5Iwk17bWWlW9JMnfJlnWWvv6CNYCAAAAwAjNOB4N9zA6N8lVSe5M8vnW2u1V9YGqOnWYdmmSuVW1OsnvJ1k2jJ+b5IAk/72qbh3+vWymawIAAABgNKq1Nu41bLWJiYk2OTk57mUAAAAA7DKq6ubW2sSm4zvEDbMBAAAA2DGJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSNJB5V1UlVdXdVra6qZdPsf2FVfW7Yf2NVzd9o33nD+N1VdeIo1gMAAADAaMw4HlXVbkkuSXJykkOSnFlVh2wy7d1JHm2tHZDkI0kuGr73kCRvT3JokpOSfHx4PgAAAAB2ALNG8BzHJFndWvtOklTVFUlOS3LHRnNOS3LB8PjKJH9aVTWMX9Fa++ck362q1cPzXT+Cde3Q/um7d2XtLX837mUAAAAAM/DCfeZl0a+8ddzL2KZGEY/2S3LvRttrk7ymN6e19lRVPZZk7jB+wybfu990L1JVZyc5O0le+cpXjmDZ4/X9u2/IMd+6YNzLAAAAAGbgH2YflYhHO4bW2vIky5NkYmKijXk5M7bwl96SBw77pXEvAwAAAJiBeS+YPe4lbHOjiEf3Jdl/o+15w9h0c9ZW1awkeyV5eAu/d5f0ojl75kVz9hz3MgAAAAD+VaP4tLVvJDmwqhZU1QsydQPsFZvMWZHkrOHxGUmuba21Yfztw6exLUhyYJKbRrAmAAAAAEZgxlceDfcwOjfJVUl2S3JZa+32qvpAksnW2ooklyb5zHBD7EcyFZgyzPt8pm6u/VSS326tPT3TNQEAAAAwGjV1AdDOZWJiok1OTo57GQAAAAC7jKq6ubU2sen4KN62BgAAAMAuSjwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACgSzwCAAAAoEs8AgAAAKBLPAIAAACga0bxqKr2qaqrq2rV8HXvzryzhjmrquqsYWyPqvrbqrqrqm6vqgtnshYAAAAARm+mVx4tS/KV1tqBSb4ybD9LVe2T5Pwkr0lyTJLzN4pMH2qtHZzkyCTHVtXJM1wPAAAAACM003h0WpLLh8eXJzl9mjknJrm6tfZIa+3RJFcnOam19uPW2leTpLX2ZJJbksyb4XoAAAAAGKGZxqOXt9buHx5/P8nLp5mzX5J7N9peO4xtUFUvSfJrmbp6aVpVdXZVTVbV5Lp162a0aAAAAAC2zKzNTaiqa5L8/DS7/mDjjdZaq6q2tQuoqllJPpvk4tbad3rzWmvLkyxPkomJia1+HQAAAAC23mbjUWvt9b19VfVAVb2itXZ/Vb0iyYPTTLsvyes22p6X5LqNtpcnWdVa++iWLBgAAACA7Wemb1tbkeSs4fFZSf5mmjlXJTmhqvYebpR9wjCWqvqjJHsl+d0ZrgMAAACAbWCm8ejCJG+oqlVJXj9sp6omquqTSdJaeyTJB5N8Y/j3gdbaI1U1L1NvfTskyS1VdWtV/acZrgcAAACAEarWdr7bB01MTLTJyclxLwMAAABgl1FVN7fWJjYdn+mVRwAAAADswsQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAusQjAAAAALrEIwAAAAC6xCMAAAAAumYUj6pqn6q6uqpWDV/37sw7a5izqqrOmmb/iqq6bSZrAQAAAGD0Znrl0bIkX2mtHZjkK8P2s1TVPknOT/KaJMckOX/jyFRVb06yfobrAAAAAGAbmGk8Oi3J5cPjy5OcPs2cE5Nc3Vp7pLX2aJKrk5yUJFX14iS/n+SPZrgOAAAAALaBmcajl7fW7h8efz/Jy6eZs1+SezfaXjuMJckHk/zPJD/e3AtV1dlVNVlVk+vWrZvBkgEAAADYUrM2N6Gqrkny89Ps+oONN1prraralr5wVb06yb9trf1eVc3f3PzW2vIky5NkYmJii18HAAAAgOdus/Gotfb63r6qeqCqXtFau7+qXpHkwWmm3ZfkdRttz0tyXZKlSSaqas2wjpdV1XWttdcFAAAAgB3CTN+2tiLJM5+edlaSv5lmzlVJTqiqvYcbZZ+Q5KrW2idaa7/QWpuf5Lgk3xaOAAAAAHYsM41HFyZ5Q1WtSvL6YTtVNVFVn0yS1tojmbq30TeGfx8YxgAAAADYwVVrO9/tgyYmJtrk5OS4lwEAAACwy6iqm1trE5uOz/TKIwAAAAB2YeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd4hEAAAAAXeIRAAAAAF3iEQAAAABd1Vob9xq2WlWtS/KP417HCLw0yUPjXgQ8jzkGYXwcfzBejkEYH8cfO7JXtdb23XRwp4xHu4qqmmytTYx7HfB85RiE8XH8wXg5BmF8HH/sjLxtDQAAAIAu8QgAAACALvFovJaPewHwPOcYhPFx/MF4OQZhfBx/7HTc8wgAAACALlceAQAAANAlHo1JVZ1UVXdX1eqqWjbu9cCuoKr2r6qvVtUdVXV7Vf3OML5PVV1dVauGr3sP41VVFw/H4T9U1eKNnuusYf6qqjprXD8T7Gyqareq+mZV/Z9he0FV3TgcZ5+rqhcM4y8ctlcP++dv9BznDeN3V9WJY/pRYKdTVS+pqiur6q6qurOqljoHwvZRVb83/P15W1V9tqpmOweyKxGPxqCqdktySZKTkxyS5MyqOmS8q4JdwlNJ/ktr7ZAkS5L89nBsLUvyldbagUm+MmwnU8fggcO/s5N8IpmKTUnOT/KaJMckOf+ZP7aBzfqdJHdutH1Rko+01g5I8miSdw/j707y6DD+kWFehmP27UkOTXJSko8P501g8z6W5MuttYOTLMrUsegcCNtYVe2X5D1JJlprhyXZLVPnMudAdhni0Xgck2R1a+07rbUnk1yR5LQxrwl2eq21+1trtwyPH8/UH837Zer4unyYdnmS04fHpyX5dJtyQ5KXVNUrkpyY5OrW2iOttUeTXJ2pEzjwr6iqeUnemOSTw3Yl+dUkVw5TNj3+njkur0xy/DD/tCRXtNb+ubX23SSrM3XeBP4VVbVXktcmuTRJWmtPttZ+EOdA2F5mJXlRVc1KskeS++McyC5EPBqP/ZLcu9H22mEMGJHh8t8jk9yY5OWttfuHXd9P8vLhce9YdIzCc/PRJO9L8rNhe26SH7TWnhq2Nz6WNhxnw/7HhvmOP3huFiRZl+R/DW8d/WRVzYlzIGxzrbX7knwoyfcyFY0eS3JznAPZhYhHwC6nql6c5H8n+d3W2g833temPmLSx0zCiFXVKUkebK3dPO61wPPUrCSLk3yitXZkkh/l/79FLYlzIGwrw1s7T8tUxP2FJHPiij12MeLReNyXZP+NtucNY8AMVdXumQpHf9Fa+8Iw/MBwKX6Grw8O471j0TEKW+/YJKdW1ZpMvR37VzN1/5WXDJfwJ88+ljYcZ8P+vZI8HMcfPFdrk6xtrd04bF+ZqZjkHAjb3uuTfLe1tq619tMkX8jUedE5kF2GeDQe30hy4HD3/Rdk6qZoK8a8JtjpDe8VvzTJna21D2+0a0WSZz4t5qwkf7PR+LuGT5xZkuSx4dL+q5KcUFV7D/+TdMIwBnS01s5rrc1rrc3P1Hnt2tbaO5N8NckZw7RNj79njsszhvltGH/78Ek0CzJ1M9+bttOPATut1tr3k9xbVQcNQ8cnuSPOgbA9fC/JkqraY/h79JnjzzmQXcaszU9h1FprT1XVuZk6Ee+W5LLW2u1jXhbsCo5N8h+SfKuqbh3G/luSC5N8vqreneQfk/z7Yd//TfLvMnUzwh8n+Y9J0lp7pKo+mKnQmyQfaK09sl1+Atj1vD/JFVX1R0m+meFmvsPXz1TV6iSPZCo4pbV2e1V9PlN/dD+V5Ldba09v/2XDTuk/J/mL4T8nv5Op89rPxTkQtqnW2o1VdWWSWzJ17vpmkuVJ/jbOgewiaipwAgAAAMC/5G1rAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0iUcAAAAAdIlHAAAAAHSJRwAAAAB0/T+7QoleipNaKgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# figure size of the plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "testing_data['max_u_regressor_sparse']['mlp']['predicted']['bus_1'].plot()\n",
    "testing_data['max_u_regressor_sparse']['mlp']['real']['bus_1'].plot()\n",
    "# plot a line with the threshold\n",
    "# Add legend\n",
    "plt.legend(['predicted', 'real'])\n",
    "testing_data['max_u_regressor_sparse']['mlp']['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_positives_ctr:  5528\n",
      "true_negatives_ctr:  217049\n",
      "false_positives_ctr:  7\n",
      "false_negatives_ctr:  84912\n",
      "32809591956366086400\n"
     ]
    }
   ],
   "source": [
    "metric = metrics.Metrics()\n",
    "metric.get_prediction_scores(testing_data['max_u_regressor_sparse']['mlp']['real'], testing_data['max_u_regressor_sparse']['mlp']['predicted'], max_u_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression focused\n"
     ]
    }
   ],
   "source": [
    "# max_u regression focused\n",
    "if 'max_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_max_u.csv']) \n",
    "    regressor_max_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_focused['y_train'].shape[1]\n",
    "    regressor_max_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_focused', regressor_max_u_focused)\n",
    "else: \n",
    "    print('Loading max_u regression focused')\n",
    "    regressor_max_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\\\max_u_regressor_focused')\n",
    "\n",
    "testing_data['max_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    testing_data['max_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_focused'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u filtered regression\n"
     ]
    }
   ],
   "source": [
    "# max_u regression filtered\n",
    "if 'max_u_filtered_regressor.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression filtered')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_filtered = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_gradient_boost_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_xgboost_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_support_vector_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_mlp_regression_filtered_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_filtered['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_filtered['y_train'].shape[1]\n",
    "    regressor_max_u_filtered.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_filtered_regressor', regressor_max_u_filtered)\n",
    "else: \n",
    "    print('Loading max_u filtered regression')\n",
    "    regressor_max_u_filtered = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_filtered_regressor')\n",
    "\n",
    "testing_data['max_u_filtered_regressor'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_filtered.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_filtered['y_test'].columns)\n",
    "    testing_data['max_u_filtered_regressor'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_filtered_regressor'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_filtered_regressor'][model]['real'] = deepcopy(data_max_u_sparse['y_test'][utils.cols_with_positive_values(prediction)].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9044, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy = regressor_max_u_filtered.strategies[0]\n",
    "prediction = strategy.predict(data=data_max_u_sparse)\n",
    "prediction.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression balanced\n"
     ]
    }
   ],
   "source": [
    "# max u regression balanced\n",
    "if 'max_u_regressor_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression balanced')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_balanced = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_gradient_boost_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_xgboost_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_support_vector_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_mlp_regression_balanced_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_balanced['y_train'].shape[1]\n",
    "    regressor_max_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_balanced', regressor_max_u_balanced)\n",
    "else: \n",
    "    print('Loading max_u regression balanced')\n",
    "    regressor_max_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_balanced')\n",
    "\n",
    "testing_data['max_u_regressor_balanced'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    testing_data['max_u_regressor_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_balanced'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u classification\n"
     ]
    }
   ],
   "source": [
    "# max_u classification\n",
    "if 'max_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_gradient_boost_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_xgboost_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_support_vector_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_mlp_sparse_classifier_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_bool['y_train'].shape[1]\n",
    "    classifier_max_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier', classifier_max_u)\n",
    "else: \n",
    "    print('Loading max_u classification')\n",
    "    classifier_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier')\n",
    "\n",
    "testing_data['max_u_classifier'] = {}\n",
    "for model, strategy in zip(class_models, classifier_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_bool)\n",
    "    testing_data['max_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_classifier'][model]['real'] = deepcopy(data_max_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_data['max_u_classifier']['xgb']['predicted']['bus_15'].plot()\n",
    "testing_data['max_u_classifier']['xgb']['real']['bus_15'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u classification balanced\n"
     ]
    }
   ],
   "source": [
    "# max_u classification balanced\n",
    "if 'max_u_classifier_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification balanced')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_gradient_boost_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_xgboost_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_support_vector_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_mlp_balanced_classifier_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_bool_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_bool_balanced['y_train'].shape[1]\n",
    "    classifier_max_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier_balanced', classifier_max_u_balanced)\n",
    "else: \n",
    "    print('Loading max_u classification balanced')\n",
    "    classifier_max_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier_balanced')\n",
    "\n",
    "testing_data['max_u_classifier_balanced'] = {}\n",
    "for model, strategy in zip(class_models, classifier_max_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_bool)\n",
    "    testing_data['max_u_classifier_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_classifier_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_classifier_balanced'][model]['real'] = deepcopy(data_max_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<thesis_package.aimodels.GradientBoostClassifierStrategy at 0x2439208de80>,\n",
       " <thesis_package.aimodels.XGBoostClassifierStrategy at 0x2438e988b50>,\n",
       " <thesis_package.aimodels.SupportVectorClassifierStrategy at 0x2438e98a280>,\n",
       " <thesis_package.aimodels.MultilayerPerceptronStrategy at 0x2438e991820>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_max_u_balanced.strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min u regression training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression sparse\n"
     ]
    }
   ],
   "source": [
    "# min_u regression sparse\n",
    "if 'min_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_min_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regression_sparse_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_sparse['y_train'].shape[1]\n",
    "    regressor_min_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse', regressor_min_u)\n",
    "else:\n",
    "    print('Loading min_u regression sparse')\n",
    "    regressor_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse')\n",
    "\n",
    "testing_data['min_u_regressor_sparse'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    testing_data['min_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_sparse'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression focused\n"
     ]
    }
   ],
   "source": [
    "# min_u regression focused\n",
    "if 'min_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_focused['y_train'].shape[1]\n",
    "    regressor_min_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused', regressor_min_u_focused)\n",
    "else:\n",
    "    print('Loading min_u regression focused')\n",
    "    regressor_min_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused')\n",
    "\n",
    "testing_data['min_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    testing_data['min_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_focused'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u filtered regression\n"
     ]
    }
   ],
   "source": [
    "# min u regression filtered\n",
    "if 'min_u_filtered_regressor.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression filtered')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_filtered = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_gradient_boost_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_xgboost_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_support_vector_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_mlp_regression_filtered_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_filtered['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_filtered['y_train'].shape[1]\n",
    "    regressor_min_u_filtered.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_filtered_regressor', regressor_min_u_filtered)\n",
    "else: \n",
    "    print('Loading min_u filtered regression')\n",
    "    regressor_min_u_filtered = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_filtered_regressor')\n",
    "\n",
    "testing_data['min_u_filtered_regressor'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_filtered.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_filtered['y_test'].columns)\n",
    "    testing_data['min_u_filtered_regressor'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_filtered_regressor'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_filtered_regressor'][model]['real'] = deepcopy(data_min_u_sparse['y_test'][utils.cols_with_positive_values(prediction)].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression balanced\n"
     ]
    }
   ],
   "source": [
    "# min u regression balanced\n",
    "if 'min_u_regressor_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression balanced')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_balanced = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_gradient_boost_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_xgboost_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_support_vector_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_mlp_regression_balanced_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_balanced['y_train'].shape[1]\n",
    "    regressor_min_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_balanced', regressor_min_u_balanced)\n",
    "else: \n",
    "    print('Loading min_u regression balanced')\n",
    "    regressor_min_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_balanced')\n",
    "\n",
    "testing_data['min_u_regressor_balanced'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    testing_data['min_u_regressor_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_balanced'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u classification\n"
     ]
    }
   ],
   "source": [
    "# min_u classification\n",
    "if 'min_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_gradient_boost_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_xgboost_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_support_vector_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_mlp_sparse_classifier_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_bool['y_train'].shape[1]\n",
    "    classifier_min_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier', classifier_min_u)\n",
    "else: \n",
    "    print('Loading min_u classification')\n",
    "    classifier_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier')\n",
    "\n",
    "testing_data['min_u_classifier'] = {}\n",
    "for model, strategy in zip(class_models, classifier_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_bool)\n",
    "    testing_data['min_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_classifier'][model]['real'] = deepcopy(data_min_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u classification balanced\n"
     ]
    }
   ],
   "source": [
    "# min u classification balanced\n",
    "if 'min_u_classifier_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification balanced')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_gradient_boost_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_xgboost_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_support_vector_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_mlp_balanced_classifier_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_bool_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_bool_balanced['y_train'].shape[1]\n",
    "    classifier_min_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier_balanced', classifier_min_u_balanced)\n",
    "else: \n",
    "    print('Loading min_u classification balanced')\n",
    "    classifier_min_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier_balanced')\n",
    "\n",
    "testing_data['min_u_classifier_balanced'] = {}\n",
    "for model, strategy in zip(class_models, classifier_min_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_bool)\n",
    "    testing_data['min_u_classifier_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_classifier_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_classifier_balanced'][model]['real'] = deepcopy(data_min_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "In this section the results of the training and testing are presented and compared. The main objectives of this experience is to compare the performance of the regression models in terms of the hybrid metrics confusion matrix and the hybrid metrics rmse. The comparisons will be the following:\n",
    "- Compare the confusion matrices of the classification models and the regression models evaluate with the hybrid metrics.\n",
    "- Compare the error results of the regression models trained with the focused dataset and the sparse dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_u_regressor_sparse :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_regressor_focused :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_filtered_regressor :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_regressor_balanced :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_classifier :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_classifier_balanced :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_sparse :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_focused :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_filtered_regressor :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_balanced :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_classifier :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_classifier_balanced :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n"
     ]
    }
   ],
   "source": [
    "for experience in testing_data.keys():\n",
    "    print(experience,': ', testing_data[experience].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 + 0 = 0 = 1590.4300280519656 possible positive values.\n",
      "217047 + 77858 = 294905 = 305905.56997194805 possible negative values.\n"
     ]
    }
   ],
   "source": [
    "# Testing all models: Function that receives a dict with the real and predicted values, and outputs a dataframe with the results of the metrics.\n",
    "# Accumulate all the classifications for each bus.\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for bus in testing_data['max_u_regressor_sparse']['mlp']['predicted'].columns:\n",
    "    # Compute tp, tn, fp, fn\n",
    "    tp += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 1) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 1))\n",
    "    tn += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 0) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 0))\n",
    "    fp += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 1) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 0))\n",
    "    fn += sum((testing_data['max_u_regressor_sparse']['mlp']['predicted'][bus] == 0) & (testing_data['max_u_regressor_sparse']['mlp']['real'][bus] == 1))\n",
    "print('{} + {} = {} = {} possible positive values.'.format(tp, fn, tp+fn, testing_data['max_u_regressor_sparse']['mlp']['real'].sum().sum()))\n",
    "print('{} + {} = {} = {} possible negative values.'.format(tn, fp, tn+fp, testing_data['max_u_regressor_sparse']['mlp']['real'].shape[0]*testing_data['max_u_regressor_sparse']['mlp']['real'].shape[1] - testing_data['max_u_regressor_sparse']['mlp']['real'].sum().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beepy import beep; beep(sound=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: max_u_regressor_sparse, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3151\n",
      "true_negatives_ctr:  297203\n",
      "false_positives_ctr:  5344\n",
      "false_negatives_ctr:  1798\n",
      "3803175167752364985\n",
      "Experiment: max_u_regressor_sparse, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3410\n",
      "true_negatives_ctr:  299857\n",
      "false_positives_ctr:  2690\n",
      "false_negatives_ctr:  1539\n",
      "2752818789825106800\n",
      "Experiment: max_u_regressor_sparse, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4550\n",
      "true_negatives_ctr:  292244\n",
      "false_positives_ctr:  10303\n",
      "false_negatives_ctr:  399\n",
      "6508226007841622337\n",
      "Experiment: max_u_regressor_sparse, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4615\n",
      "true_negatives_ctr:  275913\n",
      "false_positives_ctr:  26634\n",
      "false_negatives_ctr:  334\n",
      "12925400211095992809\n",
      "Experiment: max_u_regressor_sparse, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4948\n",
      "true_negatives_ctr:  217055\n",
      "false_positives_ctr:  85492\n",
      "false_negatives_ctr:  1\n",
      "29392914664141297920\n",
      "Experiment: max_u_regressor_focused, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4321\n",
      "true_negatives_ctr:  297379\n",
      "false_positives_ctr:  5168\n",
      "false_negatives_ctr:  628\n",
      "4234062035962222569\n",
      "Experiment: max_u_regressor_focused, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4523\n",
      "true_negatives_ctr:  249361\n",
      "false_positives_ctr:  53186\n",
      "false_negatives_ctr:  426\n",
      "21583590147476487249\n",
      "Experiment: max_u_regressor_focused, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4660\n",
      "true_negatives_ctr:  179741\n",
      "false_positives_ctr:  122806\n",
      "false_negatives_ctr:  289\n",
      "34359714271387409940\n",
      "Experiment: max_u_regressor_focused, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4940\n",
      "true_negatives_ctr:  249296\n",
      "false_positives_ctr:  53251\n",
      "false_negatives_ctr:  9\n",
      "21721865183700422265\n",
      "Experiment: max_u_regressor_focused, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3714\n",
      "true_negatives_ctr:  204398\n",
      "false_positives_ctr:  98149\n",
      "false_negatives_ctr:  1235\n",
      "31363143043396705737\n",
      "Experiment: max_u_filtered_regressor, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3151\n",
      "true_negatives_ctr:  89191\n",
      "false_positives_ctr:  5344\n",
      "false_negatives_ctr:  1798\n",
      "361628256521776825\n",
      "Experiment: max_u_filtered_regressor, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  3356\n",
      "true_negatives_ctr:  91872\n",
      "false_positives_ctr:  2663\n",
      "false_negatives_ctr:  1593\n",
      "263198515836827025\n",
      "Experiment: max_u_filtered_regressor, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4949\n",
      "true_negatives_ctr:  128\n",
      "false_positives_ctr:  94407\n",
      "false_negatives_ctr:  0\n",
      "5949961434565120\n",
      "Experiment: max_u_filtered_regressor, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4443\n",
      "true_negatives_ctr:  46628\n",
      "false_positives_ctr:  47907\n",
      "false_negatives_ctr:  506\n",
      "1154412620097103500\n",
      "Experiment: max_u_filtered_regressor, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4949\n",
      "true_negatives_ctr:  513\n",
      "false_positives_ctr:  94022\n",
      "false_negatives_ctr:  0\n",
      "23753926363986945\n",
      "Experiment: max_u_regressor_balanced, model: lr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4521\n",
      "true_negatives_ctr:  280815\n",
      "false_positives_ctr:  21732\n",
      "false_negatives_ctr:  428\n",
      "11055311020666760337\n",
      "Experiment: max_u_regressor_balanced, model: gb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4090\n",
      "true_negatives_ctr:  297475\n",
      "false_positives_ctr:  5072\n",
      "false_negatives_ctr:  859\n",
      "4092638102722559124\n",
      "Experiment: max_u_regressor_balanced, model: xgb, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4448\n",
      "true_negatives_ctr:  293409\n",
      "false_positives_ctr:  9138\n",
      "false_negatives_ctr:  501\n",
      "5978831001189609780\n",
      "Experiment: max_u_regressor_balanced, model: svr, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4222\n",
      "true_negatives_ctr:  287934\n",
      "false_positives_ctr:  14613\n",
      "false_negatives_ctr:  727\n",
      "8140742936328958305\n",
      "Experiment: max_u_regressor_balanced, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  4948\n",
      "true_negatives_ctr:  213161\n",
      "false_positives_ctr:  89386\n",
      "false_negatives_ctr:  1\n",
      "30108446030196623124\n",
      "Experiment: min_u_regressor_sparse, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  2553\n",
      "true_negatives_ctr:  297508\n",
      "false_positives_ctr:  3966\n",
      "false_negatives_ctr:  3469\n",
      "3562090133984546964\n",
      "Experiment: min_u_regressor_sparse, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5039\n",
      "true_negatives_ctr:  294582\n",
      "false_positives_ctr:  6892\n",
      "false_negatives_ctr:  983\n",
      "6402070686261354420\n",
      "Experiment: min_u_regressor_sparse, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4781\n",
      "true_negatives_ctr:  294780\n",
      "false_positives_ctr:  6694\n",
      "false_negatives_ctr:  1241\n",
      "6166884719777037300\n",
      "Experiment: min_u_regressor_sparse, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5502\n",
      "true_negatives_ctr:  281219\n",
      "false_positives_ctr:  20255\n",
      "false_negatives_ctr:  520\n",
      "13174461152311957044\n",
      "Experiment: min_u_regressor_sparse, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  6013\n",
      "true_negatives_ctr:  232129\n",
      "false_positives_ctr:  69345\n",
      "false_negatives_ctr:  9\n",
      "31758955930231216912\n",
      "Experiment: min_u_regressor_focused, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5877\n",
      "true_negatives_ctr:  244952\n",
      "false_positives_ctr:  56522\n",
      "false_negatives_ctr:  145\n",
      "27765547379161324884\n",
      "Experiment: min_u_regressor_focused, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5592\n",
      "true_negatives_ctr:  259564\n",
      "false_positives_ctr:  41910\n",
      "false_negatives_ctr:  430\n",
      "22421560500974862864\n",
      "Experiment: min_u_regressor_focused, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5628\n",
      "true_negatives_ctr:  252109\n",
      "false_positives_ctr:  49365\n",
      "false_negatives_ctr:  394\n",
      "25209519554749125012\n",
      "Experiment: min_u_regressor_focused, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5975\n",
      "true_negatives_ctr:  253411\n",
      "false_positives_ctr:  48063\n",
      "false_negatives_ctr:  47\n",
      "24865424909283840912\n",
      "Experiment: min_u_regressor_focused, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4078\n",
      "true_negatives_ctr:  222792\n",
      "false_positives_ctr:  78682\n",
      "false_negatives_ctr:  1944\n",
      "33766320874884142080\n",
      "Experiment: min_u_filtered_regressor, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  2553\n",
      "true_negatives_ctr:  80452\n",
      "false_positives_ctr:  3966\n",
      "false_negatives_ctr:  3469\n",
      "278116939284510804\n",
      "Experiment: min_u_filtered_regressor, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4993\n",
      "true_negatives_ctr:  77816\n",
      "false_positives_ctr:  6602\n",
      "false_negatives_ctr:  1029\n",
      "464751414722598900\n",
      "Experiment: min_u_filtered_regressor, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4936\n",
      "true_negatives_ctr:  78434\n",
      "false_positives_ctr:  5984\n",
      "false_negatives_ctr:  1086\n",
      "441443188214246400\n",
      "Experiment: min_u_filtered_regressor, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5369\n",
      "true_negatives_ctr:  66433\n",
      "false_positives_ctr:  17985\n",
      "false_negatives_ctr:  653\n",
      "796469195782443024\n",
      "Experiment: min_u_filtered_regressor, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4712\n",
      "true_negatives_ctr:  31210\n",
      "false_positives_ctr:  35240\n",
      "false_negatives_ctr:  1190\n",
      "507665587777920000\n",
      "Experiment: min_u_regressor_balanced, model: lr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5117\n",
      "true_negatives_ctr:  282366\n",
      "false_positives_ctr:  19108\n",
      "false_negatives_ctr:  905\n",
      "12458234917891809300\n",
      "Experiment: min_u_regressor_balanced, model: gb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  4997\n",
      "true_negatives_ctr:  292064\n",
      "false_positives_ctr:  9410\n",
      "false_negatives_ctr:  1025\n",
      "7665909532803367444\n",
      "Experiment: min_u_regressor_balanced, model: xgb, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5316\n",
      "true_negatives_ctr:  289858\n",
      "false_positives_ctr:  11616\n",
      "false_negatives_ctr:  706\n",
      "8931834755719537344\n",
      "Experiment: min_u_regressor_balanced, model: svr, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  5366\n",
      "true_negatives_ctr:  283756\n",
      "false_positives_ctr:  17718\n",
      "false_negatives_ctr:  656\n",
      "11919268318002316224\n",
      "Experiment: min_u_regressor_balanced, model: mlp, threshold: 0.0644069763149719\n",
      "true_positives_ctr:  6015\n",
      "true_negatives_ctr:  226077\n",
      "false_positives_ctr:  75397\n",
      "false_negatives_ctr:  7\n",
      "33415569463756268224\n"
     ]
    }
   ],
   "source": [
    "from numpy import sqrt \n",
    "# Build a multi-index dataframe with the results of the metrics. The first index is the testing_data.keys(), the second index are the tp, tn, fp, fn, and the columns are the models.\n",
    "columns = ['tp', 'tn', 'fp', 'fn', '(hybrid)accuracy', '(hybrid)precision', '(hybrid)recall', '(hybrid)f1']\n",
    "index = pd.MultiIndex.from_product([testing_data.keys(), ['lr', 'gb', 'xgb', 'svr', 'mlp']], names=['experiment', 'class'])\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "classifier_experiments =[experiment for experiment in testing_data.keys() if 'classifier' in experiment.split('_')] # TODO confirm this\n",
    "regressor_experiments = [experiment for experiment in testing_data.keys() if 'regressor' in experiment.split('_')]\n",
    "# Classifier experiments\n",
    "class_metrics = metrics.Metrics()\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for experiment in classifier_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        for bus in testing_data[experiment][model]['predicted'].columns:\n",
    "            try:\n",
    "                tp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "                tn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "            except: \n",
    "                print('In the experiment ', experiment, ' and model ', model, ' there was a problem with bus: ', bus)\n",
    "                if not testing_data[experiment][model]['real'][bus].any():\n",
    "                    print('Bus {} has no positive data points. Just ignore the little shit.'.format(bus))    \n",
    "        df.loc[(experiment, model), 'tp'] = tp\n",
    "        df.loc[(experiment, model), 'tn'] = tn\n",
    "        df.loc[(experiment, model), 'fp'] = fp\n",
    "        df.loc[(experiment, model), 'fn'] = fn\n",
    "        #print('Experiment: {}, model: {}, tp: {}, tn: {}, fp: {}, fn: {}'.format(experiment, model, tp, tn, fp, fn))\n",
    "        recall = class_metrics.compute_recall(tp, fn)\n",
    "        precision = class_metrics.compute_precision(tp, fp)\n",
    "        f1 = class_metrics.compute_f1(recall, precision)\n",
    "        accuracy = class_metrics.compute_accuracy(tp, tn, fp, fn)\n",
    "        mcc = class_metrics.compute_mcc(tp, tn, fp, fn)\n",
    "        df.loc[(experiment, model), '(hybrid)accuracy'] = accuracy\n",
    "        df.loc[(experiment, model), '(hybrid)precision'] = precision\n",
    "        df.loc[(experiment, model), '(hybrid)recall'] = recall\n",
    "        df.loc[(experiment, model), '(hybrid)f1'] = f1\n",
    "        df.loc[(experiment, model), '(hybrid)mcc'] = mcc\n",
    "        # print('Experiment: {}, model: {}, accuracy: {}, precision: {}, recall: {}, f1: {}'.format(experiment, model, accuracy, precision, recall, f1))\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0 \n",
    "# Regressor experiments\n",
    "_threshold = lambda experiment: max_u_threshold / data_max_u_sparse['scaler']['y'] if 'max_u' in experiment else min_u_threshold/ data_min_u_sparse['scaler']['y']\n",
    "# _threshold = lambda experiment: max_u_threshold if 'max_u' in experiment else min_u_threshold\n",
    "for experiment in regressor_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        # try:\n",
    "        threshold = _threshold(experiment)\n",
    "        print('Experiment: {}, model: {}, threshold: {}'.format(experiment, model, threshold))\n",
    "        hybrid_metrics = metrics.Metrics()\n",
    "        hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted'], testing_data[experiment][model]['real'], threshold=threshold)\n",
    "        df.loc[(experiment, model), 'tp'] = hybrid_metrics.true_positives_ctr\n",
    "        df.loc[(experiment, model), 'tn'] = hybrid_metrics.true_negatives_ctr\n",
    "        df.loc[(experiment, model), 'fp'] = hybrid_metrics.false_positives_ctr\n",
    "        df.loc[(experiment, model), 'fn'] = hybrid_metrics.false_negatives_ctr\n",
    "        df.loc[(experiment, model), '(hybrid)accuracy'] = hybrid_metrics.hybrid_accuracy\n",
    "        df.loc[(experiment, model), '(hybrid)precision'] = hybrid_metrics.hybrid_precision\n",
    "        df.loc[(experiment, model), '(hybrid)recall'] = hybrid_metrics.hybrid_recall\n",
    "        df.loc[(experiment, model), '(hybrid)f1'] = hybrid_metrics.hybrid_f1\n",
    "        df.loc[(experiment, model), '(hybrid)mcc'] = hybrid_metrics.hybrid_mcc\n",
    "        # print('Experiment: {}, model: {}, tp: {}, tn: {}, fp: {}, fn: {}'.format(experiment, model, hybrid_metrics.true_positives_ctr, hybrid_metrics.true_negatives_ctr, hybrid_metrics.false_positives_ctr, hybrid_metrics.false_negatives_ctr))\n",
    "        # print('Experiment: {}, model: {}, accuracy: {}, precision: {}, recall: {}, f1: {}'.format(experiment, model, hybrid_metrics.hybrid_accuracy_rmse, hybrid_metrics.hybrid_precision_rmse, hybrid_metrics.hybrid_recall_rmse, hybrid_metrics.hybrid_f1_rmse))\n",
    "        # except(Exception) as e:\n",
    "        #     print('In the experiment ', experiment, ' and model ', model, ' there was a problem')\n",
    "        #     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_db1_mcc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562243</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.016844</td>\n",
       "      <td>0.068940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4321</td>\n",
       "      <td>297379</td>\n",
       "      <td>5168</td>\n",
       "      <td>628</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.540358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4523</td>\n",
       "      <td>249361</td>\n",
       "      <td>53186</td>\n",
       "      <td>426</td>\n",
       "      <td>0.79822</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.878914</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.187375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4660</td>\n",
       "      <td>179741</td>\n",
       "      <td>122806</td>\n",
       "      <td>289</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.919546</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.105429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4940</td>\n",
       "      <td>249296</td>\n",
       "      <td>53251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.225088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3714</td>\n",
       "      <td>204398</td>\n",
       "      <td>98149</td>\n",
       "      <td>1235</td>\n",
       "      <td>0.635756</td>\n",
       "      <td>0.023866</td>\n",
       "      <td>0.631137</td>\n",
       "      <td>0.045992</td>\n",
       "      <td>0.064838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>513</td>\n",
       "      <td>94022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015264</td>\n",
       "      <td>0.004556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4521</td>\n",
       "      <td>280815</td>\n",
       "      <td>21732</td>\n",
       "      <td>428</td>\n",
       "      <td>0.917912</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.314492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4090</td>\n",
       "      <td>297475</td>\n",
       "      <td>5072</td>\n",
       "      <td>859</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.35234</td>\n",
       "      <td>0.759724</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>0.508297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4448</td>\n",
       "      <td>293409</td>\n",
       "      <td>9138</td>\n",
       "      <td>501</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.25097</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.452522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4222</td>\n",
       "      <td>287934</td>\n",
       "      <td>14613</td>\n",
       "      <td>727</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.798145</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.357587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>213161</td>\n",
       "      <td>89386</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545816</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.016041</td>\n",
       "      <td>0.066263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3900</td>\n",
       "      <td>58970</td>\n",
       "      <td>35565</td>\n",
       "      <td>1049</td>\n",
       "      <td>0.631961</td>\n",
       "      <td>0.098822</td>\n",
       "      <td>0.788038</td>\n",
       "      <td>0.17562</td>\n",
       "      <td>0.183029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3499</td>\n",
       "      <td>91026</td>\n",
       "      <td>3509</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0.585264</td>\n",
       "      <td>0.569179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3158</td>\n",
       "      <td>92054</td>\n",
       "      <td>2481</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.957058</td>\n",
       "      <td>0.560028</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>0.575312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3956</td>\n",
       "      <td>89928</td>\n",
       "      <td>4607</td>\n",
       "      <td>993</td>\n",
       "      <td>0.94371</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>0.581876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4047</td>\n",
       "      <td>58332</td>\n",
       "      <td>36203</td>\n",
       "      <td>902</td>\n",
       "      <td>0.627025</td>\n",
       "      <td>0.100547</td>\n",
       "      <td>0.817741</td>\n",
       "      <td>0.179075</td>\n",
       "      <td>0.192601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6013</td>\n",
       "      <td>232129</td>\n",
       "      <td>69345</td>\n",
       "      <td>9</td>\n",
       "      <td>0.629996</td>\n",
       "      <td>0.00939</td>\n",
       "      <td>0.992413</td>\n",
       "      <td>0.018603</td>\n",
       "      <td>0.076194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5877</td>\n",
       "      <td>244952</td>\n",
       "      <td>56522</td>\n",
       "      <td>145</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.223576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5592</td>\n",
       "      <td>259564</td>\n",
       "      <td>41910</td>\n",
       "      <td>430</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.908282</td>\n",
       "      <td>0.160995</td>\n",
       "      <td>0.254038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5628</td>\n",
       "      <td>252109</td>\n",
       "      <td>49365</td>\n",
       "      <td>394</td>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.228193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5975</td>\n",
       "      <td>253411</td>\n",
       "      <td>48063</td>\n",
       "      <td>47</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.262651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4078</td>\n",
       "      <td>222792</td>\n",
       "      <td>78682</td>\n",
       "      <td>1944</td>\n",
       "      <td>0.702677</td>\n",
       "      <td>0.035257</td>\n",
       "      <td>0.580554</td>\n",
       "      <td>0.066476</td>\n",
       "      <td>0.083337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4712</td>\n",
       "      <td>31210</td>\n",
       "      <td>35240</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.181608</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.395188</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>-0.192029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5117</td>\n",
       "      <td>282366</td>\n",
       "      <td>19108</td>\n",
       "      <td>905</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.165926</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.345050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4997</td>\n",
       "      <td>292064</td>\n",
       "      <td>9410</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.284526</td>\n",
       "      <td>0.77814</td>\n",
       "      <td>0.41669</td>\n",
       "      <td>0.456403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5316</td>\n",
       "      <td>289858</td>\n",
       "      <td>11616</td>\n",
       "      <td>706</td>\n",
       "      <td>0.954371</td>\n",
       "      <td>0.255966</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.393042</td>\n",
       "      <td>0.450693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5366</td>\n",
       "      <td>283756</td>\n",
       "      <td>17718</td>\n",
       "      <td>656</td>\n",
       "      <td>0.933244</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.391941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6015</td>\n",
       "      <td>226077</td>\n",
       "      <td>75397</td>\n",
       "      <td>7</td>\n",
       "      <td>0.601228</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.993897</td>\n",
       "      <td>0.016537</td>\n",
       "      <td>0.070218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5318</td>\n",
       "      <td>50201</td>\n",
       "      <td>34217</td>\n",
       "      <td>704</td>\n",
       "      <td>0.613877</td>\n",
       "      <td>0.134514</td>\n",
       "      <td>0.883095</td>\n",
       "      <td>0.233466</td>\n",
       "      <td>0.240123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4379</td>\n",
       "      <td>77799</td>\n",
       "      <td>6619</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.398163</td>\n",
       "      <td>0.727167</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.494868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4395</td>\n",
       "      <td>77766</td>\n",
       "      <td>6652</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.908459</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>0.729824</td>\n",
       "      <td>0.514969</td>\n",
       "      <td>0.495647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4931</td>\n",
       "      <td>79390</td>\n",
       "      <td>5028</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.49513</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.604686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5309</td>\n",
       "      <td>46569</td>\n",
       "      <td>37849</td>\n",
       "      <td>713</td>\n",
       "      <td>0.573618</td>\n",
       "      <td>0.123013</td>\n",
       "      <td>0.881601</td>\n",
       "      <td>0.215901</td>\n",
       "      <td>0.216245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                                \n",
       "max_u_regressor_sparse    lr     3151  297203    5344  1798         0.973939   \n",
       "                          gb     3410  299857    2690  1539          0.98396   \n",
       "                          xgb    4550  292244   10303   399         0.960463   \n",
       "                          svr    4615  275913   26634   334         0.904389   \n",
       "                          mlp    4948  217055   85492     1         0.562243   \n",
       "max_u_regressor_focused   lr     4321  297379    5168   628         0.977467   \n",
       "                          gb     4523  249361   53186   426          0.79822   \n",
       "                          xgb    4660  179741  122806   289         0.554576   \n",
       "                          svr    4940  249296   53251     9         0.808736   \n",
       "                          mlp    3714  204398   98149  1235         0.635756   \n",
       "max_u_filtered_regressor  lr     3151   89191    5344  1798         0.918805   \n",
       "                          gb     3356   91872    2663  1593         0.949925   \n",
       "                          xgb    4949     128   94407     0         0.037666   \n",
       "                          svr    4443   46628   47907   506         0.481777   \n",
       "                          mlp    4949     513   94022     0         0.010349   \n",
       "max_u_regressor_balanced  lr     4521  280815   21732   428         0.917912   \n",
       "                          gb     4090  297475    5072   859         0.977647   \n",
       "                          xgb    4448  293409    9138   501         0.963717   \n",
       "                          svr    4222  287934   14613   727         0.944365   \n",
       "                          mlp    4948  213161   89386     1         0.545816   \n",
       "max_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     2487   92303    2232  2462         0.952817   \n",
       "                          xgb    1817   93214    1321  3132         0.955239   \n",
       "                          svr       0   94535       0  4949         0.950253   \n",
       "                          mlp    3900   58970   35565  1049         0.631961   \n",
       "max_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     3499   91026    3509  1450         0.950153   \n",
       "                          xgb    3158   92054    2481  1791         0.957058   \n",
       "                          svr    3956   89928    4607   993          0.94371   \n",
       "                          mlp    4047   58332   36203   902         0.627025   \n",
       "min_u_regressor_sparse    lr     2553  297508    3966  3469         0.972468   \n",
       "                          gb     5039  294582    6892   983         0.970974   \n",
       "                          xgb    4781  294780    6694  1241         0.970684   \n",
       "                          svr    5502  281219   20255   520         0.925053   \n",
       "                          mlp    6013  232129   69345     9         0.629996   \n",
       "min_u_regressor_focused   lr     5877  244952   56522   145         0.780846   \n",
       "                          gb     5592  259564   41910   430         0.839482   \n",
       "                          xgb    5628  252109   49365   394         0.808055   \n",
       "                          svr    5975  253411   48063    47         0.822388   \n",
       "                          mlp    4078  222792   78682  1944         0.702677   \n",
       "min_u_filtered_regressor  lr     2553   80452    3966  3469         0.905889   \n",
       "                          gb     4993   77816    6602  1029         0.903749   \n",
       "                          xgb    4936   78434    5984  1086         0.911141   \n",
       "                          svr    5369   66433   17985   653         0.770305   \n",
       "                          mlp    4712   31210   35240  1190         0.181608   \n",
       "min_u_regressor_balanced  lr     5117  282366   19108   905         0.926901   \n",
       "                          gb     4997  292064    9410  1025         0.961439   \n",
       "                          xgb    5316  289858   11616   706         0.954371   \n",
       "                          svr    5366  283756   17718   656         0.933244   \n",
       "                          mlp    6015  226077   75397     7         0.601228   \n",
       "min_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4068   81151    3267  1954         0.942271   \n",
       "                          xgb    4167   80534    3884  1855         0.936544   \n",
       "                          svr    2965   82965    1453  3057         0.950133   \n",
       "                          mlp    5318   50201   34217   704         0.613877   \n",
       "min_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4379   77799    6619  1643         0.908647   \n",
       "                          xgb    4395   77766    6652  1627         0.908459   \n",
       "                          svr    4931   79390    5028  1091         0.932342   \n",
       "                          mlp    5309   46569   37849   713         0.573618   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_regressor_sparse    lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.441493       0.567722   0.496713   \n",
       "                          xgb            0.230752       0.882031   0.365804   \n",
       "                          svr            0.107401       0.898987   0.191878   \n",
       "                          mlp            0.008494       0.999275   0.016844   \n",
       "max_u_regressor_focused   lr             0.366413       0.822844   0.507041   \n",
       "                          gb             0.053925       0.878914   0.101616   \n",
       "                          xgb            0.025552       0.919546   0.049723   \n",
       "                          svr            0.063073       0.997519   0.118643   \n",
       "                          mlp            0.023866       0.631137   0.045992   \n",
       "max_u_filtered_regressor  lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.439197       0.552025    0.48919   \n",
       "                          xgb            0.036546            1.0   0.070515   \n",
       "                          svr            0.060259       0.842986   0.112478   \n",
       "                          mlp            0.007691            1.0   0.015264   \n",
       "max_u_regressor_balanced  lr                0.126       0.877757   0.220366   \n",
       "                          gb              0.35234       0.759724   0.481414   \n",
       "                          xgb             0.25097       0.857354   0.388281   \n",
       "                          svr            0.174752       0.798145   0.286726   \n",
       "                          mlp            0.008085       0.999274   0.016041   \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.527018       0.502526   0.514481   \n",
       "                          xgb            0.579031       0.367145   0.449363   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.098822       0.788038    0.17562   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.499287       0.707012   0.585264   \n",
       "                          xgb            0.560028       0.638109   0.596524   \n",
       "                          svr            0.461988       0.799353   0.585554   \n",
       "                          mlp            0.100547       0.817741   0.179075   \n",
       "min_u_regressor_sparse    lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.353983       0.787945   0.488506   \n",
       "                          xgb            0.345599       0.731315   0.469381   \n",
       "                          svr            0.174263       0.890969    0.29151   \n",
       "                          mlp             0.00939       0.992413   0.018603   \n",
       "min_u_regressor_focused   lr             0.067654       0.968548   0.126474   \n",
       "                          gb             0.088325       0.908282   0.160995   \n",
       "                          xgb            0.073954        0.91519   0.136849   \n",
       "                          svr            0.085393       0.990249   0.157228   \n",
       "                          mlp            0.035257       0.580554   0.066476   \n",
       "min_u_filtered_regressor  lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.360775       0.778289   0.493014   \n",
       "                          xgb            0.382714        0.76811    0.51088   \n",
       "                          svr            0.186868       0.861772   0.307136   \n",
       "                          mlp            0.015304       0.395188   0.029467   \n",
       "min_u_regressor_balanced  lr             0.165926       0.804743   0.275126   \n",
       "                          gb             0.284526        0.77814    0.41669   \n",
       "                          xgb            0.255966       0.846198   0.393042   \n",
       "                          svr            0.194107         0.8676   0.317238   \n",
       "                          mlp            0.008338       0.993897   0.016537   \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.554601       0.675523   0.609119   \n",
       "                          xgb            0.517575       0.691963   0.592198   \n",
       "                          svr            0.671118       0.492361   0.568008   \n",
       "                          mlp            0.134514       0.883095   0.233466   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.398163       0.727167   0.514571   \n",
       "                          xgb            0.397846       0.729824   0.514969   \n",
       "                          svr             0.49513       0.818831   0.617108   \n",
       "                          mlp            0.123013       0.881601   0.215901   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "max_u_regressor_sparse    lr        0.346102  \n",
       "                          gb        0.492687  \n",
       "                          xgb       0.439649  \n",
       "                          svr       0.291796  \n",
       "                          mlp       0.068940  \n",
       "max_u_regressor_focused   lr        0.540358  \n",
       "                          gb        0.187375  \n",
       "                          xgb       0.105429  \n",
       "                          svr       0.225088  \n",
       "                          mlp       0.064838  \n",
       "max_u_filtered_regressor  lr        0.318793  \n",
       "                          gb        0.466570  \n",
       "                          xgb       0.006640  \n",
       "                          svr       0.120496  \n",
       "                          mlp       0.004556  \n",
       "max_u_regressor_balanced  lr        0.314492  \n",
       "                          gb        0.508297  \n",
       "                          xgb       0.452522  \n",
       "                          svr       0.357587  \n",
       "                          mlp       0.066263  \n",
       "max_u_classifier          lr             NaN  \n",
       "                          gb        0.489852  \n",
       "                          xgb       0.439336  \n",
       "                          svr      -1.000000  \n",
       "                          mlp       0.183029  \n",
       "max_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.569179  \n",
       "                          xgb       0.575312  \n",
       "                          svr       0.581876  \n",
       "                          mlp       0.192601  \n",
       "min_u_regressor_sparse    lr        0.297390  \n",
       "                          gb        0.516571  \n",
       "                          xgb       0.490517  \n",
       "                          svr       0.374989  \n",
       "                          mlp       0.076194  \n",
       "min_u_regressor_focused   lr        0.223576  \n",
       "                          gb        0.254038  \n",
       "                          xgb       0.228193  \n",
       "                          svr       0.262651  \n",
       "                          mlp       0.083337  \n",
       "min_u_filtered_regressor  lr        0.260936  \n",
       "                          gb        0.488250  \n",
       "                          xgb       0.502496  \n",
       "                          svr       0.331681  \n",
       "                          mlp      -0.192029  \n",
       "min_u_regressor_balanced  lr        0.345050  \n",
       "                          gb        0.456403  \n",
       "                          xgb       0.450693  \n",
       "                          svr       0.391941  \n",
       "                          mlp       0.070218  \n",
       "min_u_classifier          lr             NaN  \n",
       "                          gb        0.581558  \n",
       "                          xgb       0.565496  \n",
       "                          svr       0.549541  \n",
       "                          mlp       0.240123  \n",
       "min_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.494868  \n",
       "                          xgb       0.495647  \n",
       "                          svr       0.604686  \n",
       "                          mlp       0.216245  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>possible_positives</th>\n",
       "      <th>possible_negatives</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>302547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>94535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5902</td>\n",
       "      <td>66450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>301474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6022</td>\n",
       "      <td>84418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                possible_positives possible_negatives\n",
       "experiment                class                                      \n",
       "max_u_regressor_sparse    lr                  4949             302547\n",
       "                          gb                  4949             302547\n",
       "                          xgb                 4949             302547\n",
       "                          svr                 4949             302547\n",
       "                          mlp                 4949             302547\n",
       "max_u_regressor_focused   lr                  4949             302547\n",
       "                          gb                  4949             302547\n",
       "                          xgb                 4949             302547\n",
       "                          svr                 4949             302547\n",
       "                          mlp                 4949             302547\n",
       "max_u_filtered_regressor  lr                  4949              94535\n",
       "                          gb                  4949              94535\n",
       "                          xgb                 4949              94535\n",
       "                          svr                 4949              94535\n",
       "                          mlp                 4949              94535\n",
       "max_u_regressor_balanced  lr                  4949             302547\n",
       "                          gb                  4949             302547\n",
       "                          xgb                 4949             302547\n",
       "                          svr                 4949             302547\n",
       "                          mlp                 4949             302547\n",
       "max_u_classifier          lr                   NaN                NaN\n",
       "                          gb                  4949              94535\n",
       "                          xgb                 4949              94535\n",
       "                          svr                 4949              94535\n",
       "                          mlp                 4949              94535\n",
       "max_u_classifier_balanced lr                   NaN                NaN\n",
       "                          gb                  4949              94535\n",
       "                          xgb                 4949              94535\n",
       "                          svr                 4949              94535\n",
       "                          mlp                 4949              94535\n",
       "min_u_regressor_sparse    lr                  6022             301474\n",
       "                          gb                  6022             301474\n",
       "                          xgb                 6022             301474\n",
       "                          svr                 6022             301474\n",
       "                          mlp                 6022             301474\n",
       "min_u_regressor_focused   lr                  6022             301474\n",
       "                          gb                  6022             301474\n",
       "                          xgb                 6022             301474\n",
       "                          svr                 6022             301474\n",
       "                          mlp                 6022             301474\n",
       "min_u_filtered_regressor  lr                  6022              84418\n",
       "                          gb                  6022              84418\n",
       "                          xgb                 6022              84418\n",
       "                          svr                 6022              84418\n",
       "                          mlp                 5902              66450\n",
       "min_u_regressor_balanced  lr                  6022             301474\n",
       "                          gb                  6022             301474\n",
       "                          xgb                 6022             301474\n",
       "                          svr                 6022             301474\n",
       "                          mlp                 6022             301474\n",
       "min_u_classifier          lr                   NaN                NaN\n",
       "                          gb                  6022              84418\n",
       "                          xgb                 6022              84418\n",
       "                          svr                 6022              84418\n",
       "                          mlp                 6022              84418\n",
       "min_u_classifier_balanced lr                   NaN                NaN\n",
       "                          gb                  6022              84418\n",
       "                          xgb                 6022              84418\n",
       "                          svr                 6022              84418\n",
       "                          mlp                 6022              84418"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirmation_df = pd.DataFrame()\n",
    "confirmation_df['possible_positives'] = df['tp'] + df['fn']\n",
    "confirmation_df['possible_negatives'] = df['fp'] + df['tn']\n",
    "confirmation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscale everything\n",
    "testing_data['max_u_regressor_sparse'][model]['predicted'] = testing_data['max_u_regressor_sparse'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_sparse'][model]['real'] = testing_data['max_u_regressor_sparse'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_focused'][model]['predicted'] = testing_data['max_u_regressor_focused'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_focused'][model]['real'] = testing_data['max_u_regressor_focused'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_filtered_regressor'][model]['predicted'] = testing_data['max_u_filtered_regressor'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_filtered_regressor'][model]['real'] = testing_data['max_u_filtered_regressor'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_balanced'][model]['predicted'] = testing_data['max_u_regressor_balanced'][model]['predicted'] * data_max_u_balanced['scaler']['y']\n",
    "testing_data['max_u_regressor_balanced'][model]['real'] = testing_data['max_u_regressor_balanced'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_sparse'][model]['predicted'] = testing_data['min_u_regressor_sparse'][model]['predicted'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_sparse'][model]['real'] = testing_data['min_u_regressor_sparse'][model]['real'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_focused'][model]['predicted'] = testing_data['min_u_regressor_focused'][model]['predicted'] * data_min_u_focused['scaler']['y']\n",
    "testing_data['min_u_regressor_focused'][model]['real'] = testing_data['min_u_regressor_focused'][model]['real'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_filtered_regressor'][model]['predicted'] = testing_data['min_u_filtered_regressor'][model]['predicted'] * data_min_u_sparse['scaler']['y'] \n",
    "testing_data['min_u_filtered_regressor'][model]['real'] = testing_data['min_u_filtered_regressor'][model]['real'][utils.cols_with_positive_values(prediction)] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_balanced'][model]['predicted'] = testing_data['min_u_regressor_balanced'][model]['predicted'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_balanced'][model]['real'] = testing_data['min_u_regressor_balanced'][model]['real'] * data_min_u_sparse['scaler']['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to evaluate all the results obtained above. This benchmarking has the objective of obtaining the answer following questions:\n",
    "- What is the optimum number of rows for the training data set? What is the respective model?\n",
    "    - sparse reg. vs balanced reg. vs focused reg.\n",
    "- What is the optimum number present busses in regresison?\n",
    "    - sparse reg. vs filtered reg.\n",
    "- Regression vs Classification\n",
    "    - filtered reg. vs sparse class.\n",
    "- What is the optimum number of rows in class?\n",
    "    - sparse class. vs balanced class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum proportion of P/N rows for the training data set? What is the respective model?\n",
    "In order to understand the optinum number of rows for the training set of the regression data set the data sets used will be:\n",
    "\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Maximum Voltage Constraints|Balanced Regression|6971|34|\n",
    "|Maximum Voltage Constraints|Focused Regression|3486|34|\n",
    "|Minimum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Minimum Voltage Constraints|Balanced Regression|13917|34|\n",
    "|Minimum Voltage Constraints|Focused Regression|6958|34|\n",
    "\n",
    "The **Sparse Regression data set** is generated directly from the power flow results. The important moments are those where the constraints are violated, so the output feature contains null values for when there is no constraint, and positive value for when there is a constraint. The positive values represent the amplitude of the constraint violation. It can be expressed as follows:\n",
    "$$\n",
    "    \\begin{align}\n",
    "        \\text{Target} &= \\begin{cases}\n",
    "            0 & \\text{if} \\; \\text{constraint} \\; \\text{is not violated} \\\\\n",
    "            \\text{amplitude of constraint} & \\text{if} \\; \\text{constraint} \\; \\text{is violated} \\\\\n",
    "        \\end{cases}\n",
    "    \\end{align}\n",
    "$$\n",
    "In our case, the constraints are being considered as the following:\n",
    "- Minimal voltage on bus: $v_bus < 0.95 \\text{ [pu]}$ (constraint is violated if the voltage is below $0.95 \\text{ [pu]} $)\n",
    "- Maximal voltage on bus: $v_bus > 1.05 \\text{ [pu]}$ (constraint is violated if the voltage is above $1.05 \\text{ [pu]} $)\n",
    "- Maximal current on line: $i_{line} > 1 \\text{ [kA]}$ (constraint is violated if the current is above $1 \\text{ [kA]} $)\n",
    "\n",
    "The **Balanced Regression** data set is created from the **Sparse Regression data set**. It is created by taking all the rows that containt at least one constraint violation and then taking the same number of rows that do not contain any constraint violation. Finally, the **Focused Regression data set** is created by taking all the rows that contain at least one constraint violation.\n",
    "\n",
    "Since these data sets have the same number of possible negative and possible positives, all the metrics can be used to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4521</td>\n",
       "      <td>280815</td>\n",
       "      <td>21732</td>\n",
       "      <td>428</td>\n",
       "      <td>0.917912</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.314492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4090</td>\n",
       "      <td>297475</td>\n",
       "      <td>5072</td>\n",
       "      <td>859</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.35234</td>\n",
       "      <td>0.759724</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>0.508297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4448</td>\n",
       "      <td>293409</td>\n",
       "      <td>9138</td>\n",
       "      <td>501</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.25097</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.452522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4222</td>\n",
       "      <td>287934</td>\n",
       "      <td>14613</td>\n",
       "      <td>727</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.798145</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.357587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>213184</td>\n",
       "      <td>89363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.066274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4321</td>\n",
       "      <td>297379</td>\n",
       "      <td>5168</td>\n",
       "      <td>628</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.540358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4523</td>\n",
       "      <td>249361</td>\n",
       "      <td>53186</td>\n",
       "      <td>426</td>\n",
       "      <td>0.79822</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.878914</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.187375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4660</td>\n",
       "      <td>179741</td>\n",
       "      <td>122806</td>\n",
       "      <td>289</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.919546</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.105429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4940</td>\n",
       "      <td>249296</td>\n",
       "      <td>53251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.225088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3713</td>\n",
       "      <td>204413</td>\n",
       "      <td>98134</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.635806</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.631136</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.064861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                                \n",
       "max_u_regressor_sparse   lr     3151  297203    5344  1798         0.973939   \n",
       "                         gb     3410  299857    2690  1539          0.98396   \n",
       "                         xgb    4550  292244   10303   399         0.960463   \n",
       "                         svr    4615  275913   26634   334         0.904389   \n",
       "                         mlp    4948  217055   85492     1         0.562262   \n",
       "max_u_regressor_balanced lr     4521  280815   21732   428         0.917912   \n",
       "                         gb     4090  297475    5072   859         0.977647   \n",
       "                         xgb    4448  293409    9138   501         0.963717   \n",
       "                         svr    4222  287934   14613   727         0.944365   \n",
       "                         mlp    4948  213184   89363     1         0.545878   \n",
       "max_u_regressor_focused  lr     4321  297379    5168   628         0.977467   \n",
       "                         gb     4523  249361   53186   426          0.79822   \n",
       "                         xgb    4660  179741  122806   289         0.554576   \n",
       "                         svr    4940  249296   53251     9         0.808736   \n",
       "                         mlp    3713  204413   98134  1236         0.635806   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.441493       0.567722   0.496713   \n",
       "                         xgb            0.230752       0.882031   0.365804   \n",
       "                         svr            0.107401       0.898987   0.191878   \n",
       "                         mlp            0.008497       0.999275    0.01685   \n",
       "max_u_regressor_balanced lr                0.126       0.877757   0.220366   \n",
       "                         gb              0.35234       0.759724   0.481414   \n",
       "                         xgb             0.25097       0.857354   0.388281   \n",
       "                         svr            0.174752       0.798145   0.286726   \n",
       "                         mlp            0.008087       0.999274   0.016044   \n",
       "max_u_regressor_focused  lr             0.366413       0.822844   0.507041   \n",
       "                         gb             0.053925       0.878914   0.101616   \n",
       "                         xgb            0.025552       0.919546   0.049723   \n",
       "                         svr            0.063073       0.997519   0.118643   \n",
       "                         mlp            0.023876       0.631136   0.046011   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_regressor_sparse   lr        0.346102  \n",
       "                         gb        0.492687  \n",
       "                         xgb       0.439649  \n",
       "                         svr       0.291796  \n",
       "                         mlp       0.068953  \n",
       "max_u_regressor_balanced lr        0.314492  \n",
       "                         gb        0.508297  \n",
       "                         xgb       0.452522  \n",
       "                         svr       0.357587  \n",
       "                         mlp       0.066274  \n",
       "max_u_regressor_focused  lr        0.540358  \n",
       "                         gb        0.187375  \n",
       "                         xgb       0.105429  \n",
       "                         svr       0.225088  \n",
       "                         mlp       0.064861  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_regressor_sparse', 'max_u_regressor_balanced', 'max_u_regressor_focused']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best alternative is to use the focused data set with a the linear regression model, because it presents a the best values for F1 and MCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5117</td>\n",
       "      <td>282366</td>\n",
       "      <td>19108</td>\n",
       "      <td>905</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.165926</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.345050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4997</td>\n",
       "      <td>292064</td>\n",
       "      <td>9410</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.284526</td>\n",
       "      <td>0.77814</td>\n",
       "      <td>0.41669</td>\n",
       "      <td>0.456403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5316</td>\n",
       "      <td>289858</td>\n",
       "      <td>11616</td>\n",
       "      <td>706</td>\n",
       "      <td>0.954371</td>\n",
       "      <td>0.255966</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.393042</td>\n",
       "      <td>0.450693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5366</td>\n",
       "      <td>283756</td>\n",
       "      <td>17718</td>\n",
       "      <td>656</td>\n",
       "      <td>0.933244</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.391941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6015</td>\n",
       "      <td>226077</td>\n",
       "      <td>75397</td>\n",
       "      <td>7</td>\n",
       "      <td>0.601244</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.993896</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.070213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5877</td>\n",
       "      <td>244952</td>\n",
       "      <td>56522</td>\n",
       "      <td>145</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.223576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5592</td>\n",
       "      <td>259564</td>\n",
       "      <td>41910</td>\n",
       "      <td>430</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.908282</td>\n",
       "      <td>0.160995</td>\n",
       "      <td>0.254038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5628</td>\n",
       "      <td>252109</td>\n",
       "      <td>49365</td>\n",
       "      <td>394</td>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.228193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5975</td>\n",
       "      <td>253411</td>\n",
       "      <td>48063</td>\n",
       "      <td>47</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.262651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4106</td>\n",
       "      <td>222759</td>\n",
       "      <td>78715</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.702687</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.585727</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.084777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr     2553  297508   3966  3469         0.972468   \n",
       "                         gb     5039  294582   6892   983         0.970974   \n",
       "                         xgb    4781  294780   6694  1241         0.970684   \n",
       "                         svr    5502  281219  20255   520         0.925053   \n",
       "                         mlp    6014  232123  69351     8         0.629952   \n",
       "min_u_regressor_balanced lr     5117  282366  19108   905         0.926901   \n",
       "                         gb     4997  292064   9410  1025         0.961439   \n",
       "                         xgb    5316  289858  11616   706         0.954371   \n",
       "                         svr    5366  283756  17718   656         0.933244   \n",
       "                         mlp    6015  226077  75397     7         0.601244   \n",
       "min_u_regressor_focused  lr     5877  244952  56522   145         0.780846   \n",
       "                         gb     5592  259564  41910   430         0.839482   \n",
       "                         xgb    5628  252109  49365   394         0.808055   \n",
       "                         svr    5975  253411  48063    47         0.822388   \n",
       "                         mlp    4106  222759  78715  1916         0.702687   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.353983       0.787945   0.488506   \n",
       "                         xgb            0.345599       0.731315   0.469381   \n",
       "                         svr            0.174263       0.890969    0.29151   \n",
       "                         mlp            0.009394       0.993227   0.018612   \n",
       "min_u_regressor_balanced lr             0.165926       0.804743   0.275126   \n",
       "                         gb             0.284526        0.77814    0.41669   \n",
       "                         xgb            0.255966       0.846198   0.393042   \n",
       "                         svr            0.194107         0.8676   0.317238   \n",
       "                         mlp            0.008336       0.993896   0.016534   \n",
       "min_u_regressor_focused  lr             0.067654       0.968548   0.126474   \n",
       "                         gb             0.088325       0.908282   0.160995   \n",
       "                         xgb            0.073954        0.91519   0.136849   \n",
       "                         svr            0.085393       0.990249   0.157228   \n",
       "                         mlp            0.035524       0.585727   0.066985   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_regressor_sparse   lr        0.297390  \n",
       "                         gb        0.516571  \n",
       "                         xgb       0.490517  \n",
       "                         svr       0.374989  \n",
       "                         mlp       0.076279  \n",
       "min_u_regressor_balanced lr        0.345050  \n",
       "                         gb        0.456403  \n",
       "                         xgb       0.450693  \n",
       "                         svr       0.391941  \n",
       "                         mlp       0.070213  \n",
       "min_u_regressor_focused  lr        0.223576  \n",
       "                         gb        0.254038  \n",
       "                         xgb       0.228193  \n",
       "                         svr       0.262651  \n",
       "                         mlp       0.084777  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_regressor_sparse', 'min_u_regressor_balanced', 'min_u_regressor_focused']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best sparse, with gradient boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum number present busses in regresison?\n",
    "In order to understand the optinum number of busses for the training set of the regression data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Maximum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Minimum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Minimum Voltage Constraints|Filtered Regression|45216|10|\n",
    "\n",
    "The **Filtered Regression data set** is created from the Sparse Regression data set, but only keeping the columns that contain at least one time step with a constraint violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr     3151  297203   5344  1798         0.973939   \n",
       "                         gb     3410  299857   2690  1539          0.98396   \n",
       "                         xgb    4550  292244  10303   399         0.960463   \n",
       "                         svr    4615  275913  26634   334         0.904389   \n",
       "                         mlp    4948  217055  85492     1         0.562262   \n",
       "max_u_filtered_regressor lr     3151   89191   5344  1798         0.918805   \n",
       "                         gb     3356   91872   2663  1593         0.949925   \n",
       "                         xgb    4949     128  94407     0         0.037666   \n",
       "                         svr    4443   46628  47907   506         0.481777   \n",
       "                         mlp    4949     549  93986     0         0.010538   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.441493       0.567722   0.496713   \n",
       "                         xgb            0.230752       0.882031   0.365804   \n",
       "                         svr            0.107401       0.898987   0.191878   \n",
       "                         mlp            0.008497       0.999275    0.01685   \n",
       "max_u_filtered_regressor lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.439197       0.552025    0.48919   \n",
       "                         xgb            0.036546            1.0   0.070515   \n",
       "                         svr            0.060259       0.842986   0.112478   \n",
       "                         mlp            0.007693            1.0   0.015269   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_regressor_sparse   lr        0.346102  \n",
       "                         gb        0.492687  \n",
       "                         xgb       0.439649  \n",
       "                         svr       0.291796  \n",
       "                         mlp       0.068953  \n",
       "max_u_filtered_regressor lr        0.318793  \n",
       "                         gb        0.466570  \n",
       "                         xgb       0.006640  \n",
       "                         svr       0.120496  \n",
       "                         mlp       0.004715  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_regressor_sparse', 'max_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse, with GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr     2553  297508   3966  3469         0.972468   \n",
       "                         gb     5039  294582   6892   983         0.970974   \n",
       "                         xgb    4781  294780   6694  1241         0.970684   \n",
       "                         svr    5502  281219  20255   520         0.925053   \n",
       "                         mlp    6014  232123  69351     8         0.629952   \n",
       "min_u_filtered_regressor lr     2553   80452   3966  3469         0.905889   \n",
       "                         gb     4993   77816   6602  1029         0.903749   \n",
       "                         xgb    4936   78434   5984  1086         0.911141   \n",
       "                         svr    5369   66433  17985   653         0.770305   \n",
       "                         mlp    4709   31253  35197  1193         0.181759   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.353983       0.787945   0.488506   \n",
       "                         xgb            0.345599       0.731315   0.469381   \n",
       "                         svr            0.174263       0.890969    0.29151   \n",
       "                         mlp            0.009394       0.993227   0.018612   \n",
       "min_u_filtered_regressor lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.360775       0.778289   0.493014   \n",
       "                         xgb            0.382714        0.76811    0.51088   \n",
       "                         svr            0.186868       0.861772   0.307136   \n",
       "                         mlp            0.015308       0.393679    0.02947   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_regressor_sparse   lr        0.297390  \n",
       "                         gb        0.516571  \n",
       "                         xgb       0.490517  \n",
       "                         svr       0.374989  \n",
       "                         mlp       0.076279  \n",
       "min_u_filtered_regressor lr        0.260936  \n",
       "                         gb        0.488250  \n",
       "                         xgb       0.502496  \n",
       "                         svr       0.331681  \n",
       "                         mlp      -0.192864  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_regressor_sparse', 'min_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse, with GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression vs Classification\n",
    "In order to understand the optinum number of busses for the training set of the regression data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Maximum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Minimum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Minimum Voltage Constraints|Sparse Classification|45216|10|\n",
    "\n",
    "The **Sparse Classification data set** is created from the Sparse Regression data set, but instead of having the target feature as the amplitude of the constraint violation, it is a binary feature that indicates if there is a constraint violation or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                              \n",
       "max_u_classifier         lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                         gb     2487  92303   2232  2462         0.952817   \n",
       "                         xgb    1817  93214   1321  3132         0.955239   \n",
       "                         svr       0  94535      0  4949         0.950253   \n",
       "                         mlp    3902  58964  35571  1047         0.631921   \n",
       "max_u_filtered_regressor lr     3151  89191   5344  1798         0.918805   \n",
       "                         gb     3356  91872   2663  1593         0.949925   \n",
       "                         xgb    4949    128  94407     0         0.037666   \n",
       "                         svr    4443  46628  47907   506         0.481777   \n",
       "                         mlp    4949    549  93986     0         0.010538   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_classifier         lr                  NaN            NaN        NaN   \n",
       "                         gb             0.527018       0.502526   0.514481   \n",
       "                         xgb            0.579031       0.367145   0.449363   \n",
       "                         svr                   0            0.0          0   \n",
       "                         mlp            0.098852       0.788442   0.175679   \n",
       "max_u_filtered_regressor lr             0.266485        0.48156   0.343104   \n",
       "                         gb             0.439197       0.552025    0.48919   \n",
       "                         xgb            0.036546            1.0   0.070515   \n",
       "                         svr            0.060259       0.842986   0.112478   \n",
       "                         mlp            0.007693            1.0   0.015269   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_classifier         lr             NaN  \n",
       "                         gb        0.489852  \n",
       "                         xgb       0.439336  \n",
       "                         svr      -1.000000  \n",
       "                         mlp       0.183174  \n",
       "max_u_filtered_regressor lr        0.318793  \n",
       "                         gb        0.466570  \n",
       "                         xgb       0.006640  \n",
       "                         svr       0.120496  \n",
       "                         mlp       0.004715  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_classifier', 'max_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_u_filtered regressor with the gradient boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                              \n",
       "min_u_classifier         lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                         gb     4068  81151   3267  1954         0.942271   \n",
       "                         xgb    4167  80534   3884  1855         0.936544   \n",
       "                         svr    2965  82965   1453  3057         0.950133   \n",
       "                         mlp    5320  50125  34293   702         0.613058   \n",
       "min_u_filtered_regressor lr     2553  80452   3966  3469         0.905889   \n",
       "                         gb     4993  77816   6602  1029         0.903749   \n",
       "                         xgb    4936  78434   5984  1086         0.911141   \n",
       "                         svr    5369  66433  17985   653         0.770305   \n",
       "                         mlp    4709  31253  35197  1193         0.181759   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_classifier         lr                  NaN            NaN        NaN   \n",
       "                         gb             0.554601       0.675523   0.609119   \n",
       "                         xgb            0.517575       0.691963   0.592198   \n",
       "                         svr            0.671118       0.492361   0.568008   \n",
       "                         mlp            0.134299       0.883427   0.233154   \n",
       "min_u_filtered_regressor lr             0.307467       0.315454   0.311409   \n",
       "                         gb             0.360775       0.778289   0.493014   \n",
       "                         xgb            0.382714        0.76811    0.51088   \n",
       "                         svr            0.186868       0.861772   0.307136   \n",
       "                         mlp            0.015308       0.393679    0.02947   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_classifier         lr             NaN  \n",
       "                         gb        0.581558  \n",
       "                         xgb       0.565496  \n",
       "                         svr       0.549541  \n",
       "                         mlp       0.239785  \n",
       "min_u_filtered_regressor lr        0.260936  \n",
       "                         gb        0.488250  \n",
       "                         xgb       0.502496  \n",
       "                         svr       0.331681  \n",
       "                         mlp      -0.192864  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_classifier', 'min_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_u_classifier with the gradient boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum number of rows in class?\n",
    "In order to understand the optinum number of rows for the training set of the classification data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Maximum Voltage Constraints|Balanced Classification|6971|10|\n",
    "|Minimum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Minimum Voltage Constraints|Balanced Classification|13917|10|\n",
    "\n",
    "The **Balanced Classification data set** is created from the Sparse Classification data set. It is created by taking all the rows that containt at least one constraint violation and then taking the same number of rows that do not contain any constraint violation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3499</td>\n",
       "      <td>91026</td>\n",
       "      <td>3509</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0.585264</td>\n",
       "      <td>0.569179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3158</td>\n",
       "      <td>92054</td>\n",
       "      <td>2481</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.957058</td>\n",
       "      <td>0.560028</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>0.575312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3956</td>\n",
       "      <td>89928</td>\n",
       "      <td>4607</td>\n",
       "      <td>993</td>\n",
       "      <td>0.94371</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>0.581876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4041</td>\n",
       "      <td>58329</td>\n",
       "      <td>36206</td>\n",
       "      <td>908</td>\n",
       "      <td>0.626935</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.816529</td>\n",
       "      <td>0.178821</td>\n",
       "      <td>0.192052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                              \n",
       "max_u_classifier          lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     2487  92303   2232  2462         0.952817   \n",
       "                          xgb    1817  93214   1321  3132         0.955239   \n",
       "                          svr       0  94535      0  4949         0.950253   \n",
       "                          mlp    3902  58964  35571  1047         0.631921   \n",
       "max_u_classifier_balanced lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     3499  91026   3509  1450         0.950153   \n",
       "                          xgb    3158  92054   2481  1791         0.957058   \n",
       "                          svr    3956  89928   4607   993          0.94371   \n",
       "                          mlp    4041  58329  36206   908         0.626935   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.527018       0.502526   0.514481   \n",
       "                          xgb            0.579031       0.367145   0.449363   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.098852       0.788442   0.175679   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.499287       0.707012   0.585264   \n",
       "                          xgb            0.560028       0.638109   0.596524   \n",
       "                          svr            0.461988       0.799353   0.585554   \n",
       "                          mlp            0.100405       0.816529   0.178821   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "max_u_classifier          lr             NaN  \n",
       "                          gb        0.489852  \n",
       "                          xgb       0.439336  \n",
       "                          svr      -1.000000  \n",
       "                          mlp       0.183174  \n",
       "max_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.569179  \n",
       "                          xgb       0.575312  \n",
       "                          svr       0.581876  \n",
       "                          mlp       0.192052  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_classifier', 'max_u_classifier_balanced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier balanced with xgb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4379</td>\n",
       "      <td>77799</td>\n",
       "      <td>6619</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.398163</td>\n",
       "      <td>0.727167</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.494868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4395</td>\n",
       "      <td>77766</td>\n",
       "      <td>6652</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.908459</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>0.729824</td>\n",
       "      <td>0.514969</td>\n",
       "      <td>0.495647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4931</td>\n",
       "      <td>79390</td>\n",
       "      <td>5028</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.49513</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.604686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5328</td>\n",
       "      <td>46466</td>\n",
       "      <td>37952</td>\n",
       "      <td>694</td>\n",
       "      <td>0.572689</td>\n",
       "      <td>0.123105</td>\n",
       "      <td>0.884756</td>\n",
       "      <td>0.216137</td>\n",
       "      <td>0.217185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                              \n",
       "min_u_classifier          lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     4068  81151   3267  1954         0.942271   \n",
       "                          xgb    4167  80534   3884  1855         0.936544   \n",
       "                          svr    2965  82965   1453  3057         0.950133   \n",
       "                          mlp    5320  50125  34293   702         0.613058   \n",
       "min_u_classifier_balanced lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     4379  77799   6619  1643         0.908647   \n",
       "                          xgb    4395  77766   6652  1627         0.908459   \n",
       "                          svr    4931  79390   5028  1091         0.932342   \n",
       "                          mlp    5328  46466  37952   694         0.572689   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.554601       0.675523   0.609119   \n",
       "                          xgb            0.517575       0.691963   0.592198   \n",
       "                          svr            0.671118       0.492361   0.568008   \n",
       "                          mlp            0.134299       0.883427   0.233154   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.398163       0.727167   0.514571   \n",
       "                          xgb            0.397846       0.729824   0.514969   \n",
       "                          svr             0.49513       0.818831   0.617108   \n",
       "                          mlp            0.123105       0.884756   0.216137   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "min_u_classifier          lr             NaN  \n",
       "                          gb        0.581558  \n",
       "                          xgb       0.565496  \n",
       "                          svr       0.549541  \n",
       "                          mlp       0.239785  \n",
       "min_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.494868  \n",
       "                          xgb       0.495647  \n",
       "                          svr       0.604686  \n",
       "                          mlp       0.217185  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_classifier', 'min_u_classifier_balanced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier balanced with svr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "In order to understand how good our predictions really are, we can compare it to a random classifier. [source](https://inside.getyourguide.com/blog/2020/9/30/what-makes-a-good-f1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "      <th>q</th>\n",
       "      <th>f1_coin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>297203</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.346102</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3410</td>\n",
       "      <td>299857</td>\n",
       "      <td>2690</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.98396</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.496713</td>\n",
       "      <td>0.492687</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4550</td>\n",
       "      <td>292244</td>\n",
       "      <td>10303</td>\n",
       "      <td>399</td>\n",
       "      <td>0.960463</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.882031</td>\n",
       "      <td>0.365804</td>\n",
       "      <td>0.439649</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4615</td>\n",
       "      <td>275913</td>\n",
       "      <td>26634</td>\n",
       "      <td>334</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.107401</td>\n",
       "      <td>0.898987</td>\n",
       "      <td>0.191878</td>\n",
       "      <td>0.291796</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>217055</td>\n",
       "      <td>85492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562262</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.01685</td>\n",
       "      <td>0.068953</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4321</td>\n",
       "      <td>297379</td>\n",
       "      <td>5168</td>\n",
       "      <td>628</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>0.366413</td>\n",
       "      <td>0.822844</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>0.540358</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4523</td>\n",
       "      <td>249361</td>\n",
       "      <td>53186</td>\n",
       "      <td>426</td>\n",
       "      <td>0.79822</td>\n",
       "      <td>0.053925</td>\n",
       "      <td>0.878914</td>\n",
       "      <td>0.101616</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4660</td>\n",
       "      <td>179741</td>\n",
       "      <td>122806</td>\n",
       "      <td>289</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.919546</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0.105429</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4940</td>\n",
       "      <td>249296</td>\n",
       "      <td>53251</td>\n",
       "      <td>9</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.118643</td>\n",
       "      <td>0.225088</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3713</td>\n",
       "      <td>204413</td>\n",
       "      <td>98134</td>\n",
       "      <td>1236</td>\n",
       "      <td>0.635806</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.631136</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.064861</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3151</td>\n",
       "      <td>89191</td>\n",
       "      <td>5344</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.918805</td>\n",
       "      <td>0.266485</td>\n",
       "      <td>0.48156</td>\n",
       "      <td>0.343104</td>\n",
       "      <td>0.318793</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3356</td>\n",
       "      <td>91872</td>\n",
       "      <td>2663</td>\n",
       "      <td>1593</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.439197</td>\n",
       "      <td>0.552025</td>\n",
       "      <td>0.48919</td>\n",
       "      <td>0.466570</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4949</td>\n",
       "      <td>128</td>\n",
       "      <td>94407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.036546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4443</td>\n",
       "      <td>46628</td>\n",
       "      <td>47907</td>\n",
       "      <td>506</td>\n",
       "      <td>0.481777</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.842986</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.120496</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4949</td>\n",
       "      <td>549</td>\n",
       "      <td>93986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4521</td>\n",
       "      <td>280815</td>\n",
       "      <td>21732</td>\n",
       "      <td>428</td>\n",
       "      <td>0.917912</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.877757</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.314492</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4090</td>\n",
       "      <td>297475</td>\n",
       "      <td>5072</td>\n",
       "      <td>859</td>\n",
       "      <td>0.977647</td>\n",
       "      <td>0.35234</td>\n",
       "      <td>0.759724</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4448</td>\n",
       "      <td>293409</td>\n",
       "      <td>9138</td>\n",
       "      <td>501</td>\n",
       "      <td>0.963717</td>\n",
       "      <td>0.25097</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.452522</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4222</td>\n",
       "      <td>287934</td>\n",
       "      <td>14613</td>\n",
       "      <td>727</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.798145</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.357587</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4948</td>\n",
       "      <td>213184</td>\n",
       "      <td>89363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.066274</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.031679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2487</td>\n",
       "      <td>92303</td>\n",
       "      <td>2232</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.952817</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.502526</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>0.489852</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1817</td>\n",
       "      <td>93214</td>\n",
       "      <td>1321</td>\n",
       "      <td>3132</td>\n",
       "      <td>0.955239</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.439336</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>94535</td>\n",
       "      <td>0</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3902</td>\n",
       "      <td>58964</td>\n",
       "      <td>35571</td>\n",
       "      <td>1047</td>\n",
       "      <td>0.631921</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.788442</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>0.183174</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3499</td>\n",
       "      <td>91026</td>\n",
       "      <td>3509</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>0.585264</td>\n",
       "      <td>0.569179</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3158</td>\n",
       "      <td>92054</td>\n",
       "      <td>2481</td>\n",
       "      <td>1791</td>\n",
       "      <td>0.957058</td>\n",
       "      <td>0.560028</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.596524</td>\n",
       "      <td>0.575312</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>3956</td>\n",
       "      <td>89928</td>\n",
       "      <td>4607</td>\n",
       "      <td>993</td>\n",
       "      <td>0.94371</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>0.581876</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4041</td>\n",
       "      <td>58329</td>\n",
       "      <td>36206</td>\n",
       "      <td>908</td>\n",
       "      <td>0.626935</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.816529</td>\n",
       "      <td>0.178821</td>\n",
       "      <td>0.192052</td>\n",
       "      <td>0.049747</td>\n",
       "      <td>0.094778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>297508</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.297390</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5039</td>\n",
       "      <td>294582</td>\n",
       "      <td>6892</td>\n",
       "      <td>983</td>\n",
       "      <td>0.970974</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.488506</td>\n",
       "      <td>0.516571</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4781</td>\n",
       "      <td>294780</td>\n",
       "      <td>6694</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.345599</td>\n",
       "      <td>0.731315</td>\n",
       "      <td>0.469381</td>\n",
       "      <td>0.490517</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5502</td>\n",
       "      <td>281219</td>\n",
       "      <td>20255</td>\n",
       "      <td>520</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>0.29151</td>\n",
       "      <td>0.374989</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6014</td>\n",
       "      <td>232123</td>\n",
       "      <td>69351</td>\n",
       "      <td>8</td>\n",
       "      <td>0.629952</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.993227</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>0.076279</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5877</td>\n",
       "      <td>244952</td>\n",
       "      <td>56522</td>\n",
       "      <td>145</td>\n",
       "      <td>0.780846</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.126474</td>\n",
       "      <td>0.223576</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5592</td>\n",
       "      <td>259564</td>\n",
       "      <td>41910</td>\n",
       "      <td>430</td>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.088325</td>\n",
       "      <td>0.908282</td>\n",
       "      <td>0.160995</td>\n",
       "      <td>0.254038</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5628</td>\n",
       "      <td>252109</td>\n",
       "      <td>49365</td>\n",
       "      <td>394</td>\n",
       "      <td>0.808055</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.91519</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.228193</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5975</td>\n",
       "      <td>253411</td>\n",
       "      <td>48063</td>\n",
       "      <td>47</td>\n",
       "      <td>0.822388</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>0.262651</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4106</td>\n",
       "      <td>222759</td>\n",
       "      <td>78715</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.702687</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.585727</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.084777</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2553</td>\n",
       "      <td>80452</td>\n",
       "      <td>3966</td>\n",
       "      <td>3469</td>\n",
       "      <td>0.905889</td>\n",
       "      <td>0.307467</td>\n",
       "      <td>0.315454</td>\n",
       "      <td>0.311409</td>\n",
       "      <td>0.260936</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4993</td>\n",
       "      <td>77816</td>\n",
       "      <td>6602</td>\n",
       "      <td>1029</td>\n",
       "      <td>0.903749</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0.778289</td>\n",
       "      <td>0.493014</td>\n",
       "      <td>0.488250</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4936</td>\n",
       "      <td>78434</td>\n",
       "      <td>5984</td>\n",
       "      <td>1086</td>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.382714</td>\n",
       "      <td>0.76811</td>\n",
       "      <td>0.51088</td>\n",
       "      <td>0.502496</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5369</td>\n",
       "      <td>66433</td>\n",
       "      <td>17985</td>\n",
       "      <td>653</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.186868</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.307136</td>\n",
       "      <td>0.331681</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>4709</td>\n",
       "      <td>31253</td>\n",
       "      <td>35197</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.393679</td>\n",
       "      <td>0.02947</td>\n",
       "      <td>-0.192864</td>\n",
       "      <td>0.081573</td>\n",
       "      <td>0.150842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5117</td>\n",
       "      <td>282366</td>\n",
       "      <td>19108</td>\n",
       "      <td>905</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.165926</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.275126</td>\n",
       "      <td>0.345050</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4997</td>\n",
       "      <td>292064</td>\n",
       "      <td>9410</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.961439</td>\n",
       "      <td>0.284526</td>\n",
       "      <td>0.77814</td>\n",
       "      <td>0.41669</td>\n",
       "      <td>0.456403</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5316</td>\n",
       "      <td>289858</td>\n",
       "      <td>11616</td>\n",
       "      <td>706</td>\n",
       "      <td>0.954371</td>\n",
       "      <td>0.255966</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.393042</td>\n",
       "      <td>0.450693</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5366</td>\n",
       "      <td>283756</td>\n",
       "      <td>17718</td>\n",
       "      <td>656</td>\n",
       "      <td>0.933244</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.391941</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6015</td>\n",
       "      <td>226077</td>\n",
       "      <td>75397</td>\n",
       "      <td>7</td>\n",
       "      <td>0.601244</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.993896</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.070213</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4068</td>\n",
       "      <td>81151</td>\n",
       "      <td>3267</td>\n",
       "      <td>1954</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.554601</td>\n",
       "      <td>0.675523</td>\n",
       "      <td>0.609119</td>\n",
       "      <td>0.581558</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4167</td>\n",
       "      <td>80534</td>\n",
       "      <td>3884</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.691963</td>\n",
       "      <td>0.592198</td>\n",
       "      <td>0.565496</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2965</td>\n",
       "      <td>82965</td>\n",
       "      <td>1453</td>\n",
       "      <td>3057</td>\n",
       "      <td>0.950133</td>\n",
       "      <td>0.671118</td>\n",
       "      <td>0.492361</td>\n",
       "      <td>0.568008</td>\n",
       "      <td>0.549541</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5320</td>\n",
       "      <td>50125</td>\n",
       "      <td>34293</td>\n",
       "      <td>702</td>\n",
       "      <td>0.613058</td>\n",
       "      <td>0.134299</td>\n",
       "      <td>0.883427</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.239785</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4379</td>\n",
       "      <td>77799</td>\n",
       "      <td>6619</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.398163</td>\n",
       "      <td>0.727167</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.494868</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4395</td>\n",
       "      <td>77766</td>\n",
       "      <td>6652</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.908459</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>0.729824</td>\n",
       "      <td>0.514969</td>\n",
       "      <td>0.495647</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4931</td>\n",
       "      <td>79390</td>\n",
       "      <td>5028</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.932342</td>\n",
       "      <td>0.49513</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.604686</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5328</td>\n",
       "      <td>46466</td>\n",
       "      <td>37952</td>\n",
       "      <td>694</td>\n",
       "      <td>0.572689</td>\n",
       "      <td>0.123105</td>\n",
       "      <td>0.884756</td>\n",
       "      <td>0.216137</td>\n",
       "      <td>0.217185</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.124857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                                \n",
       "max_u_regressor_sparse    lr     3151  297203    5344  1798         0.973939   \n",
       "                          gb     3410  299857    2690  1539          0.98396   \n",
       "                          xgb    4550  292244   10303   399         0.960463   \n",
       "                          svr    4615  275913   26634   334         0.904389   \n",
       "                          mlp    4948  217055   85492     1         0.562262   \n",
       "max_u_regressor_focused   lr     4321  297379    5168   628         0.977467   \n",
       "                          gb     4523  249361   53186   426          0.79822   \n",
       "                          xgb    4660  179741  122806   289         0.554576   \n",
       "                          svr    4940  249296   53251     9         0.808736   \n",
       "                          mlp    3713  204413   98134  1236         0.635806   \n",
       "max_u_filtered_regressor  lr     3151   89191    5344  1798         0.918805   \n",
       "                          gb     3356   91872    2663  1593         0.949925   \n",
       "                          xgb    4949     128   94407     0         0.037666   \n",
       "                          svr    4443   46628   47907   506         0.481777   \n",
       "                          mlp    4949     549   93986     0         0.010538   \n",
       "max_u_regressor_balanced  lr     4521  280815   21732   428         0.917912   \n",
       "                          gb     4090  297475    5072   859         0.977647   \n",
       "                          xgb    4448  293409    9138   501         0.963717   \n",
       "                          svr    4222  287934   14613   727         0.944365   \n",
       "                          mlp    4948  213184   89363     1         0.545878   \n",
       "max_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     2487   92303    2232  2462         0.952817   \n",
       "                          xgb    1817   93214    1321  3132         0.955239   \n",
       "                          svr       0   94535       0  4949         0.950253   \n",
       "                          mlp    3902   58964   35571  1047         0.631921   \n",
       "max_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     3499   91026    3509  1450         0.950153   \n",
       "                          xgb    3158   92054    2481  1791         0.957058   \n",
       "                          svr    3956   89928    4607   993          0.94371   \n",
       "                          mlp    4041   58329   36206   908         0.626935   \n",
       "min_u_regressor_sparse    lr     2553  297508    3966  3469         0.972468   \n",
       "                          gb     5039  294582    6892   983         0.970974   \n",
       "                          xgb    4781  294780    6694  1241         0.970684   \n",
       "                          svr    5502  281219   20255   520         0.925053   \n",
       "                          mlp    6014  232123   69351     8         0.629952   \n",
       "min_u_regressor_focused   lr     5877  244952   56522   145         0.780846   \n",
       "                          gb     5592  259564   41910   430         0.839482   \n",
       "                          xgb    5628  252109   49365   394         0.808055   \n",
       "                          svr    5975  253411   48063    47         0.822388   \n",
       "                          mlp    4106  222759   78715  1916         0.702687   \n",
       "min_u_filtered_regressor  lr     2553   80452    3966  3469         0.905889   \n",
       "                          gb     4993   77816    6602  1029         0.903749   \n",
       "                          xgb    4936   78434    5984  1086         0.911141   \n",
       "                          svr    5369   66433   17985   653         0.770305   \n",
       "                          mlp    4709   31253   35197  1193         0.181759   \n",
       "min_u_regressor_balanced  lr     5117  282366   19108   905         0.926901   \n",
       "                          gb     4997  292064    9410  1025         0.961439   \n",
       "                          xgb    5316  289858   11616   706         0.954371   \n",
       "                          svr    5366  283756   17718   656         0.933244   \n",
       "                          mlp    6015  226077   75397     7         0.601244   \n",
       "min_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4068   81151    3267  1954         0.942271   \n",
       "                          xgb    4167   80534    3884  1855         0.936544   \n",
       "                          svr    2965   82965    1453  3057         0.950133   \n",
       "                          mlp    5320   50125   34293   702         0.613058   \n",
       "min_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4379   77799    6619  1643         0.908647   \n",
       "                          xgb    4395   77766    6652  1627         0.908459   \n",
       "                          svr    4931   79390    5028  1091         0.932342   \n",
       "                          mlp    5328   46466   37952   694         0.572689   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_regressor_sparse    lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.441493       0.567722   0.496713   \n",
       "                          xgb            0.230752       0.882031   0.365804   \n",
       "                          svr            0.107401       0.898987   0.191878   \n",
       "                          mlp            0.008497       0.999275    0.01685   \n",
       "max_u_regressor_focused   lr             0.366413       0.822844   0.507041   \n",
       "                          gb             0.053925       0.878914   0.101616   \n",
       "                          xgb            0.025552       0.919546   0.049723   \n",
       "                          svr            0.063073       0.997519   0.118643   \n",
       "                          mlp            0.023876       0.631136   0.046011   \n",
       "max_u_filtered_regressor  lr             0.266485        0.48156   0.343104   \n",
       "                          gb             0.439197       0.552025    0.48919   \n",
       "                          xgb            0.036546            1.0   0.070515   \n",
       "                          svr            0.060259       0.842986   0.112478   \n",
       "                          mlp            0.007693            1.0   0.015269   \n",
       "max_u_regressor_balanced  lr                0.126       0.877757   0.220366   \n",
       "                          gb              0.35234       0.759724   0.481414   \n",
       "                          xgb             0.25097       0.857354   0.388281   \n",
       "                          svr            0.174752       0.798145   0.286726   \n",
       "                          mlp            0.008087       0.999274   0.016044   \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.527018       0.502526   0.514481   \n",
       "                          xgb            0.579031       0.367145   0.449363   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.098852       0.788442   0.175679   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.499287       0.707012   0.585264   \n",
       "                          xgb            0.560028       0.638109   0.596524   \n",
       "                          svr            0.461988       0.799353   0.585554   \n",
       "                          mlp            0.100405       0.816529   0.178821   \n",
       "min_u_regressor_sparse    lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.353983       0.787945   0.488506   \n",
       "                          xgb            0.345599       0.731315   0.469381   \n",
       "                          svr            0.174263       0.890969    0.29151   \n",
       "                          mlp            0.009394       0.993227   0.018612   \n",
       "min_u_regressor_focused   lr             0.067654       0.968548   0.126474   \n",
       "                          gb             0.088325       0.908282   0.160995   \n",
       "                          xgb            0.073954        0.91519   0.136849   \n",
       "                          svr            0.085393       0.990249   0.157228   \n",
       "                          mlp            0.035524       0.585727   0.066985   \n",
       "min_u_filtered_regressor  lr             0.307467       0.315454   0.311409   \n",
       "                          gb             0.360775       0.778289   0.493014   \n",
       "                          xgb            0.382714        0.76811    0.51088   \n",
       "                          svr            0.186868       0.861772   0.307136   \n",
       "                          mlp            0.015308       0.393679    0.02947   \n",
       "min_u_regressor_balanced  lr             0.165926       0.804743   0.275126   \n",
       "                          gb             0.284526        0.77814    0.41669   \n",
       "                          xgb            0.255966       0.846198   0.393042   \n",
       "                          svr            0.194107         0.8676   0.317238   \n",
       "                          mlp            0.008336       0.993896   0.016534   \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.554601       0.675523   0.609119   \n",
       "                          xgb            0.517575       0.691963   0.592198   \n",
       "                          svr            0.671118       0.492361   0.568008   \n",
       "                          mlp            0.134299       0.883427   0.233154   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.398163       0.727167   0.514571   \n",
       "                          xgb            0.397846       0.729824   0.514969   \n",
       "                          svr             0.49513       0.818831   0.617108   \n",
       "                          mlp            0.123105       0.884756   0.216137   \n",
       "\n",
       "                                 (hybrid)mcc         q   f1_coin  \n",
       "experiment                class                                   \n",
       "max_u_regressor_sparse    lr        0.346102  0.016095  0.031679  \n",
       "                          gb        0.492687  0.016095  0.031679  \n",
       "                          xgb       0.439649  0.016095  0.031679  \n",
       "                          svr       0.291796  0.016095  0.031679  \n",
       "                          mlp       0.068953  0.016095  0.031679  \n",
       "max_u_regressor_focused   lr        0.540358  0.016095  0.031679  \n",
       "                          gb        0.187375  0.016095  0.031679  \n",
       "                          xgb       0.105429  0.016095  0.031679  \n",
       "                          svr       0.225088  0.016095  0.031679  \n",
       "                          mlp       0.064861  0.016095  0.031679  \n",
       "max_u_filtered_regressor  lr        0.318793  0.049747  0.094778  \n",
       "                          gb        0.466570  0.049747  0.094778  \n",
       "                          xgb       0.006640  0.049747  0.094778  \n",
       "                          svr       0.120496  0.049747  0.094778  \n",
       "                          mlp       0.004715  0.049747  0.094778  \n",
       "max_u_regressor_balanced  lr        0.314492  0.016095  0.031679  \n",
       "                          gb        0.508297  0.016095  0.031679  \n",
       "                          xgb       0.452522  0.016095  0.031679  \n",
       "                          svr       0.357587  0.016095  0.031679  \n",
       "                          mlp       0.066274  0.016095  0.031679  \n",
       "max_u_classifier          lr             NaN       NaN       NaN  \n",
       "                          gb        0.489852  0.049747  0.094778  \n",
       "                          xgb       0.439336  0.049747  0.094778  \n",
       "                          svr      -1.000000  0.049747  0.094778  \n",
       "                          mlp       0.183174  0.049747  0.094778  \n",
       "max_u_classifier_balanced lr             NaN       NaN       NaN  \n",
       "                          gb        0.569179  0.049747  0.094778  \n",
       "                          xgb       0.575312  0.049747  0.094778  \n",
       "                          svr       0.581876  0.049747  0.094778  \n",
       "                          mlp       0.192052  0.049747  0.094778  \n",
       "min_u_regressor_sparse    lr        0.297390  0.019584  0.038416  \n",
       "                          gb        0.516571  0.019584  0.038416  \n",
       "                          xgb       0.490517  0.019584  0.038416  \n",
       "                          svr       0.374989  0.019584  0.038416  \n",
       "                          mlp       0.076279  0.019584  0.038416  \n",
       "min_u_regressor_focused   lr        0.223576  0.019584  0.038416  \n",
       "                          gb        0.254038  0.019584  0.038416  \n",
       "                          xgb       0.228193  0.019584  0.038416  \n",
       "                          svr       0.262651  0.019584  0.038416  \n",
       "                          mlp       0.084777  0.019584  0.038416  \n",
       "min_u_filtered_regressor  lr        0.260936  0.066586  0.124857  \n",
       "                          gb        0.488250  0.066586  0.124857  \n",
       "                          xgb       0.502496  0.066586  0.124857  \n",
       "                          svr       0.331681  0.066586  0.124857  \n",
       "                          mlp      -0.192864  0.081573  0.150842  \n",
       "min_u_regressor_balanced  lr        0.345050  0.019584  0.038416  \n",
       "                          gb        0.456403  0.019584  0.038416  \n",
       "                          xgb       0.450693  0.019584  0.038416  \n",
       "                          svr       0.391941  0.019584  0.038416  \n",
       "                          mlp       0.070213  0.019584  0.038416  \n",
       "min_u_classifier          lr             NaN       NaN       NaN  \n",
       "                          gb        0.581558  0.066586  0.124857  \n",
       "                          xgb       0.565496  0.066586  0.124857  \n",
       "                          svr       0.549541  0.066586  0.124857  \n",
       "                          mlp       0.239785  0.066586  0.124857  \n",
       "min_u_classifier_balanced lr             NaN       NaN       NaN  \n",
       "                          gb        0.494868  0.066586  0.124857  \n",
       "                          xgb       0.495647  0.066586  0.124857  \n",
       "                          svr       0.604686  0.066586  0.124857  \n",
       "                          mlp       0.217185  0.066586  0.124857  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['q'] =  (df['tp'] + df['fn']) / (df['fp'] + df['tn'] + df['tp'] + df['fn'])\n",
    "df['f1_coin'] = (2*df['q'])/(df['q']+1)\n",
    "# write df to csv in this directory, with the name dataset_benchmark.csv\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5328"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[('min_u_classifier_balanced', 'mlp'), 'tp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: max_u_regressor_sparse, model: mlp, threshold: 0.05260425830867303\n",
      "true_positives_ctr:  1432\n",
      "true_negatives_ctr:  0\n",
      "false_positives_ctr:  16656\n",
      "false_negatives_ctr:  0\n",
      "0\n",
      "hybrid_metrics.true_positives_ctr:  1432\n",
      "hybrid_metrics.true_negatives_ctr:  0\n",
      "hybrid_metrics.false_positives_ctr:  16656\n",
      "hybrid_metrics.false_negatives_ctr:  0\n",
      "\n",
      "\n",
      "hybrid_true_positives_rmse 483.64282925858015\n",
      "hybrid_true_negatives_rmse 0\n",
      "hybrid_false_positives_rmse 33308.75967554767\n",
      "hybrid_false_negatives_rmse 0\n",
      "\n",
      "\n",
      "true_positives_rmse 0.6622605940931703\n",
      "true_negatives_rmse 0\n",
      "false_positives_rmse 0.9998054560247163\n",
      "false_negatives_rmse 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Metrics' object has no attribute 'hybrid_accuracy_rmse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\jupyter_notebooks\\datasets_benchmark.ipynb Cell 77\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfalse_negatives_rmse\u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39mfalse_negatives_rmse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhybrid_metrics.hybrid_accuracy_rmse: \u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39;49mhybrid_accuracy_rmse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhybrid_metrics.hybrid_precision_rmse: \u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39mhybrid_precision_rmse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jamil/Documents/IST/Thesis/new_thesis/code/AI-to-forecast-constraints-in-the-energy-systems/jupyter_notebooks/datasets_benchmark.ipynb#Y134sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhybrid_metrics.hybrid_recall_rmse: \u001b[39m\u001b[39m'\u001b[39m, hybrid_metrics\u001b[39m.\u001b[39mhybrid_recall_rmse)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Metrics' object has no attribute 'hybrid_accuracy_rmse'"
     ]
    }
   ],
   "source": [
    "threshold = _threshold(experiment)\n",
    "experiment = 'max_u_regressor_sparse'\n",
    "model = 'mlp' \n",
    "threshold = _threshold(experiment)\n",
    "print('Experiment: {}, model: {}, threshold: {}'.format(experiment, model, threshold))\n",
    "hybrid_metrics = metrics.Metrics()\n",
    "hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted'][['bus_15', 'bus_16']], testing_data[experiment][model]['real'][['bus_15', 'bus_16']], threshold=threshold)\n",
    "print('hybrid_metrics.true_positives_ctr: ', hybrid_metrics.true_positives_ctr)\n",
    "print('hybrid_metrics.true_negatives_ctr: ', hybrid_metrics.true_negatives_ctr)\n",
    "print('hybrid_metrics.false_positives_ctr: ', hybrid_metrics.false_positives_ctr)\n",
    "print('hybrid_metrics.false_negatives_ctr: ', hybrid_metrics.false_negatives_ctr)\n",
    "print('\\n')\n",
    "print('hybrid_true_positives_rmse', hybrid_metrics.hybrid_true_positives_rmse)\n",
    "print('hybrid_true_negatives_rmse', hybrid_metrics.hybrid_true_negatives_rmse)\n",
    "print('hybrid_false_positives_rmse', hybrid_metrics.hybrid_false_positives_rmse)\n",
    "print('hybrid_false_negatives_rmse', hybrid_metrics.hybrid_false_negatives_rmse)\n",
    "print('\\n')\n",
    "print('true_positives_rmse', hybrid_metrics.true_positives_rmse)\n",
    "print('true_negatives_rmse', hybrid_metrics.true_negatives_rmse)\n",
    "print('false_positives_rmse', hybrid_metrics.false_positives_rmse)\n",
    "print('false_negatives_rmse', hybrid_metrics.false_negatives_rmse)\n",
    "print('\\n')\n",
    "print('hybrid_metrics.hybrid_accuracy_rmse: ', hybrid_metrics.hybrid_accuracy_rmse)\n",
    "print('hybrid_metrics.hybrid_precision_rmse: ', hybrid_metrics.hybrid_precision_rmse)\n",
    "print('hybrid_metrics.hybrid_recall_rmse: ', hybrid_metrics.hybrid_recall_rmse)\n",
    "print('hybrid_metrics.hybrid_f1_rmse: ', hybrid_metrics.hybrid_f1_rmse)\n",
    "print('hybrid_metrics.hybrid_mcc_rmse: ', hybrid_metrics.hybrid_mcc_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure size of the plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 10))\n",
    "testing_data['max_u_classifier']['mlp']['predicted']['bus_16'].plot()\n",
    "#testing_data['max_u_classifier']['mlp']['real']['bus_16'].plot()\n",
    "\n",
    "# plot a line with the threshold\n",
    "_threshold = lambda experiment: max_u_threshold / data_max_u_balanced['scaler']['y'] if 'max_u' in experiment else min_u_threshold/ data_min_u_balanced['scaler']['y']\n",
    "threshold = _threshold('max_u_regressor_sparse')\n",
    "plt.axhline(y=threshold, color='r', linestyle='-')\n",
    "# Add legend\n",
    "plt.legend(['predicted', 'real', 'threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data['max_u_regressor_sparse']['mlp']['predicted'].apply(lambda x: x.apply(lambda y: min(1.0, max(0.0, y))))['bus_1'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data['max_u_classifier']['mlp']['predicted'].astype('float64')['bus_16'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn df to numpy array\n",
    "testing_data['max_u_classifier']['gb']['predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment: min_u_classifier, model: gb, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier, model: xgb, max: 1, min: 0\n",
      "experiment: min_u_classifier, model: svr, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier_balanced, model: gb, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier_balanced, model: xgb, max: 1, min: 0\n",
      "experiment: min_u_classifier_balanced, model: svr, max: 1.0, min: 0.0\n",
      "experiment: min_u_classifier_balanced, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: lr, max: 0.13619870924844507, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: gb, max: 0.3810799686594865, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: xgb, max: 0.3127909302711487, min: 0.024557016789913177\n",
      "experiment: max_u_regressor_sparse, model: svr, max: 0.4946822431673944, min: 0.0\n",
      "experiment: max_u_regressor_sparse, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: lr, max: 0.6501631250830311, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: gb, max: 0.42120136723128043, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: xgb, max: 0.42610928416252136, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: svr, max: 0.46197486433850854, min: 0.0\n",
      "experiment: max_u_regressor_focused, model: mlp, max: 0.577883243560791, min: 0.0\n",
      "experiment: max_u_filtered_regressor, model: lr, max: 0.12660268004533026, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: lr, max: 0.4010267617457135, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: gb, max: 0.7517199729659615, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: xgb, max: 0.5393862724304199, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: svr, max: 0.787608227817534, min: 0.0\n",
      "experiment: max_u_regressor_balanced, model: mlp, max: 1.0, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: lr, max: 0.5855579684553072, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: gb, max: 0.5932988934689641, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: xgb, max: 0.5121873617172241, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: svr, max: 0.6045885499738398, min: 0.0\n",
      "experiment: min_u_regressor_focused, model: mlp, max: 0.34603604674339294, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: lr, max: 0.34171831351797666, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: gb, max: 0.5165846932947002, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: xgb, max: 0.4210992753505707, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: svr, max: 0.6300204477633999, min: 0.0\n",
      "experiment: min_u_regressor_balanced, model: mlp, max: 1.0, min: 0.0\n"
     ]
    }
   ],
   "source": [
    "classifier_experiments =[experiment for experiment in testing_data.keys() if 'classifier' in experiment.split('_')] # TODO confirm this\n",
    "regressor_experiments = [experiment for experiment in testing_data.keys() if 'regressor' in experiment.split('_')]\n",
    "# Classifier experiments\n",
    "for experiment in classifier_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        try:\n",
    "            print('experiment: {}, model: {}, max: {}, min: {}'.format(experiment, model, testing_data[experiment][model]['predicted'].max().max(), testing_data[experiment][model]['predicted'].min().min()))\n",
    "        except:\n",
    "            print('experiment {} model {} failed'.format(experiment, model))\n",
    "for experiment in regressor_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        try:\n",
    "            print('experiment: {}, model: {}, max: {}, min: {}'.format(experiment, model, testing_data[experiment][model]['predicted'].max().max(), testing_data[experiment][model]['predicted'].min().min()))\n",
    "        except:\n",
    "            print('experiment {} model {} failed'.format(experiment, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe4baa4d27e3b73db55d4bb4674105e8dd41faaf9e559c3cc8381041ce15293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
