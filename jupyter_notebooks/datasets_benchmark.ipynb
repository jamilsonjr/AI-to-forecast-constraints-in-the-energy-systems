{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of this Article** \n",
    "- Loading best hyperparameters for each model\n",
    "- Model training\n",
    "- Results discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading best hyperparameters for each model\n",
    "\n",
    "TODO... explain this model bench mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hyperparameters dataset.\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse hyperparameters: 8/8\n",
      "Focused hyperparameters: 8/8\n",
      "Balanced hyperparameters: 8/8\n",
      "Filtered hyperparameters: 8/8\n",
      "Sparse classifier hyperparameters: 8/8\n",
      "Balanced classifier hyperparameters: 8/8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparse_hyper_params = {}\n",
    "focused_hyper_params = {}\n",
    "balanced_hyper_params = {}\n",
    "filtered_hyper_params = {}\n",
    "sparse_class_hyper_params = {}\n",
    "balanced_class_hyper_params = {}\n",
    "for file in os.listdir('hyper_params_results'):\n",
    "    if file.endswith('.csv') and 'regression_sparse' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'regression_focused' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        focused_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'regression_balanced' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        balanced_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'filtered' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        filtered_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'sparse_classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        sparse_class_hyper_params[file] = df\n",
    "    elif file.endswith('.csv') and 'balanced_classifier' in file:\n",
    "        df = pd.read_csv(os.path.join('hyper_params_results', file))\n",
    "        balanced_class_hyper_params[file] = df\n",
    "print('Sparse hyperparameters: {}/8'.format(len(sparse_hyper_params)))\n",
    "print('Focused hyperparameters: {}/8'.format(len(focused_hyper_params)))\n",
    "print('Balanced hyperparameters: {}/8'.format(len(balanced_hyper_params)))\n",
    "print('Filtered hyperparameters: {}/8'.format(len(filtered_hyper_params)))\n",
    "print('Sparse classifier hyperparameters: {}/8'.format(len(sparse_class_hyper_params)))\n",
    "print('Balanced classifier hyperparameters: {}/8'.format(len(balanced_class_hyper_params)))\n",
    "print('\\n')\n",
    "# print('Sparse hyper params:\\n')\n",
    "# for key in sparse_hyper_params.keys():\n",
    "#     print(key, ':\\n ',sparse_hyper_params[key])\n",
    "# print('Focused hyper params:\\n')\n",
    "# for key in focused_hyper_params.keys():\n",
    "#     print(key, ':\\n',focused_hyper_params[key])\n",
    "# print('Boolean hyper params:\\n')\n",
    "# for key in sparse_class_hyper_params.keys():\n",
    "#     print(key, ':\\n',sparse_class_hyper_params[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 34,\n",
       " 'n_layers': 3,\n",
       " 'dropout': 0.0030412321477918842,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'sgd',\n",
       " 'lr': 9.741292351005151e-05,\n",
       " 'epochs': 55,\n",
       " 'batch_size': 8,\n",
       " 'classifier': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "def get_hyper_params_from_df(df):\n",
    "    output = {}\n",
    "    for row in df.iterrows():\n",
    "        if row[1]['params'] != 'value':\n",
    "            try:\n",
    "                output[row[1]['params']] = ast.literal_eval(row[1]['value'])\n",
    "            except :\n",
    "                output[row[1]['params']] = row[1]['value']\n",
    "    return output\n",
    "get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_max_u.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..');from thesis_package import aimodels as my_ai, utils, metrics\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression data sparse\n",
    "y_max_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_sparse = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv').drop(columns=['timestamps'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_sparse, test_size=0.2, scaling=True)\n",
    "data_max_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_sparse, test_size=0.2, scaling=True)\n",
    "data_min_u_sparse = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data sparse\n",
    "y_max_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_min_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_bool_constr.csv').drop(columns=['timestamps'])\n",
    "y_max_u_bool = y_max_u_bool[utils.cols_with_positive_values(y_max_u_bool)]\n",
    "y_min_u_bool = y_min_u_bool[utils.cols_with_positive_values(y_min_u_bool)]\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_bool, test_size=0.2, scaling=True)\n",
    "data_max_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_bool, test_size=0.2, scaling=True)\n",
    "data_min_u_bool = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered data\n",
    "y_max_u_filtered = deepcopy(y_max_u_sparse[utils.cols_with_positive_values(y_max_u_bool)])\n",
    "y_min_u_filtered = deepcopy(y_min_u_sparse[utils.cols_with_positive_values(y_min_u_bool)])\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_max_u_filtered, test_size=0.2, scaling=True)\n",
    "data_max_u_filtered = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data, y_min_u_filtered, test_size=0.2, scaling=True)\n",
    "data_min_u_filtered = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification data size:  (9044, 10)\n",
      "Regression data size:  (9044, 10)\n",
      "Positive in classification data:  5036.0\n",
      "Positive in regression data:  5036\n",
      "Theshhold:  0.001591058368850724\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the classiciation testing data and the filtered testing data\n",
    "print('Classification data size: ', data_max_u_bool['y_test'].shape)\n",
    "print('Regression data size: ', data_max_u_filtered['y_test'].shape)\n",
    "print('Positive in classification data: ', utils.count_positives_class(data_max_u_bool['y_test']))\n",
    "#unscaled_y_test = pd.DataFrame(data_max_u_filtered['scaler']['y'].inverse_transform(data_max_u_filtered['y_test']), columns=data_max_u_filtered['y_test'].columns)\n",
    "unscaled_y_test = data_max_u_filtered['y_test'] * data_max_u_filtered['scaler']['y']\n",
    "print('Positive in regression data: ', utils.count_positives_reg(unscaled_y_test, utils.compute_threshold(y_max_u_sparse)))\n",
    "print('Theshhold: ', utils.compute_threshold(y_max_u_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data focused\n",
    "y_max_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_focused_constr.csv')\n",
    "exogenous_data_focused_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_focused.csv').drop(columns=['date'])\n",
    "y_min_u_focused = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_focused_constr.csv')\n",
    "exogenous_data_focused_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_focused.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_max_u, y_max_u_focused, test_size=0.2, scaling=True)\n",
    "data_max_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_focused_min_u, y_min_u_focused, test_size=0.2, scaling=True)\n",
    "data_min_u_focused = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresison data balanced\n",
    "y_max_u_balanced = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_constr.csv')\n",
    "exogenous_data_balanced_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "y_min_u_balanced = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_constr.csv')\n",
    "exogenous_data_balanced_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_max_u, y_max_u_balanced, test_size=0.2, scaling=True)\n",
    "data_max_u_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_min_u, y_min_u_balanced, test_size=0.2, scaling=True)\n",
    "data_min_u_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification data balanced\n",
    "y_max_u_balanced_class = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_bool_constr.csv')\n",
    "exogenous_data_balanced_max_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "y_min_u_balanced_class = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_bool_constr.csv')\n",
    "exogenous_data_balanced_min_u = pd.read_csv('..\\data\\ground_truth\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "y_max_u_balanced_class = y_max_u_balanced_class[utils.cols_with_positive_values(y_max_u_balanced_class)]\n",
    "y_min_u_balanced_class = y_min_u_balanced_class[utils.cols_with_positive_values(y_min_u_balanced_class)]\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_max_u, y_max_u_balanced_class, test_size=0.2, scaling=True)\n",
    "data_max_u_bool_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}\n",
    "\n",
    "train_x, test_x, train_y, test_y, scaler = utils.split_and_suffle(exogenous_data_balanced_min_u, y_min_u_balanced_class, test_size=0.2, scaling=True)\n",
    "data_min_u_bool_balanced = {'X_train': deepcopy(train_x), 'X_test': deepcopy(test_x), 'y_train': deepcopy(train_y), 'y_test': deepcopy(test_y), 'scaler': deepcopy(scaler)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a quick sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count in classification data max_u : 5036.0\n",
      "Positive count in regression data max_u with threshold 0.001591058368850724 : 5036\n",
      "\n",
      "\n",
      "Positive count in classification data min_u : 6018.0\n",
      "Positive count in regression data min_u with threshold 0.0020242378560612192 : 6018\n",
      "\n",
      "\n",
      "Negative count in classification data max_u : 85404.0\n",
      "Negative count in regression data max_u with threshold 0.001591058368850724 : 85404\n",
      "\n",
      "\n",
      "Negative count in classification data min_u : 84422.0\n",
      "Negative count in regression data min_u with threshold 0.0020242378560612192 : 84422\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.check_positive_count(data_max_u_filtered['y_test']* data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')\n",
    "utils.check_positive_count(data_min_u_filtered['y_test']* data_min_u_filtered['scaler']['y'], data_min_u_bool['y_test'], utils.compute_threshold(y_min_u_sparse), experiment='min_u')\n",
    "utils.check_negative_count(data_max_u_filtered['y_test']* data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')\n",
    "utils.check_negative_count(data_min_u_filtered['y_test']* data_min_u_filtered['scaler']['y'], data_min_u_bool['y_test'], utils.compute_threshold(y_min_u_sparse), experiment='min_u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count in classification data max_u : 5036.0\n",
      "Positive count in regression data max_u with threshold 0.001591058368850724 : 5036\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.check_positive_count(data_max_u_filtered['y_test'] * data_max_u_filtered['scaler']['y'], data_max_u_bool['y_test'], utils.compute_threshold(y_max_u_sparse), experiment='max_u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "In this section the models will be trained with the hyperparameters loaded above. All the models will be stored in the same `Context` object for later evaluation. The `Context` object is a class that stores all the models and their respective hyperparameters. The `Context` object is defined in the `aimodels.py` file. The `Context` object is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_models = ['lr', 'gb', 'xgb', 'svr', 'mlp']\n",
    "class_models =  ['gb', 'xgb', 'svr', 'mlp']\n",
    "max_u_threshold = utils.compute_threshold(y_max_u_sparse)\n",
    "min_u_threshold = utils.compute_threshold(y_min_u_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_filtered(df, scaler):\n",
    "    for bus in df.columns:\n",
    "        idx = list(scaler.feature_names_in_).index(bus)\n",
    "        df[bus] = scaler.max_abs_[idx] * df[bus]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params_gradient_boost_regression_sparse_max_u.csv', 'params_gradient_boost_regression_sparse_min_u.csv', 'params_mlp_regression_sparse_max_u.csv', 'params_mlp_regression_sparse_min_u.csv', 'params_support_vector_regression_sparse_max_u.csv', 'params_support_vector_regression_sparse_min_u.csv', 'params_xgboost_regression_sparse_max_u.csv', 'params_xgboost_regression_sparse_min_u.csv'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_hyper_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression sparse\n"
     ]
    }
   ],
   "source": [
    "# max_u regression sparse\n",
    "if 'max_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_max_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_max_u.csv']) \n",
    "    regressor_max_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_max_u.csv'])\n",
    "    regressor_max_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regression_sparse_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_sparse['y_train'].shape[1]\n",
    "    regressor_max_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data=data_max_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse', regressor_max_u)\n",
    "else:\n",
    "    print('Loading max_u regression sparse') \n",
    "    regressor_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_sparse')\n",
    "\n",
    "testing_data = {'max_u_regressor_sparse': {}}\n",
    "for model, strategy in zip(reg_models, regressor_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_sparse['y_test'].columns)\n",
    "    testing_data['max_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_sparse'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cb2d13a160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# figure size of the plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "testing_data['max_u_regressor_sparse']['gb']['predicted']['bus_15'].plot()\n",
    "testing_data['max_u_regressor_sparse']['gb']['real']['bus_15'].plot()\n",
    "# plot a line with the threshold\n",
    "# Add legend\n",
    "plt.legend(['predicted', 'real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression focused\n"
     ]
    }
   ],
   "source": [
    "# max_u regression focused\n",
    "if 'max_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_max_u.csv']) \n",
    "    regressor_max_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_max_u.csv'])\n",
    "    regressor_max_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_focused['y_train'].shape[1]\n",
    "    regressor_max_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_focused.fit(data=data_max_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_focused', regressor_max_u_focused)\n",
    "else: \n",
    "    print('Loading max_u regression focused')\n",
    "    regressor_max_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\\\max_u_regressor_focused')\n",
    "\n",
    "testing_data['max_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_sparse['y_test'].columns)\n",
    "    testing_data['max_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_focused'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u filtered regression\n"
     ]
    }
   ],
   "source": [
    "# max_u regression filtered\n",
    "if 'max_u_filtered_regressor.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression filtered')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_filtered = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_gradient_boost_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_xgboost_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_support_vector_regression_filtered_max_u.csv'])\n",
    "    regressor_max_u_filtered.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_mlp_regression_filtered_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_filtered['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_filtered['y_train'].shape[1]\n",
    "    regressor_max_u_filtered.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_filtered.fit(data=data_max_u_filtered)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_filtered_regressor', regressor_max_u_filtered)\n",
    "else: \n",
    "    print('Loading max_u filtered regression')\n",
    "    regressor_max_u_filtered = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_filtered_regressor')\n",
    "\n",
    "testing_data['max_u_filtered_regressor'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_filtered.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_filtered['y_test'].columns)\n",
    "    testing_data['max_u_filtered_regressor'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_filtered_regressor'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_filtered_regressor'][model]['real'] = deepcopy(data_max_u_sparse['y_test'][utils.cols_with_positive_values(prediction)].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u regression balanced\n"
     ]
    }
   ],
   "source": [
    "# max u regression balanced\n",
    "if 'max_u_regressor_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u regression balanced')\n",
    "    # Linear Regression\n",
    "    regressor_max_u_balanced = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_gradient_boost_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_xgboost_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_support_vector_regression_balanced_max_u.csv'])\n",
    "    regressor_max_u_balanced.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_mlp_regression_balanced_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_balanced['y_train'].shape[1]\n",
    "    regressor_max_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_max_u_balanced.fit(data=data_max_u_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_regressor_balanced', regressor_max_u_balanced)\n",
    "else: \n",
    "    print('Loading max_u regression balanced')\n",
    "    regressor_max_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_regressor_balanced')\n",
    "\n",
    "testing_data['max_u_regressor_balanced'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_max_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_balanced['y_test'].columns)\n",
    "    testing_data['max_u_regressor_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_regressor_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_regressor_balanced'][model]['real'] = deepcopy(data_max_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u classification\n"
     ]
    }
   ],
   "source": [
    "# max_u classification\n",
    "if 'max_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_gradient_boost_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_xgboost_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_support_vector_sparse_classifier_max_u.csv'])\n",
    "    classifier_max_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_mlp_sparse_classifier_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_bool['y_train'].shape[1]\n",
    "    classifier_max_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_max_u.fit(data=data_max_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier', classifier_max_u)\n",
    "else: \n",
    "    print('Loading max_u classification')\n",
    "    classifier_max_u = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier')\n",
    "\n",
    "testing_data['max_u_classifier'] = {}\n",
    "for model, strategy in zip(class_models, classifier_max_u.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_bool)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_bool['y_test'].columns)\n",
    "    testing_data['max_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_classifier'][model]['real'] = deepcopy(data_max_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_data['max_u_classifier']['xgb']['predicted']['bus_15'].plot()\n",
    "testing_data['max_u_classifier']['xgb']['real']['bus_15'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading max_u classification balanced\n"
     ]
    }
   ],
   "source": [
    "# max_u classification balanced\n",
    "if 'max_u_classifier_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training max_u classification balanced')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_gradient_boost_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_xgboost_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_support_vector_balanced_classifier_max_u.csv'])\n",
    "    classifier_max_u_balanced.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_mlp_balanced_classifier_max_u.csv'])\n",
    "    hyper_params['input_size'] = data_max_u_bool_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_max_u_bool_balanced['y_train'].shape[1]\n",
    "    classifier_max_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_max_u_balanced.fit(data=data_max_u_bool_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\max_u_classifier_balanced', classifier_max_u_balanced)\n",
    "else: \n",
    "    print('Loading max_u classification balanced')\n",
    "    classifier_max_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\max_u_classifier_balanced')\n",
    "\n",
    "testing_data['max_u_classifier_balanced'] = {}\n",
    "for model, strategy in zip(class_models, classifier_max_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_max_u_bool)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_max_u_bool_balanced['y_test'].columns)\n",
    "    testing_data['max_u_classifier_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['max_u_classifier_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['max_u_classifier_balanced'][model]['real'] = deepcopy(data_max_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<thesis_package.aimodels.GradientBoostClassifierStrategy at 0x1cb2d1a06a0>,\n",
       " <thesis_package.aimodels.XGBoostClassifierStrategy at 0x1cb2d1ccb20>,\n",
       " <thesis_package.aimodels.SupportVectorClassifierStrategy at 0x1cb2d1ce280>,\n",
       " <thesis_package.aimodels.MultilayerPerceptronStrategy at 0x1cb2e825040>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_max_u_balanced.strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min u regression training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression sparse\n"
     ]
    }
   ],
   "source": [
    "# min_u regression sparse\n",
    "if 'min_u_regressor_sparse.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression sparse')\n",
    "    # Linear Regression\n",
    "    regressor_min_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_gradient_boost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_xgboost_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_support_vector_regression_sparse_min_u.csv'])\n",
    "    regressor_min_u.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_hyper_params['params_mlp_regression_sparse_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_sparse['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_sparse['y_train'].shape[1]\n",
    "    regressor_min_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data=data_min_u_sparse)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse', regressor_min_u)\n",
    "else:\n",
    "    print('Loading min_u regression sparse')\n",
    "    regressor_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_sparse')\n",
    "\n",
    "testing_data['min_u_regressor_sparse'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_sparse['y_test'].columns)\n",
    "    testing_data['min_u_regressor_sparse'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_sparse'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_sparse'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression focused\n"
     ]
    }
   ],
   "source": [
    "# min_u regression focused\n",
    "if 'min_u_regressor_focused.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression focused')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_focused = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_gradient_boost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Extreme GBoost Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_xgboost_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # Support Vector Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_support_vector_regression_focused_min_u.csv'])\n",
    "    regressor_min_u_focused.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(focused_hyper_params['params_mlp_regression_focused_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_focused['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_focused['y_train'].shape[1]\n",
    "    regressor_min_u_focused.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_focused.fit(data=data_min_u_focused)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused', regressor_min_u_focused)\n",
    "else:\n",
    "    print('Loading min_u regression focused')\n",
    "    regressor_min_u_focused = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_focused')\n",
    "\n",
    "testing_data['min_u_regressor_focused'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_focused.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_focused['y_test'].columns)\n",
    "    testing_data['min_u_regressor_focused'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_focused'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_focused'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u filtered regression\n"
     ]
    }
   ],
   "source": [
    "# min u regression filtered\n",
    "if 'min_u_filtered_regressor.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression filtered')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_filtered = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_gradient_boost_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_xgboost_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_support_vector_regression_filtered_min_u.csv'])\n",
    "    regressor_min_u_filtered.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(filtered_hyper_params['params_mlp_regression_filtered_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_filtered['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_filtered['y_train'].shape[1]\n",
    "    regressor_min_u_filtered.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_filtered.fit(data=data_min_u_filtered)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_filtered_regressor', regressor_min_u_filtered)\n",
    "else: \n",
    "    print('Loading min_u filtered regression')\n",
    "    regressor_min_u_filtered = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_filtered_regressor')\n",
    "\n",
    "testing_data['min_u_filtered_regressor'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_filtered.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_filtered['y_test'].columns)\n",
    "    testing_data['min_u_filtered_regressor'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_filtered_regressor'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_filtered_regressor'][model]['real'] = deepcopy(data_min_u_sparse['y_test'][utils.cols_with_positive_values(prediction)].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u regression balanced\n"
     ]
    }
   ],
   "source": [
    "# min u regression balanced\n",
    "if 'min_u_regressor_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u regression balanced')\n",
    "    # Linear Regression\n",
    "    regressor_min_u_balanced = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_gradient_boost_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_xgboost_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.XGBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_support_vector_regression_balanced_min_u.csv'])\n",
    "    regressor_min_u_balanced.strategy = my_ai.SupportVectorRegressorStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_hyper_params['params_mlp_regression_balanced_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_balanced['y_train'].shape[1]\n",
    "    regressor_min_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    regressor_min_u_balanced.fit(data=data_min_u_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_regressor_balanced', regressor_min_u_balanced)\n",
    "else: \n",
    "    print('Loading min_u regression balanced')\n",
    "    regressor_min_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_regressor_balanced')\n",
    "\n",
    "testing_data['min_u_regressor_balanced'] = {}\n",
    "for model, strategy in zip(reg_models, regressor_min_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_sparse)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_balanced['y_test'].columns)\n",
    "    testing_data['min_u_regressor_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_regressor_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_regressor_balanced'][model]['real'] = deepcopy(data_min_u_sparse['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u classification\n"
     ]
    }
   ],
   "source": [
    "# min_u classification\n",
    "if 'min_u_classifier.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_gradient_boost_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_xgboost_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_support_vector_sparse_classifier_min_u.csv'])\n",
    "    classifier_min_u.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    # MLP Regression\n",
    "    hyper_params = get_hyper_params_from_df(sparse_class_hyper_params['params_mlp_sparse_classifier_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_bool['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_bool['y_train'].shape[1]\n",
    "    classifier_min_u.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_min_u.fit(data=data_min_u_bool)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier', classifier_min_u)\n",
    "else: \n",
    "    print('Loading min_u classification')\n",
    "    classifier_min_u = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier')\n",
    "\n",
    "testing_data['min_u_classifier'] = {}\n",
    "for model, strategy in zip(class_models, classifier_min_u.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_bool)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_bool['y_test'].columns)\n",
    "    testing_data['min_u_classifier'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_classifier'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_classifier'][model]['real'] = deepcopy(data_min_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<thesis_package.aimodels.GradientBoostClassifierStrategy at 0x1cb2d1cc3d0>,\n",
       " <thesis_package.aimodels.XGBoostClassifierStrategy at 0x1cb3e02c070>,\n",
       " <thesis_package.aimodels.SupportVectorClassifierStrategy at 0x1cb3e032cd0>,\n",
       " <thesis_package.aimodels.MultilayerPerceptronStrategy at 0x1cb3e059250>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_min_u.strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading min_u classification balanced\n"
     ]
    }
   ],
   "source": [
    "# min u classification balanced\n",
    "if 'min_u_classifier_balanced.pickle' not in os.listdir('pickles\\dataset_benchmark'):\n",
    "    print('Training min_u classification balanced')\n",
    "    # Gradient Boost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_gradient_boost_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced = my_ai.Context(strategy=my_ai.GradientBoostClassifierStrategy(hyper_params))\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # Extreme GBoost Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_xgboost_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced.strategy = my_ai.XGBoostClassifierStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # Support Vector Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_support_vector_balanced_classifier_min_u.csv'])\n",
    "    classifier_min_u_balanced.strategy = my_ai.SupportVectorClassifierStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    # MLP Classifier\n",
    "    hyper_params = get_hyper_params_from_df(balanced_class_hyper_params['params_mlp_balanced_classifier_min_u.csv'])\n",
    "    hyper_params['input_size'] = data_min_u_bool_balanced['X_train'].shape[1]\n",
    "    hyper_params['output_size'] = data_min_u_bool_balanced['y_train'].shape[1]\n",
    "    classifier_min_u_balanced.strategy = my_ai.MultilayerPerceptronStrategy(hyper_params)\n",
    "    classifier_min_u_balanced.fit(data=data_min_u_bool_balanced)\n",
    "    utils.serialize_object('pickles\\dataset_benchmark\\min_u_classifier_balanced', classifier_min_u_balanced)\n",
    "else: \n",
    "    print('Loading min_u classification balanced')\n",
    "    classifier_min_u_balanced = utils.deserialize_object('pickles\\dataset_benchmark\\min_u_classifier_balanced')\n",
    "\n",
    "testing_data['min_u_classifier_balanced'] = {}\n",
    "for model, strategy in zip(class_models, classifier_min_u_balanced.strategies):\n",
    "    prediction = strategy.predict(data=data_min_u_bool)\n",
    "    prediction = pd.DataFrame(prediction, columns=data_min_u_bool_balanced['y_test'].columns)\n",
    "    testing_data['min_u_classifier_balanced'][model] = {'real': None, 'predicted': None}\n",
    "    testing_data['min_u_classifier_balanced'][model]['predicted'] = deepcopy(prediction)\n",
    "    testing_data['min_u_classifier_balanced'][model]['real'] = deepcopy(data_min_u_bool['y_test'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "In this section the results of the training and testing are presented and compared. The main objectives of this experience is to compare the performance of the regression models in terms of the hybrid metrics confusion matrix and the hybrid metrics rmse. The comparisons will be the following:\n",
    "- Compare the confusion matrices of the classification models and the regression models evaluate with the hybrid metrics.\n",
    "- Compare the error results of the regression models trained with the focused dataset and the sparse dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_u_regressor_sparse :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_regressor_focused :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_filtered_regressor :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_regressor_balanced :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_classifier :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "max_u_classifier_balanced :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_sparse :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_focused :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_filtered_regressor :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_regressor_balanced :  dict_keys(['lr', 'gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_classifier :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n",
      "min_u_classifier_balanced :  dict_keys(['gb', 'xgb', 'svr', 'mlp'])\n"
     ]
    }
   ],
   "source": [
    "for experience in testing_data.keys():\n",
    "    print(experience,': ', testing_data[experience].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3979 + 1057 = 5036 = 5036.0 possible positive values.\n",
      "59448 + 25956 = 85404 = 85404.0 possible negative values.\n"
     ]
    }
   ],
   "source": [
    "# Testing all models: Function that receives a dict with the real and predicted values, and outputs a dataframe with the results of the metrics.\n",
    "# Accumulate all the classifications for each bus.\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for bus in testing_data['max_u_classifier']['mlp']['predicted'].columns:\n",
    "    # Compute tp, tn, fp, fn\n",
    "    tp += sum((testing_data['max_u_classifier']['mlp']['predicted'][bus] == 1) & (testing_data['max_u_classifier']['mlp']['real'][bus] == 1))\n",
    "    tn += sum((testing_data['max_u_classifier']['mlp']['predicted'][bus] == 0) & (testing_data['max_u_classifier']['mlp']['real'][bus] == 0))\n",
    "    fp += sum((testing_data['max_u_classifier']['mlp']['predicted'][bus] == 1) & (testing_data['max_u_classifier']['mlp']['real'][bus] == 0))\n",
    "    fn += sum((testing_data['max_u_classifier']['mlp']['predicted'][bus] == 0) & (testing_data['max_u_classifier']['mlp']['real'][bus] == 1))\n",
    "print('{} + {} = {} = {} possible positive values.'.format(tp, fn, tp+fn, testing_data['max_u_classifier']['mlp']['real'].sum().sum()))\n",
    "print('{} + {} = {} = {} possible negative values.'.format(tn, fp, tn+fp, testing_data['max_u_classifier']['mlp']['real'].shape[0]*testing_data['max_u_classifier']['mlp']['real'].shape[1] - testing_data['max_u_classifier']['mlp']['real'].sum().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: max_u_regressor_sparse, model: lr, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_sparse, model: gb, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_sparse, model: xgb, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_sparse, model: svr, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_sparse, model: mlp, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_focused, model: lr, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_focused, model: gb, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_focused, model: xgb, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_focused, model: svr, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_focused, model: mlp, threshold: 0.054008631153497785\n",
      "Experiment: max_u_filtered_regressor, model: lr, threshold: 0.054008631153497785\n",
      "Experiment: max_u_filtered_regressor, model: gb, threshold: 0.054008631153497785\n",
      "Experiment: max_u_filtered_regressor, model: xgb, threshold: 0.054008631153497785\n",
      "Experiment: max_u_filtered_regressor, model: svr, threshold: 0.054008631153497785\n",
      "Experiment: max_u_filtered_regressor, model: mlp, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_balanced, model: lr, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_balanced, model: gb, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_balanced, model: xgb, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_balanced, model: svr, threshold: 0.054008631153497785\n",
      "Experiment: max_u_regressor_balanced, model: mlp, threshold: 0.054008631153497785\n",
      "Experiment: min_u_regressor_sparse, model: lr, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_sparse, model: gb, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_sparse, model: xgb, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_sparse, model: svr, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_sparse, model: mlp, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_focused, model: lr, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_focused, model: gb, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_focused, model: xgb, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_focused, model: svr, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_focused, model: mlp, threshold: 0.06450243730741544\n",
      "Experiment: min_u_filtered_regressor, model: lr, threshold: 0.06450243730741544\n",
      "Experiment: min_u_filtered_regressor, model: gb, threshold: 0.06450243730741544\n",
      "Experiment: min_u_filtered_regressor, model: xgb, threshold: 0.06450243730741544\n",
      "Experiment: min_u_filtered_regressor, model: svr, threshold: 0.06450243730741544\n",
      "Experiment: min_u_filtered_regressor, model: mlp, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_balanced, model: lr, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_balanced, model: gb, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_balanced, model: xgb, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_balanced, model: svr, threshold: 0.06450243730741544\n",
      "Experiment: min_u_regressor_balanced, model: mlp, threshold: 0.06450243730741544\n"
     ]
    }
   ],
   "source": [
    "from numpy import sqrt \n",
    "# Build a multi-index dataframe with the results of the metrics. The first index is the testing_data.keys(), the second index are the tp, tn, fp, fn, and the columns are the models.\n",
    "columns = ['tp', 'tn', 'fp', 'fn', '(hybrid)accuracy', '(hybrid)precision', '(hybrid)recall', '(hybrid)f1']\n",
    "index = pd.MultiIndex.from_product([testing_data.keys(), ['lr', 'gb', 'xgb', 'svr', 'mlp']], names=['experiment', 'class'])\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "classifier_experiments =[experiment for experiment in testing_data.keys() if 'classifier' in experiment.split('_')] # TODO confirm this\n",
    "regressor_experiments = [experiment for experiment in testing_data.keys() if 'regressor' in experiment.split('_')]\n",
    "# Classifier experiments\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "for experiment in classifier_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        for bus in testing_data[experiment][model]['predicted'].columns:\n",
    "            try:\n",
    "                tp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "                tn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fp += sum((testing_data[experiment][model]['predicted'][bus] == 1) & (testing_data[experiment][model]['real'][bus] == 0))\n",
    "                fn += sum((testing_data[experiment][model]['predicted'][bus] == 0) & (testing_data[experiment][model]['real'][bus] == 1))\n",
    "            except: \n",
    "                print('In the experiment ', experiment, ' and model ', model, ' there was a problem with bus: ', bus)\n",
    "                if not testing_data[experiment][model]['real'][bus].any():\n",
    "                    print('Bus {} has no positive data points. Just ignore the little shit.'.format(bus))    \n",
    "        df.loc[(experiment, model), 'tp'] = tp\n",
    "        df.loc[(experiment, model), 'tn'] = tn\n",
    "        df.loc[(experiment, model), 'fp'] = fp\n",
    "        df.loc[(experiment, model), 'fn'] = fn\n",
    "        #print('Experiment: {}, model: {}, tp: {}, tn: {}, fp: {}, fn: {}'.format(experiment, model, tp, tn, fp, fn))\n",
    "        if (tp + tn + fp + fn) != 0:\n",
    "            accuracy = (tp + tn ) / (tp + tn + fp + fn)\n",
    "        else: \n",
    "            accuracy = 0\n",
    "        if (tp + fp) != 0:\n",
    "            precision = tp / (tp + fp)\n",
    "        else:\n",
    "            precision = 0\n",
    "        if (tp + fn) != 0:\n",
    "            recall = tp / (tp + fn)\n",
    "        else:\n",
    "            recall = 0\n",
    "        if (precision + recall) != 0:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "        if (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn) > 0:\n",
    "            mcc = (tp * tn - fp * fn) / sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "        df.loc[(experiment, model), '(hybrid)accuracy'] = accuracy\n",
    "        df.loc[(experiment, model), '(hybrid)precision'] = precision\n",
    "        df.loc[(experiment, model), '(hybrid)recall'] = recall\n",
    "        df.loc[(experiment, model), '(hybrid)f1'] = f1\n",
    "        df.loc[(experiment, model), '(hybrid)mcc'] = mcc\n",
    "        # print('Experiment: {}, model: {}, accuracy: {}, precision: {}, recall: {}, f1: {}'.format(experiment, model, accuracy, precision, recall, f1))\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0 \n",
    "# Regressor experiments\n",
    "_threshold = lambda experiment: max_u_threshold / data_max_u_balanced['scaler']['y'] if 'max_u' in experiment else min_u_threshold/ data_min_u_balanced['scaler']['y']\n",
    "# _threshold = lambda experiment: max_u_threshold if 'max_u' in experiment else min_u_threshold\n",
    "for experiment in regressor_experiments:\n",
    "    for model in testing_data[experiment].keys():\n",
    "        try:\n",
    "            threshold = _threshold(experiment)\n",
    "            print('Experiment: {}, model: {}, threshold: {}'.format(experiment, model, threshold))\n",
    "            hybrid_metrics = metrics.Metrics()\n",
    "            hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted'], testing_data[experiment][model]['real'], threshold=threshold)\n",
    "            df.loc[(experiment, model), 'tp'] = hybrid_metrics.true_positives_ctr\n",
    "            df.loc[(experiment, model), 'tn'] = hybrid_metrics.true_negatives_ctr\n",
    "            df.loc[(experiment, model), 'fp'] = hybrid_metrics.false_positives_ctr\n",
    "            df.loc[(experiment, model), 'fn'] = hybrid_metrics.false_negatives_ctr\n",
    "            df.loc[(experiment, model), '(hybrid)accuracy'] = hybrid_metrics.hybrid_accuracy\n",
    "            df.loc[(experiment, model), '(hybrid)precision'] = hybrid_metrics.hybrid_precision\n",
    "            df.loc[(experiment, model), '(hybrid)recall'] = hybrid_metrics.hybrid_recall\n",
    "            df.loc[(experiment, model), '(hybrid)f1'] = hybrid_metrics.hybrid_f1\n",
    "            df.loc[(experiment, model), '(hybrid)mcc'] = hybrid_metrics.hybrid_mcc\n",
    "            # print('Experiment: {}, model: {}, tp: {}, tn: {}, fp: {}, fn: {}'.format(experiment, model, hybrid_metrics.true_positives_ctr, hybrid_metrics.true_negatives_ctr, hybrid_metrics.false_positives_ctr, hybrid_metrics.false_negatives_ctr))\n",
    "            # print('Experiment: {}, model: {}, accuracy: {}, precision: {}, recall: {}, f1: {}'.format(experiment, model, hybrid_metrics.hybrid_accuracy, hybrid_metrics.hybrid_precision, hybrid_metrics.hybrid_recall, hybrid_metrics.hybrid_f1))\n",
    "        except(Exception) as e:\n",
    "            print('In the experiment ', experiment, ' and model ', model, ' there was a problem')\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3671</td>\n",
       "      <td>295704</td>\n",
       "      <td>6756</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.975707</td>\n",
       "      <td>0.275935</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>0.427611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3916</td>\n",
       "      <td>299157</td>\n",
       "      <td>3303</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.498915</td>\n",
       "      <td>0.755742</td>\n",
       "      <td>0.601043</td>\n",
       "      <td>0.608358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4748</td>\n",
       "      <td>292152</td>\n",
       "      <td>10308</td>\n",
       "      <td>288</td>\n",
       "      <td>0.967555</td>\n",
       "      <td>0.274727</td>\n",
       "      <td>0.933765</td>\n",
       "      <td>0.424546</td>\n",
       "      <td>0.496928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4712</td>\n",
       "      <td>268831</td>\n",
       "      <td>33629</td>\n",
       "      <td>324</td>\n",
       "      <td>0.895444</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>0.928593</td>\n",
       "      <td>0.184537</td>\n",
       "      <td>0.289015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>203962</td>\n",
       "      <td>98498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420708</td>\n",
       "      <td>0.053948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.147067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4250</td>\n",
       "      <td>298058</td>\n",
       "      <td>4402</td>\n",
       "      <td>786</td>\n",
       "      <td>0.957173</td>\n",
       "      <td>0.497321</td>\n",
       "      <td>0.865045</td>\n",
       "      <td>0.631556</td>\n",
       "      <td>0.637046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4924</td>\n",
       "      <td>240377</td>\n",
       "      <td>62083</td>\n",
       "      <td>112</td>\n",
       "      <td>0.828385</td>\n",
       "      <td>0.072713</td>\n",
       "      <td>0.975359</td>\n",
       "      <td>0.135337</td>\n",
       "      <td>0.240749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4971</td>\n",
       "      <td>154066</td>\n",
       "      <td>148394</td>\n",
       "      <td>65</td>\n",
       "      <td>0.555002</td>\n",
       "      <td>0.031938</td>\n",
       "      <td>0.986185</td>\n",
       "      <td>0.061873</td>\n",
       "      <td>0.129897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5002</td>\n",
       "      <td>230283</td>\n",
       "      <td>72177</td>\n",
       "      <td>34</td>\n",
       "      <td>0.778019</td>\n",
       "      <td>0.059362</td>\n",
       "      <td>0.992966</td>\n",
       "      <td>0.112027</td>\n",
       "      <td>0.213272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3572</td>\n",
       "      <td>203649</td>\n",
       "      <td>98811</td>\n",
       "      <td>1464</td>\n",
       "      <td>0.701026</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>0.747112</td>\n",
       "      <td>0.065628</td>\n",
       "      <td>0.114311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3671</td>\n",
       "      <td>78648</td>\n",
       "      <td>6756</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.915323</td>\n",
       "      <td>0.275935</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>0.402325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3897</td>\n",
       "      <td>82212</td>\n",
       "      <td>3192</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.958275</td>\n",
       "      <td>0.502028</td>\n",
       "      <td>0.749402</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.593148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>712</td>\n",
       "      <td>84692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089263</td>\n",
       "      <td>0.019893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4455</td>\n",
       "      <td>49419</td>\n",
       "      <td>35985</td>\n",
       "      <td>581</td>\n",
       "      <td>0.601283</td>\n",
       "      <td>0.090107</td>\n",
       "      <td>0.878752</td>\n",
       "      <td>0.163454</td>\n",
       "      <td>0.194093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>1</td>\n",
       "      <td>85403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05707</td>\n",
       "      <td>0.057071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.107979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4855</td>\n",
       "      <td>278759</td>\n",
       "      <td>23701</td>\n",
       "      <td>181</td>\n",
       "      <td>0.930287</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.961609</td>\n",
       "      <td>0.27391</td>\n",
       "      <td>0.376638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4396</td>\n",
       "      <td>296857</td>\n",
       "      <td>5603</td>\n",
       "      <td>640</td>\n",
       "      <td>0.98262</td>\n",
       "      <td>0.423158</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.569025</td>\n",
       "      <td>0.599350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4617</td>\n",
       "      <td>293585</td>\n",
       "      <td>8875</td>\n",
       "      <td>419</td>\n",
       "      <td>0.973091</td>\n",
       "      <td>0.320434</td>\n",
       "      <td>0.911948</td>\n",
       "      <td>0.474235</td>\n",
       "      <td>0.531773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4301</td>\n",
       "      <td>293761</td>\n",
       "      <td>8699</td>\n",
       "      <td>735</td>\n",
       "      <td>0.971903</td>\n",
       "      <td>0.314354</td>\n",
       "      <td>0.856756</td>\n",
       "      <td>0.459947</td>\n",
       "      <td>0.509193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5013</td>\n",
       "      <td>226007</td>\n",
       "      <td>76453</td>\n",
       "      <td>23</td>\n",
       "      <td>0.979983</td>\n",
       "      <td>0.057633</td>\n",
       "      <td>1.000342</td>\n",
       "      <td>0.108987</td>\n",
       "      <td>0.237693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2598</td>\n",
       "      <td>83124</td>\n",
       "      <td>2280</td>\n",
       "      <td>2438</td>\n",
       "      <td>0.947833</td>\n",
       "      <td>0.532595</td>\n",
       "      <td>0.515886</td>\n",
       "      <td>0.524107</td>\n",
       "      <td>0.496589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1867</td>\n",
       "      <td>84013</td>\n",
       "      <td>1391</td>\n",
       "      <td>3169</td>\n",
       "      <td>0.94958</td>\n",
       "      <td>0.573051</td>\n",
       "      <td>0.370731</td>\n",
       "      <td>0.450205</td>\n",
       "      <td>0.436154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>85404</td>\n",
       "      <td>0</td>\n",
       "      <td>5036</td>\n",
       "      <td>0.944317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3979</td>\n",
       "      <td>59448</td>\n",
       "      <td>25956</td>\n",
       "      <td>1057</td>\n",
       "      <td>0.701316</td>\n",
       "      <td>0.132921</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>0.22756</td>\n",
       "      <td>0.236921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3546</td>\n",
       "      <td>81683</td>\n",
       "      <td>3721</td>\n",
       "      <td>1490</td>\n",
       "      <td>0.942382</td>\n",
       "      <td>0.487959</td>\n",
       "      <td>0.70413</td>\n",
       "      <td>0.576445</td>\n",
       "      <td>0.557219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3180</td>\n",
       "      <td>83080</td>\n",
       "      <td>2324</td>\n",
       "      <td>1856</td>\n",
       "      <td>0.953782</td>\n",
       "      <td>0.577762</td>\n",
       "      <td>0.631454</td>\n",
       "      <td>0.603416</td>\n",
       "      <td>0.579572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4029</td>\n",
       "      <td>80498</td>\n",
       "      <td>4906</td>\n",
       "      <td>1007</td>\n",
       "      <td>0.93462</td>\n",
       "      <td>0.450923</td>\n",
       "      <td>0.80004</td>\n",
       "      <td>0.576766</td>\n",
       "      <td>0.570683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3961</td>\n",
       "      <td>49320</td>\n",
       "      <td>36084</td>\n",
       "      <td>1075</td>\n",
       "      <td>0.589131</td>\n",
       "      <td>0.098914</td>\n",
       "      <td>0.786537</td>\n",
       "      <td>0.175728</td>\n",
       "      <td>0.168054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2978</td>\n",
       "      <td>296439</td>\n",
       "      <td>5039</td>\n",
       "      <td>3040</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>0.324899</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.384441</td>\n",
       "      <td>0.379444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5322</td>\n",
       "      <td>293242</td>\n",
       "      <td>8236</td>\n",
       "      <td>696</td>\n",
       "      <td>0.974264</td>\n",
       "      <td>0.385312</td>\n",
       "      <td>0.885434</td>\n",
       "      <td>0.536957</td>\n",
       "      <td>0.574551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5162</td>\n",
       "      <td>292073</td>\n",
       "      <td>9405</td>\n",
       "      <td>856</td>\n",
       "      <td>0.97033</td>\n",
       "      <td>0.344235</td>\n",
       "      <td>0.858975</td>\n",
       "      <td>0.491501</td>\n",
       "      <td>0.532996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5575</td>\n",
       "      <td>266504</td>\n",
       "      <td>34974</td>\n",
       "      <td>443</td>\n",
       "      <td>0.892789</td>\n",
       "      <td>0.131861</td>\n",
       "      <td>0.92292</td>\n",
       "      <td>0.230754</td>\n",
       "      <td>0.325950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6011</td>\n",
       "      <td>229092</td>\n",
       "      <td>72386</td>\n",
       "      <td>7</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.075117</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.139732</td>\n",
       "      <td>0.268128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>6009</td>\n",
       "      <td>234851</td>\n",
       "      <td>66627</td>\n",
       "      <td>9</td>\n",
       "      <td>0.828677</td>\n",
       "      <td>0.093785</td>\n",
       "      <td>0.998395</td>\n",
       "      <td>0.171463</td>\n",
       "      <td>0.277939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5891</td>\n",
       "      <td>248922</td>\n",
       "      <td>52556</td>\n",
       "      <td>127</td>\n",
       "      <td>0.856077</td>\n",
       "      <td>0.108228</td>\n",
       "      <td>0.977798</td>\n",
       "      <td>0.194885</td>\n",
       "      <td>0.299362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5936</td>\n",
       "      <td>242553</td>\n",
       "      <td>58925</td>\n",
       "      <td>82</td>\n",
       "      <td>0.84589</td>\n",
       "      <td>0.103075</td>\n",
       "      <td>0.985416</td>\n",
       "      <td>0.186629</td>\n",
       "      <td>0.291826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5996</td>\n",
       "      <td>241247</td>\n",
       "      <td>60231</td>\n",
       "      <td>22</td>\n",
       "      <td>0.826397</td>\n",
       "      <td>0.090706</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.16627</td>\n",
       "      <td>0.272487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>2617</td>\n",
       "      <td>232520</td>\n",
       "      <td>68958</td>\n",
       "      <td>3401</td>\n",
       "      <td>0.770289</td>\n",
       "      <td>0.034413</td>\n",
       "      <td>0.468941</td>\n",
       "      <td>0.06412</td>\n",
       "      <td>0.074741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2978</td>\n",
       "      <td>79383</td>\n",
       "      <td>5039</td>\n",
       "      <td>3040</td>\n",
       "      <td>0.917579</td>\n",
       "      <td>0.324899</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.384441</td>\n",
       "      <td>0.348618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5262</td>\n",
       "      <td>76391</td>\n",
       "      <td>8031</td>\n",
       "      <td>756</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.389289</td>\n",
       "      <td>0.876206</td>\n",
       "      <td>0.539073</td>\n",
       "      <td>0.548845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5273</td>\n",
       "      <td>77092</td>\n",
       "      <td>7330</td>\n",
       "      <td>745</td>\n",
       "      <td>0.919196</td>\n",
       "      <td>0.411138</td>\n",
       "      <td>0.875964</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>0.566921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5447</td>\n",
       "      <td>64051</td>\n",
       "      <td>20371</td>\n",
       "      <td>571</td>\n",
       "      <td>0.778377</td>\n",
       "      <td>0.203083</td>\n",
       "      <td>0.901347</td>\n",
       "      <td>0.331481</td>\n",
       "      <td>0.361775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5792</td>\n",
       "      <td>29373</td>\n",
       "      <td>55049</td>\n",
       "      <td>226</td>\n",
       "      <td>0.682453</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>1.110404</td>\n",
       "      <td>0.028397</td>\n",
       "      <td>0.109162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5263</td>\n",
       "      <td>281549</td>\n",
       "      <td>19929</td>\n",
       "      <td>755</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>0.199563</td>\n",
       "      <td>0.869791</td>\n",
       "      <td>0.324642</td>\n",
       "      <td>0.399644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5304</td>\n",
       "      <td>289766</td>\n",
       "      <td>11712</td>\n",
       "      <td>714</td>\n",
       "      <td>0.964194</td>\n",
       "      <td>0.305848</td>\n",
       "      <td>0.882862</td>\n",
       "      <td>0.45431</td>\n",
       "      <td>0.507674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5596</td>\n",
       "      <td>288017</td>\n",
       "      <td>13461</td>\n",
       "      <td>422</td>\n",
       "      <td>0.959203</td>\n",
       "      <td>0.285961</td>\n",
       "      <td>0.929793</td>\n",
       "      <td>0.437399</td>\n",
       "      <td>0.503226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5452</td>\n",
       "      <td>281901</td>\n",
       "      <td>19577</td>\n",
       "      <td>566</td>\n",
       "      <td>0.939816</td>\n",
       "      <td>0.217209</td>\n",
       "      <td>0.904885</td>\n",
       "      <td>0.350326</td>\n",
       "      <td>0.426681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6018</td>\n",
       "      <td>217887</td>\n",
       "      <td>83591</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44267</td>\n",
       "      <td>0.081676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151017</td>\n",
       "      <td>0.183797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4149</td>\n",
       "      <td>80988</td>\n",
       "      <td>3434</td>\n",
       "      <td>1869</td>\n",
       "      <td>0.941364</td>\n",
       "      <td>0.547145</td>\n",
       "      <td>0.689432</td>\n",
       "      <td>0.610102</td>\n",
       "      <td>0.583377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4092</td>\n",
       "      <td>80554</td>\n",
       "      <td>3868</td>\n",
       "      <td>1926</td>\n",
       "      <td>0.935935</td>\n",
       "      <td>0.51407</td>\n",
       "      <td>0.67996</td>\n",
       "      <td>0.585491</td>\n",
       "      <td>0.557840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2976</td>\n",
       "      <td>82972</td>\n",
       "      <td>1450</td>\n",
       "      <td>3042</td>\n",
       "      <td>0.950332</td>\n",
       "      <td>0.67239</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.569897</td>\n",
       "      <td>0.551432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5339</td>\n",
       "      <td>47422</td>\n",
       "      <td>37000</td>\n",
       "      <td>679</td>\n",
       "      <td>0.583381</td>\n",
       "      <td>0.126101</td>\n",
       "      <td>0.887172</td>\n",
       "      <td>0.220816</td>\n",
       "      <td>0.224209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4478</td>\n",
       "      <td>77802</td>\n",
       "      <td>6620</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.403496</td>\n",
       "      <td>0.744101</td>\n",
       "      <td>0.523253</td>\n",
       "      <td>0.505649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4267</td>\n",
       "      <td>78129</td>\n",
       "      <td>6293</td>\n",
       "      <td>1751</td>\n",
       "      <td>0.911057</td>\n",
       "      <td>0.404072</td>\n",
       "      <td>0.70904</td>\n",
       "      <td>0.514779</td>\n",
       "      <td>0.492417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4934</td>\n",
       "      <td>79490</td>\n",
       "      <td>4932</td>\n",
       "      <td>1084</td>\n",
       "      <td>0.933481</td>\n",
       "      <td>0.500101</td>\n",
       "      <td>0.819874</td>\n",
       "      <td>0.621254</td>\n",
       "      <td>0.608736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5448</td>\n",
       "      <td>46592</td>\n",
       "      <td>37830</td>\n",
       "      <td>570</td>\n",
       "      <td>0.575409</td>\n",
       "      <td>0.125884</td>\n",
       "      <td>0.905284</td>\n",
       "      <td>0.221032</td>\n",
       "      <td>0.228092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                                \n",
       "max_u_regressor_sparse    lr     3671  295704    6756  1365         0.975707   \n",
       "                          gb     3916  299157    3303  1120         0.987745   \n",
       "                          xgb    4748  292152   10308   288         0.967555   \n",
       "                          svr    4712  268831   33629   324         0.895444   \n",
       "                          mlp    5036  203962   98498     0         0.420708   \n",
       "max_u_regressor_focused   lr     4250  298058    4402   786         0.957173   \n",
       "                          gb     4924  240377   62083   112         0.828385   \n",
       "                          xgb    4971  154066  148394    65         0.555002   \n",
       "                          svr    5002  230283   72177    34         0.778019   \n",
       "                          mlp    3572  203649   98811  1464         0.701026   \n",
       "max_u_filtered_regressor  lr     3671   78648    6756  1365         0.915323   \n",
       "                          gb     3897   82212    3192  1139         0.958275   \n",
       "                          xgb    5036     712   84692     0         0.054418   \n",
       "                          svr    4455   49419   35985   581         0.601283   \n",
       "                          mlp    5036       1   85403     0          0.05707   \n",
       "max_u_regressor_balanced  lr     4855  278759   23701   181         0.930287   \n",
       "                          gb     4396  296857    5603   640          0.98262   \n",
       "                          xgb    4617  293585    8875   419         0.973091   \n",
       "                          svr    4301  293761    8699   735         0.971903   \n",
       "                          mlp    5013  226007   76453    23         0.979983   \n",
       "max_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     2598   83124    2280  2438         0.947833   \n",
       "                          xgb    1867   84013    1391  3169          0.94958   \n",
       "                          svr       0   85404       0  5036         0.944317   \n",
       "                          mlp    3979   59448   25956  1057         0.701316   \n",
       "max_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     3546   81683    3721  1490         0.942382   \n",
       "                          xgb    3180   83080    2324  1856         0.953782   \n",
       "                          svr    4029   80498    4906  1007          0.93462   \n",
       "                          mlp    3961   49320   36084  1075         0.589131   \n",
       "min_u_regressor_sparse    lr     2978  296439    5039  3040         0.976296   \n",
       "                          gb     5322  293242    8236   696         0.974264   \n",
       "                          xgb    5162  292073    9405   856          0.97033   \n",
       "                          svr    5575  266504   34974   443         0.892789   \n",
       "                          mlp    6011  229092   72386     7         0.957692   \n",
       "min_u_regressor_focused   lr     6009  234851   66627     9         0.828677   \n",
       "                          gb     5891  248922   52556   127         0.856077   \n",
       "                          xgb    5936  242553   58925    82          0.84589   \n",
       "                          svr    5996  241247   60231    22         0.826397   \n",
       "                          mlp    2617  232520   68958  3401         0.770289   \n",
       "min_u_filtered_regressor  lr     2978   79383    5039  3040         0.917579   \n",
       "                          gb     5262   76391    8031   756           0.9123   \n",
       "                          xgb    5273   77092    7330   745         0.919196   \n",
       "                          svr    5447   64051   20371   571         0.778377   \n",
       "                          mlp    5792   29373   55049   226         0.682453   \n",
       "min_u_regressor_balanced  lr     5263  281549   19929   755         0.938965   \n",
       "                          gb     5304  289766   11712   714         0.964194   \n",
       "                          xgb    5596  288017   13461   422         0.959203   \n",
       "                          svr    5452  281901   19577   566         0.939816   \n",
       "                          mlp    6018  217887   83591     0          0.44267   \n",
       "min_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4149   80988    3434  1869         0.941364   \n",
       "                          xgb    4092   80554    3868  1926         0.935935   \n",
       "                          svr    2976   82972    1450  3042         0.950332   \n",
       "                          mlp    5339   47422   37000   679         0.583381   \n",
       "min_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4478   77802    6620  1540         0.909774   \n",
       "                          xgb    4267   78129    6293  1751         0.911057   \n",
       "                          svr    4934   79490    4932  1084         0.933481   \n",
       "                          mlp    5448   46592   37830   570         0.575409   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_regressor_sparse    lr             0.275935       0.692488   0.394624   \n",
       "                          gb             0.498915       0.755742   0.601043   \n",
       "                          xgb            0.274727       0.933765   0.424546   \n",
       "                          svr            0.102448       0.928593   0.184537   \n",
       "                          mlp            0.053948            1.0   0.102374   \n",
       "max_u_regressor_focused   lr             0.497321       0.865045   0.631556   \n",
       "                          gb             0.072713       0.975359   0.135337   \n",
       "                          xgb            0.031938       0.986185   0.061873   \n",
       "                          svr            0.059362       0.992966   0.112027   \n",
       "                          mlp            0.034321       0.747112   0.065628   \n",
       "max_u_filtered_regressor  lr             0.275935       0.692488   0.394624   \n",
       "                          gb             0.502028       0.749402   0.601266   \n",
       "                          xgb            0.046716            1.0   0.089263   \n",
       "                          svr            0.090107       0.878752   0.163454   \n",
       "                          mlp            0.057071            1.0   0.107979   \n",
       "max_u_regressor_balanced  lr               0.1597       0.961609    0.27391   \n",
       "                          gb             0.423158       0.868357   0.569025   \n",
       "                          xgb            0.320434       0.911948   0.474235   \n",
       "                          svr            0.314354       0.856756   0.459947   \n",
       "                          mlp            0.057633       1.000342   0.108987   \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.532595       0.515886   0.524107   \n",
       "                          xgb            0.573051       0.370731   0.450205   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.132921       0.790111    0.22756   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.487959        0.70413   0.576445   \n",
       "                          xgb            0.577762       0.631454   0.603416   \n",
       "                          svr            0.450923        0.80004   0.576766   \n",
       "                          mlp            0.098914       0.786537   0.175728   \n",
       "min_u_regressor_sparse    lr             0.324899       0.470704   0.384441   \n",
       "                          gb             0.385312       0.885434   0.536957   \n",
       "                          xgb            0.344235       0.858975   0.491501   \n",
       "                          svr            0.131861        0.92292   0.230754   \n",
       "                          mlp            0.075117       0.999552   0.139732   \n",
       "min_u_regressor_focused   lr             0.093785       0.998395   0.171463   \n",
       "                          gb             0.108228       0.977798   0.194885   \n",
       "                          xgb            0.103075       0.985416   0.186629   \n",
       "                          svr            0.090706       0.995955    0.16627   \n",
       "                          mlp            0.034413       0.468941    0.06412   \n",
       "min_u_filtered_regressor  lr             0.324899       0.470704   0.384441   \n",
       "                          gb             0.389289       0.876206   0.539073   \n",
       "                          xgb            0.411138       0.875964   0.559617   \n",
       "                          svr            0.203083       0.901347   0.331481   \n",
       "                          mlp            0.014383       1.110404   0.028397   \n",
       "min_u_regressor_balanced  lr             0.199563       0.869791   0.324642   \n",
       "                          gb             0.305848       0.882862    0.45431   \n",
       "                          xgb            0.285961       0.929793   0.437399   \n",
       "                          svr            0.217209       0.904885   0.350326   \n",
       "                          mlp            0.081676            1.0   0.151017   \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.547145       0.689432   0.610102   \n",
       "                          xgb             0.51407        0.67996   0.585491   \n",
       "                          svr             0.67239       0.494516   0.569897   \n",
       "                          mlp            0.126101       0.887172   0.220816   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.403496       0.744101   0.523253   \n",
       "                          xgb            0.404072        0.70904   0.514779   \n",
       "                          svr            0.500101       0.819874   0.621254   \n",
       "                          mlp            0.125884       0.905284   0.221032   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "max_u_regressor_sparse    lr        0.427611  \n",
       "                          gb        0.608358  \n",
       "                          xgb       0.496928  \n",
       "                          svr       0.289015  \n",
       "                          mlp       0.147067  \n",
       "max_u_regressor_focused   lr        0.637046  \n",
       "                          gb        0.240749  \n",
       "                          xgb       0.129897  \n",
       "                          svr       0.213272  \n",
       "                          mlp       0.114311  \n",
       "max_u_filtered_regressor  lr        0.402325  \n",
       "                          gb        0.593148  \n",
       "                          xgb       0.019893  \n",
       "                          svr       0.194093  \n",
       "                          mlp       0.000000  \n",
       "max_u_regressor_balanced  lr        0.376638  \n",
       "                          gb        0.599350  \n",
       "                          xgb       0.531773  \n",
       "                          svr       0.509193  \n",
       "                          mlp       0.237693  \n",
       "max_u_classifier          lr             NaN  \n",
       "                          gb        0.496589  \n",
       "                          xgb       0.436154  \n",
       "                          svr       0.436154  \n",
       "                          mlp       0.236921  \n",
       "max_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.557219  \n",
       "                          xgb       0.579572  \n",
       "                          svr       0.570683  \n",
       "                          mlp       0.168054  \n",
       "min_u_regressor_sparse    lr        0.379444  \n",
       "                          gb        0.574551  \n",
       "                          xgb       0.532996  \n",
       "                          svr       0.325950  \n",
       "                          mlp       0.268128  \n",
       "min_u_regressor_focused   lr        0.277939  \n",
       "                          gb        0.299362  \n",
       "                          xgb       0.291826  \n",
       "                          svr       0.272487  \n",
       "                          mlp       0.074741  \n",
       "min_u_filtered_regressor  lr        0.348618  \n",
       "                          gb        0.548845  \n",
       "                          xgb       0.566921  \n",
       "                          svr       0.361775  \n",
       "                          mlp       0.109162  \n",
       "min_u_regressor_balanced  lr        0.399644  \n",
       "                          gb        0.507674  \n",
       "                          xgb       0.503226  \n",
       "                          svr       0.426681  \n",
       "                          mlp       0.183797  \n",
       "min_u_classifier          lr             NaN  \n",
       "                          gb        0.583377  \n",
       "                          xgb       0.557840  \n",
       "                          svr       0.551432  \n",
       "                          mlp       0.224209  \n",
       "min_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.505649  \n",
       "                          xgb       0.492417  \n",
       "                          svr       0.608736  \n",
       "                          mlp       0.228092  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>possible_positives</th>\n",
       "      <th>possible_negatives</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>302460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>85404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6018</td>\n",
       "      <td>301478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6018</td>\n",
       "      <td>84422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                possible_positives possible_negatives\n",
       "experiment                class                                      \n",
       "max_u_regressor_sparse    lr                  5036             302460\n",
       "                          gb                  5036             302460\n",
       "                          xgb                 5036             302460\n",
       "                          svr                 5036             302460\n",
       "                          mlp                 5036             302460\n",
       "max_u_regressor_focused   lr                  5036             302460\n",
       "                          gb                  5036             302460\n",
       "                          xgb                 5036             302460\n",
       "                          svr                 5036             302460\n",
       "                          mlp                 5036             302460\n",
       "max_u_filtered_regressor  lr                  5036              85404\n",
       "                          gb                  5036              85404\n",
       "                          xgb                 5036              85404\n",
       "                          svr                 5036              85404\n",
       "                          mlp                 5036              85404\n",
       "max_u_regressor_balanced  lr                  5036             302460\n",
       "                          gb                  5036             302460\n",
       "                          xgb                 5036             302460\n",
       "                          svr                 5036             302460\n",
       "                          mlp                 5036             302460\n",
       "max_u_classifier          lr                   NaN                NaN\n",
       "                          gb                  5036              85404\n",
       "                          xgb                 5036              85404\n",
       "                          svr                 5036              85404\n",
       "                          mlp                 5036              85404\n",
       "max_u_classifier_balanced lr                   NaN                NaN\n",
       "                          gb                  5036              85404\n",
       "                          xgb                 5036              85404\n",
       "                          svr                 5036              85404\n",
       "                          mlp                 5036              85404\n",
       "min_u_regressor_sparse    lr                  6018             301478\n",
       "                          gb                  6018             301478\n",
       "                          xgb                 6018             301478\n",
       "                          svr                 6018             301478\n",
       "                          mlp                 6018             301478\n",
       "min_u_regressor_focused   lr                  6018             301478\n",
       "                          gb                  6018             301478\n",
       "                          xgb                 6018             301478\n",
       "                          svr                 6018             301478\n",
       "                          mlp                 6018             301478\n",
       "min_u_filtered_regressor  lr                  6018              84422\n",
       "                          gb                  6018              84422\n",
       "                          xgb                 6018              84422\n",
       "                          svr                 6018              84422\n",
       "                          mlp                 6018              84422\n",
       "min_u_regressor_balanced  lr                  6018             301478\n",
       "                          gb                  6018             301478\n",
       "                          xgb                 6018             301478\n",
       "                          svr                 6018             301478\n",
       "                          mlp                 6018             301478\n",
       "min_u_classifier          lr                   NaN                NaN\n",
       "                          gb                  6018              84422\n",
       "                          xgb                 6018              84422\n",
       "                          svr                 6018              84422\n",
       "                          mlp                 6018              84422\n",
       "min_u_classifier_balanced lr                   NaN                NaN\n",
       "                          gb                  6018              84422\n",
       "                          xgb                 6018              84422\n",
       "                          svr                 6018              84422\n",
       "                          mlp                 6018              84422"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirmation_df = pd.DataFrame()\n",
    "confirmation_df['possible_positives'] = df['tp'] + df['fn']\n",
    "confirmation_df['possible_negatives'] = df['fp'] + df['tn']\n",
    "confirmation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscale everything\n",
    "testing_data['max_u_regressor_sparse'][model]['predicted'] = testing_data['max_u_regressor_sparse'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_sparse'][model]['real'] = testing_data['max_u_regressor_sparse'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_focused'][model]['predicted'] = testing_data['max_u_regressor_focused'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_focused'][model]['real'] = testing_data['max_u_regressor_focused'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_filtered_regressor'][model]['predicted'] = testing_data['max_u_filtered_regressor'][model]['predicted'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_filtered_regressor'][model]['real'] = testing_data['max_u_filtered_regressor'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['max_u_regressor_balanced'][model]['predicted'] = testing_data['max_u_regressor_balanced'][model]['predicted'] * data_max_u_balanced['scaler']['y']\n",
    "testing_data['max_u_regressor_balanced'][model]['real'] = testing_data['max_u_regressor_balanced'][model]['real'] * data_max_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_sparse'][model]['predicted'] = testing_data['min_u_regressor_sparse'][model]['predicted'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_sparse'][model]['real'] = testing_data['min_u_regressor_sparse'][model]['real'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_focused'][model]['predicted'] = testing_data['min_u_regressor_focused'][model]['predicted'] * data_min_u_focused['scaler']['y']\n",
    "testing_data['min_u_regressor_focused'][model]['real'] = testing_data['min_u_regressor_focused'][model]['real'] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_filtered_regressor'][model]['predicted'] = testing_data['min_u_filtered_regressor'][model]['predicted'] * data_min_u_sparse['scaler']['y'] \n",
    "testing_data['min_u_filtered_regressor'][model]['real'] = testing_data['min_u_filtered_regressor'][model]['real'][utils.cols_with_positive_values(prediction)] * data_min_u_sparse['scaler']['y']\n",
    "testing_data['min_u_regressor_balanced'][model]['predicted'] = testing_data['min_u_regressor_balanced'][model]['predicted'] * data_min_u_balanced['scaler']['y']\n",
    "testing_data['min_u_regressor_balanced'][model]['real'] = testing_data['min_u_regressor_balanced'][model]['real'] * data_min_u_sparse['scaler']['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to evaluate all the results obtained above. This benchmarking has the objective of obtaining the answer following questions:\n",
    "- What is the optimum number of rows for the training data set? What is the respective model?\n",
    "    - sparse reg. vs balanced reg. vs focused reg.\n",
    "- What is the optimum number present busses in regresison?\n",
    "    - sparse reg. vs filtered reg.\n",
    "- Regression vs Classification\n",
    "    - filtered reg. vs sparse class.\n",
    "- What is the optimum number of rows in class?\n",
    "    - sparse class. vs balanced class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum proportion of P/N rows for the training data set? What is the respective model?\n",
    "In order to understand the optinum number of rows for the training set of the regression data set the data sets used will be:\n",
    "\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Maximum Voltage Constraints|Balanced Regression|6971|34|\n",
    "|Maximum Voltage Constraints|Focused Regression|3486|34|\n",
    "|Minimum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Minimum Voltage Constraints|Balanced Regression|13917|34|\n",
    "|Minimum Voltage Constraints|Focused Regression|6958|34|\n",
    "\n",
    "The **Sparse Regression data set** is generated directly from the power flow results. The important moments are those where the constraints are violated, so the output feature contains null values for when there is no constraint, and positive value for when there is a constraint. The positive values represent the amplitude of the constraint violation. It can be expressed as follows:\n",
    "$$\n",
    "    \\begin{align}\n",
    "        \\text{Target} &= \\begin{cases}\n",
    "            0 & \\text{if} \\; \\text{constraint} \\; \\text{is not violated} \\\\\n",
    "            \\text{amplitude of constraint} & \\text{if} \\; \\text{constraint} \\; \\text{is violated} \\\\\n",
    "        \\end{cases}\n",
    "    \\end{align}\n",
    "$$\n",
    "In our case, the constraints are being considered as the following:\n",
    "- Minimal voltage on bus: $v_bus < 0.95 \\text{ [pu]}$ (constraint is violated if the voltage is below $0.95 \\text{ [pu]} $)\n",
    "- Maximal voltage on bus: $v_bus > 1.05 \\text{ [pu]}$ (constraint is violated if the voltage is above $1.05 \\text{ [pu]} $)\n",
    "- Maximal current on line: $i_{line} > 1 \\text{ [kA]}$ (constraint is violated if the current is above $1 \\text{ [kA]} $)\n",
    "\n",
    "The **Balanced Regression** data set is created from the **Sparse Regression data set**. It is created by taking all the rows that containt at least one constraint violation and then taking the same number of rows that do not contain any constraint violation. Finally, the **Focused Regression data set** is created by taking all the rows that contain at least one constraint violation.\n",
    "\n",
    "Since these data sets have the same number of possible negative and possible positives, all the metrics can be used to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3671</td>\n",
       "      <td>295704</td>\n",
       "      <td>6756</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.975707</td>\n",
       "      <td>0.275935</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>0.427611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3916</td>\n",
       "      <td>299157</td>\n",
       "      <td>3303</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.498915</td>\n",
       "      <td>0.755742</td>\n",
       "      <td>0.601043</td>\n",
       "      <td>0.608358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4748</td>\n",
       "      <td>292152</td>\n",
       "      <td>10308</td>\n",
       "      <td>288</td>\n",
       "      <td>0.967555</td>\n",
       "      <td>0.274727</td>\n",
       "      <td>0.933765</td>\n",
       "      <td>0.424546</td>\n",
       "      <td>0.496928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4712</td>\n",
       "      <td>268831</td>\n",
       "      <td>33629</td>\n",
       "      <td>324</td>\n",
       "      <td>0.895444</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>0.928593</td>\n",
       "      <td>0.184537</td>\n",
       "      <td>0.289015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>203962</td>\n",
       "      <td>98498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420708</td>\n",
       "      <td>0.053948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.147067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4855</td>\n",
       "      <td>278759</td>\n",
       "      <td>23701</td>\n",
       "      <td>181</td>\n",
       "      <td>0.930287</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.961609</td>\n",
       "      <td>0.27391</td>\n",
       "      <td>0.376638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4396</td>\n",
       "      <td>296857</td>\n",
       "      <td>5603</td>\n",
       "      <td>640</td>\n",
       "      <td>0.98262</td>\n",
       "      <td>0.423158</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.569025</td>\n",
       "      <td>0.599350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4617</td>\n",
       "      <td>293585</td>\n",
       "      <td>8875</td>\n",
       "      <td>419</td>\n",
       "      <td>0.973091</td>\n",
       "      <td>0.320434</td>\n",
       "      <td>0.911948</td>\n",
       "      <td>0.474235</td>\n",
       "      <td>0.531773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4301</td>\n",
       "      <td>293761</td>\n",
       "      <td>8699</td>\n",
       "      <td>735</td>\n",
       "      <td>0.971903</td>\n",
       "      <td>0.314354</td>\n",
       "      <td>0.856756</td>\n",
       "      <td>0.459947</td>\n",
       "      <td>0.509193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5013</td>\n",
       "      <td>226007</td>\n",
       "      <td>76453</td>\n",
       "      <td>23</td>\n",
       "      <td>0.979983</td>\n",
       "      <td>0.057633</td>\n",
       "      <td>1.000342</td>\n",
       "      <td>0.108987</td>\n",
       "      <td>0.237693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4250</td>\n",
       "      <td>298058</td>\n",
       "      <td>4402</td>\n",
       "      <td>786</td>\n",
       "      <td>0.957173</td>\n",
       "      <td>0.497321</td>\n",
       "      <td>0.865045</td>\n",
       "      <td>0.631556</td>\n",
       "      <td>0.637046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4924</td>\n",
       "      <td>240377</td>\n",
       "      <td>62083</td>\n",
       "      <td>112</td>\n",
       "      <td>0.828385</td>\n",
       "      <td>0.072713</td>\n",
       "      <td>0.975359</td>\n",
       "      <td>0.135337</td>\n",
       "      <td>0.240749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4971</td>\n",
       "      <td>154066</td>\n",
       "      <td>148394</td>\n",
       "      <td>65</td>\n",
       "      <td>0.555002</td>\n",
       "      <td>0.031938</td>\n",
       "      <td>0.986185</td>\n",
       "      <td>0.061873</td>\n",
       "      <td>0.129897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5002</td>\n",
       "      <td>230283</td>\n",
       "      <td>72177</td>\n",
       "      <td>34</td>\n",
       "      <td>0.778019</td>\n",
       "      <td>0.059362</td>\n",
       "      <td>0.992966</td>\n",
       "      <td>0.112027</td>\n",
       "      <td>0.213272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3572</td>\n",
       "      <td>203649</td>\n",
       "      <td>98811</td>\n",
       "      <td>1464</td>\n",
       "      <td>0.701026</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>0.747112</td>\n",
       "      <td>0.065628</td>\n",
       "      <td>0.114311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                                \n",
       "max_u_regressor_sparse   lr     3671  295704    6756  1365         0.975707   \n",
       "                         gb     3916  299157    3303  1120         0.987745   \n",
       "                         xgb    4748  292152   10308   288         0.967555   \n",
       "                         svr    4712  268831   33629   324         0.895444   \n",
       "                         mlp    5036  203962   98498     0         0.420708   \n",
       "max_u_regressor_balanced lr     4855  278759   23701   181         0.930287   \n",
       "                         gb     4396  296857    5603   640          0.98262   \n",
       "                         xgb    4617  293585    8875   419         0.973091   \n",
       "                         svr    4301  293761    8699   735         0.971903   \n",
       "                         mlp    5013  226007   76453    23         0.979983   \n",
       "max_u_regressor_focused  lr     4250  298058    4402   786         0.957173   \n",
       "                         gb     4924  240377   62083   112         0.828385   \n",
       "                         xgb    4971  154066  148394    65         0.555002   \n",
       "                         svr    5002  230283   72177    34         0.778019   \n",
       "                         mlp    3572  203649   98811  1464         0.701026   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr             0.275935       0.692488   0.394624   \n",
       "                         gb             0.498915       0.755742   0.601043   \n",
       "                         xgb            0.274727       0.933765   0.424546   \n",
       "                         svr            0.102448       0.928593   0.184537   \n",
       "                         mlp            0.053948            1.0   0.102374   \n",
       "max_u_regressor_balanced lr               0.1597       0.961609    0.27391   \n",
       "                         gb             0.423158       0.868357   0.569025   \n",
       "                         xgb            0.320434       0.911948   0.474235   \n",
       "                         svr            0.314354       0.856756   0.459947   \n",
       "                         mlp            0.057633       1.000342   0.108987   \n",
       "max_u_regressor_focused  lr             0.497321       0.865045   0.631556   \n",
       "                         gb             0.072713       0.975359   0.135337   \n",
       "                         xgb            0.031938       0.986185   0.061873   \n",
       "                         svr            0.059362       0.992966   0.112027   \n",
       "                         mlp            0.034321       0.747112   0.065628   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_regressor_sparse   lr        0.427611  \n",
       "                         gb        0.608358  \n",
       "                         xgb       0.496928  \n",
       "                         svr       0.289015  \n",
       "                         mlp       0.147067  \n",
       "max_u_regressor_balanced lr        0.376638  \n",
       "                         gb        0.599350  \n",
       "                         xgb       0.531773  \n",
       "                         svr       0.509193  \n",
       "                         mlp       0.237693  \n",
       "max_u_regressor_focused  lr        0.637046  \n",
       "                         gb        0.240749  \n",
       "                         xgb       0.129897  \n",
       "                         svr       0.213272  \n",
       "                         mlp       0.114311  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_regressor_sparse', 'max_u_regressor_balanced', 'max_u_regressor_focused']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best alternative is to use the focused data set with a the linear regression model, because it presents a the best values for F1 and MCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2978</td>\n",
       "      <td>296439</td>\n",
       "      <td>5039</td>\n",
       "      <td>3040</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>0.324899</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.384441</td>\n",
       "      <td>0.379444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5322</td>\n",
       "      <td>293242</td>\n",
       "      <td>8236</td>\n",
       "      <td>696</td>\n",
       "      <td>0.974264</td>\n",
       "      <td>0.385312</td>\n",
       "      <td>0.885434</td>\n",
       "      <td>0.536957</td>\n",
       "      <td>0.574551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5162</td>\n",
       "      <td>292073</td>\n",
       "      <td>9405</td>\n",
       "      <td>856</td>\n",
       "      <td>0.97033</td>\n",
       "      <td>0.344235</td>\n",
       "      <td>0.858975</td>\n",
       "      <td>0.491501</td>\n",
       "      <td>0.532996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5575</td>\n",
       "      <td>266504</td>\n",
       "      <td>34974</td>\n",
       "      <td>443</td>\n",
       "      <td>0.892789</td>\n",
       "      <td>0.131861</td>\n",
       "      <td>0.92292</td>\n",
       "      <td>0.230754</td>\n",
       "      <td>0.325950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6011</td>\n",
       "      <td>229092</td>\n",
       "      <td>72386</td>\n",
       "      <td>7</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.075117</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.139732</td>\n",
       "      <td>0.268128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5263</td>\n",
       "      <td>281549</td>\n",
       "      <td>19929</td>\n",
       "      <td>755</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>0.199563</td>\n",
       "      <td>0.869791</td>\n",
       "      <td>0.324642</td>\n",
       "      <td>0.399644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5304</td>\n",
       "      <td>289766</td>\n",
       "      <td>11712</td>\n",
       "      <td>714</td>\n",
       "      <td>0.964194</td>\n",
       "      <td>0.305848</td>\n",
       "      <td>0.882862</td>\n",
       "      <td>0.45431</td>\n",
       "      <td>0.507674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5596</td>\n",
       "      <td>288017</td>\n",
       "      <td>13461</td>\n",
       "      <td>422</td>\n",
       "      <td>0.959203</td>\n",
       "      <td>0.285961</td>\n",
       "      <td>0.929793</td>\n",
       "      <td>0.437399</td>\n",
       "      <td>0.503226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5452</td>\n",
       "      <td>281901</td>\n",
       "      <td>19577</td>\n",
       "      <td>566</td>\n",
       "      <td>0.939816</td>\n",
       "      <td>0.217209</td>\n",
       "      <td>0.904885</td>\n",
       "      <td>0.350326</td>\n",
       "      <td>0.426681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6018</td>\n",
       "      <td>217887</td>\n",
       "      <td>83591</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44267</td>\n",
       "      <td>0.081676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151017</td>\n",
       "      <td>0.183797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>6009</td>\n",
       "      <td>234851</td>\n",
       "      <td>66627</td>\n",
       "      <td>9</td>\n",
       "      <td>0.828677</td>\n",
       "      <td>0.093785</td>\n",
       "      <td>0.998395</td>\n",
       "      <td>0.171463</td>\n",
       "      <td>0.277939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5891</td>\n",
       "      <td>248922</td>\n",
       "      <td>52556</td>\n",
       "      <td>127</td>\n",
       "      <td>0.856077</td>\n",
       "      <td>0.108228</td>\n",
       "      <td>0.977798</td>\n",
       "      <td>0.194885</td>\n",
       "      <td>0.299362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5936</td>\n",
       "      <td>242553</td>\n",
       "      <td>58925</td>\n",
       "      <td>82</td>\n",
       "      <td>0.84589</td>\n",
       "      <td>0.103075</td>\n",
       "      <td>0.985416</td>\n",
       "      <td>0.186629</td>\n",
       "      <td>0.291826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5996</td>\n",
       "      <td>241247</td>\n",
       "      <td>60231</td>\n",
       "      <td>22</td>\n",
       "      <td>0.826397</td>\n",
       "      <td>0.090706</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.16627</td>\n",
       "      <td>0.272487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>2617</td>\n",
       "      <td>232520</td>\n",
       "      <td>68958</td>\n",
       "      <td>3401</td>\n",
       "      <td>0.770289</td>\n",
       "      <td>0.034413</td>\n",
       "      <td>0.468941</td>\n",
       "      <td>0.06412</td>\n",
       "      <td>0.074741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr     2978  296439   5039  3040         0.976296   \n",
       "                         gb     5322  293242   8236   696         0.974264   \n",
       "                         xgb    5162  292073   9405   856          0.97033   \n",
       "                         svr    5575  266504  34974   443         0.892789   \n",
       "                         mlp    6011  229092  72386     7         0.957692   \n",
       "min_u_regressor_balanced lr     5263  281549  19929   755         0.938965   \n",
       "                         gb     5304  289766  11712   714         0.964194   \n",
       "                         xgb    5596  288017  13461   422         0.959203   \n",
       "                         svr    5452  281901  19577   566         0.939816   \n",
       "                         mlp    6018  217887  83591     0          0.44267   \n",
       "min_u_regressor_focused  lr     6009  234851  66627     9         0.828677   \n",
       "                         gb     5891  248922  52556   127         0.856077   \n",
       "                         xgb    5936  242553  58925    82          0.84589   \n",
       "                         svr    5996  241247  60231    22         0.826397   \n",
       "                         mlp    2617  232520  68958  3401         0.770289   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr             0.324899       0.470704   0.384441   \n",
       "                         gb             0.385312       0.885434   0.536957   \n",
       "                         xgb            0.344235       0.858975   0.491501   \n",
       "                         svr            0.131861        0.92292   0.230754   \n",
       "                         mlp            0.075117       0.999552   0.139732   \n",
       "min_u_regressor_balanced lr             0.199563       0.869791   0.324642   \n",
       "                         gb             0.305848       0.882862    0.45431   \n",
       "                         xgb            0.285961       0.929793   0.437399   \n",
       "                         svr            0.217209       0.904885   0.350326   \n",
       "                         mlp            0.081676            1.0   0.151017   \n",
       "min_u_regressor_focused  lr             0.093785       0.998395   0.171463   \n",
       "                         gb             0.108228       0.977798   0.194885   \n",
       "                         xgb            0.103075       0.985416   0.186629   \n",
       "                         svr            0.090706       0.995955    0.16627   \n",
       "                         mlp            0.034413       0.468941    0.06412   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_regressor_sparse   lr        0.379444  \n",
       "                         gb        0.574551  \n",
       "                         xgb       0.532996  \n",
       "                         svr       0.325950  \n",
       "                         mlp       0.268128  \n",
       "min_u_regressor_balanced lr        0.399644  \n",
       "                         gb        0.507674  \n",
       "                         xgb       0.503226  \n",
       "                         svr       0.426681  \n",
       "                         mlp       0.183797  \n",
       "min_u_regressor_focused  lr        0.277939  \n",
       "                         gb        0.299362  \n",
       "                         xgb       0.291826  \n",
       "                         svr       0.272487  \n",
       "                         mlp       0.074741  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_regressor_sparse', 'min_u_regressor_balanced', 'min_u_regressor_focused']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best sparse, with gradient boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum number present busses in regresison?\n",
    "In order to understand the optinum number of busses for the training set of the regression data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Maximum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Minimum Voltage Constraints|Sparse Regression|45216|34|\n",
    "|Minimum Voltage Constraints|Filtered Regression|45216|10|\n",
    "\n",
    "The **Filtered Regression data set** is created from the Sparse Regression data set, but only keeping the columns that contain at least one time step with a constraint violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3671</td>\n",
       "      <td>295704</td>\n",
       "      <td>6756</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.975707</td>\n",
       "      <td>0.275935</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>0.427611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3916</td>\n",
       "      <td>299157</td>\n",
       "      <td>3303</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.498915</td>\n",
       "      <td>0.755742</td>\n",
       "      <td>0.601043</td>\n",
       "      <td>0.608358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4748</td>\n",
       "      <td>292152</td>\n",
       "      <td>10308</td>\n",
       "      <td>288</td>\n",
       "      <td>0.967555</td>\n",
       "      <td>0.274727</td>\n",
       "      <td>0.933765</td>\n",
       "      <td>0.424546</td>\n",
       "      <td>0.496928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4712</td>\n",
       "      <td>268831</td>\n",
       "      <td>33629</td>\n",
       "      <td>324</td>\n",
       "      <td>0.895444</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>0.928593</td>\n",
       "      <td>0.184537</td>\n",
       "      <td>0.289015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>203962</td>\n",
       "      <td>98498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420708</td>\n",
       "      <td>0.053948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.147067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3671</td>\n",
       "      <td>78648</td>\n",
       "      <td>6756</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.915323</td>\n",
       "      <td>0.275935</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>0.402325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3897</td>\n",
       "      <td>82212</td>\n",
       "      <td>3192</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.958275</td>\n",
       "      <td>0.502028</td>\n",
       "      <td>0.749402</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.593148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>712</td>\n",
       "      <td>84692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089263</td>\n",
       "      <td>0.019893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4455</td>\n",
       "      <td>49419</td>\n",
       "      <td>35985</td>\n",
       "      <td>581</td>\n",
       "      <td>0.601283</td>\n",
       "      <td>0.090107</td>\n",
       "      <td>0.878752</td>\n",
       "      <td>0.163454</td>\n",
       "      <td>0.194093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>1</td>\n",
       "      <td>85403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05707</td>\n",
       "      <td>0.057071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.107979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr     3671  295704   6756  1365         0.975707   \n",
       "                         gb     3916  299157   3303  1120         0.987745   \n",
       "                         xgb    4748  292152  10308   288         0.967555   \n",
       "                         svr    4712  268831  33629   324         0.895444   \n",
       "                         mlp    5036  203962  98498     0         0.420708   \n",
       "max_u_filtered_regressor lr     3671   78648   6756  1365         0.915323   \n",
       "                         gb     3897   82212   3192  1139         0.958275   \n",
       "                         xgb    5036     712  84692     0         0.054418   \n",
       "                         svr    4455   49419  35985   581         0.601283   \n",
       "                         mlp    5036       1  85403     0          0.05707   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_regressor_sparse   lr             0.275935       0.692488   0.394624   \n",
       "                         gb             0.498915       0.755742   0.601043   \n",
       "                         xgb            0.274727       0.933765   0.424546   \n",
       "                         svr            0.102448       0.928593   0.184537   \n",
       "                         mlp            0.053948            1.0   0.102374   \n",
       "max_u_filtered_regressor lr             0.275935       0.692488   0.394624   \n",
       "                         gb             0.502028       0.749402   0.601266   \n",
       "                         xgb            0.046716            1.0   0.089263   \n",
       "                         svr            0.090107       0.878752   0.163454   \n",
       "                         mlp            0.057071            1.0   0.107979   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_regressor_sparse   lr        0.427611  \n",
       "                         gb        0.608358  \n",
       "                         xgb       0.496928  \n",
       "                         svr       0.289015  \n",
       "                         mlp       0.147067  \n",
       "max_u_filtered_regressor lr        0.402325  \n",
       "                         gb        0.593148  \n",
       "                         xgb       0.019893  \n",
       "                         svr       0.194093  \n",
       "                         mlp       0.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_regressor_sparse', 'max_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse, with GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2978</td>\n",
       "      <td>296439</td>\n",
       "      <td>5039</td>\n",
       "      <td>3040</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>0.324899</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.384441</td>\n",
       "      <td>0.379444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5322</td>\n",
       "      <td>293242</td>\n",
       "      <td>8236</td>\n",
       "      <td>696</td>\n",
       "      <td>0.974264</td>\n",
       "      <td>0.385312</td>\n",
       "      <td>0.885434</td>\n",
       "      <td>0.536957</td>\n",
       "      <td>0.574551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5162</td>\n",
       "      <td>292073</td>\n",
       "      <td>9405</td>\n",
       "      <td>856</td>\n",
       "      <td>0.97033</td>\n",
       "      <td>0.344235</td>\n",
       "      <td>0.858975</td>\n",
       "      <td>0.491501</td>\n",
       "      <td>0.532996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5575</td>\n",
       "      <td>266504</td>\n",
       "      <td>34974</td>\n",
       "      <td>443</td>\n",
       "      <td>0.892789</td>\n",
       "      <td>0.131861</td>\n",
       "      <td>0.92292</td>\n",
       "      <td>0.230754</td>\n",
       "      <td>0.325950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6011</td>\n",
       "      <td>229092</td>\n",
       "      <td>72386</td>\n",
       "      <td>7</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.075117</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.139732</td>\n",
       "      <td>0.268128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2978</td>\n",
       "      <td>79383</td>\n",
       "      <td>5039</td>\n",
       "      <td>3040</td>\n",
       "      <td>0.917579</td>\n",
       "      <td>0.324899</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.384441</td>\n",
       "      <td>0.348618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5262</td>\n",
       "      <td>76391</td>\n",
       "      <td>8031</td>\n",
       "      <td>756</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.389289</td>\n",
       "      <td>0.876206</td>\n",
       "      <td>0.539073</td>\n",
       "      <td>0.548845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5273</td>\n",
       "      <td>77092</td>\n",
       "      <td>7330</td>\n",
       "      <td>745</td>\n",
       "      <td>0.919196</td>\n",
       "      <td>0.411138</td>\n",
       "      <td>0.875964</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>0.566921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5447</td>\n",
       "      <td>64051</td>\n",
       "      <td>20371</td>\n",
       "      <td>571</td>\n",
       "      <td>0.778377</td>\n",
       "      <td>0.203083</td>\n",
       "      <td>0.901347</td>\n",
       "      <td>0.331481</td>\n",
       "      <td>0.361775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5792</td>\n",
       "      <td>29373</td>\n",
       "      <td>55049</td>\n",
       "      <td>226</td>\n",
       "      <td>0.682453</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>1.110404</td>\n",
       "      <td>0.028397</td>\n",
       "      <td>0.109162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp      tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr     2978  296439   5039  3040         0.976296   \n",
       "                         gb     5322  293242   8236   696         0.974264   \n",
       "                         xgb    5162  292073   9405   856          0.97033   \n",
       "                         svr    5575  266504  34974   443         0.892789   \n",
       "                         mlp    6011  229092  72386     7         0.957692   \n",
       "min_u_filtered_regressor lr     2978   79383   5039  3040         0.917579   \n",
       "                         gb     5262   76391   8031   756           0.9123   \n",
       "                         xgb    5273   77092   7330   745         0.919196   \n",
       "                         svr    5447   64051  20371   571         0.778377   \n",
       "                         mlp    5792   29373  55049   226         0.682453   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_regressor_sparse   lr             0.324899       0.470704   0.384441   \n",
       "                         gb             0.385312       0.885434   0.536957   \n",
       "                         xgb            0.344235       0.858975   0.491501   \n",
       "                         svr            0.131861        0.92292   0.230754   \n",
       "                         mlp            0.075117       0.999552   0.139732   \n",
       "min_u_filtered_regressor lr             0.324899       0.470704   0.384441   \n",
       "                         gb             0.389289       0.876206   0.539073   \n",
       "                         xgb            0.411138       0.875964   0.559617   \n",
       "                         svr            0.203083       0.901347   0.331481   \n",
       "                         mlp            0.014383       1.110404   0.028397   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_regressor_sparse   lr        0.379444  \n",
       "                         gb        0.574551  \n",
       "                         xgb       0.532996  \n",
       "                         svr       0.325950  \n",
       "                         mlp       0.268128  \n",
       "min_u_filtered_regressor lr        0.348618  \n",
       "                         gb        0.548845  \n",
       "                         xgb       0.566921  \n",
       "                         svr       0.361775  \n",
       "                         mlp       0.109162  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_regressor_sparse', 'min_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse, with GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression vs Classification\n",
    "In order to understand the optinum number of busses for the training set of the regression data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Maximum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Minimum Voltage Constraints|Filtered Regression|45216|10|\n",
    "|Minimum Voltage Constraints|Sparse Classification|45216|10|\n",
    "\n",
    "The **Sparse Classification data set** is created from the Sparse Regression data set, but instead of having the target feature as the amplitude of the constraint violation, it is a binary feature that indicates if there is a constraint violation or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2598</td>\n",
       "      <td>83124</td>\n",
       "      <td>2280</td>\n",
       "      <td>2438</td>\n",
       "      <td>0.947833</td>\n",
       "      <td>0.532595</td>\n",
       "      <td>0.515886</td>\n",
       "      <td>0.524107</td>\n",
       "      <td>0.496589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1867</td>\n",
       "      <td>84013</td>\n",
       "      <td>1391</td>\n",
       "      <td>3169</td>\n",
       "      <td>0.94958</td>\n",
       "      <td>0.573051</td>\n",
       "      <td>0.370731</td>\n",
       "      <td>0.450205</td>\n",
       "      <td>0.436154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>85404</td>\n",
       "      <td>0</td>\n",
       "      <td>5036</td>\n",
       "      <td>0.944317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3979</td>\n",
       "      <td>59448</td>\n",
       "      <td>25956</td>\n",
       "      <td>1057</td>\n",
       "      <td>0.701316</td>\n",
       "      <td>0.132921</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>0.22756</td>\n",
       "      <td>0.236921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3671</td>\n",
       "      <td>78648</td>\n",
       "      <td>6756</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.915323</td>\n",
       "      <td>0.275935</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>0.402325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3897</td>\n",
       "      <td>82212</td>\n",
       "      <td>3192</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.958275</td>\n",
       "      <td>0.502028</td>\n",
       "      <td>0.749402</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.593148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>712</td>\n",
       "      <td>84692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089263</td>\n",
       "      <td>0.019893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4455</td>\n",
       "      <td>49419</td>\n",
       "      <td>35985</td>\n",
       "      <td>581</td>\n",
       "      <td>0.601283</td>\n",
       "      <td>0.090107</td>\n",
       "      <td>0.878752</td>\n",
       "      <td>0.163454</td>\n",
       "      <td>0.194093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>1</td>\n",
       "      <td>85403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05707</td>\n",
       "      <td>0.057071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.107979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                              \n",
       "max_u_classifier         lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                         gb     2598  83124   2280  2438         0.947833   \n",
       "                         xgb    1867  84013   1391  3169          0.94958   \n",
       "                         svr       0  85404      0  5036         0.944317   \n",
       "                         mlp    3979  59448  25956  1057         0.701316   \n",
       "max_u_filtered_regressor lr     3671  78648   6756  1365         0.915323   \n",
       "                         gb     3897  82212   3192  1139         0.958275   \n",
       "                         xgb    5036    712  84692     0         0.054418   \n",
       "                         svr    4455  49419  35985   581         0.601283   \n",
       "                         mlp    5036      1  85403     0          0.05707   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "max_u_classifier         lr                  NaN            NaN        NaN   \n",
       "                         gb             0.532595       0.515886   0.524107   \n",
       "                         xgb            0.573051       0.370731   0.450205   \n",
       "                         svr                   0            0.0          0   \n",
       "                         mlp            0.132921       0.790111    0.22756   \n",
       "max_u_filtered_regressor lr             0.275935       0.692488   0.394624   \n",
       "                         gb             0.502028       0.749402   0.601266   \n",
       "                         xgb            0.046716            1.0   0.089263   \n",
       "                         svr            0.090107       0.878752   0.163454   \n",
       "                         mlp            0.057071            1.0   0.107979   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "max_u_classifier         lr             NaN  \n",
       "                         gb        0.496589  \n",
       "                         xgb       0.436154  \n",
       "                         svr       0.436154  \n",
       "                         mlp       0.236921  \n",
       "max_u_filtered_regressor lr        0.402325  \n",
       "                         gb        0.593148  \n",
       "                         xgb       0.019893  \n",
       "                         svr       0.194093  \n",
       "                         mlp       0.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_classifier', 'max_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_u_filtered regressor with the gradient boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4149</td>\n",
       "      <td>80988</td>\n",
       "      <td>3434</td>\n",
       "      <td>1869</td>\n",
       "      <td>0.941364</td>\n",
       "      <td>0.547145</td>\n",
       "      <td>0.689432</td>\n",
       "      <td>0.610102</td>\n",
       "      <td>0.583377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4092</td>\n",
       "      <td>80554</td>\n",
       "      <td>3868</td>\n",
       "      <td>1926</td>\n",
       "      <td>0.935935</td>\n",
       "      <td>0.51407</td>\n",
       "      <td>0.67996</td>\n",
       "      <td>0.585491</td>\n",
       "      <td>0.557840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2976</td>\n",
       "      <td>82972</td>\n",
       "      <td>1450</td>\n",
       "      <td>3042</td>\n",
       "      <td>0.950332</td>\n",
       "      <td>0.67239</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.569897</td>\n",
       "      <td>0.551432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5339</td>\n",
       "      <td>47422</td>\n",
       "      <td>37000</td>\n",
       "      <td>679</td>\n",
       "      <td>0.583381</td>\n",
       "      <td>0.126101</td>\n",
       "      <td>0.887172</td>\n",
       "      <td>0.220816</td>\n",
       "      <td>0.224209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2978</td>\n",
       "      <td>79383</td>\n",
       "      <td>5039</td>\n",
       "      <td>3040</td>\n",
       "      <td>0.917579</td>\n",
       "      <td>0.324899</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.384441</td>\n",
       "      <td>0.348618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5262</td>\n",
       "      <td>76391</td>\n",
       "      <td>8031</td>\n",
       "      <td>756</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.389289</td>\n",
       "      <td>0.876206</td>\n",
       "      <td>0.539073</td>\n",
       "      <td>0.548845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5273</td>\n",
       "      <td>77092</td>\n",
       "      <td>7330</td>\n",
       "      <td>745</td>\n",
       "      <td>0.919196</td>\n",
       "      <td>0.411138</td>\n",
       "      <td>0.875964</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>0.566921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5447</td>\n",
       "      <td>64051</td>\n",
       "      <td>20371</td>\n",
       "      <td>571</td>\n",
       "      <td>0.778377</td>\n",
       "      <td>0.203083</td>\n",
       "      <td>0.901347</td>\n",
       "      <td>0.331481</td>\n",
       "      <td>0.361775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5792</td>\n",
       "      <td>29373</td>\n",
       "      <td>55049</td>\n",
       "      <td>226</td>\n",
       "      <td>0.682453</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>1.110404</td>\n",
       "      <td>0.028397</td>\n",
       "      <td>0.109162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment               class                                              \n",
       "min_u_classifier         lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                         gb     4149  80988   3434  1869         0.941364   \n",
       "                         xgb    4092  80554   3868  1926         0.935935   \n",
       "                         svr    2976  82972   1450  3042         0.950332   \n",
       "                         mlp    5339  47422  37000   679         0.583381   \n",
       "min_u_filtered_regressor lr     2978  79383   5039  3040         0.917579   \n",
       "                         gb     5262  76391   8031   756           0.9123   \n",
       "                         xgb    5273  77092   7330   745         0.919196   \n",
       "                         svr    5447  64051  20371   571         0.778377   \n",
       "                         mlp    5792  29373  55049   226         0.682453   \n",
       "\n",
       "                               (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment               class                                               \n",
       "min_u_classifier         lr                  NaN            NaN        NaN   \n",
       "                         gb             0.547145       0.689432   0.610102   \n",
       "                         xgb             0.51407        0.67996   0.585491   \n",
       "                         svr             0.67239       0.494516   0.569897   \n",
       "                         mlp            0.126101       0.887172   0.220816   \n",
       "min_u_filtered_regressor lr             0.324899       0.470704   0.384441   \n",
       "                         gb             0.389289       0.876206   0.539073   \n",
       "                         xgb            0.411138       0.875964   0.559617   \n",
       "                         svr            0.203083       0.901347   0.331481   \n",
       "                         mlp            0.014383       1.110404   0.028397   \n",
       "\n",
       "                                (hybrid)mcc  \n",
       "experiment               class               \n",
       "min_u_classifier         lr             NaN  \n",
       "                         gb        0.583377  \n",
       "                         xgb       0.557840  \n",
       "                         svr       0.551432  \n",
       "                         mlp       0.224209  \n",
       "min_u_filtered_regressor lr        0.348618  \n",
       "                         gb        0.548845  \n",
       "                         xgb       0.566921  \n",
       "                         svr       0.361775  \n",
       "                         mlp       0.109162  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_classifier', 'min_u_filtered_regressor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_u_classifier with the gradient boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimum number of rows in class?\n",
    "In order to understand the optinum number of rows for the training set of the classification data set the data sets used will be:\n",
    "|Experience| Data Set Name | Rows | Busses |\n",
    "|----------|---------------|------|--------|\n",
    "|Maximum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Maximum Voltage Constraints|Balanced Classification|6971|10|\n",
    "|Minimum Voltage Constraints|Sparse Classification|45216|10|\n",
    "|Minimum Voltage Constraints|Balanced Classification|13917|10|\n",
    "\n",
    "The **Balanced Classification data set** is created from the Sparse Classification data set. It is created by taking all the rows that containt at least one constraint violation and then taking the same number of rows that do not contain any constraint violation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2598</td>\n",
       "      <td>83124</td>\n",
       "      <td>2280</td>\n",
       "      <td>2438</td>\n",
       "      <td>0.947833</td>\n",
       "      <td>0.532595</td>\n",
       "      <td>0.515886</td>\n",
       "      <td>0.524107</td>\n",
       "      <td>0.496589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1867</td>\n",
       "      <td>84013</td>\n",
       "      <td>1391</td>\n",
       "      <td>3169</td>\n",
       "      <td>0.94958</td>\n",
       "      <td>0.573051</td>\n",
       "      <td>0.370731</td>\n",
       "      <td>0.450205</td>\n",
       "      <td>0.436154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>85404</td>\n",
       "      <td>0</td>\n",
       "      <td>5036</td>\n",
       "      <td>0.944317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3979</td>\n",
       "      <td>59448</td>\n",
       "      <td>25956</td>\n",
       "      <td>1057</td>\n",
       "      <td>0.701316</td>\n",
       "      <td>0.132921</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>0.22756</td>\n",
       "      <td>0.236921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3546</td>\n",
       "      <td>81683</td>\n",
       "      <td>3721</td>\n",
       "      <td>1490</td>\n",
       "      <td>0.942382</td>\n",
       "      <td>0.487959</td>\n",
       "      <td>0.70413</td>\n",
       "      <td>0.576445</td>\n",
       "      <td>0.557219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3180</td>\n",
       "      <td>83080</td>\n",
       "      <td>2324</td>\n",
       "      <td>1856</td>\n",
       "      <td>0.953782</td>\n",
       "      <td>0.577762</td>\n",
       "      <td>0.631454</td>\n",
       "      <td>0.603416</td>\n",
       "      <td>0.579572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4029</td>\n",
       "      <td>80498</td>\n",
       "      <td>4906</td>\n",
       "      <td>1007</td>\n",
       "      <td>0.93462</td>\n",
       "      <td>0.450923</td>\n",
       "      <td>0.80004</td>\n",
       "      <td>0.576766</td>\n",
       "      <td>0.570683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3961</td>\n",
       "      <td>49320</td>\n",
       "      <td>36084</td>\n",
       "      <td>1075</td>\n",
       "      <td>0.589131</td>\n",
       "      <td>0.098914</td>\n",
       "      <td>0.786537</td>\n",
       "      <td>0.175728</td>\n",
       "      <td>0.168054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                              \n",
       "max_u_classifier          lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     2598  83124   2280  2438         0.947833   \n",
       "                          xgb    1867  84013   1391  3169          0.94958   \n",
       "                          svr       0  85404      0  5036         0.944317   \n",
       "                          mlp    3979  59448  25956  1057         0.701316   \n",
       "max_u_classifier_balanced lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     3546  81683   3721  1490         0.942382   \n",
       "                          xgb    3180  83080   2324  1856         0.953782   \n",
       "                          svr    4029  80498   4906  1007          0.93462   \n",
       "                          mlp    3961  49320  36084  1075         0.589131   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.532595       0.515886   0.524107   \n",
       "                          xgb            0.573051       0.370731   0.450205   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.132921       0.790111    0.22756   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.487959        0.70413   0.576445   \n",
       "                          xgb            0.577762       0.631454   0.603416   \n",
       "                          svr            0.450923        0.80004   0.576766   \n",
       "                          mlp            0.098914       0.786537   0.175728   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "max_u_classifier          lr             NaN  \n",
       "                          gb        0.496589  \n",
       "                          xgb       0.436154  \n",
       "                          svr       0.436154  \n",
       "                          mlp       0.236921  \n",
       "max_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.557219  \n",
       "                          xgb       0.579572  \n",
       "                          svr       0.570683  \n",
       "                          mlp       0.168054  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['max_u_classifier', 'max_u_classifier_balanced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier balanced with xgb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4149</td>\n",
       "      <td>80988</td>\n",
       "      <td>3434</td>\n",
       "      <td>1869</td>\n",
       "      <td>0.941364</td>\n",
       "      <td>0.547145</td>\n",
       "      <td>0.689432</td>\n",
       "      <td>0.610102</td>\n",
       "      <td>0.583377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4092</td>\n",
       "      <td>80554</td>\n",
       "      <td>3868</td>\n",
       "      <td>1926</td>\n",
       "      <td>0.935935</td>\n",
       "      <td>0.51407</td>\n",
       "      <td>0.67996</td>\n",
       "      <td>0.585491</td>\n",
       "      <td>0.557840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2976</td>\n",
       "      <td>82972</td>\n",
       "      <td>1450</td>\n",
       "      <td>3042</td>\n",
       "      <td>0.950332</td>\n",
       "      <td>0.67239</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.569897</td>\n",
       "      <td>0.551432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5339</td>\n",
       "      <td>47422</td>\n",
       "      <td>37000</td>\n",
       "      <td>679</td>\n",
       "      <td>0.583381</td>\n",
       "      <td>0.126101</td>\n",
       "      <td>0.887172</td>\n",
       "      <td>0.220816</td>\n",
       "      <td>0.224209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4478</td>\n",
       "      <td>77802</td>\n",
       "      <td>6620</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.403496</td>\n",
       "      <td>0.744101</td>\n",
       "      <td>0.523253</td>\n",
       "      <td>0.505649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4267</td>\n",
       "      <td>78129</td>\n",
       "      <td>6293</td>\n",
       "      <td>1751</td>\n",
       "      <td>0.911057</td>\n",
       "      <td>0.404072</td>\n",
       "      <td>0.70904</td>\n",
       "      <td>0.514779</td>\n",
       "      <td>0.492417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4934</td>\n",
       "      <td>79490</td>\n",
       "      <td>4932</td>\n",
       "      <td>1084</td>\n",
       "      <td>0.933481</td>\n",
       "      <td>0.500101</td>\n",
       "      <td>0.819874</td>\n",
       "      <td>0.621254</td>\n",
       "      <td>0.608736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5448</td>\n",
       "      <td>46592</td>\n",
       "      <td>37830</td>\n",
       "      <td>570</td>\n",
       "      <td>0.575409</td>\n",
       "      <td>0.125884</td>\n",
       "      <td>0.905284</td>\n",
       "      <td>0.221032</td>\n",
       "      <td>0.228092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp     tn     fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                              \n",
       "min_u_classifier          lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     4149  80988   3434  1869         0.941364   \n",
       "                          xgb    4092  80554   3868  1926         0.935935   \n",
       "                          svr    2976  82972   1450  3042         0.950332   \n",
       "                          mlp    5339  47422  37000   679         0.583381   \n",
       "min_u_classifier_balanced lr      NaN    NaN    NaN   NaN              NaN   \n",
       "                          gb     4478  77802   6620  1540         0.909774   \n",
       "                          xgb    4267  78129   6293  1751         0.911057   \n",
       "                          svr    4934  79490   4932  1084         0.933481   \n",
       "                          mlp    5448  46592  37830   570         0.575409   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.547145       0.689432   0.610102   \n",
       "                          xgb             0.51407        0.67996   0.585491   \n",
       "                          svr             0.67239       0.494516   0.569897   \n",
       "                          mlp            0.126101       0.887172   0.220816   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.403496       0.744101   0.523253   \n",
       "                          xgb            0.404072        0.70904   0.514779   \n",
       "                          svr            0.500101       0.819874   0.621254   \n",
       "                          mlp            0.125884       0.905284   0.221032   \n",
       "\n",
       "                                 (hybrid)mcc  \n",
       "experiment                class               \n",
       "min_u_classifier          lr             NaN  \n",
       "                          gb        0.583377  \n",
       "                          xgb       0.557840  \n",
       "                          svr       0.551432  \n",
       "                          mlp       0.224209  \n",
       "min_u_classifier_balanced lr             NaN  \n",
       "                          gb        0.505649  \n",
       "                          xgb       0.492417  \n",
       "                          svr       0.608736  \n",
       "                          mlp       0.228092  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['min_u_classifier', 'min_u_classifier_balanced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier balanced with svr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "In order to understand how good our predictions really are, we can compare it to a random classifier. [source](https://inside.getyourguide.com/blog/2020/9/30/what-makes-a-good-f1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>(hybrid)accuracy</th>\n",
       "      <th>(hybrid)precision</th>\n",
       "      <th>(hybrid)recall</th>\n",
       "      <th>(hybrid)f1</th>\n",
       "      <th>(hybrid)mcc</th>\n",
       "      <th>q</th>\n",
       "      <th>f1_coin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>3671</td>\n",
       "      <td>295704</td>\n",
       "      <td>6756</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.975707</td>\n",
       "      <td>0.275935</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>0.427611</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3916</td>\n",
       "      <td>299157</td>\n",
       "      <td>3303</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.498915</td>\n",
       "      <td>0.755742</td>\n",
       "      <td>0.601043</td>\n",
       "      <td>0.608358</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4748</td>\n",
       "      <td>292152</td>\n",
       "      <td>10308</td>\n",
       "      <td>288</td>\n",
       "      <td>0.967555</td>\n",
       "      <td>0.274727</td>\n",
       "      <td>0.933765</td>\n",
       "      <td>0.424546</td>\n",
       "      <td>0.496928</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4712</td>\n",
       "      <td>268831</td>\n",
       "      <td>33629</td>\n",
       "      <td>324</td>\n",
       "      <td>0.895444</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>0.928593</td>\n",
       "      <td>0.184537</td>\n",
       "      <td>0.289015</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>203962</td>\n",
       "      <td>98498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420708</td>\n",
       "      <td>0.053948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.147067</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>4250</td>\n",
       "      <td>298058</td>\n",
       "      <td>4402</td>\n",
       "      <td>786</td>\n",
       "      <td>0.957173</td>\n",
       "      <td>0.497321</td>\n",
       "      <td>0.865045</td>\n",
       "      <td>0.631556</td>\n",
       "      <td>0.637046</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4924</td>\n",
       "      <td>240377</td>\n",
       "      <td>62083</td>\n",
       "      <td>112</td>\n",
       "      <td>0.828385</td>\n",
       "      <td>0.072713</td>\n",
       "      <td>0.975359</td>\n",
       "      <td>0.135337</td>\n",
       "      <td>0.240749</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4971</td>\n",
       "      <td>154066</td>\n",
       "      <td>148394</td>\n",
       "      <td>65</td>\n",
       "      <td>0.555002</td>\n",
       "      <td>0.031938</td>\n",
       "      <td>0.986185</td>\n",
       "      <td>0.061873</td>\n",
       "      <td>0.129897</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5002</td>\n",
       "      <td>230283</td>\n",
       "      <td>72177</td>\n",
       "      <td>34</td>\n",
       "      <td>0.778019</td>\n",
       "      <td>0.059362</td>\n",
       "      <td>0.992966</td>\n",
       "      <td>0.112027</td>\n",
       "      <td>0.213272</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3572</td>\n",
       "      <td>203649</td>\n",
       "      <td>98811</td>\n",
       "      <td>1464</td>\n",
       "      <td>0.701026</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>0.747112</td>\n",
       "      <td>0.065628</td>\n",
       "      <td>0.114311</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>3671</td>\n",
       "      <td>78648</td>\n",
       "      <td>6756</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.915323</td>\n",
       "      <td>0.275935</td>\n",
       "      <td>0.692488</td>\n",
       "      <td>0.394624</td>\n",
       "      <td>0.402325</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3897</td>\n",
       "      <td>82212</td>\n",
       "      <td>3192</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.958275</td>\n",
       "      <td>0.502028</td>\n",
       "      <td>0.749402</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.593148</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5036</td>\n",
       "      <td>712</td>\n",
       "      <td>84692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089263</td>\n",
       "      <td>0.019893</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4455</td>\n",
       "      <td>49419</td>\n",
       "      <td>35985</td>\n",
       "      <td>581</td>\n",
       "      <td>0.601283</td>\n",
       "      <td>0.090107</td>\n",
       "      <td>0.878752</td>\n",
       "      <td>0.163454</td>\n",
       "      <td>0.194093</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5036</td>\n",
       "      <td>1</td>\n",
       "      <td>85403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05707</td>\n",
       "      <td>0.057071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.107979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>4855</td>\n",
       "      <td>278759</td>\n",
       "      <td>23701</td>\n",
       "      <td>181</td>\n",
       "      <td>0.930287</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.961609</td>\n",
       "      <td>0.27391</td>\n",
       "      <td>0.376638</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4396</td>\n",
       "      <td>296857</td>\n",
       "      <td>5603</td>\n",
       "      <td>640</td>\n",
       "      <td>0.98262</td>\n",
       "      <td>0.423158</td>\n",
       "      <td>0.868357</td>\n",
       "      <td>0.569025</td>\n",
       "      <td>0.599350</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4617</td>\n",
       "      <td>293585</td>\n",
       "      <td>8875</td>\n",
       "      <td>419</td>\n",
       "      <td>0.973091</td>\n",
       "      <td>0.320434</td>\n",
       "      <td>0.911948</td>\n",
       "      <td>0.474235</td>\n",
       "      <td>0.531773</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4301</td>\n",
       "      <td>293761</td>\n",
       "      <td>8699</td>\n",
       "      <td>735</td>\n",
       "      <td>0.971903</td>\n",
       "      <td>0.314354</td>\n",
       "      <td>0.856756</td>\n",
       "      <td>0.459947</td>\n",
       "      <td>0.509193</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5013</td>\n",
       "      <td>226007</td>\n",
       "      <td>76453</td>\n",
       "      <td>23</td>\n",
       "      <td>0.979983</td>\n",
       "      <td>0.057633</td>\n",
       "      <td>1.000342</td>\n",
       "      <td>0.108987</td>\n",
       "      <td>0.237693</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>2598</td>\n",
       "      <td>83124</td>\n",
       "      <td>2280</td>\n",
       "      <td>2438</td>\n",
       "      <td>0.947833</td>\n",
       "      <td>0.532595</td>\n",
       "      <td>0.515886</td>\n",
       "      <td>0.524107</td>\n",
       "      <td>0.496589</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1867</td>\n",
       "      <td>84013</td>\n",
       "      <td>1391</td>\n",
       "      <td>3169</td>\n",
       "      <td>0.94958</td>\n",
       "      <td>0.573051</td>\n",
       "      <td>0.370731</td>\n",
       "      <td>0.450205</td>\n",
       "      <td>0.436154</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>0</td>\n",
       "      <td>85404</td>\n",
       "      <td>0</td>\n",
       "      <td>5036</td>\n",
       "      <td>0.944317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436154</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3979</td>\n",
       "      <td>59448</td>\n",
       "      <td>25956</td>\n",
       "      <td>1057</td>\n",
       "      <td>0.701316</td>\n",
       "      <td>0.132921</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>0.22756</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">max_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>3546</td>\n",
       "      <td>81683</td>\n",
       "      <td>3721</td>\n",
       "      <td>1490</td>\n",
       "      <td>0.942382</td>\n",
       "      <td>0.487959</td>\n",
       "      <td>0.70413</td>\n",
       "      <td>0.576445</td>\n",
       "      <td>0.557219</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>3180</td>\n",
       "      <td>83080</td>\n",
       "      <td>2324</td>\n",
       "      <td>1856</td>\n",
       "      <td>0.953782</td>\n",
       "      <td>0.577762</td>\n",
       "      <td>0.631454</td>\n",
       "      <td>0.603416</td>\n",
       "      <td>0.579572</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4029</td>\n",
       "      <td>80498</td>\n",
       "      <td>4906</td>\n",
       "      <td>1007</td>\n",
       "      <td>0.93462</td>\n",
       "      <td>0.450923</td>\n",
       "      <td>0.80004</td>\n",
       "      <td>0.576766</td>\n",
       "      <td>0.570683</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>3961</td>\n",
       "      <td>49320</td>\n",
       "      <td>36084</td>\n",
       "      <td>1075</td>\n",
       "      <td>0.589131</td>\n",
       "      <td>0.098914</td>\n",
       "      <td>0.786537</td>\n",
       "      <td>0.175728</td>\n",
       "      <td>0.168054</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.105492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_sparse</th>\n",
       "      <th>lr</th>\n",
       "      <td>2978</td>\n",
       "      <td>296439</td>\n",
       "      <td>5039</td>\n",
       "      <td>3040</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>0.324899</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.384441</td>\n",
       "      <td>0.379444</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5322</td>\n",
       "      <td>293242</td>\n",
       "      <td>8236</td>\n",
       "      <td>696</td>\n",
       "      <td>0.974264</td>\n",
       "      <td>0.385312</td>\n",
       "      <td>0.885434</td>\n",
       "      <td>0.536957</td>\n",
       "      <td>0.574551</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5162</td>\n",
       "      <td>292073</td>\n",
       "      <td>9405</td>\n",
       "      <td>856</td>\n",
       "      <td>0.97033</td>\n",
       "      <td>0.344235</td>\n",
       "      <td>0.858975</td>\n",
       "      <td>0.491501</td>\n",
       "      <td>0.532996</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5575</td>\n",
       "      <td>266504</td>\n",
       "      <td>34974</td>\n",
       "      <td>443</td>\n",
       "      <td>0.892789</td>\n",
       "      <td>0.131861</td>\n",
       "      <td>0.92292</td>\n",
       "      <td>0.230754</td>\n",
       "      <td>0.325950</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6011</td>\n",
       "      <td>229092</td>\n",
       "      <td>72386</td>\n",
       "      <td>7</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.075117</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.139732</td>\n",
       "      <td>0.268128</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_focused</th>\n",
       "      <th>lr</th>\n",
       "      <td>6009</td>\n",
       "      <td>234851</td>\n",
       "      <td>66627</td>\n",
       "      <td>9</td>\n",
       "      <td>0.828677</td>\n",
       "      <td>0.093785</td>\n",
       "      <td>0.998395</td>\n",
       "      <td>0.171463</td>\n",
       "      <td>0.277939</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5891</td>\n",
       "      <td>248922</td>\n",
       "      <td>52556</td>\n",
       "      <td>127</td>\n",
       "      <td>0.856077</td>\n",
       "      <td>0.108228</td>\n",
       "      <td>0.977798</td>\n",
       "      <td>0.194885</td>\n",
       "      <td>0.299362</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5936</td>\n",
       "      <td>242553</td>\n",
       "      <td>58925</td>\n",
       "      <td>82</td>\n",
       "      <td>0.84589</td>\n",
       "      <td>0.103075</td>\n",
       "      <td>0.985416</td>\n",
       "      <td>0.186629</td>\n",
       "      <td>0.291826</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5996</td>\n",
       "      <td>241247</td>\n",
       "      <td>60231</td>\n",
       "      <td>22</td>\n",
       "      <td>0.826397</td>\n",
       "      <td>0.090706</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.16627</td>\n",
       "      <td>0.272487</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>2617</td>\n",
       "      <td>232520</td>\n",
       "      <td>68958</td>\n",
       "      <td>3401</td>\n",
       "      <td>0.770289</td>\n",
       "      <td>0.034413</td>\n",
       "      <td>0.468941</td>\n",
       "      <td>0.06412</td>\n",
       "      <td>0.074741</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_filtered_regressor</th>\n",
       "      <th>lr</th>\n",
       "      <td>2978</td>\n",
       "      <td>79383</td>\n",
       "      <td>5039</td>\n",
       "      <td>3040</td>\n",
       "      <td>0.917579</td>\n",
       "      <td>0.324899</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.384441</td>\n",
       "      <td>0.348618</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5262</td>\n",
       "      <td>76391</td>\n",
       "      <td>8031</td>\n",
       "      <td>756</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.389289</td>\n",
       "      <td>0.876206</td>\n",
       "      <td>0.539073</td>\n",
       "      <td>0.548845</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5273</td>\n",
       "      <td>77092</td>\n",
       "      <td>7330</td>\n",
       "      <td>745</td>\n",
       "      <td>0.919196</td>\n",
       "      <td>0.411138</td>\n",
       "      <td>0.875964</td>\n",
       "      <td>0.559617</td>\n",
       "      <td>0.566921</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5447</td>\n",
       "      <td>64051</td>\n",
       "      <td>20371</td>\n",
       "      <td>571</td>\n",
       "      <td>0.778377</td>\n",
       "      <td>0.203083</td>\n",
       "      <td>0.901347</td>\n",
       "      <td>0.331481</td>\n",
       "      <td>0.361775</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5792</td>\n",
       "      <td>29373</td>\n",
       "      <td>55049</td>\n",
       "      <td>226</td>\n",
       "      <td>0.682453</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>1.110404</td>\n",
       "      <td>0.028397</td>\n",
       "      <td>0.109162</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_regressor_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>5263</td>\n",
       "      <td>281549</td>\n",
       "      <td>19929</td>\n",
       "      <td>755</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>0.199563</td>\n",
       "      <td>0.869791</td>\n",
       "      <td>0.324642</td>\n",
       "      <td>0.399644</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>5304</td>\n",
       "      <td>289766</td>\n",
       "      <td>11712</td>\n",
       "      <td>714</td>\n",
       "      <td>0.964194</td>\n",
       "      <td>0.305848</td>\n",
       "      <td>0.882862</td>\n",
       "      <td>0.45431</td>\n",
       "      <td>0.507674</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>5596</td>\n",
       "      <td>288017</td>\n",
       "      <td>13461</td>\n",
       "      <td>422</td>\n",
       "      <td>0.959203</td>\n",
       "      <td>0.285961</td>\n",
       "      <td>0.929793</td>\n",
       "      <td>0.437399</td>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5452</td>\n",
       "      <td>281901</td>\n",
       "      <td>19577</td>\n",
       "      <td>566</td>\n",
       "      <td>0.939816</td>\n",
       "      <td>0.217209</td>\n",
       "      <td>0.904885</td>\n",
       "      <td>0.350326</td>\n",
       "      <td>0.426681</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>6018</td>\n",
       "      <td>217887</td>\n",
       "      <td>83591</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44267</td>\n",
       "      <td>0.081676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151017</td>\n",
       "      <td>0.183797</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.038391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4149</td>\n",
       "      <td>80988</td>\n",
       "      <td>3434</td>\n",
       "      <td>1869</td>\n",
       "      <td>0.941364</td>\n",
       "      <td>0.547145</td>\n",
       "      <td>0.689432</td>\n",
       "      <td>0.610102</td>\n",
       "      <td>0.583377</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4092</td>\n",
       "      <td>80554</td>\n",
       "      <td>3868</td>\n",
       "      <td>1926</td>\n",
       "      <td>0.935935</td>\n",
       "      <td>0.51407</td>\n",
       "      <td>0.67996</td>\n",
       "      <td>0.585491</td>\n",
       "      <td>0.557840</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>2976</td>\n",
       "      <td>82972</td>\n",
       "      <td>1450</td>\n",
       "      <td>3042</td>\n",
       "      <td>0.950332</td>\n",
       "      <td>0.67239</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.569897</td>\n",
       "      <td>0.551432</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5339</td>\n",
       "      <td>47422</td>\n",
       "      <td>37000</td>\n",
       "      <td>679</td>\n",
       "      <td>0.583381</td>\n",
       "      <td>0.126101</td>\n",
       "      <td>0.887172</td>\n",
       "      <td>0.220816</td>\n",
       "      <td>0.224209</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">min_u_classifier_balanced</th>\n",
       "      <th>lr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>4478</td>\n",
       "      <td>77802</td>\n",
       "      <td>6620</td>\n",
       "      <td>1540</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.403496</td>\n",
       "      <td>0.744101</td>\n",
       "      <td>0.523253</td>\n",
       "      <td>0.505649</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>4267</td>\n",
       "      <td>78129</td>\n",
       "      <td>6293</td>\n",
       "      <td>1751</td>\n",
       "      <td>0.911057</td>\n",
       "      <td>0.404072</td>\n",
       "      <td>0.70904</td>\n",
       "      <td>0.514779</td>\n",
       "      <td>0.492417</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>4934</td>\n",
       "      <td>79490</td>\n",
       "      <td>4932</td>\n",
       "      <td>1084</td>\n",
       "      <td>0.933481</td>\n",
       "      <td>0.500101</td>\n",
       "      <td>0.819874</td>\n",
       "      <td>0.621254</td>\n",
       "      <td>0.608736</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>5448</td>\n",
       "      <td>46592</td>\n",
       "      <td>37830</td>\n",
       "      <td>570</td>\n",
       "      <td>0.575409</td>\n",
       "      <td>0.125884</td>\n",
       "      <td>0.905284</td>\n",
       "      <td>0.221032</td>\n",
       "      <td>0.228092</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.12478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tp      tn      fp    fn (hybrid)accuracy  \\\n",
       "experiment                class                                                \n",
       "max_u_regressor_sparse    lr     3671  295704    6756  1365         0.975707   \n",
       "                          gb     3916  299157    3303  1120         0.987745   \n",
       "                          xgb    4748  292152   10308   288         0.967555   \n",
       "                          svr    4712  268831   33629   324         0.895444   \n",
       "                          mlp    5036  203962   98498     0         0.420708   \n",
       "max_u_regressor_focused   lr     4250  298058    4402   786         0.957173   \n",
       "                          gb     4924  240377   62083   112         0.828385   \n",
       "                          xgb    4971  154066  148394    65         0.555002   \n",
       "                          svr    5002  230283   72177    34         0.778019   \n",
       "                          mlp    3572  203649   98811  1464         0.701026   \n",
       "max_u_filtered_regressor  lr     3671   78648    6756  1365         0.915323   \n",
       "                          gb     3897   82212    3192  1139         0.958275   \n",
       "                          xgb    5036     712   84692     0         0.054418   \n",
       "                          svr    4455   49419   35985   581         0.601283   \n",
       "                          mlp    5036       1   85403     0          0.05707   \n",
       "max_u_regressor_balanced  lr     4855  278759   23701   181         0.930287   \n",
       "                          gb     4396  296857    5603   640          0.98262   \n",
       "                          xgb    4617  293585    8875   419         0.973091   \n",
       "                          svr    4301  293761    8699   735         0.971903   \n",
       "                          mlp    5013  226007   76453    23         0.979983   \n",
       "max_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     2598   83124    2280  2438         0.947833   \n",
       "                          xgb    1867   84013    1391  3169          0.94958   \n",
       "                          svr       0   85404       0  5036         0.944317   \n",
       "                          mlp    3979   59448   25956  1057         0.701316   \n",
       "max_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     3546   81683    3721  1490         0.942382   \n",
       "                          xgb    3180   83080    2324  1856         0.953782   \n",
       "                          svr    4029   80498    4906  1007          0.93462   \n",
       "                          mlp    3961   49320   36084  1075         0.589131   \n",
       "min_u_regressor_sparse    lr     2978  296439    5039  3040         0.976296   \n",
       "                          gb     5322  293242    8236   696         0.974264   \n",
       "                          xgb    5162  292073    9405   856          0.97033   \n",
       "                          svr    5575  266504   34974   443         0.892789   \n",
       "                          mlp    6011  229092   72386     7         0.957692   \n",
       "min_u_regressor_focused   lr     6009  234851   66627     9         0.828677   \n",
       "                          gb     5891  248922   52556   127         0.856077   \n",
       "                          xgb    5936  242553   58925    82          0.84589   \n",
       "                          svr    5996  241247   60231    22         0.826397   \n",
       "                          mlp    2617  232520   68958  3401         0.770289   \n",
       "min_u_filtered_regressor  lr     2978   79383    5039  3040         0.917579   \n",
       "                          gb     5262   76391    8031   756           0.9123   \n",
       "                          xgb    5273   77092    7330   745         0.919196   \n",
       "                          svr    5447   64051   20371   571         0.778377   \n",
       "                          mlp    5792   29373   55049   226         0.682453   \n",
       "min_u_regressor_balanced  lr     5263  281549   19929   755         0.938965   \n",
       "                          gb     5304  289766   11712   714         0.964194   \n",
       "                          xgb    5596  288017   13461   422         0.959203   \n",
       "                          svr    5452  281901   19577   566         0.939816   \n",
       "                          mlp    6018  217887   83591     0          0.44267   \n",
       "min_u_classifier          lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4149   80988    3434  1869         0.941364   \n",
       "                          xgb    4092   80554    3868  1926         0.935935   \n",
       "                          svr    2976   82972    1450  3042         0.950332   \n",
       "                          mlp    5339   47422   37000   679         0.583381   \n",
       "min_u_classifier_balanced lr      NaN     NaN     NaN   NaN              NaN   \n",
       "                          gb     4478   77802    6620  1540         0.909774   \n",
       "                          xgb    4267   78129    6293  1751         0.911057   \n",
       "                          svr    4934   79490    4932  1084         0.933481   \n",
       "                          mlp    5448   46592   37830   570         0.575409   \n",
       "\n",
       "                                (hybrid)precision (hybrid)recall (hybrid)f1  \\\n",
       "experiment                class                                               \n",
       "max_u_regressor_sparse    lr             0.275935       0.692488   0.394624   \n",
       "                          gb             0.498915       0.755742   0.601043   \n",
       "                          xgb            0.274727       0.933765   0.424546   \n",
       "                          svr            0.102448       0.928593   0.184537   \n",
       "                          mlp            0.053948            1.0   0.102374   \n",
       "max_u_regressor_focused   lr             0.497321       0.865045   0.631556   \n",
       "                          gb             0.072713       0.975359   0.135337   \n",
       "                          xgb            0.031938       0.986185   0.061873   \n",
       "                          svr            0.059362       0.992966   0.112027   \n",
       "                          mlp            0.034321       0.747112   0.065628   \n",
       "max_u_filtered_regressor  lr             0.275935       0.692488   0.394624   \n",
       "                          gb             0.502028       0.749402   0.601266   \n",
       "                          xgb            0.046716            1.0   0.089263   \n",
       "                          svr            0.090107       0.878752   0.163454   \n",
       "                          mlp            0.057071            1.0   0.107979   \n",
       "max_u_regressor_balanced  lr               0.1597       0.961609    0.27391   \n",
       "                          gb             0.423158       0.868357   0.569025   \n",
       "                          xgb            0.320434       0.911948   0.474235   \n",
       "                          svr            0.314354       0.856756   0.459947   \n",
       "                          mlp            0.057633       1.000342   0.108987   \n",
       "max_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.532595       0.515886   0.524107   \n",
       "                          xgb            0.573051       0.370731   0.450205   \n",
       "                          svr                   0            0.0          0   \n",
       "                          mlp            0.132921       0.790111    0.22756   \n",
       "max_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.487959        0.70413   0.576445   \n",
       "                          xgb            0.577762       0.631454   0.603416   \n",
       "                          svr            0.450923        0.80004   0.576766   \n",
       "                          mlp            0.098914       0.786537   0.175728   \n",
       "min_u_regressor_sparse    lr             0.324899       0.470704   0.384441   \n",
       "                          gb             0.385312       0.885434   0.536957   \n",
       "                          xgb            0.344235       0.858975   0.491501   \n",
       "                          svr            0.131861        0.92292   0.230754   \n",
       "                          mlp            0.075117       0.999552   0.139732   \n",
       "min_u_regressor_focused   lr             0.093785       0.998395   0.171463   \n",
       "                          gb             0.108228       0.977798   0.194885   \n",
       "                          xgb            0.103075       0.985416   0.186629   \n",
       "                          svr            0.090706       0.995955    0.16627   \n",
       "                          mlp            0.034413       0.468941    0.06412   \n",
       "min_u_filtered_regressor  lr             0.324899       0.470704   0.384441   \n",
       "                          gb             0.389289       0.876206   0.539073   \n",
       "                          xgb            0.411138       0.875964   0.559617   \n",
       "                          svr            0.203083       0.901347   0.331481   \n",
       "                          mlp            0.014383       1.110404   0.028397   \n",
       "min_u_regressor_balanced  lr             0.199563       0.869791   0.324642   \n",
       "                          gb             0.305848       0.882862    0.45431   \n",
       "                          xgb            0.285961       0.929793   0.437399   \n",
       "                          svr            0.217209       0.904885   0.350326   \n",
       "                          mlp            0.081676            1.0   0.151017   \n",
       "min_u_classifier          lr                  NaN            NaN        NaN   \n",
       "                          gb             0.547145       0.689432   0.610102   \n",
       "                          xgb             0.51407        0.67996   0.585491   \n",
       "                          svr             0.67239       0.494516   0.569897   \n",
       "                          mlp            0.126101       0.887172   0.220816   \n",
       "min_u_classifier_balanced lr                  NaN            NaN        NaN   \n",
       "                          gb             0.403496       0.744101   0.523253   \n",
       "                          xgb            0.404072        0.70904   0.514779   \n",
       "                          svr            0.500101       0.819874   0.621254   \n",
       "                          mlp            0.125884       0.905284   0.221032   \n",
       "\n",
       "                                 (hybrid)mcc         q   f1_coin  \n",
       "experiment                class                                   \n",
       "max_u_regressor_sparse    lr        0.427611  0.016377  0.032227  \n",
       "                          gb        0.608358  0.016377  0.032227  \n",
       "                          xgb       0.496928  0.016377  0.032227  \n",
       "                          svr       0.289015  0.016377  0.032227  \n",
       "                          mlp       0.147067  0.016377  0.032227  \n",
       "max_u_regressor_focused   lr        0.637046  0.016377  0.032227  \n",
       "                          gb        0.240749  0.016377  0.032227  \n",
       "                          xgb       0.129897  0.016377  0.032227  \n",
       "                          svr       0.213272  0.016377  0.032227  \n",
       "                          mlp       0.114311  0.016377  0.032227  \n",
       "max_u_filtered_regressor  lr        0.402325  0.055683  0.105492  \n",
       "                          gb        0.593148  0.055683  0.105492  \n",
       "                          xgb       0.019893  0.055683  0.105492  \n",
       "                          svr       0.194093  0.055683  0.105492  \n",
       "                          mlp       0.000000  0.055683  0.105492  \n",
       "max_u_regressor_balanced  lr        0.376638  0.016377  0.032227  \n",
       "                          gb        0.599350  0.016377  0.032227  \n",
       "                          xgb       0.531773  0.016377  0.032227  \n",
       "                          svr       0.509193  0.016377  0.032227  \n",
       "                          mlp       0.237693  0.016377  0.032227  \n",
       "max_u_classifier          lr             NaN       NaN       NaN  \n",
       "                          gb        0.496589  0.055683  0.105492  \n",
       "                          xgb       0.436154  0.055683  0.105492  \n",
       "                          svr       0.436154  0.055683  0.105492  \n",
       "                          mlp       0.236921  0.055683  0.105492  \n",
       "max_u_classifier_balanced lr             NaN       NaN       NaN  \n",
       "                          gb        0.557219  0.055683  0.105492  \n",
       "                          xgb       0.579572  0.055683  0.105492  \n",
       "                          svr       0.570683  0.055683  0.105492  \n",
       "                          mlp       0.168054  0.055683  0.105492  \n",
       "min_u_regressor_sparse    lr        0.379444  0.019571  0.038391  \n",
       "                          gb        0.574551  0.019571  0.038391  \n",
       "                          xgb       0.532996  0.019571  0.038391  \n",
       "                          svr       0.325950  0.019571  0.038391  \n",
       "                          mlp       0.268128  0.019571  0.038391  \n",
       "min_u_regressor_focused   lr        0.277939  0.019571  0.038391  \n",
       "                          gb        0.299362  0.019571  0.038391  \n",
       "                          xgb       0.291826  0.019571  0.038391  \n",
       "                          svr       0.272487  0.019571  0.038391  \n",
       "                          mlp       0.074741  0.019571  0.038391  \n",
       "min_u_filtered_regressor  lr        0.348618  0.066541   0.12478  \n",
       "                          gb        0.548845  0.066541   0.12478  \n",
       "                          xgb       0.566921  0.066541   0.12478  \n",
       "                          svr       0.361775  0.066541   0.12478  \n",
       "                          mlp       0.109162  0.066541   0.12478  \n",
       "min_u_regressor_balanced  lr        0.399644  0.019571  0.038391  \n",
       "                          gb        0.507674  0.019571  0.038391  \n",
       "                          xgb       0.503226  0.019571  0.038391  \n",
       "                          svr       0.426681  0.019571  0.038391  \n",
       "                          mlp       0.183797  0.019571  0.038391  \n",
       "min_u_classifier          lr             NaN       NaN       NaN  \n",
       "                          gb        0.583377  0.066541   0.12478  \n",
       "                          xgb       0.557840  0.066541   0.12478  \n",
       "                          svr       0.551432  0.066541   0.12478  \n",
       "                          mlp       0.224209  0.066541   0.12478  \n",
       "min_u_classifier_balanced lr             NaN       NaN       NaN  \n",
       "                          gb        0.505649  0.066541   0.12478  \n",
       "                          xgb       0.492417  0.066541   0.12478  \n",
       "                          svr       0.608736  0.066541   0.12478  \n",
       "                          mlp       0.228092  0.066541   0.12478  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['q'] =  (df['tp'] + df['fn']) / (df['fp'] + df['tn'] + df['tp'] + df['fn'])\n",
    "df['f1_coin'] = (2*df['q'])/(df['q']+1)\n",
    "# write df to csv in this directory, with the name dataset_benchmark.csv\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5448"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[('min_u_classifier_balanced', 'mlp'), 'tp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: max_u_regressor_sparse, model: mlp, threshold: 0.054008631153497785\n",
      "hybrid_metrics.true_positives_ctr:  0\n",
      "hybrid_metrics.true_negatives_ctr:  0\n",
      "hybrid_metrics.false_positives_ctr:  307496\n",
      "hybrid_metrics.false_negatives_ctr:  0\n",
      "\n",
      "\n",
      "true_positives_hybrid_error 0\n",
      "true_negatives_hybrid_error 0\n",
      "false_positives_hybrid_error -307189115.52679145\n",
      "false_negatives_hybrid_error 0\n",
      "\n",
      "\n",
      "true_positives_rmse 0\n",
      "true_negatives_rmse 0\n",
      "false_positives_rmse 1000.0019887308825\n",
      "false_negatives_rmse 0\n",
      "\n",
      "\n",
      "hybrid_metrics.hybrid_accuracy:  -0.0\n",
      "hybrid_metrics.hybrid_precision:  -0.0\n",
      "hybrid_metrics.hybrid_recall:  0\n",
      "hybrid_metrics.hybrid_f1:  0\n",
      "hybrid_metrics.hybrid_mcc:  0\n"
     ]
    }
   ],
   "source": [
    "threshold = _threshold(experiment)\n",
    "experiment = 'max_u_regressor_sparse'\n",
    "model = 'mlp' \n",
    "threshold = _threshold(experiment)\n",
    "print('Experiment: {}, model: {}, threshold: {}'.format(experiment, model, threshold))\n",
    "hybrid_metrics = metrics.Metrics()\n",
    "hybrid_metrics.get_prediction_scores(testing_data[experiment][model]['predicted']+1000, testing_data[experiment][model]['real'], threshold=threshold)\n",
    "print('hybrid_metrics.true_positives_ctr: ', hybrid_metrics.true_positives_ctr)\n",
    "print('hybrid_metrics.true_negatives_ctr: ', hybrid_metrics.true_negatives_ctr)\n",
    "print('hybrid_metrics.false_positives_ctr: ', hybrid_metrics.false_positives_ctr)\n",
    "print('hybrid_metrics.false_negatives_ctr: ', hybrid_metrics.false_negatives_ctr)\n",
    "print('\\n')\n",
    "print('true_positives_hybrid_error', hybrid_metrics.true_positives_hybrid_error)\n",
    "print('true_negatives_hybrid_error', hybrid_metrics.true_negatives_hybrid_error)\n",
    "print('false_positives_hybrid_error', hybrid_metrics.false_positives_hybrid_error)\n",
    "print('false_negatives_hybrid_error', hybrid_metrics.false_negatives_hybrid_error)\n",
    "print('\\n')\n",
    "print('true_positives_rmse', hybrid_metrics.true_positives_rmse)\n",
    "print('true_negatives_rmse', hybrid_metrics.true_negatives_rmse)\n",
    "print('false_positives_rmse', hybrid_metrics.false_positives_rmse)\n",
    "print('false_negatives_rmse', hybrid_metrics.false_negatives_rmse)\n",
    "print('\\n')\n",
    "print('hybrid_metrics.hybrid_accuracy: ', hybrid_metrics.hybrid_accuracy)\n",
    "print('hybrid_metrics.hybrid_precision: ', hybrid_metrics.hybrid_precision)\n",
    "print('hybrid_metrics.hybrid_recall: ', hybrid_metrics.hybrid_recall)\n",
    "print('hybrid_metrics.hybrid_f1: ', hybrid_metrics.hybrid_f1)\n",
    "print('hybrid_metrics.hybrid_mcc: ', hybrid_metrics.hybrid_mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cb3e0affa0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI4AAAHSCAYAAACKH4CyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADP7klEQVR4nOzddXwcRf8H8M8kaZu6C9XU3VOnpQVKCwWKu7s//HiQIsWl8OAPzoM7FCuUCqUtRWppqbu7u6ZJ5vfH3V729mZ3Z+/2JMnn/XpBk8ve7tzeyux3Zr4jpJQgIiIiIiIiIiKySkt2AYiIiIiIiIiIKDUxcEREREREREREREoMHBERERERERERkRIDR0REREREREREpMTAERERERERERERKTFwREREREREREREShnJLoAXNWrUkFlZWckuBhERERERERFRsTFr1qwdUsqaqr8VqcBRVlYWcnJykl0MIiIiIiIiIqJiQwix1u5vHKpGRERERERERERKDBwREREREREREZESA0dERERERERERKTEwBERERERERERESkxcEREREREREREREoMHBERERERERERkRIDR0REREREREREpMTAERERERERERERKWkFjoQQg4UQS4UQK4QQwxR/v0sIsUgIMU8I8ZsQopHpb1cKIZYH/7vS9HpXIcT84DpfFUIIfz4SERERERERERH5wTVwJIRIB/A6gFMBtAFwsRCijWWxfwBkSyk7ABgJ4Lnge6sBeARADwDdATwihKgafM+bAK4H0Dz43+CYPw0REREREREREflGp8dRdwArpJSrpJS5AL4EMNS8gJRykpTyUPDXaQDqB38eBOBXKeUuKeVuAL8CGCyEOA5AJSnlNCmlBPAxgLNi/zhEREREREREROQXncBRPQDrTb9vCL5m51oAY1zeWy/4s+46iYiIiIiIiIgowTL8XJkQ4jIA2QBO8HGdNwC4AQAaNmzo12qJiIiIiIiIiMiFTo+jjQAamH6vH3wtjBDiZAAPAjhTSnnU5b0bUTiczXadACClfEdKmS2lzK5Zs6ZGcYmIiIiIiIiIyA86gaOZAJoLIRoLIUoDuAjAKPMCQojOAN5GIGi0zfSncQBOEUJUDSbFPgXAOCnlZgD7hBA9g7OpXQHgRx8+DxERERERERER+cR1qJqUMk8IcRsCQaB0AO9LKRcKIR4HkCOlHAXgPwAqAPgmEAfCOinlmVLKXUKIJxAIPgHA41LKXcGfbwHwIYCyCOREGgMiIiIiIiIiIkoZIjCpWdGQnZ0tc3Jykl0MIiIiIiIiIqJiQwgxS0qZrfqbzlA1IkqSVdsPIGvYaExaus19YaIU9P6fq/Hir8uSXQyihDiWX4CCAv0GuUO5eegzYiKmrdoZx1IRERERxYaBI6IUNnvdHgDAT3M3JbcgKWTZ1v3Yd+RYXNa9ff9R94WKqNnrdmPvoej224KNe3HVBzOQm1fg+b2P/7wIr/62PKrtUuIcOJqHw7n5yS5Gkdf8wTG46sOZ7gsGLd68Hxv3HMaIMUviWCpKRWt2HMSCjXuTXQwi0rR250Hsj1P9k6goYOCIYvLqb8vx5Yx1yS5GwuWs2YX/JuBhuCgNJU2UU16agsv+Nx0AkJdfgEdHLfQl4DNy1gZ0e2oC5q7fg/W7DhW7fX/OG3/jsvemR7x+5Fg+Jlt6tK3ecRDrdx0K/X7PyHmYvHQ7lm/bH/dyJouUEvkeeoq4OZybn7RjaM+hXKzecdDTe9o9Mg7dn54QpxKVLFOWbddeNpAWEiheVxvS0f/5yTj9v38muxhEpOmE/0zG+W9NdV2uoEAiL997QxtRqmPgiGLy4q/LMOy7+QnZ1oGjeXhnykpPwwB0SCmxZe8RT+85762peCGK4TcLNu711MJofFIB4Xlbxdm8DYF9OHHJNnz49xo8MmpBzOs0hop8M2s9+j43CZ9OWxvzOlOFEcCYrzj2Hv5xAa76YCaWbNkXem3A85PR97lJEe9PE6l5HHo9f1Xe+3M1mj7wC3YfzPWlPK0fHov3/lwd87qicdorf2DA85M9v2//kTz/C0OOUvOMIq+mrdoZVY9MP6zYth9HjrG3YFH1ydQ1uD9B9WiK3ZIt7g1oF787Dc0eLJpzPm3bfwSb9x7GvA17kl2UhMrNK8DGPYeTXYyUx8BRCZCbV4BNxeBkeGr0Yjz9yxJMWLzV1/V+PHUtej7zGxZv3ue+cIxO/++fYS2MB4/m4azX/8JSjRuRm18XbXXtQrty+wH8OGdjzNuKxf3fzfetDAXBgIafPUWMnho5a3f7ts5kc9o9K7cHPq9T0MDYz4mMG01asg3fztrgutxvi7ei5zO/YeKS2K4L3+QEtrVlX+xBqA27A721xizYgu37j2J6gvPXbPIhkBaNNTsOeu7pREHFrIejm9y8gmLTIr9w015c9M40PDNmcVTvd2pMOnIsHyPGLLENDO09dAwnvzgFw76dF9W2KfmG/7gQX6Roz/0jx/Jjvremsh/+2Yi/V+zwfb3TV+9yXygFjZq7Cd2f+g29npmIM1/7K2HbnbZqJy55d1pS7wnDvpuHPiMm4lAuG9CcMHBUhKzbeSiqFq1/fzMXvUdMTFprmK4x8zdjlsPD+r7DgaDIUZ8/x9SVgYe6NUl44Jm2aifmrN+DEVFWOA3rdh7C9R/n4P++muu43Ekv/I5/fTknpm3F6osZ6yLKcORYPu4bOc/zkLNon7Wu/zgHg16a4us6/XTVBzOQNWy0b+tzGjJV2Jso8m9H8/Jx8GheaJ8ICHz41+qEtMpc/eFM/Psb5+MZAOYGe5/NXR9brpDQkCEfvn9jFbPW7ka3pybgwnemxb5SDSNnbcC2/ckJGgGBoTdeezp9k7MeJ77g7T3FiUjRXnzx1uKhMTj7jb+TXQxf7Ar2Uly2NboGIKfhau//tRpv/b4S//tjlfLvB4MPOdNWFc0HVS+8PtC9PmkFsoaN9r2Xeqo4eDQP4xduiXk9//tjFf5Yrh5e+9hPC3HNhznFNhfXnV/NwSX/ixzCX1LNTFLA619f/oO/V+7E9gPJyzM6cUkgZcORY6n9rJxsDBwVEbsO5qLffybhsZ8War9n674jeGH8Uvy6KHBjOZbCrXtb9h7BzZ/Nxrlv2lck4/2wmoyqRXrwaT3PpWLj9mxx6FigQmXOS2OQUqb0dw8AYxZsxlc56/HU6EWe3hftUL5fF23F0igr+Ykweal+jhQdTkdX4d8i9+Gpr/yBto+MCy2z62AuHv1pES5X5EpKFqdvfvPew1i0Sd2TcO/hY8pApYRE1rDRti34705Zhaxho+OWoN2rD/9ajXu+mYtt+4/g7m/m4rqPclzfs2LbAXR94ldfhvjF6p6R87Bqe+xB+y9mrMPanYkP/h85lu9LL6vi+WjrTDV0tiiK51Byo8EvN199hCQq7jh+4RbP9+do7D18DK9NXB4R7Fmx7QDaPDxOqxeq4aVgOoH8VGgNioNh383HDZ/MijpgaXhy9GJc/t4M5d+Ma1uq3O+Ki18XbcXBo+zZYjCuock8VY1LaXHLb+o3Bo6KCOMBZ4aHaPC/v56L/05cEYqepvKpcOCo+01pzvo9cdm2nz0NvDICRwV2G/dYJgmJA0fzwoa+PTt2KZo/OAZH81I/B8LSrQeiet9fcehqXJzYHl8oPO5VDyDGA731/Ubvv1TglFy41zMTcdqrfwBAxMN996cmoNtThcmgjbwFxkf9cuZ65fY+nR7IfbXzgLdcSPFqsX30p0X4ZtYG5AUfLHV67X0ydQ12HszF2AWb41KmeFq+dT9u/Wx2WDA8v0Di/u/m45wk9GC55bPZGPD8ZOTlF0T1AGf09Ju3YW9CevLlF0i8PGEZ9no4hyct3ZbyjQ+pIK51CJuVx7LNfI0EvlJKvD5pBW74ZBbe/WM1vv/HPXATyzDEx35aiOfHLwu1/huMOs1vxWzY1LqdkY19+u8N3NPsAhArth3AIz8u8LXH1YzVu1J+9EKqW751P67/OCdh+WFTxY4DR23rJ6nc8Xb9rkPIGjYafy7ncwbAwFGRcTg4vr1c6XTt91gDBX5EUaWUcen266Vofl9gYllfm4fH4rcYci6FehzZtCYavBTxmg9mYtDLhcOwPg8+6B7JDb/ZG7OHpRKveaaM42b/0Tws3BT9g/k/63ZjZLAlM16BxPyCQM+vpVv244aPcxJa+XL6LMZ1wekYM95vHs42eek2XPD21KQPAyhsqbIvx49zNmLA85PDZo8zD3k1P7BbH1isCoftqU1ask0560oqzZ6Uyo0Ibu7+Zi5Gz9+MhaaeZMZ3v/tQ7InNvTKGeIyevxmn2Ax/Ndu05zB++Kcwx5u5t8rNn87yv4AW4xduwcsTlmv1Hnlx/FJkDRuNqz+YGeq9YfbyhGW47qOZSb8GJFs8H3ri2ZvppBcmuybw3X7gKP4zbmnod+tw+IICGXEva/HQGJzysvu5oGIEQfwMVKZyB4JTX4luP5lZh7vuPpiLzXsP47qPZuKjqWuxxqeemKu2H8AFb0/FI6P0Rz64OZZfgKxho/HaRPdZiscv3IKzXv8rJa43sZThQPAYX5eEHrLJlP1keGOdSvK/2UhGh41vZ+v3dizOGDgqIoybaKl0va9s5fYDmLnGW3LfRZv24eUJzjOFDf9xAZo88Iun9eowXyyWb90fdTLvnQeO4vlxS6NKliyjuGQdys0Pq1R5lS5cehxFYcaawEXOLVA49PW/wmbOSkVHjuU7znJl/s6sLej5BRJvTl6Jw7nuPa0SkWvjvLf+RvMHx+Deb+dh/KKtWBBDoMsrx8BR8F+nGdNCeZDSCrsT3/b5P5ixelcox4ZKNME8Lz0hAL2HNqO3j10SenOL7YuWB+ThPyzA1R9EduO32+7/fT3HvUAudh3Mdcz35sRbED6Fm/lsFLgE7hLNeLB3muDgaF4+sp/8FeMWbsGl/5uOO7+ao0x2fMDjrHZSSoxdsNnTQ3ZucNndh465Du17deKK0M9rLY0MBQUSL09YjgmLtyVlJpr8AonuT03Q6gGTKPEMUNitOpZTeI1ObxeXz3TPyHlo8VBk8GnV9oPIzSsIC9Y7sZ4PflyaUuXyduRYvu197aBG/WTPoVxlgmrVV3PiC5PR+Ylf0euZiYVD+X3aEca1I2dNbHlwVm4/EBr6ZjSKv/W7OoeX2e1f/IM56/do5Tk9mpcf116Sr08qvDZu2H0obrMafpOzHq/+5h5Ui5drPpwZygNrNmP1Lq26ta5UOFXtzhPjeTIVypgKGDgqIozotu502GcoWrc/m+48a8PZb/yFlycsd+xi/Ok0vZkffvhnY9QzZw18aQp6j5gY9trbv6/Ueu/wHxfgtUkrbBP9AYEH077PTQw9TDq16PkxG91F70xFS0XFCijscWQX6HIKZhUUSCwPDo0wPsMy01AvoxKbihF8w44DR/G1zZAgALj8veno/MSvtn8Pq6jLwINUbl4B9h4+hv/9sQrPjl2CF3/1FtgrCB7+flc6/1m3J7Be02uz1u4OPXBOX7UTl7833dcZ4gxOx5HTUDWDUSTj+iNReMw6XZOGvOqtl82kpdvQ8bHxyoqK2ZuTV0YEeP47cYVtjzVhKrfy7w7b+mTaWkwy5Zwy78vfl23H1zPXY8irf4RaEf04bC58eyrOffNvZA0bHfdpmrftOxKaBS4Rvp65Xvngodsj1tj/qfJQqGPzniPYcSAXT41ejG3BWfuMhzDz5/Ay8cOKbfsxYswS3PTpbNzxxT/aD+g7gkMsf120FSf8Z7L+kCLL1/PdP8mdnfPwsXxs238UD32/IKnlAOzP+Z0HjuKur+doJXW2S3L8kqUxzy7XTDQNX35waoV/buwSXPXBTMxa6xxomLpyJ1oNH4upK3dGFXz7cc5Gm/yO3tcVDbfew+e99Tc6PjY+6vXf8MksXPNhTigJu5X5+PMjX5ydsqUCIx6OxJj24KQXfkfHx8Yja9horN0R/r299+dqX4YEtXxoLJo/OMbzhCu65gWfH/ILJI5/dhJu/+KfmNf594od2Lw3/JnjnpHzIuo6OvYeOoZnflnsOXhmvY5MXLINN38W3hN2/a5DuODtqbj/O/9ncoxHfqG8/ALs8JB0e8u+I6H6HADcyxkrwzBwVESETiXNyvIhRSR4xJglYSeDlXGBafbgGM8Pr9bK551fzfE0e5fbteJ/f67WWs/RYD4np6Ff01btxPpdh/HyBOco/qi5m9B7xETtqTpfGL8UZ74W+aA8bdUu2wcCc4tQQYHEyFkbwval00P9W1NWYuBLUzB/w15lpTGVA0aGWz6djXu/nYeNu9UBOq+95p4fvxQtHhqDLk/8imfGLAEAHDjqrZKTyJxX5775Nwa9PAUf/rUaF74zDX8s3xGXio5zjyOjNcX+4mL0iDMPVSt8LfDisfyCUL6GL2eswyfT1noup9El+Kd5mxyXe3bsklArnLnUdpMH+PGd7j6Yi6xho7F+V+BY/WP5Dlz5/gzc++08LNy0L3Sd8KN1d/m2wgDwFzPWxTwz0O6DuXji50URlUgpJbo//RuOfzZxPQ/v/XYezlMM5dP9bswz/O09dAwHjuaFrnV2u2jG6l3IGjY6Pnnygl/3G5PtGzeMyQ8y0gUygr2GVQ+bXnrunPziFLw9JdBKP2bBFlz1wUzX97wyYTme+Dl8iJo5cfCBo3naeRR3miridt9d1rDRuHek+8yIRY2UEo+OWhiR02qrZUbD1yatwHezN+LLGfaNI4YbPnEepihloKGhw6PjMc4UZIrnUDY7946ca9tbzRwkWxXMK7f74DE89tNCXPB25HkPAFNXBRoKpq0yNxiEfy6nwNi/vpyDs9+wnzpcWT+S0peZdGes3oUWD43B3yvt64kLNnobgm9llDPZuYX8PNaMa8b4ReEB0yd+XoTLfJx8Y7nlHJVS4t0pq7Bt/5GYghT/rAvUTY160CSXIe4qeQUyrNHmkv9N1xrurLL38DG0Gj4mVA8ZMXYx3p6yCqPnxZ7H0Pqt7w/2jF1i6mU7fdVO7ck2FmzcG9Fbyag3uaXtiMaToxcj+8kJ2O+S4N34nENe/ROnvfKH9vpz8wowdkHssxsWFQwcpRgpJR74fj5enrAslHMl8Hrg31gv21JKfJ2zXtlt1lzp9hqlnrrKuYeAkzU7DsY8G87ew8ew+2CuY6JcINDt8sZgBS30fGfzUDlhUaBr8CLNvDv/nbgC8zboDc3ZE8zFYf5ev5m1Hnd/Mxfv/6UXJJsT7MGycY+6t4DuTbHJ/aOxcnt0SaljZUy9aTdjjNmRY/lhQbVvciIr418Fey/Fo9eO38xfz6M/FT7MxaMnhWoo5LezNiBr2OhQpdZpu4U5jgrzCVmDmo+MWoh+/5mEXQdzMey7+Rj+g/eeAMY6P3fpHemVUeFV7YdmD/yitc9X7Qg/Rx6yfL5jcajwmLnNvOjkidGL8N6fq0OVG2M3PDF6sR9Fi8rMNbuwKorrjvm46/j4eLR7ZBya2+RpOZybj1s+m4XPgnne/Eyiv2nPYeTlF2jdk/OC3Rgz0gRKpQfeYdd7wEvLqFfW3itAYQ9LALjzy39wwdtTw4JCdsyHo/Fgnl8g8d/flof1ivk6J3WGkvll094j+PDvNbjy/fAhrNbeHuVLZwCAY4Odndu/+Aej5oYH0OcGA59TV+5E1rDReOLnRUnpafR1zgbc/Y06IHjQpqHmg7/W2AYlzcMN3T7NL/PVD2g7DuTi6g9mhO1rpwaDL2euR//nJ2NmjMOupgfrvn+viL4O7KawXhv+QXTjHrpVinELt+CdKYEA+Ncz1+P3ZeE991XH2hcz1vnSQ0invhpN3ch8nbry/RkY9PIUPPXLYtz22T/KXIS6jJ6bsTRGLdy0D8c/Oynservf43Blw4KNe3HkWAH+GxxebDSiG3Xh9/9cjTHz3YNIquCgzkiXC9+ZhoEv/a5V1tP/+yf+/c0c5d/6Pz9Zax1eGIF2t31r/pjrVPlfbXbDi78uw02fzsKUZf7OhpyqGDhKMfkFEp9PX4eXJywPuzH71T1/yZb9uHfkPNxjuenP27An7PcJLgmfb/1sdlj01uvF0xyY6v/8ZNfWNjcdHxsfHNLknCjXmvh29Y6DmLg48Jr1HUal7dNpazHfISB0LL/A87C8Wz6bHVZOIYBdBwP7c6dDTh8zc6VIdbGP2AM2x06BDHQdTgZVkey+u1bDx+LCd6aFfr9n5Lywz5iIUcg/ztloO6RAl/G9TbMJtpo/wVyfekio9ui/bSr+yvcHv5N0U5cjaxDm9+BwrkRPMWu+Jtq1iKY5HBa6ARm3xYxypOLsU0Yr3rezN+ACU2VZN8C6+2AuPpm6xtdu5Oe/NRUnmq47/6wP7104f8NeZD/5a0SOswKpfy/8dfFW/DJ/C36cs0n7PUDgeN+23771dNfBXPQeMRFP/LzIdZ0/zd2E1cGAQkZaWuiB46EfFuCTaWsjhtg4zVi4/8gx3PrZbNugUzTM57GRcFxnyJz1IXLhpr1o+8hYvPDrMjz1szogOWruJuw/cgwrTD3q7Fqp9x4+5tiKbz4Wxy3cEhj24rEB6uoPZqD5g95zNqaZ7r06y0Xjp7mbcIdl+Iv1WHtPsyd2POhca3V6yOw9fCzUi1MCoSCE9bPq9HaZtHQ7xi7YgvW7DuGxnxY6XrONHiPRBK/3Hj6Gk16YjMWb92FbsIewTp7KrGGjo7qGFjbYqP/uV2PTjZ/MwtO/BHpq3/vtvLDA6CXvFg6jN5fj/u/m47L3puPA0Tws2eK9Z5Vd0fMLZFT76oHv54edF+Yelb8v2x5K57Bs237kRJlHMFbWXsn7NIJFF78zzTEAbazRuC5b99zjPy/CzcHnDq90jy8vQS8jdYNqG0bjySdT12DRpth66wGF+ybWXLJ21yCjp3AyJudIBgaOigpLi3+0jKEc2y0tisaN23Db587jdUfP34z2jxaO2dY5ITfsDkxpOPjlKWj+4BhP05CqPvWOA0dx86ezwgJYbj2OrE556fdQcj7Dki37wlpa1uw8hDOCQ9AKCiS+nRXegrpy+0FPw/IA4G9LDhcBEbrgH87Nx6y1u8KGLKkuWG4VqYjvJBU74YTudoWFUx1KRv4Oa8Jgc8Xi65z1vrTWG9/Nxj2HI7qy/+vLOTEHOY2PrNMKHc1wL8PXOeuxcc9hZA0bjY//XuNeLo0cR+bzyzi+jK+gQBFccjJ3/R6tiqFbZdR6/qoY5bYb7qUT69Gtczhdo9/7c3VcxvADhQG7LfsiH8SNIk1euj2UPN+L//t6Dob/uBCLNu+DlBIf/LXaNtdKtM59M7z1983fV2DHgdyIa6XB6fq3+2Auhrz6B/6wtADqDrV46/dV6P7Ub7aBCKPH7uRl2x3XuWjTPtz+xT+hCntGeuGym/cexvAfFkRU5nPW7sYzYyIDL1JKtH90PEbP34w3J6+I+LuTj/5eo1wnoF+Z3m+5XpnfJmWge/+RYCu3KmH+sq37cccX/+Dub+bi5BcLA4Y9n/ktYtkf52xEx8fG4+oPZzoG8AxGD0WvQ4ImLd0eVU9B4xwPPZTaHAJHgoGTjbsP49FRC7UCtcu37ne95pmvIXEfqmazervLnPmh2JjZ1/HeYtonP8/dpHU9N7PmoZRS4vYv/sEHf60J7W+nY1z1pwNH8xy/q79X7MDK7Qfx0q/LQvdo3Q6huVE0LJgffM2zJSe6t5nTd3PNBzMx+GXn4T2Bnsp6ZW76wC94wCZ/mdPn/nz6urDhuHb3fGtQs6BA4uJ3ptn2GikokPjQMhpg8eZ9GBFMiWBd1gud68LUVTudZ3D2eJ56E74SP9a5ee8R26Gi2U8GZl4b/uNCnPZq5DFVUCA9jSoQLoHXaOQXSGQNG62df7c4YeCoiLA+uEXLS8XKS0uM+YS0S7Rq5AMwxsUu32Y/C42O1yauwJgFW8KG9CniEI5UlcbBL/8R0QUdCLQWNXngF089NcxUyRFVxfx46lqc++ZUdHtqQqil3EnO2t14UjG1stM+UPUKefHXZcgaNjoiX1X2kxPwydQ1Ecuv2HYgNJwvWoUVItN6FcfdWo0go86+8mLW2t1x6TbrmgNHkUdIx84DR0Pf097Dx3DvyHm4MJhT4vnx7skVHWdVs+RBkjKyomzcyHUCR1OWbcfQ1/+KCIwdVjxwrtxm34vgyLF8vD7J/cY9c3Ug4Gi3N53yYxh2HXQOSoZGvjp8/Cd+XhSWF8BPnnLKeXzg2H0oEChZumU/pq3ahcd+WoSHvl+APYdynSuzHr39+8rQNcg4HvMKrHmZAv+qKpSG8976Gws37cM3liB/vmldl783HW8FK30LNu5F1rDRoZbD35cFAtV2udfM9xm773vplv0RZczQODfuHTkPbytmGIrmgdPwyKiFynUC6gdeici8hVOWbQ976Av7WfF+K2PoxAabfWr29C+FQS7jfVbGdbRAItTQk6gHafOQXSfvBHNQfZWzHh/+vQbzgwl1jxzLxys2ORYHvjRF+QAuIU29CgrdEkxcm+gp53Xqol6H12429T7TqeoWFMiIiVQkIh/EB70cmTfGuJd98NcatH14bOj13LwCtHtkHB51mHLe+OzmSRysx4LOzJi6kxIYx/p/f1uBlg+NxQPfzw9uM/yzWPl9TFjXZ+4tqTObb4+nf1MGigH1NeOLGYGA8PRVO9FnxMRQYNoL3TrUpr2HMXXVTtxq0ytn/KItYSkFgMAkFqrUEmM99ko/+cXf8atGXTovPxCsUAWrDKFJcaL88lXXULtzPda6TFiuNg/PtkP++yeaKmb3XrJlX2jSI7O0YKTjh3/USfSjYQRwnxmzBD/N9ffZI9UxcJRi7E51nQS2fjMPC3Jjvjhf82Fkks7DufkR4/+9TRtt+jm4D4xKuHloSGHl2vtF06+eADsPHA09gJhzSVnzSu05lIuLjH0s1PvDuBl/Fczns23/EWQNG42JS7aG9sl7f67GHzpjzE37sO0j4yL+bDxEWSt7Ow4cxfAfIytRJ7/4O677OMdxk7l5Bfh46ho88uMCdHo8MnBmVIheM01tespLUyJ6o9kFI/QelmP/Xo/lF/jWsuBWmTSf4+YhKQUF4a2NVv/6MtArZOmW/aGKs85DmsEpcGSt/4c/NIa36upUAIxWYmt3ZVWuK6fP3Gr42LDf7bZtnEd2lUjVZAJW1rJaGdt2+/heZs4yM/bz9v1HlZWf1Q6JXq1BVaeht2bPjV2C58YuCQ0/uevruaEZdfYePoabP52Naz/K0erp9+fyHa7TOBsTFhzNKwhd363fmc6DwEqbmYXMAdQ/lu8IVcA/Dz6gGEOZzeeglDLi8xnf9bpdh2yPHdXDqpEYGwC6Nqzq+Bms96N43ftV972CAolzXRKYh+U40ujdalTeveafs/u6jW0mI8ePcT6EGvQ0v5v04IHz9C+Llfmm3KgaHWa7XJdU/Hp4UjHfqr0muvU6tE8VmFINJbf2qDdbunU/DprOYaMO+Z3DbHHGVf6oqe5pvS5dEJwZM/KdhR/y2g+d609WX88K1AOtOQCFCNS1pseQa9SOuXG1MCgR+HeIIni/55B9T9Rt+49i6z71vcLpsj5i7JKwiQP+76s5yjytKmtsGh2t9R2jd5O1Z6VBlbvLrsjRTFP/6yL3YJNx7XxLURcNNepZXnf6PnQ5nZeqDgbjFm7xPMmLl/ub3ey5g1/+A6crZhQ3vusXfl2Goa+rGwnzC2RoGDk5Y+AoxVgvnj/O2Yif5m7SmjLbC/NwmRfHL41o1QW8XfzM9+9tigvGjZ/OwpOWRKxeqhSqi0qpjMDha76xOfU4+teX/3jYYvS6PjkBfUZMxKrtByJmdDB70JRcV+dr/XHORnR/KtBa88nUta7Hguc4WHD50fM2Y5Lm1M5u3vp9JR7+cSE+mrrW0w2s338m4YipW7ROS72T9bsO4dw3/w4lfvTq02lrQ7O02VHNFOHkTYdZmAyTTdPAPzF6EVo+NDaiJ4CRC8AIMh3LL3AMghq5Hax0kmM7PaQZ1wC7AFTWsNH4z7glyH5yQqii/n1wSu/lW/dj897DygrKzgO5eH3SCs/dv1XdoGPJme7+Vr1jNNrE7cZ30O2pCej73KTIrXs4ReY6BI7MFcE3Jq/EG5NXhn2n5mPLGMqlEwy77L3pytnUzIzNbNt/FOnBSENevsSx/AJc8f4MzFm/J+Y8BdacSUDhA73qGPt0+jpkPzkhbAataIM45uTAVcqVdlz2G4ek0na7YOu+I3j6l8WezhXzosan+mneJmV+NfNaw4aqKdZrDnrvOHA0FPz3+v25BYZ0vouCAhnzBBxmRomMc1n33DOCZ14C+oaDR/PxYXDIsWoX6u7Vn+ZuQt/nJuGP5XqJXPfa3LftrvPm78No1LPr7QaElzvNdAPQmZ1SdSxNWLwt1LPLauOew66JnL0kaQ7vgRe+jDmPV9j6IXHkWD7OeeMvLLXUD61TsUduz75MI8YsiWjsVSb41WBujDU3dFnLp8rN0/XJX6Pa5uFj+cgaNlr5N2ujzbiFW7Xze1lnkTRYjy63CQE8Pa+Ye40XyIjemtFy6sFnd7o8rvj8k5Zus23EmbAosu7vdI21luloXj5u/GQWLnlXv+PBD/9sjPpY1WG+VtnlB1SNMrEy7+Olit5Wie71mSwMHKWI2et2490pqyJm0fjXl3Nw+xf/hE3b7qeXfl2GVyeuCD3AmXnZkvkGrgoQ/KmopHi5kJrzdhhBrlKKaY0nBR+0VddXv4cyudm054ht6wWAsGkyrTmnDOZ99Nm0wlamaCtVOv79zVxcrTG1sw63YJHTpzD3JkmLMXDU97lJmLV2dyjxo2HPoVxMXOLeRfiAQ9K/jXsOY8veI44zRXhh99Ua37/1Rt30gV8w/MfwXABO3/zZb0S2ggJu53uwdV+afwvoM2Iihr72pzJxptXrk1Zix4GjEcGrgS9NQa9nJirf89Qvi/GfcUsxXnNY5KHcPGzee1g9zDCGO7vuEeh2bqrOy/+MW6LsYu2FX3eGE1/4PSKomW76TNNXFVY4jc860afhasZWBjw/ORQszi+QmLdhL6Ys2467v5nrWoG3a400dH7i14ghIummbZlJIJTzwjyxgh+34Q9d8o45Te9t5+5v5uKdKaswY80uzF2/x3X6YUAdyHxu7FLlsub7UYHDQ7OERJcnCh8gL39vRugY8qvHkXlb5mW/yVkf0Qr+2qQVOOE/k/HulFXIGjY64hjR2U9AYCjlgo17Q2VS9Xpwyl2XEYwcRXP4fPj3mlCvwmjv7Re+PRW3BxNu2+UOs7r8PfUDlZeharp51XSGS4e95mE3nPj8ZJz8wu+2U707NfIZjhzLDwuq2PXAM7MGcaUE5m3Yq+wpZncP1Mltusyh/F6vV0/aBFt08jta98OeQ7mOw7CivSN7PYcirjvC5e9eyyPUP9/06Sxc8f6MiGc7JzPX7EKXJ36NyCOoauCPoKijWV39wUxlI07WsNGOORJ1GOeEOb3ELZ/NUo44MNz51RyXdQZWevBoXlhqEl1O5d+27wg27TmMPz3OuKpbHy2OGDhKEee88Tee+mWx7RSnW4KRfj/DRp9OWxuK2ivzCHi6WHi/6P4yfzMWbrJ/WPo0mP/EOuObMTypdHrkUDXD2l3urYvWj+f7eHBI7QDMqu0H8b8/Ilvlwu5llgK7tbTKiB+cqStmha+9+Osy/Gecc68bsz+Wb1eO/zbTTfae7nPA1HDDJ7Nwjcfu4lZ9RkzEBcFcQjNWq3vzxKL5g79g1NxNoUSsqqFun04L77ruVglSDVVw2sURXXhNq9996BjmbtjrqZeDuQeZuReY0xqchqyZtXl4nO0sgUYRrbMV+UF3qFp+gQwbVnYsvwCvT1qplWfJyUFFb7doWzmfs57npg/1j6knitGDYviPC5V50w4ezXMN5NgxgsV5BTI05KNAStfrmc5MOcc/G95jyy5wBBTm+nHKK5Fo/9jMtmg0ouTmFWDo63/huo/cr21ejpGdB3Nx9zdzkTVstOXa7ryOxZv3hXrZ6FwmwoYKml7fuOdw6H5vNxvbPSPn4dRXwofQGDNYvhwcHmb9+5gFejlJnhmzBKf/98+Ie6X5nG/3yDhkDRutfMAxRirG43amMzRkuqnHm1OP1wUb94YC2aoHScAhr45p36juCdZeuea16A4/MuR7OHZX7TjomNz5qmBdzSnw32r4WJzx3z+VuabsgnmqMnr5/nPzCmx7IhmrXrHtgOcHXycfTV3ry3r2HzmGmz6dhes/zrE9PnVy+6io9qFTAHhkcJhf4bLh96vw2SUjn0tU10m7WcTM54YRYLC7Xqm8OH4Zdh3MjRhS7nS4Gz3cjB5t5sZO8zPSX6bjRNX7VmXz3iNhjX3hqUPUzMf9L/O3KBuRnc5e83BMY1WPjlpo+4zsxOl06/70bxF50tz0GTFRa8RAccXAUZLtP3IMPyh6+1jd920gGd6SLftCJ/vanQdx4vOTcfE700IPk2MXbMbrk/RmXHnINFRKddPzUrf5ddE2166eVj/M2YQhr0aORzUY5VONLQYKb/CqLo52LaZmbrlmYmUkxtS128NQLhH6nz3rjc4uGadBlSjc3GPq1d+WhxIR68x045Y4e/2uQxFdte3oztTllTXvlh236qlxDPrRHdn6SY/lSzw7ZknoHL30f9PR+5nf8O2sDbbbc+vNcNOnqpZD932s6nFkMCoKOjlHzM8T5l5gse4+48HZLu+MUTYvrX+F7/XHfd/Ow4DnJ4eGgxrDvI7lS8epZwe/PEUrEGAW7f6UEuhtSmJqd/qZA78b90Q+3Nz82Wyc+sof2kE/c/BLmePIPW7k+Rw8ciw/lKRd9ZCXrN7n1odcc2DO7t5llNUIgM21NLqoFITvXkc9nv4tFBAxPzRF9DhSrOjqYO5Dry37BVJixbb9WLZ1P/qMmBhKWnxxcCiEKmGucU5JKfH3yh2hY8huSKUAMGb+ZmVdrM+IiTj9v5ZcLhofQfWAU3i+2A/n1RHvY/L0//6pzBViZhf82He48LhQnU/DvpsX9rvdZ9G548faS8TqzckrcZ4iLxFQWOdZsmW/KTG7+/YjejFK/br1nkO56PfcJGXd7IsZ67AoGJT/YY77M4ThxfFLQ0mn42nD7kNo/+h4TAv2UD3vLfV+jTbB8sxgL7a8/AK8PmkFDufmh830bOU2Vby5J/eQV/+ElBIvjl8aCvi433cKf1adG5567YRy2uqtY9nW/aHnJSmBk174Hb+ZeshuNQV/L/1fYY+7zk/8qp1eweipfs4bf+GlX+3zsxn7wTjuv//Hew8hAKEE8EAgTQMAbPWYN8kQ62zkBmMtqrpOScLAUZIN+26+azc9s637joZu6I//tAirdhzE1FU7Qy2yN306G/8Z5x40sVJdFL0Mi/t29gbbLs1e1+XVz6YhX1arth+wrWTvVETbt9m0rkVDK2G1B/tMrXETl24LG+qmYv1O3Xr/qHSwuRFfZBpL/3XOeuUyblRJ1O1Ec0z7yVo/nLRkm7KHhV3lwi2vgpnduWIuw6a9R3D/d/OVrfdfzFgX1qqkokpaqnOKaiWi1VjEPnBj/2adPDpuvU0KJPCUYgZCO+YWTLeAhO4VzujCvSxYYW5nSlR/5mv2D2trdh7CBI9DwmJ5rNpkaiENC9yaVmqukJ3yUmEy6E17DuOrmetCw7y+n63/YGPdpvlYLZDu0/B6zYX13NiloYCjNWeNavZA89/jadzCwu96/a5D6PyE99whOvl/QgFfKcNmtfLCuoucHqijGap28otTQseXkfdNlcjUuubPpq/DJe9ODz282uUIEULg5s9m486v5uCM//4Z1st5457DEbPR2vX4cmOcL7EeP35N5BEPb0wubLhUzYa6fKvebL0vTViGJvfbB9Ju/Ww2TnvFefp3J9bvQEqJZ8cusQ1kvGhKrB/qcWT6Gmx7HEUMf9X/7q7+cKZtj6+PTI1DbofTrZ/PDvWcfHXiCtz/3XyXdzjbuOew7XA2g7VBV2dmXC/+WrETN386C7d+Hnjmefk352Tzbs8g1kbEeRv24tWJK7Rzo+YVyIj8k2ZP/7IEUkps238EZ9kkaDaEDiVLkR9WTFIzY/WusHvvvI17PQU2jAYKnRn+Ojw6DrPX7Qm7N0WcR5bje9IS+1xqn0xd6zi01/DBX2sC23Jd0n/mXlmueWWT1syUWAwcJdnmKCKXG/ccxpFj+WER5VipKiJpIpAYUbeSsmRLZGu5HxUc1cmoG8U+8YXflTNb2G3nNIceUMlmTqips1tl9LM3A7AP7GzeezjsJvv4T/oP4s0fLJxCU2cmK0OyI/zWY/DqD2fifMUY8fQ0gYICiZXBHBtG/iO7vAqxyM0vwLUfRX5Hn01fh3kus2apzqnDufn4fPo6x3P2zNcCFR7VMk69kXR9McM+CHnvyEBLtdfAgJmUwLt/6AdQnVowrYTHh0IhAr34zLxOX+3GrwdMVYvd78u2237W3iMmhnrJAoEGEq+MwNFMU34UCfeEr69p9rg17DpY2IqpOrZUr8WzIURllcOMeWEUX/estc75ZYzPF8uhpxpmbUd1TDoPswpf3uleYF23bsJV87c5f+Pe0HXObt03auR6UZYPgf0d66xmOqlOgMC+8jr8S5cQApMtk2g88P18fDlTryFppcvkIQs37bM9Jqeu3InR8zf7Wi9QbepoXr5yOI/q9LcGx9NNQ23DtiP17xErHIJsXnrqLNi4z3amyWj9TzM5dTyNWbAlFMQ4ZDMyAQgkvs71OJup8b2FhndG2cvQ7MixAtsAmnkiFPOQUjdGmgSD189pBDynLHNv3FQlQ7fSmGAzZOOew3j4hwUOS4TTHXhw4Ghe2OQ6qjL8NHdTWN3CzjjFLI0lXUayC1DSRTOVKgAM+3ZexGt3eei5ZKW6Qe8+dAwdHx+P+09thRtPaBrVOiYt3YYTW9WOulx2/u+rubhnUEvt5VW9Q6ykhNa00kWFRGC2LacE3U4m2gQm37dUGLw8nKq6XCeXe3nsHmoWKXK3bN9/FK9NWoEXf12G3k2raycgNTNye4WV0mYfmysbqvLYUa1u+I8L8M+6PWhas7z7+5WvBV7dZjPdrl8+mx59/oVYAiluuRi8hhIEBF506PLtB7/iUOZAiTnoGK/cY0Dhg5c5/4zO0BCvU+qaH+z+9+fqiET8qh4yiW751D1uQ99NsICHj+Xj3DedZ7Iz9mks58bXlhngnFa1SdGrqdtTE7BmxJDQ7+ZeFqp1PfSDOhBpXnbhpr3aiVTtjqvGph4vTp9JN5C4/8gxvDF5RdTDc0JlcblvGTnUBjw/GbUqlsGMB0+OaXsqAoV5gQzWaeKdGHnoZg8f6LjcO1NWokACDaqWC712sYcZm3Spvt9rPpyJv1bsDDs2AZv8OpZ6VroQyIeMmJ1QAo4zgu0/cgwbdh9G3cpltRthUq1WBSDhhXI6Bbs+OSGmdW/dd0SrN8kPczbh5Ys6214PfpizMdQL10o1G3Ui6MyY6yz8s3pdi+7nLiiQocmPVMz3r3aPjEOdSpmY9sBJtsvfrpnnMppGr+KOgaMi6gfFDGHfaeRKMlif351aup8ZswQnta6NZrUqOK5TiMjK544DuZAawwviTTeXTXHS/enfPLc+6LDeFFXf7I4DR3HAoQUISH4vIkDvIbPbU94qHdNXB4JF0QSNACiDCX6fPSu3R7Zk7gzuC6cEoqHyKApkvHaGw3ArP2zcE8Nw0hie+NdodrX3GriI1nezN6BTgyqOy4yauymqZJJWYSPVTN99vHozAOpkovEYoWMe6rz38DH8Z9xSdG5YJfSaOajw+qQVuKZPY/8LYaOgQOLDv9dg6iq9a0moqB72k3FrTvItOsQ63ENVLOtkAAbzd+WUP9HqQUWr95M/Lwo73t78PfZkqOe88Td6N6sR83rMeYTMFm/ehxXbDoQ9FMXyQOqUPDeWmLHbUGoz60yofnEbYgMEhkOpfD7dvVdVWhqAfOAKyzTfUkr8Mt++F8O1H+Zoz0LnRUkZRuMX8wQWPZ7+DRd3b6j9XrtTw+sQQZ2hxrEyjgu/7q3mZ8CNew67zliZ6zC8z8ztHmhtJNiy7wi27D0S1eykhj2HIq9/Tr0kt8a50TRVMHCURK2Gj0natq2tINbfrS56ZxpyHnJutSqVlhZx8REAHhkVOS5XV36BxI//qPOhuM1S8KEpp4/Ow2wKpw0A4L2iFo+gERCZ9FvKQFfg6at34bT2xwEAsmNs4Ykn3QSk0bKrbMbC72Mz1odE1bSwiTh9Vm0/gLd8eICLB6/n5xGNAJ2Tu752Dwj96CFpqpO0sB5HheLZSrpWMZwnUdfof0w9gc3b/M+4pZi+eheu6NkoIeV4ecIyvDrR29A7wFtQ3mjU8fPBMpY1Wd/r5TuPtoFKda+0DsWx603z4vil6NuiptZ28gqkL4+CY22GT1hni/Pqq5nrwoaYOgWdJzu0/jsRIjxBb6rw8tDnNdecmdsRGk3QKJZjSie3TTKt0R2m6zPrsb9im34vwUSMZB7+wwI8cVa72FckA8GeF8ZHn0fUPJzbfAnuozFbmWpWbOU2XG4EqpyyV74/A0u37ketimW0tmHV6fHwvILH8qWy0dUwYswS3KQxOqeoY+AoCY4cy0dGmlDOBpKqVA+KVrn5BWjywC9hrz3w/fyYhie1Gj7G9v2fKIb0mD3qIfcOABzKjW5IV0l3+Fg+bvxkFnLW7kbOQyejRoXoLtLxEs+HTd3pTGOViNZCIx/IZxrDDZTnZAIe6r3kJ1KKYxm9VhZfiPMwNcC/Yz8ZSSnLZESmYEx0UmAJGTEz1JRl222HG/jNa9DIKOlDHvJGGPvUz10by/dkfasxLXw07/WT3YPLqxNX4BvNIXFAYh4qo2XMmmrYEYf720KHmSNTSdjwXM0Da/v+o6jp8pCarAbKHftzgTrhr63ZcRD9n5+clPLo0i3fx1OjH8LuN+vQ3Wg5XSs+mbbWl8CRBLB4835Pszqbnfzi7+iWVTV8hR6oJmpRcZp8CVBPuGLM2qwbnHLz/T8b8b2HkT3FFQNHSdBq+Fi0r1c52cXwJCMtLawHj65Yc9okMieO38kD/eY2nWgyGbPx6E7tWVz8K4a8Yl4ksrLplsvHTknvCp+IbuVe6eQE0mGuwNrNUum30umRgaNED6fae/hYwj6vH6IJ2OTHIXAUTW+U/AKJQ7l5EUlavfRY9ut497ruaGejSyXrdh6KSCa+cpveDGiAe2JgO8mbIc75em0ul12+R6tuT03AfYNb4dmxDsPr4vBxnXK/GG78JAcLHx8c+n3PoVysj2Nvo6UOQ3qKMz97tCeiRhGYOTS2g3LmmsJ7pNd6oB/X7ElLnc/PaINipMbAUYKtC+bJmO+hFS0V7Dhw1HMPnqIm2XmYirKMdPUMIsWd82xAJUsi6v+p3Fp/2+ez8fG1PZJdjDBeems40cl75bdS6ZFftt3U1PFy2+d6CTRTRTSnoNGZ2M/AbzT3gX7PTVIOsdOZrtlg7R3mJ98SzfuzGs8edQjAtX14LKpVKB3xupd9r5uIPJZtJIuX0QGOQSMAQ19Pzsy9By2Nep0e/xWNa7hPhBGtx4rZ88LqJAyZ82v2TqfLYmASHV8247otlViuq/eNnIfMUmlFavROccDAUYId5HColBXPSmdxZ0wxmpdfkJQbbLLk5iXmgbooHJlFoYxvT9GfNtyrg7n5uP7jnJjX42fCaZ3pc3XEI2+XmwxFjyNy9k8Us7QaLb7Jjvn7MVmCl8+Q4zGXjF+NBDq9Q/wmZSDJup2Dufk4tjc5jSAn/GdyUrbrxhpo8atRTHeShUQoSXW1WCVq0otE8/u6f6fHXviLPcwGbPVVTiBJ/YXZDTy9L9b8kiUda2YJVrlsqWQXgWwUJLvmXAys330IA1J8zLyfEjW8sSjENJM35CB1+FEh6fjYeB9KUvSphqqR/4ycDcXh/PXyGc57a2ocS5JacjSGW5akocZej3UhCkcLFGXxnhjEoDvVOTnzq4f1IofgjJTS13P/9wTl/4uFKpE26WPNLMFUCT8pNXw5032KVXJWXFtlyF0i4q52MxulikMlLMdXPI2evznZRSgR3gvOHlYc2k043FztfI0gWUnaddHESNNYddf2kyJRMSWP04QnP5TAZM9+9AwvyXgpTLD0tBRO0kEUo1Q8uotHQLAE1eqJKKGOHMvHq78tT3YxYlaSgh9+Kw49znR5/aTPjFmMaau8DW0kShVOvXeXbtVPgJ+qSlpu1WRjjqME8yvZGVEqSuPxHRd+5r0hIjJrNXxssovgi5IU/PBbSXr2klJ6Gga0flfs+beIvHI7RGev05vxM8Ohw8JPczfhuuMbeyhV6vl2dnSJ+Sk67HGUYOxxRMXZ5zNSeyhRUXUsvwTV6omIovDk6MXJLgIVAQWSM6JS6nMLburOmpqumKGUKFoMHCVYOntkUDE2SyMJJxEREVEySEj8umhrsotB5ML5efErzTQMo+c55wtksyR5wcBRgjHBHhERERFR4nFEIxUFb05e4fj3hZuin8rejEN8yQuGMRKMPY6IiIiIiBKPz8lUFExYvC3ZRSCKwMBRgjF5MBERERFR4kkOziEiigoDRwmWxuTYREREREQJN3+DXlJhopKAYVTygoEjIiIiIiIq9i58Z1qyi0CUMlZuO5DsIlARohU4EkIMFkIsFUKsEEIMU/y9nxBithAiTwhxnun1AUKIOab/jgghzgr+7UMhxGrT3zr59aGIiIiIiIiISO2ekfOSXQQqQjLcFhBCpAN4HcBAABsAzBRCjJJSLjIttg7AVQDuNr9XSjkJQKfgeqoBWAFgvGmRe6SUI2MoPxERERERERERxYlr4AhAdwArpJSrAEAI8SWAoQBCgSMp5Zrg3woc1nMegDFSykNRl5aIiIiIiIiIiBJGZ6haPQDrTb9vCL7m1UUAvrC89pQQYp4Q4iUhRJko1klERERERERERHGSkOTYQojjALQHMM708v0AWgHoBqAagPts3nuDECJHCJGzffv2uJeViIiIiIiIiIgCdAJHGwE0MP1eP/iaFxcA+F5Kecx4QUq5WQYcBfABAkPiIkgp35FSZksps2vWrOlxs0REREREREREFC2dwNFMAM2FEI2FEKURGHI2yuN2LoZlmFqwFxKEEALAWQAWeFwnERERERERERHFkWvgSEqZB+A2BIaZLQbwtZRyoRDicSHEmQAghOgmhNgA4HwAbwshFhrvF0JkIdBj6XfLqj8TQswHMB9ADQBP+vB5iIiIiIiIiIjIJzqzqkFK+QuAXyyvPWz6eSYCQ9hU710DRTJtKeWJXgpKRERERERERESJlZDk2EREREREREREVPQwcERERERERERE5FGL2hWSXYSEYOCIqIj64OpuyS4CERERERFRiVW2tFb2nyKPgSOiImpAy1qoWbFMsotBRERERERUIkkpk12EhGDgiKgIE8kuABERERERUQlVQuJGDBwRFWVpgqEjIiIiIiKiZJAoGZEjBo4opTxwWqtkF6FIYdyIiIiIiIjirWeTaskuQkrKL0h2CRKDgSNKKe3qVU52EYqUQW3rJLsIREQxaVitXLKLQERERC5a1q6Y7CKkJOY4IkqGJJ93l/RomNwCePTQkNbJLgIRUUwy0th1koiIKNWl8X6tVELiRgwcEZklMmI8oGXNmNeRkR55Cv897MSY15tsHeuz55mfbunfFMNO5TBQSrwOPJfjonzp9GQXgahIqFquVLKLQFRsMLeqWkEJiRwxcEQpJdmnXUECx6iWzojP6Ve3Stm4rDceHh/aVvl6Zik+FPmpftVyuOmEpskuBpVAWlVM1kM9a1arQrKLQBS1mhXLJGxbjw9tl7BtERV37HCkluzn10Rh4IhSSrIDtomMGJeURGpOejSurnydDRr+spvtoVtW1QSXhCgST/co8CJJpJVvhacKkX84VE2NPY6ISqA7B7ZI2LaO5uUnbFupqjlbzRPC7n5Wp3LR6Z1GRRSf2sJ8fWMvX9ZTjr0yqQjz66pQlC4vD5/eJtlFKBaa1Cyf7CKUaByqZqNkxI0YOCpqzuxYN9lFiCu7nhGJUi+Bw7yO5rHLEVsuEsPurPJz7zeuEb/K3ImtasVt3ZR8uld9u8tFIq/bsere2J+pjF+5qJMv64lWn2bq3qKU2lKlscZrTc+uZ5HQeIjduPuwx63FxwXdGiS7CI4SOXyQiq50Bo6U2OOIUhKT/BUfD5/eBtmNOFTIas2IIRAcvFLk3DOoZdzW/dZlXeO2boovrTNZs77Vv6U6gHhe1/ra5SkualXKTHYRqAgqqo82TWupGyZ0ri/rdh3ytzBRSvVaTYUyGckughbOwplc3P1qRfXa6hUDR0VMelrx/spKSMAWANCuXmWMvLl3wrZ3Wvs6vq7vsTPVia2LipLUi+W3xVvjvo141iVYUSEq9PKFnaJ6H88jSpVWca+Hol1jklvnh29v7uV5aM3VfbI8LU+JVdyfg1IdRwqopcq1Nd549hUxxb2HYMk47ZLjpSgfNuxc2TtL+XqXhlV83U68XHd842QXIWFmrdkd923oDBlIxXVTfOl8dV6v+9YcFyXt8Dirc72w33UDSQW8waacGhVKK19Pj9fDWTE7BpyCQg8NaY2ujap5vj4c36wGBrSsGWPJIqX6dcooXqcGVeKy/it7NfJlPel8ck0q3UBsvxY10aF+5TiXJnWUkLgRA0cUUCo9xe9oxcwlPRomfJupltDug6u7AYhvbhwn8brGp0oOCbO8BDwxxvPwYgNX0XNpj4aomBmfoQ+t6rjPpJRIN53QFNXKqwMA8TSwTW2UShcRgaREKO75Fu34fe8+t4t6mGX7evF54CqyPW1t7gE6951UuX0UlSH4T57VLtlFcFTUehyNvMmfCRFShW59rHH1chh12/HxLYyLdvUqJWxbDBxRkVUnitwH1hZ9p1xKsT4gVszMwGU91ZUvGeWZd3lPf1oyirNEVVkyNWf7MY7T7lmRyWJTLMblyQXZDXDbgGbJLkaY/OB5dVEck3P6HZi8b3Cr0M9OPY4yS8X/NlY6w3kbJ7cuog9jcfTU2e0x/9FBcbnuZFgeHNweyC7uHt+ktELo3buePbe9r9t994psLH/qNMdlHh8anyHFzWqlVvAuUaLtjeH18uhUj4vlwf7+01pH/d5UpNMb1WuP1XjUP248oYn/K/VbnOtdfj1XF7V27mxFHbco0x2qlp8CkZRypf1rvHK7LkT7/FrUMHBUDHWoXxlT7hng6T2JbtF/8qz2uKV/U9/W9+AQ98qQ7o37mXP8rdynikT1ONKdmcOpl1utBMzuEc8Ei5XLBgKv53SJridAm+P8bSXJyw/M4NfcZmYaPySrLnd93yaY8eBJuPuUFnHbxv+uyHb++5Xd4rbtok6nKhXrseN2aTulrb/53SK2r7nc4HbHaa/z3sH+JJsfFOfPXtJEe6x6zunj8IYBrWpF3esubkPgkkTn43it+sSjZ1CZjPSUbxAzZqcsW1qv8c/OHSfGt+EsEb07HzitlftCCmcnofdnouk+S6RCHGXG6l0J21ZJGQrOwFERo3vfaVi9nKf1WqdXjOfxb2zp9A6RXd3jud3qmjebSpnxn7kuGRdUvyotRlDEdjua63Hqbvzk2fEP3vk1LXZRYNzQrN+NnxXZZPUeF0KgVsVMXNe3CTo3rBKXqdn9rvCX1eyVV1IcPpavtVzULXpxvt7qHh/RHkfvXB79rIKp8qzao5hcb09uXTuq91Wv4F9jiIC6DnFqu9QMEg5prx8wtWN3HOsc39E0mvmdVy9VzkMnr13cBa9f0gUNq3l7frCqaFOHjrXee0qb2njq7Ha4NAEjDM6xGULq5p5BLSNy8PkpFYZpW58X7RS3OIrbp5bF7hOrMXBUDEXTohRrlvyWUfRkUF574nje6Y6LdsqM/43LWOX29SqnbD4WIQRG3dYn7DWvvW7qVMrErIdOxtInBztuR4exbdXiutPCnt4h+gppfJM5+/v+aIIhqn0TzxZPv1tpvd6EM0ul4/tb+sQtN4ifjqsc/6nUY/2uh3byJ4eNTjEujyJp6iltCh/gk92yqXvsR/OVVClXKqzHVM5DJzsuP+WeAeFDwVPkfpSM3hYVfZ5e/Nf/64eqUfZ28PPjSwCntI0MYMU6AYZdPpC+zWvEtN5GHhsyvXC6jxt/87zvU+ScsROvRq/K5UphSIfjov74RsoIu3v3gFbuCcedgowZ6QKX9mgU197ihli2YLz3+fM7+p7fqLzP17Ro6F7LE9EIn0pKyudl4KgYiqp1xeV3M1UlPZpKYaKTNesmAHcKHLV0ifaPOLe9ZkAiOU861twg/z7F23AIIYCM9DSUyQj0mFD14tL9WjN8GKheyjS9RqwBA79mf5CQoXPEr2BKNKdK10ZVQz//66TmwfLEj9+ns24wIJ69qAq3Eb7Snk1iq7gnIll5rNfXax1mHTylTW008Smp/RND2+KW/uqhDR0d8sm8c0U2ymkOqfCjJdCpFV4If67oix4fhPO7Blq67Y7/Gi49VxpWL4cnzyrssZmshLx9mlWPeR2xDknxe3pkv64tOnnZ3Lb1fydHDs3NLJUe00QnX1zfU/n60E7JH35jV6/yOlQtWQ0Lft6X4j0BR7T3DmOIm91pd2Ir5956716R7ZhPcGCb6Hr76Xg7hl6dZuZd16lBZd/zG9VJQKOTG3PnBLvk/kB8A8ZWa0YMSdi27KRCUC8RGDgqhmLtPeTkCR8TbaruTdFW8HXuc9agSTTcumjWrazXMyRZLeStjwsPfDklQVexfvq/hp2oWEbv+FP1KvI6hMc8dOWn2wtnb2hRu4Lnh454nDV+VRZjzUthJHSNZy+reAeCXzi/I166sGPE69FstoxLsms3DarGViHKT0jgKLb3253HV/XOwisXdcb4/+sX2waM7Th8gT/eGt5DMpkdi5zuTbq72vpZh3Q4DleYeluVK50RCqgb17Z4539yMu7O6L/jFpZeyG73BdXDcKy93lI154TucDen4fV29bxYrvGqIUZrRgyJ6wN7rHTqG+Z7k269IB53s8xS6dpBn4u7N8QjZ7SJQyncxXorj/a0M2/2Cksv1FoVy+DsztENH9NhzQUXz7pSIk25ZwC+u6W3r+s0zichgNqV1A0Zn13XI66TsaSiFL3d+I6BoxTR1McxsdE8MFgvknYnwOW9srTer7VNxWvxCKhULlsKLWtXxGDN8f9OZXD7mEIkt5ez21TBqgeXWMazq2ZQ0zkU/rxvQKiS2iPYe+Obm3ph3qOnRF0WswGtasXcvT5aAiL0kKlzLNx5cnPXZVRBmdXPOM+mpGJdjZ/HarzrWed2ra+sOPoZsPr6xl4R+WTmPnyK75/tpATMwqbaL/1bBoYKnNOlnutMcXaf+dEz26Js6XRkpPtTffCyb62BeyPfmnG+9W1eA1nBVs6r+2SFlovHfSUsmKv5IaxLvX5JFzw+tB0qZWagftXwRodQr8UYD75Y3q3bo0urHC4FUW0r1t5S0fQ4+uTa7g5/ja481tbw587roLXKp4MTdViHKtcM9jqben9kw41u/pFk8/rN2H4qnY+ruUv6tajpZfGonNlRLxh6Tpd6uLqPuten7r7LNvU6tvPHvQMiXov2mmO8K5brrREwt86GVSaK2VOfiGH2wWi5XbOcJj0weps6sd7Xv3cJCjWsXg5dGrofB3ZqVIgMtBq3vku62z9v9GlWo9gE33S0q1cp+WPmE4SBoxRxXlf/IrOJHgIGRHej9bOYThfrrBrlMe7/+mm3NDlVNt32rW5FNxWuL01qlkfFzFKOY7CtFV6/bgT1TT02zu5cHzMePAndsqqFDT2LlaqkOkGaWJl7Jvh1jOvmfLIVLEc8kzIn47oDRDdUze786964GtqahjJ8eUNPVPbYK8/NjAdOwsOnx78lObNUOk5sFR6gOsn0e2sfZu575aJOaOzTkDUd1uvPlzf0xKNntEH54ENGy9oVMfmeAVgzYggeOaOwd6zT9Va3/NZ1PH124UOJcNlGaDmbY3PuI6dEPMAZq4u9x1HkGnQnivB6n7q+b+GDruegTxyuH6ryf3CV8wyIfZu752GJlW7v50Ft62DNiCGoYZll1Aj6qoJEJehZDQDQTKMHj/4sULFXzCbc5VNPTIe/+VV//O6W3mgQYyJss8t6NkLDauVwdud6UQ+ZDF33fDiOo8m9atDZ/FuXOQ9v8/o9PXm2e6DL2jGgc8OqCZ9sw5idt0P9yqHv655B/swC6sZrL1S3yXy8sH6d71zeNTRqI9BgXDIwcJTifri1D5Y8YZ+IWEXngmsdAuB3Ml8dqotqKgRUnMqgUwFJZsXNy6b7NI1Pj5xoPn6tiv6M2+4eHE9evrQ60HKnIi+Em3M0p1e9uHth8Ncpx9H9p4ZP86papqbpQeGDq7uFzdLx97ATMePBk6IK4sVzqlhraRI17XNkLyp/tlu3ciZ6NqkeXKd/alXK9K23jhMhgPdND8nVypdGWZvzwu79boZ2qod3r8hG27qVwo5rL9+9l+/LutsaVS+Pq2xa5XXZdbU369mkmmPiYe1Z1Ww+qxAistdvqMeR3rrtqL4Kv4YZWjWpWfgQb31wdPscbsNH7z7F+7U7X3Ezr5CZWnkoLuuhTgxvPlbsdp2qqqJTR/EjaBwrr3U91cf66JruOLeL+z3NfA7obDaWBrJmtdTBCq/3JbtyLnhskG+5Y2LpiaLSoFo5TLl3AOpUzsSku/t7fr8Q5rpTckkE6n7NalWw7blkN4oh2uPHyB3qJE2IiATidpvLUhwnA1rGHhjv2aQ6Jt/dHxdkN0j4M9tZHuqwleJ8rTdPWpEmUuP5NREYOEoRdid+qXSBzFLp+Pia7njkjDZalUidrsqR+QdiE8110s/8A47b93g2O/U4MleGr+qdpSiIp035Lppd6ve1LpmBs8+u74H7BrfCjSc0ibh5/++KbMf32u4H7c/j3vrbo3E13HhCU8e1tD6uEl42PaQOaFkr7GGgbpWy3gNtwQ8Xa8DCKamrdX+bf/v+lt6+z3AUi1SYNjW7UVWco/HQ41XvpuqkxF5PS90HnWa1KmD0HX1RKdiyd07nelj0+CCPW7NX0VT5izYY6fRtO/VYOCM4rCQjLQ3dsqqF9SYw3ybM++rxoW1dc9i8clEnfHSN3ZAoESyzt2N03J398LMpz5uqbAbVEGM/DDZVpK2JQt2Opxv6NnH8+20neu8tqrqXxxLPjse9TafHh5ft6gzJH/Ovvq73Q8B0bsTlcultpapdcEILvYdg87Gn06tIIDH1mGh6xFQok4Hr+zbBe1e6f39+q1XRPchuqF+1HOp6TOQsJdAqmIezns3QXS+i/Q5v7NcEVcuVwosXdsKEu05APw9pD5y26TShxMUOw77C1g/gtUs647YBzTBZEZwbZJpt8eWLOod+/vz6Hph6/4mhBOaxyqpRPqzOl8x6fyJGEgAudSghUqJemQgMHKU444bXr0VN2/HOVjqVa7eT/I1LumDhY4NwsmYuDrtK4a0D7B+SVSdZok67209Uz+IDRAbVzIQQoZxAqpa9VOsm7rT/DV5uyKn2+axKpafh5v5NlS03Ol3aVXS7uesspnPMXJBdH1XKhQ8liWooqM4yPn6hTquqV6Ws5w/hVsE3uiBHfIYYhqrZimE3mbuRn2XqZj3y5t548YJO0a/YxuuXdAEQ+RkDrblG7i2BMi5BxGgPjdIZaVotp4YeNjPUGbOHjflX39DDvt3xGkuFrZvDrDdDLflIbHsTmIp1Zse6ET2jrMsN7VTP9aG38PvT+yJa1qmIdpYZo0qlC+Xbdb5br9//5Lv7R0xVb+4t/bBLot94BLMuUKQA8OOaZ80d41RPesoy/OSmE5ra5hdT5RMB7O9BquvYM+e0VzdqRcHtGvztzdEn3fWvdT61e4E76d+qJq7p0zg0eYWu9DSBk1rXVk5OAugPRfUqEfXzm/o1xY+39om4Ltf0ELSK1gdXdcMrF3XC/ae19j0/z4qnTsWvd52g/FuzWhXwzDntlX+zMnqn3j2oJbJchlmbP0HvpjVwnM3kPTMfPDniNaPeckIL52fAZAdLejetbjuSwO07PMVD0v/ODasoP6mxDQH2OKIUEc21y2kKYx33Dm6J3s1qoHyZjJhnIruom30UXT1UTe/MO8mSu8PPS3zHBlUcu8WHEh+rKuTQa6lP1MVWZ+yzW5Lcosr6LbjdZO3otlDrBWoiX7vUktDcWERnu6c6tC6HHWE+nSDRDuMUwv2ssI6Rd7sUXBQcGhjNNVInGOjXGXphtwZ494pslC2VjmGntvZprdEx5494+aJOjsv6VW9uWcd+WMzEf5+ApjXVAd0WtQOv169aLhRkiVfi39F3RPbUAZz3gfn4CFQa/TlijG2GgnxRfuQfbu2DP+490eY+5b7StBhbUAXCg0G1K2Vi7iOneOopEevX/fQ57SOmX48lF5vxTuteOb2Dfd6NNpZhYcZMQ9aE1wCQ89BAx+1aqb6fUulpqKUx/NILu+Ogq0byZSDwPVqHLnqO3ft07lctZx9UkfG4abp4+Iw2+C7KAJzqGBp7Z1+8EuxpIhGoI1iHNqUqIQKzBVqfYa7v2xjvXK6+bviZwH9Aq1oY2imyF7CnxlXz+0w/Z6SnIT1NKK+9Xo40t3ph2BBXxbKqz6IKyvVrUQN/3jdAO6CVKNaP5PTduN2Tz9TMl/T7Pf3x6bU9nMvFoWqUKiIa011unr2bVo+YAvE8jUz9utuPlip/QTQznhhirURckO2cjPy2E5vbTkXsxxjsRF1gnPaTURmsVr403r0iWyvgqLPbB7SM/4xRBqfdeM3xjVHeQ6Xi6bPVN0i7Bw3rA4HyAS3i/I1cpnqFMqEEe0Bhj8FpD5yECcEWKrvv8U2H5IzxSFZtnMd3ntw8YtY6a4XGvH0hwvOf+ME2X4zGe7s0qhJTHh63XXtmx7q446TmoWUHtqmNxU8MRh2PXfdjEVnG8BeOS1BZ7gvOIuPlXLTKD57oUQ9Vc7ngtq1b2fHvKj0aF7aI2x0Pb17aJex3L6ekNTl2mlDnrLDTqUEV1KmcqTwfzOV4aIg6mKl6n5EzIqqHNRnoJXiSzTC+eMQE09NERFn9Tr12YqtaWnk3rEfgz7cfb1vHsLLbN/GuRxirj2U71cuXxgXZDTC4XfKCF2HDSuPQ2y4eoi1Cg6rlwmYge/Oyrnjdch1KBV5mvT2va4Ow4Ib5fpxhc0Jf3L0hOjeokpTvMp6bVPZa9/B+nXP525t74+ULO6N+1XIp37Ds1rhhvferZqJ006h6eZQvk+G4nwUSN2Im2VL7iCimHlF02TZXQs28JtRrUrN8xENmg6qRlU2vASk3viXH1n+3ZfveCtCgWrmw6ZpVWtZRD0twSloqhHpogJ9UrUyxGtimNqpozD6gczyemiKtW+3qVcbCx/USy792SeeIYR4Gu2Pr+1vDWwmNfSOl/XGss/+M7dWqmBkaXhfN+ZWRLgqHwzicWP/nIWH4rQOa4Zb+TXFz/6YRD/FOQ8YEwhM1+8GuwqCaPdE6i5mACAU0/LZmxBC8enFnX2fzMJzark5g2lef6SSIjpYxrfL5LsF6J269b9wSSXfR7BlhFer9ozjWzIHQyPxedkFNjfM/+G/VcqVRs2IZPHpmYHa4ZU+eit/+3d+90Nb1uVw8rAHwwvfZr6tzwyoRf7PuIafeKLoz8PhxK7WWK6YeR4r3us60aj02gr9WLV/ato4RWND8YwpEMqI0a/hANKpeHh3rh99fdXromQOlsewB3dla49kT3PjedRqYvPj9nv5hv/v1CazrfeC0VuoFHTiV5ROXHhyxbOOMjnXxzDntfZuEwulzROQUjMOpepMpL6aXQSCq64bOMd61UVXPuZCSdY1yuoz4PdzQac8JIXzrdZzqGDhKAusDRd3Kmegcw+wG3RtXwxND27ovaKJ7kp/Z0dvUh17EMqvauV2i70VliPVCp7oo6a5R9/Ly4GmRrcG/3NHXdcaKK3sFZmoRAvjsuh4RUz1HKxVa4hLN7jNb87iolwt/MUNjilpVrwqvORAA+5a4WJQrnY57B7dS5rBxOjbShFAGdPxgPY/vGxxZwY0cJmF/Brr10PBK95qms39evKAT6leJbkYdr40FpRWV7mgCTKUz0rD48cERwTs35uLl5hXYlklHjQplonpvNPeIWO8rt5/YHP1b1sR52fUx88GTcVowEG8MdfBenkjmYIdTkNtIwt8/OBOPl4qxtU5jPudUUyqrytnQp9mjwrYTw9djvNW8HxJxT7QNmMZhnWbRBtlUgcFrj28c9rtO2f99ij/BfeO+e5PLxBTm2VCLSl2nUfXwIfhpUbRdqnJ0Wdd7Q7+mof3z34s7OyZ6jpZf+9xc94n311gp0/8GIqthp7bCsNCspZGf6IULOoZ+TvhxG8dYybuKBP4Rs4+6rEP19z7NquOW/u75X70oIpcLXzBwlATWuleaQ2XQj4uA6iFJN5/sqe2Ps+3KrvN+u+0BsQ1V62B5kHbavt/XNafWbyHse4+ZmWcKckr6pxqDW7lcKTR2uWmbp93u06yG1swtJSNWrub0sOf1Wc081tl6jOjkDFPlcTFyGVX0ML1o2LYcPkO0rawR1zFLua8zPSjYXcfWjBjiUK7o6OT1UjHOw5oVy6Bt3UoYcW4H22XjkchX9zCLqeu4h53apGYFPHdeB8weXph3JZoplgGgbOl0x/ucivn4OnIsH0Cc9nsCa9o6m6pTORMfXt3dtwcStx4OtrdhEfje1owYEjHcXXW99BIY1rn1v3pxZ9up6r04MSIfYny+b+t2Crdn/T2K4J/NWwpimJrW7Tu4oV+T0INbBdN9p7/GdN6qOpAQAk1q+h9scBKx7y0vNKtVAdf3bQyreFwSCoOOha8ZOUD9uga9f1V2qIenF29d1hULH9OfCbNHk2pa96GEdMDwuA23urP3zUvrC3Fh9B4/pW3kUF+7YaCJDCLFY1sDNZJXR9PL57PreuLewa18vRcwxxHFlfXYUg0ls+PXYW5dTzyGVdhuO3iFUbee6p15fnQJNF/oPr22B140Re0dt2283+bbeOuyro7Z+h8a0hr3DirsFaGb58CLaIIButPUWpkTL/4dnOVjgYdKSKozAiJuU9GqKobW/aXTC8hpiIgXOr2bYlG3SniOHPPW1owYgntNPX90ym9dxC5pstf1qKgOdWPIXqn0NIy+o2/YrFfWVd4zqKXWjIW65XGS3ahq2DqMoUteBYZQBoPeNsu8dGH4NfCC7AZhAYFog3K2ZfK4nFvgyHqcXd0nK7YHBc3vTgj1Z7G+loxWSbdkrK2PUw+XcrpUme8vnRpUwfKnTo2oQxhfhfG66+3Fsr3jm9XQDja+dknnUP4lqxv7NcGshwpnDYqpx5Hq2hzFe7S2FfZz4o+cB05rHTp3SqWn4QM/hhqbjgGn4+HqPlno1aR62PkTzXl8hqLHvLHdB05rhZ9vPx4PDmkT8Tevotk3tw1o5nsQ48RW4fVO3XpyRnoaypfxHnAydKhfOTSbZyyyTTOpOTWShQW+Y96qu2ifN1RvMw/Z/PBq/eOm9XGVsGbEkJhziJrLZO7J/v0t0SVoN3/En25TTzLhxBpM7mAZ0mplvRKaP8/QTnWj7pWsQ9kbPW5bS10MHKWAuxxm8PLjoNS55v3vymzb4JFOd2VVEChi7K9F27r+5eqI9eHs+OY1cI7m8DfHHEcQKF8mA61s8kYAwHV9m4SNH47XEB6jPL6uT/GhX7+0Cybc1Q+zHjoZdYP5lyrEUAlJpoeGtI6YYck4/q85vrHjkD+d4Eh6lEPVQttwfXchnbwOOuuzzvpmePj0tnjlok62U0gDQGYwSafTrvn25l54+cJOYa+NvuN4DOngkivLS11O47vxMrSvYmYp3DNIL+eDbp3TrointT8urDIU7fXCvH7rtsxDNFLRaxd3wc39m6JlHW85vx45o61rL6mBNsmavQjbb8K+fIns3VS4TedyVK9QBl/e0DOm9Ttda4wZUM0Je3V4eVg7vUNd23uOEALVKxQG/b0Ov1JN7OHp0uMxsb5KjJPbJpzdZ9Sdhe2RM9riC9MxWa18adwyoBn+vG8Ach6KnDpc5axOdR17c9eulGkbiPb6FRkPu1XKJa4BNpWMuk3jfq3B3MvSPHW8U0Oo2/3QfK1rWrN86LpSrnQ6nj03PjOGOZ3jvZsVJgU3PqOftwUv6/ri+p6Y/sBJAApzEdoF4F23C6C9S9BHZfTtfTHn4cJezd/f0sfT+81HxisXdcayp051Xt70hqoez1f3YXElo8tREbsdFQ/WCpFTpcufoWqq9YavuHGN8oXTW1tum01rObf8z3jgJGXOk7NdZhpRVaLNu6Zbll4lI9EqlQ1cWFUPmn7eANocV8lzBSbeXSXtytOsVsWwynlRY3xv1/VtEjHDkvk71RnyB5h6dkQMVVPvwZ5NCoOssc6a4bYtK7djxu7PZUunB6euFY7LAYXlVxWpa6NqEbMSeZnlSit3j+VDKsvqsLus+R4Mo27rg9cu6awul/3qbMQ/qGDs177Nw4ebhHpRxrkIH13TPex3p81d0atwmFLD6uVwX6xdyxVv7dSgSiiI3z2rGv5zXgflW9zOkVTOhxJNL5nAMk4BbP0PPOLcDvhr2IlhQ2hU+9O6zmhn0HPj9bu61GW4nNv6/Dg27PZ3dZugfSoEgP+8b0BoVlDDk2e3C/Vy8BIY7N20OtLTBOpXLYcaMdQz7PbKE2e1i2gw6udh1i/jnh3L0EErL8dNNBOmrHB5wFYr/Hw6X1+sD9Itarv3Oq5TORPvXxWZC8dg3o3mQOLoO/riwm7qRjErL58iWaGD1y/pgguzG+CMDoW97JRVIdPPZUuno3al8J7j1t/jTQigSjn9xrDIRi+HfJUu51DvZjXwlsPMxEBgyLRWuSA4VI3iJ8tT99Q4VZ6svzucYeYhGyq1KmX6VnE2zrvBbevgm5vsu05aT9BoWnKjLfIHV3fHI2e0cRy65MfuuE4x9t5P1n1o/f3bm3vFtP5Mjy3MqcTcEqXbQm3XA83MLsfRSxd2QsvagSEjXnPB2NGfSUbtom4NImdcctgXqhu48ZKxD6t6qCDElccbfJ3KmVj2ZGRFu0P9Kji9g3oCAa91iEQEH9rVq4z5j56iHMIBAF1cJmmItceM273EsGbEEE/Td0dbXzN/nK9v6hUx85vueu32SsR9Srtk/lEOVdMoiCqBdTT7uXRGWsSDrd0DpXHpuzC7gaeHiXhZ9uSpGH56YY5H88yZVnaz0/nhXyc3V75ul89G54E92lNZ9+GoftVyoVlBDWUy0tEqOJOczmpiSUnQ0CbYr3J5z0ZoW7dyqFGwVEYaLuupn1/L2JeOjSdxPPl/v6c/lpsCQTrbimXGMQGR0N4VjoFQCTSsZv9dd4xiYhEv4h0s+NjS2GJnSIfj8Ox5HcJmNfYSQI7+ehC+A05uXTt0jkfDrRgRzy0ellUZHMwfakd7gihRcvLEFt0nuyKsW5Z78mSD3clcMTND/+RUnD1OFwm/bgixPGQYb51wl//5f7x48qx2EV1w61Upi6v7xDeoA9jnzdDiw1fYtZHiOPXwlS55IpoWrdRwYbeGnpNi6yhnM8VpZql0XBIcEqaarUT3VPrsuh6hoWMZ6QKXByu/be0eahzWO+LcDvjlX33DLh9lHCqbqsZWLz1ZdCs5r1zUyXV2HIPdMDtV/gS3rbslA33z0i4RLex+82NGqIoOSZfj1cvDjt8VLa+ld1q+evnS3mYm1PgwyeiZ5DVnmtF9/0bNc8zLdg3KHkcCKB8MhDxgmpCjf8uatomnw9/v3869pEdDDGhZE6Uz0rTXe+fJzR2nLPf6gGm+3rjl/YhVzkMnh4aLTLjrBPz27/hex6ym3DMAn19nPz279TsYcU57x54CH1zdDXec2MxzOZ49twMeGtI6mFdO4KreWXjlok6u7xMakSNjhkKDn4GXjPQ07YaioiiWfRVL7qbQ9h02b/2TeVk/vuN+mo0tyWacAv+7MhtjNfK2fnptDzx2ZtvQcNF/hg/E3IdP8bxd1+tqgqI5Av7k3i0KimYikhLEWmUxTrI7T26BtnUr4aJ3pgGIpnU7MTXYqsHxxxd1a4gP/17jurz1vGtWqyJObFULE5ds097mkA7HYfS8zV6Kaeuyno1wWc9GGD1vtNbyqTZkIZryXNqjIa7snaX8WymPyRYeO7MtHhm10HshUsBjQ9vhqdGLQg/TxrH5x70DlA/YOi379w4OTC+cJgKBFvP05lf0aoST29R27Hbudt72aVYDTWtWwI4Du5CRloa+bWo6zlzmRe1KZXBOF/vhp45dhoP7xuvxOOPBk3AktyDstaGd6mFoJ+CZXxZ7W5nJk2e3w09zN4WXUaNwj57RBs1rqwP25pY+wL8gRiKuKU5524qz7o3t8/DNGj4Qfy7fEfH6CS1q4sJu4T2ThAh0+99/NM9xHyYlx5HN6z/e2gerdhwAYH3YSS0fXq3X4q5Lp27/9Nnq3CeqoWHGtS0jPQ2dFT32IofSum8fAIabkjb7NfTMmADAyjz8y9pLKG5M30PD6uXQsHo5DG5bB2MXbnF960XdnYcYOSUQdvr6q5Qrjev6Ngn9bkxE8K8v5zhuT6fH0ekdjwtbNhHieS7HY4ZLK/3j3qnu4b82x1XCe47D45y3WjEzA/uP5PldrMhyuI/aj1m068uqUQ7Hm4aDGs+KbsEX62ey3ovN+javgd+Xbo+ugB7F1NBfxBTfEHUxddMJTXHHic1wWc+G2ies56CSy0XPbXrfwvUEkiSvfPo0/OskdVdrM3OSO/P66lR2HnNbyppwOMZktNqUuWj8vU0lMoBttI4MblcHLRQPxzf3b4p3rnAeD2x1Ze+suPTciYWqp56qiJf3bIQlT5wa8TU3qFYulAQ8bB2m5ey+N2tvj59v72t6v7ANGnk5DloHexfVrOg+1KNaudLaK7/9xOaO3duV6R0sAYkh7e2HH6nOx1oVM9GwujqvlE6p7c7x6uUjh5nq9C65qk9j9Gmmn/vCC78eKIxhgdZeVX72+kqWdvUCPS8Gtw3vXh7NdXLkTb1wt8PEFIB6n310TXecpjiOv7qxF4ad2gqVMkulVADOLljVsUEVnN05ckKIfMWJHDouPOxnp2PJWE0j67mdiCCpD70XzGtwSwoc7TlVNQ6TZtgNedPi83ej+hbeuLSLMvdOCp1OSsY11/rQa56FMtWvrTrMH2/YYPfJIWKtv+qcq27LmOt7YQFyT4ULX7ZxzfJhybut+rcK9BKyS9w9/v/64fPresR9uJ/60h+fbXo9vqNtRDFvZ82IIbjYIYj8wgUdta55F2TX1+rVqiyP+WOUkMiRVuBICDFYCLFUCLFCCDFM8fd+QojZQog8IcR5lr/lCyHmBP8bZXq9sRBienCdXwkhkj+gPQVZT66ypdNx1yktI5JRO52CRl6Vewa1dNxWzWCrU3WXCsvPtx8fsS7VRaNVcJrf9DSBquVL4/Gh9tNIT7v/JEy6u7/yQjp8SJuIaaIN9aqUxfKnTnMsrx27XjW6BrWtHdZjBIj94e/Dq7uhToKT01nZ3QDuG9zKNklwUfLdLb0x88HwmVmcZsEzuN3kzXvNaPG0PuAWrivA7VyL2Ibiq7FOgfrAaa3x3S290ayW+1DWu12uCQHSdtthS6lyHFne+/AZbfHP8IERy8WLqm449+FTUDojLfS387vWx7XHN/ZlVph4yEgTuCCYe8fo6fbWZV1xrs0skJXLlcIjZ7TB59dFP1NWqmpWqwJWPX1aRO8uHdbDt3GN8jHl+TBrc1xlNK5RPmIIZSrMsuL1lmQk+HV6n1+BsaL+KP3tzb1t84UZCvdVYL96ndUtfB2ay8dxz9od0e9eYe6Bob/9O0yNimlpIuyc9KvhzHxvalgt8MAfy2y253etbwkKBVhjrnMfKRx6E+05M/bOvu4LJZgQQCWbWZjdjL2zLz7wMA29Dqfj5O5BLfHvgYEGgmgPJ+vz1iWmYEVkzh2Jewe1wrT7T4oYnmg4rnLZsNnVEsko7xNntUvodq299O3a6fzslVsmI11ropXnzuuI96+K7Zgc3LYOLvWQF60oc601CSHSAbwO4FQAbQBcLIRoY1lsHYCrAHyuWMVhKWWn4H9nml5/FsBLUspmAHYDuDaK8hd7sXTUNKZVvL5fY1x3fGNcY5OXx5je9Oo+jfHKRZ1wXlfnaenb1q2MWweEjx+3nutndqwbccI6JRmrUzkTlcuWUk4LXbZ0ekTLqNPQCt3KupGot3SUDw+1KmZi+gN6U8Pq6t+yFno0CeQWilcCwlNtksGl8vDcr29UJ+o+KYqptMuVzoiYprexQ8J6p4SodtrUrYQ1I4agU8Mqyr+r8hg5cdq0dQrU0hlprkmODZml0kPrthvGoCvfITm2sQ+NILJKXI8/04WismUK1irlSmH46W18zxFRr2rgAcXp2DIz9lG7epXCAvPnZzfAY2e2xaLHB4XKOLhdHbxwgTqYDgSu5bozAAY4Bwd/vv14rV6jiRBt8njjs711WVdc3L2hpwdHt2PzeMsMTKnUu8BrPbycQ04QL6eoc44j43grXChs8TheC/y8zugciqFhTNJ4T+KOjRv7NcHqZ6JrWNN1dud6ePj0NhjYpjY629zvVIxjwGn6b7vZSc287s47T26B/12RHTGzpI7Zwwdi9vCB+M/5HbH4icERZbDW19zy4uloVcd70vUKZQL3uAZVvdwD/Kc61VrVqeQ4lNBM9zrqdEqXSk9Dt8aR+Tq9BCgaVCuHB08L5F2rWbFMWK/jJ85qi/O71g9rBExPE64jJRLBaf8dl8AG6tnDB2Lsv8IDoNHeI1OhMUZlSIe6uPZ49TN2caNzVesOYIWUcpWUMhfAlwCGmheQUq6RUs4DUKBagZUInLEnAhgZfOkjAGfpFrok0RteoDbp7v747d8noFzpDDx0epvQtMNWxvj29DSBoZ3q+TKrU5Vyka0RnipsiiL8ckfqtbxY2e05u2CNk2gukDozlvRuqs7rkcp5TrorbvxLnxysP+NBAhjnjc639uUNvfDB1d08n2t+fDXW6eNj/d6tD0Zh67Ys4yS/QOv2EWIMW2qpGHp4Q78m4bMCJiEqOqhtHXx5Q8+waeWdGPvoncuzwwLzmaXSkZYmbGdQ8pPd19SuXmX838DYAou6opmdqm6VQCVYJ1h2QouaeOac9knJN5QM5s95h03wz7jXdG5YxTaBv59C1wXTa0K4P0p8e3NvfHVDbD3pfLkURLGSAukeBPFxcwHC/QG5u4fJWlReurATronigSnG6mDUSqWn4eQ23huc6lTKRLXypZUB58KhaoXL+jHsPFot61TE25d3xTPnqHN1+clpiLdTvsZYWLeYiH16pmKWSSDQe+g/53cMNepEU5Z4NTR4udYYPYJUE4c40fm41cqXjnj+TFYKi3gdKqka0IoHnSOkHoD1pt83ALCf/iBSphAiB0AegBFSyh8AVAewR0ppZAfbENxOieTYJTyGC0r1CmVQvYL9lPHxFG2pnU69NnX1HiicLtwNqpXF+l2HAXi7qF57fGOMnLXBdTmjkmZd96sXd0bzB8fob9CDn28/HjNW70K3rGpoVy98H6k+ovEAaje7kt/Xc+PrePrs9njg+/m+rdfafTgVmc/fMaYWl5oVy2i3uvnt9A51MXHxtoihWW7fu921KKt6OWzff1TZkh7qWaBRrnxvcSOc2bEu2terrOzR80CwdfC72Ru9rdRnPZvYJ1+2MvZRvKofuveSHo2rYfrqXXEqRSBB/DtTVmHPoWOoocg19cu/vDcQnNmxLqqVL43jNbr/u1Xw/rh3APKUCbu8M9+LvrlJ3WsyUUqnp+GugS1wlyIAaPS6rVGhDHYdzPVle05HW7QPel0bhfekfGJo26iHzPjBGpRRzhZn9FgNvSea7Xhb3stDTPkyevfR0PXJ4cu7tX8zXPdxjm8Jtv0OCEQbK/7fFdloW09jOHuwvNMeOMm9LHHulTjIZpj8Nzf1wpFj+VGtU/V1qPJhGt67Mht/r9yJ27/4J6rt6XI73tvVq4zalcrg7lNaYtzCLXjvz9Wo7PG6Udh7Wq2otEPY7akmNcpj+OltcIbHIfu6DY8R57LH/VWhTAYOHM1T59K0OK9rfew8cFSrXORdImZVaySl3CiEaAJgohBiPoC9um8WQtwA4AYAaNjQeSaFosrpPEilse1eRNuaq/ug6dSF2amy8csdfXEoNz+4Df0yDj+9DYafbh2hGclYo3V2lWiGwQgIrYpTu3qVQ70vCrcXKIkqh8dZneth18FcXK7ZE8IvF3Zr4GvgKFH8uvG0jqInRby8eGEn7WXdjsF3Ls9Gztrdyl6Gp7U/Dj/P26w1PMMY6uZlSJTuMDCnLzHZPU8yS6XhyLHCqFm8pnTNqmHfGye0SRFI/nzgaPxmfLmlfzPcfEJTHM0rCJuZ54HTWkUEBnQJIVyHnuhe7829lvw8Mjo1qOLj2rx5aEhrx/3TtVFVPHBaK5zftQHOeuOviL8X9ir069iMfAoTIvCw+82sDShTSu9+eXmvrCi2HPtniGbInmoYvq5S6Wn4/PoeuOTd6Z7f61Yu/eXd33Bym9qus3he3acxxi/ail5Nq2P0vM1a6032Ndqth5LdUDUnyeqh0C2GHmZ3n9ISD3w/H5UyS2HL3iMAnM+F6hXK4PQOx8U9cFTDpYG8QpmMUFqJro2q4sZ+TTznuNIZNplqHDslCOvvIqFDrbxeB7+9uTfGLNiMMhrDP58/v3AYf8JmiSxBdO7OGwGY57urH3xNi5RyY/DfVQAmA+gMYCeAKkIII3Blu04p5TtSymwpZXbNmt7HJJc0yboZWW/sdsOhAsvar6df85qoV6VsRA6lWJjruhUzS6G2dWxvHG4EJ7SoGcodFYtov81bBzTDjf2a4NIekcHW9DSB6/s1iZhONV7HzmsXd0HbupXi2jW1fByHV+gWO571iXgFEwD9793uvK1avjQGtqkdyulj9uIFnTDjwZO0huQZQ9V0ZjfzUzz3rY7f/t0fn1/fAx2DgQUj6eqPt/bB5Lv7x7x+I9n+UzZTjJsJCGSWSnetiMdKCBFx/bmhX1N0bRTbsBknfZoF7knWJJ0lwXV9myiHdBqEELihX1NULV/at14eTg/79aqUQ2apNNw7qGVYsPDpc9pjxgMn+TLVd5bdbIyKz3dCC291y5cu7IRzutRDO0svaLvZZQPbje3Bs3dT/WS6Og9lybrstaxTEbOHD8RJwVmMWtS2f7BL5byLZunBL7VJDfeH1GQFHprVqmA7oYKuS3o0xJoRQ1A6I82Xz/HLHX3xw619XJdzOg6kDASOdCeVSU8TqBVDfh8/G+eNiYu89n7SpW5Y9/ekiva5wettuGWdirgzijycNSqUwZoRQ3CczzmnTg7lVy159QmdHkczATQXQjRGILhzEYBLdFYuhKgK4JCU8qgQogaAPgCek1JKIcQkAOchkDPpSgA/RvMBKPXMf/QU5TCo9GAvmLoO01hWLV8afw070Zdy3HhCE7z9+yrbv8fjBm5eZ7wfvpyUK52B+4PDdXTdOqAZpq2aoT0kUNeQDsfFdcaqr27oaTtlu59UN9zvbumNe0fOw4ptB5Tv8fsYi0fLq1tX4ztPboGt+47gdJfvsJLinC+dkWY7s4iVMVTNjxxrRUm9KmVRr0pZdG5QFTeesD80vLijzz1UEpG7JpX99+Iu2LT3cEKGuDYNtnKak/AXt6PaGN6mOu/dlC2djiVPBKZd33kwF7PW7kajauVQKj0t6oc66/VLd8ij0UNm1fYDqOCQGNysac0KePGCTlrLGr1+jbtHvJJjv39VtuPfYz3/2wd7NV/ftwn+WL4jpnUBgaTanRtWdew1qsqFFY14B6Ay0tPwwdXdQvsoFU246wTP71kzYgiyho2OabtOdRY/65qVy5bCln1HfFufle4x5OVQa1arAh49ow2GdEh8rs5k95yKtS6rynvql5Nb18KExdts/z57+MC4BfuKAte7pJQyTwhxG4BxANIBvC+lXCiEeBxAjpRylBCiG4DvAVQFcIYQ4jEpZVsArQG8LYQoQKB30wgp5aLgqu8D8KUQ4kkA/wB4z/dPVwzYzUBkJxWGqtnlzqmUWQpvXNolpq6yVtbPa+5+qrsv/NxjThfDCXf1w44D7vkjktXK1rd5TWU3844NqqCXh1wtidYjzmVzur91aVgVP99+PHYfysWHf62JWxncDomXPQw986pO5Ux8cHX3uK3fYCSP9bPH0aC2dfDZ9HXolmU/BCrZwyAMZUunx2U4k06LYCz5V4qKsqXT0bRmYrqt33FiM/RsUi0sx1WqHGdudIvZrl4lPHx6G5zVWZ2eUvfTXtK9IS7u1jDmgPFxlTOxYffh0O86s6Wak/c28fHYaFKjPJrWqoCeTaoXBkZccqREa+K/T0CFMhmOAbc/7h2A8ppBMTvVypd2HYbmhRDCw1Bj3zYbN245C3XPq9IZacjNC0/417tpdfy9cme0RYurRPTYTYVLp9s9MtoiXmUz27U/FHknY1yjU13Ki0S3D3rZ3LtXZKPx/b/Y/r1UuiiRPZcNWncSKeUvAH6xvPaw6eeZCAw3s77vbwDK/vHBoWvxfxopov49sAVu6t/Uc26cVM/sflp7f3qeqO5VP99+PGpXysRDPwTy6KTCzcasWa2KaOYxH3Kyh9EAgSEzZC+zVDqOc+hF5ye7Q9ru4a0ouSC7AT6bttbX3mn9WqiDoWapcI7F6u5TWuD58cscl9EJpKfYJTNleL2vZqSneRpalEoch4WYfhZCRDWblpUQwpd79VuXdcWfK3bgX1/OCa3XzXe39I59wwrVypfGu1eE9wDS7XF0Ve8snNhKv6KgCngZU4Mbyed1ZhtMRcXh2mzVPJhMumWd8N4295/aCr2b1sDDoxbgn3V7YL4af359z5h7/vjNz0bqqfef6Piso5NYOVHPPq75V1PomHXKAet3JwO36611t0S7/UTsXiEETmtfB7PX7rH9e4TU+drjLhHJscmjB09rjSt6N3INGqV6kCgRzOevNUF0qjwEabeqKZgvkncNbIGJS+y7TxY3NSqU1uqhFYszOtbFsi37tZZNZn0gntsubElL7hnTrFYFLHx8cFLLUFTddmJz28BR6+MqYeu+7Y5JJVOpsptSXE6J3+/prz0DW6rcjxIl0ZeT6hXKYGineoWBI8vfJ9x1AlZtPxC6lratWyky36GNP+8bEHPCeCn1uhw9embbmLYDBGYVKpUhcIbDEJhUa1hz4tdDbir0yB/Utg7G3dkvIufYjSc0BRC4Xv+zbo9ysoniKlENb/GU7PqTZ1EW97Ke4ZPqRF11iHL7oSTlUW5W1xuXdo3zFoouBo5S0PX9mkT93mTdGEsFu+1d3zdxWfntaI9FTsCz0vQHTtLqIv7U2e2w0xIksd6H7jipOe7wMONUUZfz0MC4t7L99+LOrsukQmXTOBaimZ3PTUmPGRS5Cp9Hr13SBQs37vU87Jng2orYqLp+o0AxP8xSjnV/N6tVAc1qVcC8DXuUf3dSv2rsPXYKexzFvCpXaWkCZ3d2ToRcr0rgM2X7mDrAb8Xp1mSuRzglqn/kjDY4p3O9hA2rjZZx/mSk6x3Qfg5Br1jGv6BazYplsO/wMdfl3BpXRpzbHiPGLNEORieC35cap97bXrfldjjYJbM2cmZaZ66mxGHgKAVEe3KnwgOtwbiJdG+cmFw4OhUK3YqhXxX6P+8bEPGa7k3k0h6N3BeipNKtxMYjEFO9fGnccWIznNkptYekPXdeh7glf41V27qVsHDTvojXi3tvmwplMuKeB4xKBi9ndjwDsq9f0gUzVjvnfHHbfqLrT4WTEKTG9bFlnYqYdHd/NErlYWwuEzck2+ND22KSz73Ay2Skp3Qwz9CydkXc2K9JRA8UlWGntkL/lt5nxbb73tvXr4yr+2Thg7/WhOpl0d7Gpw470VOA0u787du8Jvo2T/2Zv5NV27GOkHG6Dn58TXfb4GqzWhUw9s6+aJbEwKq55Kl6bYonBo5SQLQncrKHqrU5rhIWbY58EEsk1Tmr/YDv8/7zo1XSjjmJZ0m14LFBEADaPjIuods1bgzRVEz8uqkIIXDXKS39WVkcXZDdINlFsPXtzb1x5Fh+souRklJluGKqaRacKvzi7g1jXldx2Lc6l8AmNcpj1Y6DcS1HLDN1JitObNQ3UimnaizD6BMp5lnVfClFpCt6ZeGKXllxWntqS0sT2jP33hQchueV07l6Wvvj8IEPE5JkaPbiTuR1o0nN8li1PfpraFb1cliz85DjMn5dhoyGN6+3N6frYL8WzgG4VnWin43P74bCJ89qh8d/WlSienQzcERR++6W3jicG3gQS8VGe6NF0S5AZPSMSKWupVZuU6WXJLpTJfutuO/60JjxYv5BM0ulI7NU5JTUxeGBnuKjVsVMX2eSKkqcTgunc+bLG3tikaJnX6pI1gyC8UpKW5wlu3GUio6LuzfE4z8vcl8wxS19cjDShEDzB8fEvC7VdTpZPaz9So6daga1rYNBbeskuxgJxcBREZbsE8/uQSwR/Lj4ZZZKx4sXdAybMjkVsKpU6Ofbj0dmqdjy+tx/aitPuUiiVkTvgzUrBGbeqV6CWkzIfx3rVwEATzNCUepS3WJ1bru1KmaiVsvUbYwxJPpynayAVVHWuEagx1/HBlWSWxAf8Hv3zjF4bfn9muMbo0q5Urjr67lJK5MfymQk5pkq2Q1mRfl8KMpl9wMDR0VYKrXGJOpEurl/07A8JbFe/M7p4pxAkpLLOlMeAIy9sy+mrnTOb2F2Y5TdpK1czzfFn5Md3NVxdZ/GqFGhDM7sWBf3fTs/IdsslS5wLD+516+zO9fDVznrcblGjobiTnPCJ0dt6lbC8qdOjUsCd0qu1L+K6UtEi7tyC+w97Fn3xtXw279PQJMiMqQunk5oURNz1u9J+HbfuzI7JWd4a31cJRxXORP3DErMEP5Ed9R59Iw2RWL400mta+OjqWvRzSUvl3X3Jfo6mOxAWXHCwFEKKA6Hc6IuqvcNbgUAWLn9gGtZisN1oqQMI/KiVZ1KMY1x9qpr8IbYpZjO4pCeJnBW5/Ck238NOzGu25xw1wlYnOT8aLUqZWLiv/sntQypJtbrDINGxYf5WGhcM/Dg3rtpdfzmczLgRAtVVeJwU3VaY+E00ryZe+E2u5ixN2tWLIPt+4/Gv0BJ8tE13ZOy3ZNa107Kdt2UL5OBqfeflLDtJbouflWf6Geo1po8KOq1h+vXoiZWP3Oa58BMoq+DT57dDk/8vCg0K1s0UjElSzKwlpcC/DgWz+hQF+3rVcYN/Zr4sLZIVcuVsp0eMRb3Dm6JGsGhMtFQXXp6NA486DdI5dlCNDEvQvKd0KIm/hk+0DVhX3H4it64tAvG3dkv7snYG1Uvj8HtoktuS0SJ1apOJUx/4CRc1qv49M5L+FC1YtSglYrqOtyzjL/Vq8pJRig6Rh08vYifwPG4DkXTm0d3koDBPuUPGtCyFib+uz9KZ8Qe9ijpz2PscVQMCAFULV8aP91+fNy2MeuhgXFZ7y39m+GW/s08v69u5bJIE8Bdp7SI+Nt1fRtjcLs62HPomB9FTLj+LWrip7mbbKejpMSLtstwUatjnNaewZySKFkJMyn1nNquDt6esgqVy4YPT6ldKTM0i2oqX9Y6N6yCf9btsf17sg71AmP2oeRsvkQ7t0s91KhQGie4Nf7EEb/36KXC7alBtbK4vm9jX2bYTKZoU5zUjzHoaq1j6Aab3rq8a0zb9ZMQqXEsJhsDR0ny3pXZuO7jHEhZNG4oaZrh4UR9lrKl07HqGfVsN0IINKhWDgeOBiq5lTJTb3y2k3O71sfJbWqjctlSWBPnaY3JP9mNquFtrEKH+pF5mYji4c6Tm2P+hr2+ra+kt6QRcO/gVrjphKaoUs4+WJ7KdedPru2BbfuOuC6X6KD+iHM74PlxS5Gu29Su8MFV3VDGhxbzkkYIgf4tmbSfoieEwIND2iS7GL7xcq9f/tSpvtcMWNMouhg4SpKTWtdG+3qVMW/D3pSuhBVlrepUxPDT2+DMjnWTXRTPjNbe4jYTyxW9GuHjqWuTXYy4GNimNnIeOjmmoZdEXtx5cmSPS6JYpKeJIpGU1U6FMhmo4JgXJzk1rguyG+CC7AYxrWMAZyyMYAQ42xxXEXOTkDya4q+41H+LKj9yFyY7OTb5h4GjIsyYYtyvMaDFjRAC1x4ffYK5VGBcW4tL0tnHh7bD40PbJbsYcWMNGvHeSImUVT26vG5svCAdRp7DTkV4enQ/ZhCk1NG4Rnl8e3MvtK1bGV/MWJ/s4tjirE7R4/Cg6KiOuFTZl0X5fCjCRfcFA0cpINpjsF6Vslj0+CCULZWu/Z6vbuiJXQdzo9yiuxS5JhUbjaqXw60DmuL8rrG1VBJR8bbo8UExDYMBwKfpOGhSozxWFZMhx63qVMLYO/uiea2im3+vZsVAcN9t+uhoVAv21Gpfj8OVE6lrI/+/S6Li6LT2x+HvlTuRVSOxkwdlVS+P87rWxyU9GqJK2aKVPoTCMXBUxJUr7e0r7NGkepxKQvEghMA9g1oluxgUpaLcqkJFi9d7QRhG/OPmm5t6Yc3O4hE4AgLBo6KsUfXymHBXP2QFe2z7qUnNCvjptuM5sQWRj1iN8s+lPRrivK71kemhw4Ef0tMEnj+/Y0K36bdU6a2VbMVj/AulDF7fiYiKjr7NayS7CMVa9Qpl2CMixTSrVREZcRr+3b5+ZV+mfCaiAN0H9r7Na6JsqXRc06dop6iIldP+EkIkPGhExQt7HKUABjGJiCjR5j16CjIz0tH1iV+TXRQiomKLjarxV7NiGSx+YnCyi0HFlBDsdQQwcEREFDesLFIqq5RZPGdvJCIiIvILg0YB7E+bAlhXJyIiIiIiolixISg+Svp+ZeAoxdSrUjbZRSAiIiIiIh+U9IdNIioeOFQthSx9cjDSeHchKjZ4OlNRIIN9sHm4EhFRKujcsAqWbNmPSmX5qEqUKng2ppAyGUU3033Z0oGyZ6Tz0YOIqCgSjHQSEVEKePTMtri0RyPUr1ou2UUpUiSnXIorUcKb2DhUjXzx5FntcNfAFujXvGayi0JERB7838AWAIBMTiNOREQpoExGOtrVq5zsYhCRCXsckS+qlCuNO05qnuxiEKUU9uCgouC6vk1wXd8myS4GEVGxxLoAUdEmBGdWAxg4Sgk8DomIiIiIovP3sBOTXQSilFHSh1T5jUGjAAaOiIiIiIioyKrLWYmJKM5KeudBJjRIASX8GCQiIiIiIiJKiqrlSiW7CCmPPY6IiIiIiIiIijAOqYrO2Dv7okaFMskuRspj4IiIKI6u6dMYQzrUSXYxiIiIiIjIolWdSlrLlfRRQgwcERHF0cNntEl2EYiIiCjBGtcoj9U7Dia7GEREvmDgqASrVr40+reomexiEBEREZVIT57VDk1qlk92MSgOvrqxJxZv3p/sYlAJVNKTOFN8MHBUgs0ePjDZRSAiIiIqsS7r2SjZRaA4qVUxE7UqZia7GFQCMddRfIgSHpHjrGpJVL50IG6XnlayD0IiIiIiIiIiSk3scZREr1zUCd/M2oC2dfUSchERERERERFZlU4P9Akp4R1jKE4YOEqiWpUyceuAZskuBhERERERERVh713VDSNnrUf9qmWTXZRiqaTH4xg4IiIiIiIiIirCGtcoj3sGtUp2MaiYYo4jIiIiIiIiIiJSYuCIiIiIiIiIiIiUGDgiIiIiIiIiIrJR0pOOM8cRERERERG5uvb4xqhQho8PREQlDa/8RERERETkavjpbZJdBCKihLqyVyN8NHVtsouRdByqRkRERERERERk8eiZbbH8qVMhSvhYNa3AkRBisBBiqRBihRBimOLv/YQQs4UQeUKI80yvdxJCTBVCLBRCzBNCXGj624dCiNVCiDnB/zr58omIiIiIiIiIiGIkhECpdPa3cR2qJoRIB/A6gIEANgCYKYQYJaVcZFpsHYCrANxtefshAFdIKZcLIeoCmCWEGCel3BP8+z1SypExfgYiIiIiIiIiIooDnRxH3QGskFKuAgAhxJcAhgIIBY6klGuCfyswv1FKucz08yYhxDYANQHsibXgRKniqxt6Yt2uQ8kuBhEREREREZHvdPpc1QOw3vT7huBrngghugMoDWCl6eWngkPYXhJClLF53w1CiBwhRM727du9bpYo7no0qY7zsxskuxhEREREREREvkvIYD0hxHEAPgFwtZTS6JV0P4BWALoBqAbgPtV7pZTvSCmzpZTZNWvWTERxiYiIiIiIiIgIeoGjjQDM3SnqB1/TIoSoBGA0gAellNOM16WUm2XAUQAfIDAkjoiIiIiIiIiIUoRO4GgmgOZCiMZCiNIALgIwSmflweW/B/CxNQl2sBcSRGBeu7MALPBQbiIiIiIiIiIiijPXwJGUMg/AbQDGAVgM4Gsp5UIhxONCiDMBQAjRTQixAcD5AN4WQiwMvv0CAP0AXCWEmBP8r1Pwb58JIeYDmA+gBoAn/fxgREREREREREQUGyGlTHYZtGVnZ8ucnJxkF4OIiIiIiIiIqNgQQsySUmar/paQ5NhERERERERERFT0MHBERERERERERERKDBwREREREREREZESA0dERERERERERKTEwBERERERERERESkxcEREREREREREREoMHBERERERERERkRIDR0REREREREREpMTAERERERERERERKTFwRERERERERERESgwcERERERERERGREgNHRERERERERESkxMAREREREREREREpMXBERERERERERERKDBwREREREREREZESA0dERERERERERKTEwBERERERERERESkxcEREREREREREREoMHBERERERERERkRIDR0REREREREREpMTAERERERERERERKTFwRERERERERERESgwcERERERERERGRUkayC0BEREREREREZOfYsWPYsGEDjhw5kuyiFHmZmZmoX78+SpUqpf0eBo6IiIiIiIiIKGVt2LABFStWRFZWFoQQyS5OkSWlxM6dO7FhwwY0btxY+30cqkZEREREREREKevIkSOoXr06g0YxEkKgevXqnntuMXBERERERERERCmNQSN/RLMfGTgiIiIiIiIiIiIlBo6IiIiIiIiIiBJk8uTJOP300wEAo0aNwogRI2yX3bNnD9544w3P23j00Ufx/PPPR11GMwaOiIiIiIiIiIhilJ+f7/k9Z555JoYNG2b792gDR35i4IiIiIiIiIiIyMGaNWvQqlUrXHrppWjdujXOO+88HDp0CFlZWbjvvvvQpUsXfPPNNxg/fjx69eqFLl264Pzzz8eBAwcAAGPHjkWrVq3QpUsXfPfdd6H1fvjhh7jtttsAAFu3bsXZZ5+Njh07omPHjvj7778xbNgwrFy5Ep06dcI999wDAPjPf/6Dbt26oUOHDnjkkUdC63rqqafQokULHH/88Vi6dKlvnz3DtzUREREREREREcXRYz8txKJN+3xdZ5u6lfDIGW1dl1u6dCnee+899OnTB9dcc02oJ1D16tUxe/Zs7NixA+eccw4mTJiA8uXL49lnn8WLL76Ie++9F9dffz0mTpyIZs2a4cILL1Su/4477sAJJ5yA77//Hvn5+Thw4ABGjBiBBQsWYM6cOQCA8ePHY/ny5ZgxYwaklDjzzDMxZcoUlC9fHl9++SXmzJmDvLw8dOnSBV27dvVl/zBwRERERERERETkokGDBujTpw8A4LLLLsOrr74KAKFA0LRp07Bo0aLQMrm5uejVqxeWLFmCxo0bo3nz5qH3vvPOOxHrnzhxIj7++GMAQHp6OipXrozdu3eHLTN+/HiMHz8enTt3BgAcOHAAy5cvx/79+3H22WejXLlyAAJD4PzCwBERERERERERFQk6PYPixTqVvfF7+fLlAQBSSgwcOBBffPFF2HJGbyE/SClx//3348Ybbwx7/eWXX/ZtG1bMcURERERERERE5GLdunWYOnUqAODzzz/H8ccfH/b3nj174q+//sKKFSsAAAcPHsSyZcvQqlUrrFmzBitXrgSAiMCS4aSTTsKbb74JIJBoe+/evahYsSL2798fWmbQoEF4//33Q7mTNm7ciG3btqFfv3744YcfcPjwYezfvx8//fSTb5+bgSMiIiIiIiIiIhctW7bE66+/jtatW2P37t24+eabw/5es2ZNfPjhh7j44ovRoUOH0DC1zMxMvPPOOxgyZAi6dOmCWrVqKdf/yiuvYNKkSWjfvj26du2KRYsWoXr16ujTpw/atWuHe+65B6eccgouueQS9OrVC+3bt8d5552H/fv3o0uXLrjwwgvRsWNHnHrqqejWrZtvn1tIKX1bWbxlZ2fLnJycZBeDiIiIiIiIiBJk8eLFaN26dVLLsGbNGpx++ulYsGBBUsvhB9X+FELMklJmq5ZnjyMiIiIiIiIiIlJi4IiIiIiIiIiIyEFWVlax6G0UDQaOiIiIiIiIiIhIiYEjIiIiIiIiIiJS0gocCSEGCyGWCiFWCCGGKf7eTwgxWwiRJ4Q4z/K3K4UQy4P/XWl6vasQYn5wna8KIUTsH4eIiIiIiIiIiPziGjgSQqQDeB3AqQDaALhYCNHGstg6AFcB+Nzy3moAHgHQA0B3AI8IIaoG//wmgOsBNA/+NzjqT0FERERERERERL7T6XHUHcAKKeUqKWUugC8BDDUvIKVcI6WcB6DA8t5BAH6VUu6SUu4G8CuAwUKI4wBUklJOk1JKAB8DOCvGz0JERERERERElHKysrKwY8eOZBcjKjqBo3oA1pt+3xB8TYfde+sFf3ZdpxDiBiFEjhAiZ/v27ZqbJSIiIiIiIiLyn5QSBQXWfjPFV8onx5ZSviOlzJZSZtesWTPZxSEiIiIiIiKiEmbNmjVo2bIlrrjiCrRr1w5PPPEEunXrhg4dOuCRRx4JLXfWWWeha9euaNu2Ld55550kltg/GRrLbATQwPR7/eBrOjYC6G957+Tg6/WjXCcRERERERERlURjhgFb5vu7zjrtgVNHuC62fPlyfPTRR9i3bx9GjhyJGTNmQEqJM888E1OmTEG/fv3w/vvvo1q1ajh8+DC6deuGc889F9WrV/e3vAmm0+NoJoDmQojGQojSAC4CMEpz/eMAnCKEqBpMin0KgHFSys0A9gkhegZnU7sCwI9RlJ+IiIiIiIiIKO4aNWqEnj17Yvz48Rg/fjw6d+6MLl26YMmSJVi+fDkA4NVXX0XHjh3Rs2dPrF+/PvR6Ueba40hKmSeEuA2BIFA6gPellAuFEI8DyJFSjhJCdAPwPYCqAM4QQjwmpWwrpdwlhHgCgeATADwupdwV/PkWAB8CKAtgTPA/IiIiIiIiIiI1jZ5B8VK+fHkAgRxH999/P2688cawv0+ePBkTJkzA1KlTUa5cOfTv3x9HjhxJRlF9pTNUDVLKXwD8YnntYdPPMxE+9My83PsA3le8ngOgnZfCEhEREREREREl06BBgzB8+HBceumlqFChAjZu3IhSpUph7969qFq1KsqVK4clS5Zg2rRpyS6qL7QCR0REREREREREBJxyyilYvHgxevXqBQCoUKECPv30UwwePBhvvfUWWrdujZYtW6Jnz55JLqk/hJQy2WXQlp2dLXNycpJdDCIiIiIiIiJKkMWLF6N169bJLkaxodqfQohZUsps1fI6ybGJiIiIiIiIiKgEYuCIiIiIiIiIiIiUGDgiIiIiIiIiIiIlBo6IiIiIiIiIiEiJgSMiIiIiIiIiIlJi4IiIiIiIiIiIiJQYOCIiIiIiIiIicrBnzx688cYbAIDJkyfj9NNP930bV111FUaOHKm9/Jo1a9CuXTvl3/r374+cnBxfysXAERERERERERGRA3PgSFd+fn6cSpNYDBwRERERERERETkYNmwYVq5ciU6dOuGee+7BgQMHcN5556FVq1a49NJLIaUEAGRlZeG+++5Dly5d8M0332D8+PHo1asXunTpgvPPPx8HDhwIra9Nmzbo0KED7r777tB2pkyZgt69e6NJkyah3kdSStxzzz1o164d2rdvj6+++iqifIcPH8ZFF12E1q1b4+yzz8bhw4d9++wZvq2JiIiIiIiIiCie7rwTmDPH33V26gS8/LLjIiNGjMCCBQswZ84cTJ48GUOHDsXChQtRt25d9OnTB3/99ReOP/54AED16tUxe/Zs7NixA+eccw4mTJiA8uXL49lnn8WLL76IW2+9Fd9//z2WLFkCIQT27NkT2s7mzZvx559/YsmSJTjzzDNx3nnn4bvvvsOcOXMwd+5c7NixA926dUO/fv3Cyvfmm2+iXLlyWLx4MebNm4cuXbr4tnvY44iIiIiIiIiIyIPu3bujfv36SEtLQ6dOnbBmzZrQ3y688EIAwLRp07Bo0SL06dMHnTp1wkcffYS1a9eicuXKyMzMxLXXXovvvvsO5cqVC733rLPOQlpaGtq0aYOtW7cCAP78809cfPHFSE9PR+3atXHCCSdg5syZYeWZMmUKLrvsMgBAhw4d0KFDB98+K3scEREREREREVHR4NIzKFHKlCkT+jk9PR15eXmh38uXLw8gMMRs4MCB+OKLLyLeP2PGDPz2228YOXIkXnvtNUycODFivcbwt2RjjyMiIiIiIiIiIgcVK1bE/v37Pb2nZ8+e+Ouvv7BixQoAwMGDB7Fs2TIcOHAAe/fuxWmnnYaXXnoJc+fOdVxP37598dVXXyE/Px/bt2/HlClT0L1797Bl+vXrh88//xwAsGDBAsybN89TWZ2wxxERERERERERkYPq1aujT58+aNeuHcqWLYvatWu7vqdmzZr48MMPcfHFF+Po0aMAgCeffBIVK1bE0KFDceTIEUgp8eKLLzqu5+yzz8bUqVPRsWNHCCHw3HPPoU6dOmHD426++WZcffXVaN26NVq3bo2uXbvG9HnNRKp0fdKRnZ0tc3Jykl0MIiIiIiIiIkqQxYsXo3Xr1skuRrGh2p9CiFlSymzV8hyqRkRERERERERESgwcERERERERERGREgNHRERERERERJTSilKanVQWzX5k4IiIiIiIiIiIUlZmZiZ27tzJ4FGMpJTYuXMnMjMzPb2Ps6oRERERERERUcqqX78+NmzYgO3btye7KEVeZmYm6tev7+k9DBwRERERERERUcoqVaoUGjdunOxilFgcqkZEREREREREREoMHBERERERERERkRIDR0REREREREREpMTAERERERERERERKTFwRERERERERERESgwcERERERERERGREgNHRERERERERESkxMAREREREREREREpMXBERERERERERERKDBwREREREREREZESA0dERERERERERKTEwBERERERERERESkxcEREREREREREREoMHBERERERERERkRIDR0REREREREREpMTAERERERERERERKTFwRERERERERERESgwcERERERERERGRklbgSAgxWAixVAixQggxTPH3MkKIr4J/ny6EyAq+fqkQYo7pvwIhRKfg3yYH12n8rZafH4yIiIiIiIiIiGLjGjgSQqQDeB3AqQDaALhYCNHGsti1AHZLKZsBeAnAswAgpfxMStlJStkJwOUAVksp55jed6nxdynltpg/DRERERERERER+Uanx1F3ACuklKuklLkAvgQw1LLMUAAfBX8eCeAkIYSwLHNx8L1ERERERERERFQE6ASO6gFYb/p9Q/A15TJSyjwAewFUtyxzIYAvLK99EBymNlwRaCIiIiIiIiIioiRKSHJsIUQPAIeklAtML18qpWwPoG/wv8tt3nuDECJHCJGzffv2BJSWiIiIiIiIiIgAvcDRRgANTL/XD76mXEYIkQGgMoCdpr9fBEtvIynlxuC/+wF8jsCQuAhSyneklNlSyuyaNWtqFJeIiIiIiIiIiPygEziaCaC5EKKxEKI0AkGgUZZlRgG4MvjzeQAmSiklAAgh0gBcAFN+IyFEhhCiRvDnUgBOB7AARERERERERESUMjLcFpBS5gkhbgMwDkA6gPellAuFEI8DyJFSjgLwHoBPhBArAOxCILhk6AdgvZRylem1MgDGBYNG6QAmAHjXl09ERERERERERES+EMGOQUVCdna2zMnJSXYxiIiIiIiIiIiKDSHELClltupvCUmOTURERERERERERQ8DR0REREREREREpMTAERERERERERERKTFwRERERERERERESgwcERERERERERGREgNHRERERERERESkxMAREREREREREREpMXBERERERERERERKDBwREREREREREZESA0dERERERERERKTEwBERERERERERESkxcEREREREREREREoMHBERERERERERkRIDR0REREREREREpMTAERERERERERERKTFwRERERERERERESgwcERERERERERGREgNHRERERERERESkxMAREREREREREREpMXBERERERERERERKDBwREREREREREZESA0dERERERERERKTEwBERERERERERESkxcEREREREREREREoMHBERERERERERkRIDR0REREREREREpMTAERERERERERERKTFwRERERERERERESgwcERERERERERGREgNHRERERERERESkxMAREREREREREREpMXBERERERERERERKDBwREREREREREZESA0dERERERERERKTEwBERERERERERESkxcEREREREREREREoZyS6AJ0uXAv37J7sUREREREREREQlAnscERERERERERGRUtHqcdSyJTB5crJLQURERERERERUfAhh+yf2OCIiIiIiIiIiIiUGjoiIiIiIiIiISEkrcCSEGCyEWCqEWCGEGKb4exkhxFfBv08XQmQFX88SQhwWQswJ/veW6T1dhRDzg+95VQiHflFERERERERERJRwroEjIUQ6gNcBnAqgDYCLhRBtLItdC2C3lLIZgJcAPGv620opZafgfzeZXn8TwPUAmgf/Gxz9xyAiIiIiIiIiIr/p9DjqDmCFlHKVlDIXwJcAhlqWGQrgo+DPIwGc5NSDSAhxHIBKUsppUkoJ4GMAZ3ktPBERERERERERxY9O4KgegPWm3zcEX1MuI6XMA7AXQPXg3xoLIf4RQvwuhOhrWn6DyzqJiIiIiIiIiCiJMuK8/s0AGkopdwohugL4QQjR1ssKhBA3ALgBABo2bBiHIhIRERERERERkYpOj6ONABqYfq8ffE25jBAiA0BlADullEellDsBQEo5C8BKAC2Cy9d3WSeC73tHSpktpcyuWbOmRnGJiIiIiIiIiMgPOoGjmQCaCyEaCyFKA7gIwCjLMqMAXBn8+TwAE6WUUghRM5hcG0KIJggkwV4lpdwMYJ8QomcwF9IVAH704fMQEREREREREZFPXIeqSSnzhBC3ARgHIB3A+1LKhUKIxwHkSClHAXgPwCdCiBUAdiEQXAKAfgAeF0IcA1AA4CYp5a7g324B8CGAsgDGBP8jIiIiIiIiIqIUIQKTmhUN2dnZMicnJ9nFICIiIiIiIiIqNoQQs6SU2aq/6QxVIyIiIiIiIiKiEoiBIyIiIiIiIiIiUmLgiIiIiIiIiIiIlBg4IiIiIiIiIiIiJQaOiIiIiIiIiIhIiYEjIiIiIiIiIiJSYuCIiIiIiIiIiIiUGDgiIiIiIiIiIiIlBo6IiIiIiIiIiEiJgSMiIiIiIiIiIlJi4IiIiIiIiIiIiJQYOCIiIiIiIiIiIiUGjoiIiIiIiIiISImBIyIiIiIiIiIiUmLgiIiIiIiIiIiIlBg4IiIiIiIiIiIiJQaOiIiIiIiIiIhIiYEjIiIiIiIiIiJSYuCIiIiIiIiIiIiUGDgiIiIiIiIiIiIlBo6IiIiIiIiIiEiJgSMiIiIiIiIiIlJi4IiIiIiIiIiIiJQYOCIiIiIiIiIiIiUGjoiIiIiIiIiISImBIyIiIiIiIiIiUmLgiIiIiIiIiIiIlBg4IiIiIiIiIiIiJQaOiIiIiIiIiIhIiYEjIiIiIiIiIiJSYuCIiIiIiIiIiIiUGDgiIiIiIiIiIiIlBo6IiIiIiIiIiEiJgSMiIiIiIiIiIlJi4IiIiIiIiIiIiJQYOCIiIiIiIiIiIiUGjoiIiIiIiIiISImBIyIiIiIiIiIiUmLgiIiIiIiIiIiIlBg4IiIiIiIiIiIiJQaOiIiIiIiIiIhISStwJIQYLIRYKoRYIYQYpvh7GSHEV8G/TxdCZAVfHyiEmCWEmB/890TTeyYH1zkn+F8t3z4VERERERERERHFLMNtASFEOoDXAQwEsAHATCHEKCnlItNi1wLYLaVsJoS4CMCzAC4EsAPAGVLKTUKIdgDGAahnet+lUsocnz4LERERERERERUFUgL7NgKV6ye7JORCp8dRdwArpJSrpJS5AL4EMNSyzFAAHwV/HgngJCGEkFL+I6XcFHx9IYCyQogyfhSciIiIiKjYe7o+8O31yS4FEZG/pAQeqwK81BbYPC/ZpSEXOoGjegDWm37fgPBeQ2HLSCnzAOwFUN2yzLkAZkspj5pe+yA4TG24EEJ4KjkRERERUXGXux+Y/3WyS0FE5K+CvMKfd61MXjlIS0KSYwsh2iIwfO1G08uXSinbA+gb/O9ym/feIITIEULkbN++Pf6FJSIiIiIiIiIiAHqBo40AGph+rx98TbmMECIDQGUAO4O/1wfwPYArpJShUKKUcmPw3/0APkdgSFwEKeU7UspsKWV2zZo1dT4TERERERGlsr9eAXat9nedebnAxtn+rpOI4kNK9c+UknQCRzMBNBdCNBZClAZwEYBRlmVGAbgy+PN5ACZKKaUQogqA0QCGSSn/MhYWQmQIIWoEfy4F4HQAC2L6JERERERElPoObAd+fRj49Bx/1/vL3cC7A4A9692XJaIkY7CoKHENHAVzFt2GwIxoiwF8LaVcKIR4XAhxZnCx9wBUF0KsAHAXgGHB128D0AzAw8FcRnOEELUAlAEwTggxD8AcBHosvevj5yIiIiIiKlkWfAfs25zsUrgzcpsc2uXveldMCF8/EaUu9jIqUjJ0FpJS/gLgF8trD5t+PgLgfMX7ngTwpM1qu+oXk4iIiIioBMs/BqSXsv977iFg5NVA1cbAv+YkrFhRyTsS+Lcg39/1HmQ+VKKig4GjoiQhybGJiIiIiCgGuQed/35kb+Df3T7nDYqHUODI555B+bmBf2f+z9/1EpH/2OOoSGHgiIiISGXS08DnFyW7FEQl24ZZwEdnBJIel3SugaM9gX/Ty8S9KDE7djjwb8Gx+Kx/4ffxWa+fjh0BNs1JdimIkoiBo6KEgSMiIiKV358Flo3hA2tRcGQf8GhlYOmYZJeE/DbqdmD1FGDH0mSXJDnM1x/dHkely8WvPH6JV48jw6Gd8Vmvn37+P+CdE4D9W5JdEqLkkAXmX5JWDNLDwBEREZGT5eOTXQJysz0YVPiCPcSKnbRgVTXsAaMEmfVh4c+5B5yXPbwn8G+pIhQ48pM5X1I81u+3uZ8H/p32ZnLLQXqkBNbPTHYpihfzULXcQ8krB2lh4IiIiMhJmtY8EpRMJTWoUBKIEh44yjtc+LNuj6OiEDjy2stm7d/uibTzjnpb5/alwHc3BpKO+6mgwFvulpW/+bt9io/ZHwPvnQws/inZJSlGTOfJqNuSVwzSwsARERGRE6kx68+0N4Hda+NfFlIrqUGFkiAegSMpA+fsgW3+rTNeRHrhz269aEI5jkrHrTi++eFm/WVHXgt8cCrwRk/n5fJNgaP63dzX++NtwLwvgU3/6JfFzeHdwONV9XoR1QtOMN30JP+2T/GzY1ng312rkluO4oTJsYsUBo6IiIiswoY8uLRiH94DjB0WSOBLScLKZ/ElAv/4+YCxfWngnB15jd7yfk8Z70WaKXDk1jPG6HG0bWH8ypMMC0YG/jUe3O2Y80FVb+a+3oxgEvFjPg6RObgj8K/OrG61Wgf+LVfdv+1T/ISC2Lzf+If7sihh4IiIiEqOggJgxwr35Q7vLvw53y05drDic2Br1MWiGHntjcKKf9ERlx5HwXUZD/lO9m8FHq8G5Lzv3/a9GDus8Ge3GcgmPRWfMqz4TX+Wsl/uBZ7N8rZ+v85Hc48jT8PPhD/bBwqDjDrbLwgeh673GEoJwjhOeP/wDe/FRQoDR0REVHJM/S/wWldg8zzn5Xaagktulfr84KxAXvNrkH+8BhUeqwJ8dZm/ZRj3IPBYNX/XSYU9bvwMHIXWqdGTaMv8wL+LfvRv+9HyOxePrk/PAb65Sm/ZGW+HB951+NWjy9zjSCcYs+aP4A8+PrweO6i/fWNGuXjNLEc+i0Pvx0O7ArmTiIoABo6IiKjkMAJG2xY7L7d/c+HPbgGhUKWfLWdJE01F3u8Ep1Nf0wtEkDfGubhxtstyW4FHKwMLvnVfp9GLSeeB3ejFklHWfdl4cytv5YamZV2OxRUTAvtryvP6249X4MqvHjfmHkdu+2r9DNP7fAzcGDND6XwmY5lkBQTJm3j0fhx1e+A/I0Bd0rDHUZHCwBEREZUcZasG/nVrET+yr/BntwcAt+EjlACmyqdbRTTeFVU+BPprz7rAv7M+cF5u6ejAvzp5i7z08DACMEf3678nXtyOLXOuHreA94THAv9OfEJ/+24TAJjPLS+9iHwLHHnocWTu5eHnULFjwVnwdI4xYxnd7R/YVji8jRJPeOhxdHhPoDeRG+O6opuof/TdwIx39ZYtEhg4KkoYOCIiopKjTIXAv7kuD4Hmhy63Sv38b2IrE/nL7fuKd+DIbcp0ik6lev6ta9+mwL86QT6jF9naP/3bfrTcgtTmz5PvEjjSeai1yjvs/HdjvwKFARQ7tdoU/qwbbM2s7Pz3sKFqLus0B7Z8DRwFz3+hkTfJKKNOkGn3WuD55sDfr0ZfNoqRhxxHL7UFnmvsvlxaRuBf3WDQzHeBX+7WW7Yo4IyoRQoDR0REVHIYU1u7tdqap73Oc3moWDc9tjKRv9weAnetjO/2cw/4u74vLw20Mrs5dhiY9Ezxy7XV4cLAv+3OcVnQQ4LjP14M/Lt3vfuyyZxRzcptSFXBMaBU+cDPbtctY0YxL9yCQX+8UPiz+RqqYg6W6PbadPsuvAxVM//dz16CxlC19NLuy3oZqrZ9SeDfUF4mSjgvPY6M+4DbMbvyt8C/FWtHX66ijEPVihQGjoiIqOTQTYobNjuPy4N47baxlamk2bYEmP2Jzys1BQ3cHsJey/Z520GlygX+9bvH0ZKfA63Mbqa9Cfw+Apj+tr/bT7a0UsEffJz5qsP5gX+bDHBfNpVaxHV6HJUOBo7crlttzw782/Fi/e27BY52Ljct6zLFfVjvKM0eP27BICNYVrqityHGfvY4Ms5/ncCRl6FqS34O/uDjeUDeGDmOvAyv0h0W69abzqs964CJT+kN3Z4/MolDrE3lq5qVpDKQLgaOiIio5DC6hbs+gBwFIAIJcV2TY5sqXG6t/AS80QMYdVv81p+sqa1LBZMnH/Wxx5GXvDrGMX1kr3/bj5f8vMCsdm4Jr82Wj/e/HOVrui+TSoEjp4c7KQPXotKaPY6MHkFePp9bL6JWZxT+fMytx1F+YXBF96HV7bptBMtKl3dfp9cZ2HQd2lFYBjfGdnWCC0ZOJp3v683jgXkcQu0/o8eRh3NG99h2C8p69fWVwJTnCnuq2Vn0I/DttYW9MBMt2rxolBQMHBERUckRmk3JpYKSdxTIyAQySrtX/PKjGHJB8askJmuoVqjHkUvgaPO8wGxWS0a7r/NHDwG20EN4ERiqtmNZYFa772/Sf8/iUc5/18kpYzCCGhkeeoWkAqfri3E+lQ7mcXM7DozcbF56Grg93IYF0d2WzSsMtvrW4yj4mctUcP9cZasU/uxnbwsjcKwTXDC267b9sF4jGj1Its4HvrvOffvkjZehaga3Y7ZcjcC/fjY4AIXngtt91mic2OOS+D5uzIGjFLrWkhIDR0REVHKEKn46gaMygYdxt4eafA8JWamQ3y2shmR9B8ZDsNtQtVWTAv9+eYn7Ohf9qL/9jMzAv0Wh15uxj4xk9b7wEDg6sDXwb2YV92X3boyqNHHhlOPICNqEehy5BI6MfeDlYc2tx5H53NMJMhnBVr9nVStd3j2Ib5wvfm4fKAzY6VyHjDK6Dqsz3a9chx6lUA+54kZ3qFqeh1xbdTsH/t3n83VGaPaOMnKdJavBxXw8s/6U8hg4IiKiksOogLslx84/GggapZVyfwAx/50tZvr8rKiaK8dJG6qm2eOoqsZMO4bSHgIrGSnQ4yj3YCCvhlvwypjVUGc4j2486LCHWcLc8u+YTX468G8o11ISOV2L8i2BI+1ePC5BdPODnZe8Ra5DfM09jnx6YDS2qZPjKD8XKFut8Ge/GME1t3uBlMCW+ZrLmu9XDBwlj2Ywxjxc2HV4ZfDYO7ov+mKp6AaO0kuFlyPh2OOoKGHgiIiISg7d6Y8L8gIVqvQM95mMzH8vqS1mh/dE0YPIx9lUwgJHKT5UzUsFXWcolcEYquaWWyae/nghkFdj9kfOyx0JPiSVrui+zl1r9LY94VG95YDoHpJKl/P+Hr85XV+Ma5puj6PQ+1yuWeaZ51zzFpkTTrsF3POj63Hk1OPG3OPI9bptTiSucd1+tDLwyz3uyxlBU7d1moNwrkPVTNc3nWTHyfbPp4GhqMWNEcR228fmnnmugaPgd+9nT9HDuwuDkqkeSGSOoyKFgSMiIir6jh4IVJbchGaxcWsNLwBEeuBh3FOPoxIaOHq2EfBWX2/v8fUBJwW6uxuBBbdcFWEPFS6Vei/7yBh6o3MexIsRPHQLWhzZE/jXrcfRuunA2j9jLlYEI8DgZf+KdP/L4ZXTQ2iox5GR48jlQbRCbfd1AsCfLxX+7Ja3KGzYrluPn2OFx6yXB0an8zssx5FGj6OMMoEJE9yWNY6TGe+4ly/U48jlOnTE1MPEdftFrMfRj7cGkt8XN9pD1TwMXw8NV/SxwcM8vNbteDCObS854nxlDhyV0PpTEcLAERER/X97Zx5sR1Xn8e959773sq8GBrIRFoEQRJiIIDDOiAq4xVFGcRykphixZkCcKWccmHKKES1HXAZRlBoLdFjUQEWWqAhEUBTEQEIgEiAQErJAQkKWR9a3nvnjnHP73H63z3LT9/V9930/Va+677vndp/uPuu3f7/fGf58ex5wzRH+dGaS5Hu7N9AHtJWUe4o3ODZjHAGoXoo7iByFo9s+muwXZXJvJsE+dx5bOPJNxGMwEwRfHJpmwARkNa5KWWx7rjHnN/X/mUXudLaw5IuLNhQ4LY4iYxxVgud6hKMjzkz2fRZHdv68cXv6LOEoot10uutZq6r5jtnfo14MhMSxi3GrNWm9Fk8RcXAkYxxF0b0H+NUVQE+ES2oQge5fVS8HPO2GKXsNi03nE4RMeSpIOKqyFh7B46dhAoUjQgghw59QK4uKxZHvDW+/Eo5K5QBTc+v7R68Ly8dIZSDC5aJeCovVEHh+e/KdZ4DwSvyuJhA4fBirrJLHFa/RZcQEiM7CrvvNEHQ8KsaRQ+zYtyOx+vIJHG3lZD9kpbR0flxp2+uxOHI8B/OM2scGCP69WjgKeDkQI/Ca++4VriLc+mLEoFYVjtY/ptwFNy3zp330OmDpDWEWYjGErqpWFRw7cFXWPC2ObOshr25UsMVRWpz3WeGSQqFwRAghZOQQ7KrWpyZMIRZH9sBw3e8OLn+tTpU1TINEgaIm+GbC5hOOdm9O9n3WSdOOjTi/nnxvfir8N43CNwkxcaCKCoYaKi7GWNAMBc5V1UyMI+2q5qoHdhkJjcEC+IXOUFe1gX4A0rI4iigHrnvQ36Pa7XJHmKVoqMXRgYjAxX2Bq6rFuPVFxThq0Yn3miVqa1aldGH65NytBOuxOAoMjp3nYhGinul9E7iqAfla4ZLcoXBECCFk5BAaiHKgX8c4ClhVrWqC0ASBSZsZe+LZahZHFeHIU17s1XN8E/F5lgued3lzPUnyBecG1L1ffrNaBa0IKsKR51416i24XUbsFZDS2PmT/X7rnEYTYnFUWanMUQ9sK6LQiS0Q6Kom/Oc35wwRjtLthOu4MWJQf69eACEgbUzcMCMA+KwnKucUAXH0bOHItwpejHWSBK4/FfjNV/1pX3hAWfx0bQo/fq4Y0SYgaaP6FiPIPHa9O539Yir0xVOewpEtAvluRTNZHAE53weSNxSOCCHNx55taklnmqySvFn+I7X1Whz1WzGOAlZgMzTDijbNjP0mNmZJ9BiKFo58A98YCw57MO8Nchrxdv3WDwM/vxy478rw3+SJmYgXJcTYZcRlJZh2oSpqxb7K+QNiHBn3L1d5MKuZ2b/znbM8OiA4di/QqVfKcwo8qby6rivdprrya1bDbGsHIN0ucP09WjgKsCqNcSkNdVOyXQt99cCu+z63vhjhaN924PXVwMPX+NOuuFVtNz4efvw8+f039U5MH5uzGBIqrlSVAV+MowYEx65imI1JhoOr9QiGwhEhpPlYfJla0nn9o0XnhLQqPoujqhhHES4Hw22QNtTY9/K7pzTmHEUIR1ICu/Sy5Xm6/tj4BtQxA+61v1XbfdvDf5Mn+3aobYjLaCOw67/LrSMtKBT9NtwpRBgrHm1x5CoPZgJc6ggP3jtqQoDFUY8VYynE4iggr4PO4boHPUo0KrUH5KFXpw2wOOqNsMyzxXFfXgEtHMW4qvmEo4g+yHab9VHuVNuiAxivujsgUcH9cJWrWqAwKwfyE9KrXjg0+ZhkkDBcsFUncULhiBDSfBhLhGZYxYa0JnnGOLK/b/ZBWqPxWQkOhYVJEcLRY9cnK4D53vjbEwnfCmhVgUN9Fkf6+84J7nQ2bQUtMW+eUaj7XaPOD7gnKunvihaOnDGOUlY8zuvS97U8Olzo7BjnbzeDhSNz/k5/XtMigE+MMQGvvWn7wl3VYlbnqipbjvObstQ+xi8u2GOhPC2O9mwNT1sywlHBdWDrquLObeKHzXibO50tyMe4guZ1b6vGIV5fNb1tkhhHFI6aGgpHZGjYtwPY/lLRuSCEEEWeMY5ilpJudXwuD0Nxr1yTxVdXNOacax9O9n0TN3vyHyOOewWp/rB0NqIo4Ug/I1+MpUZNIoKFo1RZKnrSHOL6VLHiCRDE2keFB3EOsYzp70nc4ILc6kZXf65F2jXK6QJniUG+PFS5qnmu657Lkn3vilqhFke2IBfhquZtMyJeXsTEbirre9q9252upUMM6HtrYnNl8dBXkn1fGzbQl1g9+oTpUCG9qrz4Xjjoa3pmUb6rfIZCi6NhBYUjUj8bH1eB8pbf7E/79TnKLcGYpxNCSCMIHbR6l5Xu1xZHZf+gvkoIGIEWR5uWJ/vP3u1OOxTWQK5zNCoYtO0a4HUpsyaTvvIaZXHUH3Z+m6IsjgaaSDhy1dl03S9qxT5DTIyjEOGo9wCwc13YOTtClrjvUZPqtnKgq1qAxdHKhbV/m3X+UnsS/NsZDynCVa3bCqDuuwd93UDnRLXviuNWr6uar83wWTFWpY0QQo21zRuvutP1eISloSTvgM/mOfja4qPfk+x7xw89QEdAXLD9O4Grp/jzmM7fzpfdaTc8luzv2hB2/FxJC0f0NGhmKByR+nnyFrX9+eXhv/n9txqTF9KajMRJODk4Qi1afG/WZD/Q1ha4qtoIj3G0OcKKZyhc1VyToYa1KXZMiYBgqMYiwiuMWPkNjXEUM1kaqRZHdhlxTQIHuapFTMrzZtJsj2iSjhvkSqvvvxFEuh0r8fX3ABDKOihkpbJyp3JryivG0aAA5SGuah3J58y0tquap42f804rPwHC0dipat9lnVMRjgJc1R74onV+T5349Zfc39vElGdjnbR/lztdo2IgHTJXbd98nj/to9epbd4ihOk/fNfYblkk+VYM7O8FOrUo5+q7dm8JyyNQ3abd9Rl3WrNgCFCMaJNufxmioqmhcETqZ/Y71Hb84eG/8S1hSQghB0PooNW3oldMjKOqJbtb2Uw/B4p2VWsUURZHfYmrQ0ygW29a871HOLKtZrrfcKdtFOYZeeth6przEv7sMhJixXPcB3TaAiyOJs0G3vJxYMocf7BnwLLica0oFlFHKmJMZ5jFUchKZUbkCllVbZBw5BGkSu1hMY4GesNd1d50TLK/bXV2OimVO+OoSeqzSwiorCw3xi+oP3uPdQ5PO/C6I39pzAvgEIzHgM9at1Hi6oTpahsjLDRKCPGJd3ZMLKfVWz8AmVhz5dW+1Cu+FDF+iXVV2/0a8PTtjcsPcULhiNSP8cmdMqfYfBBCRjb2G9DQgZdvdaBKjKNyQHDLEe6qFkN6IteI+1XE5D7K4qgnbHKvDmbtBsY48lkcvfFKsj/lSM/5G4S9klBIOkNeE5uqgLQBy8ZPmqW2hVgcSQDCL2L328KR8C9FX3UKx301FnIhy9bbFj9BFkcBbnXp+uSM85ReVS0kbYCrmn0c12qv5jidAUJAxeJoXFybNXGG+/sY97PNTyX7vrZ4vxaOfH2n7/t6Mc896sVAzv2LqSe+MUHvflW2fGltd0UgP2vZettJX9/VvQf46nTgxSX1Hb/2Sas/+u7tTz8O3HUJsPf1HPNAQqFwROrHuHrEdFIzT2tMXgghI5drZif7zjfM1mCqb787VkS9Fkd7IszJRyLpSV8jXJFcAYzzjnlROa41nPKuLNebuOjEWBz5RCbjSuJzP+ux3JLGH+ZO2ygGAoWjdPnIq7wEB8fW9zxkYtco9mt3slJ7WNyiNh3jJyTo98kX6n+44jz1IHj1sf5ede5ShzseVIxwFOWqpq2IKpP2kFXVQtp4Kw+HnpCdzgiLITFrbNFgoDdcGPDVmXrFTd89MCuFeS2OGhRg2bygiRGO8ragMc/I1xb37gU6TRkIqIcVoTGifXGVl3pfyPju1/YXVf/x0JfrO37Nc0YKRybGFoNoFwKFI1I/ZgAV86akyPgAZPjRqEkeaV1c7ZGZpLebSaCjPZIDKnBwUIwjrqoWTPpeNcI6yPU8GmURZrdVXjGkN7E48gWaRYSrmomn4rXise65iQWTG4FttslDtHCUk+tJqMWRqftFCUc71qk4RCsX6oDTARZHpbJfOLLdpACPxZFtRRRqceRx/xq0qprjuabLvfPlQF8iXJn8uPIQKoiFutia8hEiGtgxjoDwsu1LV28Ad9892NcsFkcR15e7cGSCY/ueQXdSBkLqoXFVcz279Hg4Ji5YKIW42jM49nCCwhGpH/NWIaYRL2KpRzJ8GS5uPxsfB15+pOhcEMAjHOlBkVlW2DX4G+hTwlFbe8CqKBSOghkS4ajgla+8rmp9yWTCDnpb81iy9n4tKhMUTzq7PJfK7rTR6HP78mryEOp+V/mcw1tmKasFoNAl04E4i4A8sFc884nY5ruKxVGAq5oRMJ0ry/WGiUHmuEGuajpvpQ4ot7q8Yxzpcu0TbkJd1exy5yovFeEo0lXNlzYrLzXzUKdw43wGA4mrms+iKL0KXl6Y+x4TJy93ISQwOHZfdyI2RwlHEc8uZKwTS+iqtHkSa3FECoXCEakf81Yh5g0chSPSitz0HuD/3l90LggQFmTVuDH4VlOqxDiKcFUb6XjFjbRw1IB7FyMcrX04n3NGBcfuBQ47Se2boMuZRLiqhcYNqgrmXpA4X7fFUQ6TChOQtpIXjwULYFkcFShK+kTsisVRuxK9Q2KrVIK0+yyOQl3V+lSb6bNOqrjVBVhHpfPmm4iHWBxJWR1I22tJZQdTd9wDMx4OEYPSVl+h/Yg35p51Tt8KaFW/cxy3a2PyHHwWRU/cGH7OGOqJcdSoVdVCnkFFOPLE2QKStDF9l+u4jYpx1JD+IlI4Gi4vlFsUCkekfsxbB9dyo2mKWsGFEDIyCHFVqyyF7jH1Do1xRIujcNKTkzysg9IDSefkPpW2a9PBnx9AXHBs7ao2/nBg9OTwU4QKQlEBpwsYhA8MJG/WY0QuIJ+JYLrMOS0t0sJRge72PhE7JsaRqYcV68shdlUzx2krB8RuirQ4aguIcWTOF+yq1p/0G86V0lKuaj7xTrQl7no+y9ZKXnwWR1b+Duxyp+0Yn7huu8pW10a1HXeo3+LorX/n/r5eTJlpClc1X5ypbksQ9Fg2A4mFWsyLeKdLdr0WR4Hta57iTd0WRwxlUQQUjkYKfT1A1yv+dFHH1A3cga7wRsR0poQQ0ghCLI6MG4Or3RroT2Icyf7stGnrhZGOLy7ZIIujHISjmIllo1zlqoJj+yyO+pKVn3znr3JV8x1Xfx8jHBXx9rZ3HxKXtgIsjtLuZiGrf+W9XHY9hK6qFhTjKMbiKGLZ+oHeMPevtMWRSzSJjXFUsi2OMtKavFXyGmBVWhF4XK5qWlisxDjyuKqVOtT1+9JW5cVnFRIhrsqBRDwMua7Rk/0WR42az1fiqjaBq5rX4shyVfOt7AeEBVPP+m0tYspA1e8C79eWlWrulwv6np71r2ob/HKA464ioHA0Ulj8WeDaufm6ipljDfR6lG+rco+alN/5CSEkTYjffykgxpHUwlFlUO+ZgJzcoLesrcYg4SYHa62YiWUjzg/EBceuTMQDLB3qclWLcBcsQjjq2au2pc6AvDYgxlFMGTiYGCR544txZIshoTGOSibGUYSrmjMeUqD7V0XED3CrS3/ne15tZSvGUVa7bbn1hQhim1cCB7TFfJ6uaqVOdX4gP1e1GORAUgZCYvGMmuifR1Ti5OSsIJl7GSUc5dy+mXritfrqiYxxVEfw/UbEOPL9zu7nTLD0g6UyLjP1ILB8FxLIm1A4Gimsvldt83xbZg+gXB1eVRDKgoOWkmGC7py4Cl9x7NoIXD0V2PKnonMSR4jff0yMIyMcZR3XDPyKWtZ8uJHuA/IQbgZNLANcSSrkNbGIEY70RLzc6b/+KoujFnFV69mjtqMmxFscZYm9MUFdzZhkylFqGxXjaIiDY9v4YhzZ7lfeGEf6miuuai4xyHJVg/QLUpWyHbCqmlmAIEY48rnrGSsikx/XMc11+Z7rni1IAiMHCEcViyOP0Fdq91tHDfpdjq7RwRZH5rom+F3VTB0dd+jB569WHgp1VYuwOAqJXWXGuKMmJL8LpRGuajGWSm05Laxgmp7KWIvCUTND4WikkWdFs986uCp6qMBESJqfXlBsMNKRzOpfqXq97EdF5ySOoJV8ytWfs9Ka+BtA9iCtMgHpjMvnSGWQyFOwq1pewVOjgmNbrmpeISLCVS04OLb1DIoYfBvhqDNAOAp9XjFWGKZ8vPMLwNhpYS5Vxk2pSOHIF+PIjhvkc1Ub0JY5rzypPq/7nfu4xjIHyL5fUtbvquYMjp0StbwxjspWjKOM41ass0xajyBW9duYVdU8aatc1UItjnIWjkyMI5cgZFsc9ff4+0518FyymORBP7OoVdXyXtrdCEee41ZZHDnSmnmU8cZwjXcH1QPPKnj1kHcw8SD0dYVaHO3dqn9G4agIgoQjIcS5QojVQog1QogranzfKYS4XX+/VAhxhPXdlfr/q4UQ54QekzSIPBuFKkHIcdwqi6MWW2Zx7+v1N9AkjOFkddRK5dtMhH0xa5oN51u4yFXVzNtwILuNs10eCLDtedUuZmHclAwNsTgKtIAFcpyERQbHrqw8FRHjyNfXVO6DZ8Jmn7MIV7VuIxyND7POssmaVEQJR6bOamuTEDGm1KHE4RiLABebnwauOwnYvzP8N74YR0YMEiIsxlGpA3j5EfX5xQf8aaOseEKDYwcE8h4kDHusk0plv8iVdlWz/1eLsdOAt3zcfUwgGa+ExKxJC3KhbVHMOMNXv+RAInL17HOcU5f7URPV1jUuM+1f3m1LjKva5DlqO/Pt+eYh1FWtv1vFDxNtYS/WR09Kfpd98tQ5GuCqtubX7u/tZ7r+0frOkXVM31hr0O849yoCr3AkhCgB+B6A8wDMBfAJIcTcVLKLAeyUUh4N4FoA1+jfzgVwAYATAJwL4PtCiFLgMUkjyNPEtUo4CmgYRQno2tA6Synufg34xlHAw18rOietzXBasSqvSQUJJ+pttBVXA/AHhG1rt6yTfEFWczLbbgXuuCj7u/QqnLmsqpZ6jr6AtDZ5xQuJsjiyrTJ87VuMq5p1LXu2Zacr3FVNi4chrmqDLI7yEI50O20EDtdb/opLVVm5X+VlcfTba4CdLwMvR0y+Sh7LGNNmAWGuaqX2JKi7Nzh2h19gsYNzey2OjIhf9ufVtoQRbX4xpi1ADEqLXID/uMb1KCTYcbCrWkdirRpatqKWbA8Qjkw8pl6XcKTPaYQjV4Ds0CD9MUgZ56o2cYba5v3iyzSXTqFzQH1f7tSB3x1loGJxZAS5CIsjp3hX572PWeVzxW31nWMQkRZHlZ9ROCqCEIujUwGskVKulVL2AFgIYEEqzQIAN+v9RQDOFkII/f+FUspuKeU6AGv08UKOSRpBaIUMsaLpDRSOKo28bhzSb5yHK3teU9vnflFsPlqd4STGFOnGMFIZJBo4Bmn7dTDHinCUMQGTUk1WOsYkE7HMCYg1sSSKNxwreBo3JUMurmqp/sc1+B4UYykn4ciu+y6Lo4EBHZDWCEeeNsOeLOxc505rl9HNT2WnsyeIRbgm9GjxsGefeh4uq5u0YJuHcGSeVblTiQGuCbMtNucpHFVmoBHCnc+laaAvadvaSv6A122WcOTKR+8+ZT3hszgyE1mTNiR2lLEOcj0/e8zosxCruBh3VJ8njS34+9Ka7yrCUYjFkXFTcokG+1QfY9wgQxavOeSE/Fy1pAQgE5HLNTbvSwlHLre2SrnLUZQe6NPHE6pc+V5Am++LCI5tC9O++F2V8jIO6toc7Uu6PrvKS739asw4Jq++o2JxFBDjyO6vX1ySz/lJFCElZDqAjdbnTQDStn+VNFLKPiFEF4Cp+v9/TP12ut73HbM12f4ScO+/Df15u/VqEHdeknRSWby6QnVos98B56oIW59L9n/2D8myroPOrQeJbz4PWP1LFbfGdNS16OsGdr8KTJqlrJSaFXNdW1cBt36k2Ly0GuseTvZdZavZuONT7rI9nNj8tNo+cSOwwzNhLZL0YOr33wKe+knttC89qLamXbn7n5LJQPVBdeyH0clgJqvtNJPONqutGmntgbmvhp3rsu/B1merPz/4JeCx7x3c+dOT+R1rs8+/a0P152U3ARuXHtz5gepj7FgH3LIgmZhJae2bAO16wrrtBXd5scWiuz4DrLwjO+32Ncn+fVcCf7wh45gvJ/tL/hNY+9vsY8ZiysLvvgG89FDtNLs3q+0ry9T22nnZLiUmBo/hl59XsZHSpCdKrntqBOTRk9UEf/0fstN36aFqW1lZhrxwXz7129ynJVe548iZF1RAIgr95GO1J3gvPQiMmZrkd+PS7Ly+tkpdv7HIePYexz3YBMw5K+nb7vx07T7Z1MNRE1Ve97yWfcw3Xk3y2VZWLnNZaV9/IdlvaweeuQvY8kzttD27lRhl7s/S/1Xx+gal0wJ2qT1J6+q/e/YmllQrbwdeWZ5xXVo0L49SeX16IbBpWe20rz6phCDTrzzwxeT5ZdE+So09Q8vg4ssTEWsQesJuhKOHvw48eUvtpKbdNEGcf/bp7LmEGTsc6MqvLzTj7dGTlNB820fgnJ+s1y6Yj1ybPR6ohx1r1VYOZF+bET7KncoN8LHrq+dLNqYetI9W6VfePrjNM6StdX99FfCH79ZO27Wp+nPoc1hxm2oPszBzSQDY4Gg3YziwS21N+3bPpcAzd9ZOa4umv/oC8ML9B3/+vJhwOLDg+qJz0XCa/hWpEOISAJcAwKxZswrOTQ4M9KvGdKgZNUlVzv6eACVaKhX8wBvuZNOOBeb8hRqc9HW738Qd+ZfAGZerPPTu97xZkapx7pwwPN7ijz+smGfaykyaDexar/Z9ZasZ6BinBqLesj2MmDgD2Pc6MO344VW+28dk59dYF5z2j+qtZd8BoD8j7czTgDnvVG3n7DN12oy2c/aZwFHvSj4Pp/uVB2OmAvu2J5/HHpJ9DyZMV/fqqR+rz23t+d6v4z+kBuNZxzRvzMcfrl5QTJyZz/mnHasmk8d/SAkjPfv0pFwoqw6z31ZW13/02WqguXeb+/yjpwDQk5XJc9xppx0HTJoJrLpLTfCy0o6eDJz0t8DTP1F5yvP+H3KCepkyeba7Hh7/QZWHhZ8AphyZnXbq0UpgmnGqmjT37AvLryuNKAFHv1vdrxM/piZrWek7JwAnfERtT7pAiWx53K8pR6pxzqiJ7uOVtRvTB78D/NmJwKzTsy1Dps9X1wUA8z4KrLo7+9gTZwDHvV+V1+v/HDj0xOy0h70FOPZ9ahU60xZm9cmzz1Qi4OjJSpzKOmbHWOC4D6iVt048H3j+3uy0h8xVgvPR7wGmHqWEmKy00+cDR52tnte8jwI712enPeIs4LC3qgn5rHe4++8Zb1PH7d6jhJHM6xoHzF0AjJkCnHIhsHlldtopRwHz/hp405vVsQ90+cvWWZ8HHvm2vx3Y9rzaH+hzp535dlWuD3QBu7e4280T/0b1ib7+cPIR6poGevNtW2afAbz1k0rc8s1PDp0HvPaMEvDyzMOYqaotHzvNfdxZp6v8du9WljGuenD8B1WfefKF6sV9SH5NUPfMdmt8sl8eHX4PxkwNT3vI3JzurVDl6si/Um3trg1hxz3khOYaa9n3vIUR0mPGJ4Q4HcB/SSnP0Z+vBAAp5X9bae7XaR4TQpQBbAEwDcAVdlqTTv/MecxazJ8/Xy5blqHcE0IIIYQQQgghhJBohBDLpZTza30XEuPoCQDHCCHmCCE6oIJdL06lWQzARMM8H8BDUilSiwFcoFddmwPgGACPBx6TEEIIIYQQQgghhBSI1w9Ixyy6DMD9AEoAfiilXCWEuBrAMinlYgA3AbhVCLEGwA4oIQg63R0AngXQB+BSKVWktlrHzP/yCCGEEEIIIYQQQki9eF3Vmgm6qhFCCCGEEEIIIYTky8G6qhFCCCGEEEIIIYSQEQiFI0IIIYQQQgghhBBSEwpHhBBCCCGEEEIIIaQmFI4IIYQQQgghhBBCSE0oHBFCCCGEEEIIIYSQmlA4IoQQQgghhBBCCCE1oXBECCGEEEIIIYQQQmpC4YgQQgghhBBCCCGE1ITCESGEEEIIIYQQQgipCYUjQgghhBBCCCGEEFITCkeEEEIIIYQQQgghpCYUjgghhBBCCCGEEEJITSgcEUIIIYQQQgghhJCaUDgihBBCCCGEEEIIITWhcEQIIYQQQgghhBBCaiKklEXnIRghxDYA64vOR068CcDrRWeCkBEK6x8hxcH6R0ixsA4SUhysf6SZmS2lnFbri2ElHLUSQohlUsr5ReeDkJEI6x8hxcH6R0ixsA4SUhysf2S4Qlc1QgghhBBCCCGEEFITCkeEEEIIIYQQQgghpCYUjorjB0VngJARDOsfIcXB+kdIsbAOElIcrH9kWMIYR4QQQgghhBBCCCGkJrQ4IoQQQgghhBBCCCE1oXA0xAghzhVCrBZCrBFCXFF0fghpBYQQM4UQvxFCPCuEWCWE+Jz+/xQhxBIhxIt6O1n/XwghvqPr4UohxCnWsS7S6V8UQlxU1DURMtwQQpSEECuEEL/Qn+cIIZbqena7EKJD/79Tf16jvz/COsaV+v+rhRDnFHQphAw7hBCThBCLhBDPCyGeE0Kczj6QkKFBCPEvevz5jBDip0KIUewDSatB4WgIEUKUAHwPwHkA5gL4hBBibrG5IqQl6APweSnlXACnAbhU160rADwopTwGwIP6M6Dq4DH67xIANwBKaAJwFYC3AzgVwFVmoE0I8fI5AM9Zn68BcK2U8mgAOwFcrP9/MYCd+v/X6nTQdfYCACcAOBfA93W/SQjxcx2A+6SUxwE4Caousg8kpMEIIaYDuBzAfCnlPAAlqL6MfSBpKSgcDS2nAlgjpVwrpewBsBDAgoLzRMiwR0q5WUr5pN7fDTVgng5Vv27WyW4G8GG9vwDALVLxRwCThBCHATgHwBIp5Q4p5U4AS6A6b0KIAyHEDADvB3Cj/iwAvAvAIp0kXf9MvVwE4GydfgGAhVLKbinlOgBroPpNQogDIcREAH8B4CYAkFL2SCl3gX0gIUNFGcBoIUQZwBgAm8E+kLQYFI6GlukANlqfN+n/EUJyQpv8ngxgKYBDpZSb9VdbAByq97PqIusoIfXxbQBfADCgP08FsEtK2ac/23WpUs/09106PesfIfUxB8A2AD/S7qI3CiHGgn0gIQ1HSvkKgG8C2AAlGHUBWA72gaTFoHBECGkZhBDjAPwMwD9LKd+wv5NqCUkuI0lIzgghPgBgq5RyedF5IWSEUgZwCoAbpJQnA9iLxC0NAPtAQhqFdudcACXgHg5gLGipR1oQCkdDyysAZlqfZ+j/EUIOEiFEO5Ro9GMp5Z36369p83vo7Vb9/6y6yDpKSDxnAPiQEOJlKBfsd0HFW5mkzfaB6rpUqWf6+4kAtoP1j5B62QRgk5Ryqf68CEpIYh9ISON5N4B1UsptUspeAHdC9YvsA0lLQeFoaHkCwDE6yn4HVAC0xQXniZBhj/YNvwnAc1LK/7G+WgzArApzEYB7rP9/Sq8scxqALm3Ofz+A9wohJus3SO/V/yOEZCClvFJKOUNKeQRUv/aQlPKTAH4D4HydLF3/TL08X6eX+v8X6BVn5kAF7n18iC6DkGGLlHILgI1CiGP1v84G8CzYBxIyFGwAcJoQYowej5r6xz6QtBRlfxKSF1LKPiHEZVCdcAnAD6WUqwrOFiGtwBkALgTwJyHEU/p//wHgawDuEEJcDGA9gI/p7+4F8D6owIP7APw9AEgpdwghvgwl8gLA1VLKHUNyBYS0Hv8OYKEQ4isAVkAH7tXbW4UQawDsgBKbIKVcJYS4A2rA3QfgUill/9Bnm5BhyWcB/Fi/mFwL1a+1gX0gIQ1FSrlUCLEIwJNQfdcKAD8A8EuwDyQthFACJyGEEEIIIYQQQggh1dBVjRBCCCGEEEIIIYTUhMIRIYQQQgghhBBCCKkJhSNCCCGEEEIIIYQQUhMKR4QQQgghhBBCCCGkJhSOCCGEEEIIIYQQQkhNKBwRQgghhBBCCCGEkJpQOCKEEEIIIYQQQgghNaFwRAghhBBCCCGEEEJq8v92wx1l4XskhAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# figure size of the plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "testing_data['max_u_regressor_sparse']['mlp']['predicted']['bus_15'].plot()\n",
    "testing_data['max_u_regressor_sparse']['mlp']['real']['bus_15'].plot()\n",
    "# plot a line with the threshold\n",
    "plt.axhline(y=threshold, color='r', linestyle='-')\n",
    "# Add legend\n",
    "plt.legend(['predicted', 'real', 'threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>R</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>season</th>\n",
       "      <th>weekday</th>\n",
       "      <th>last_hour_mean_wind_speed</th>\n",
       "      <th>last_day_mean_wind_direction</th>\n",
       "      <th>last_hour_mean_temperature</th>\n",
       "      <th>cos_hour_day</th>\n",
       "      <th>last_hour_mean_irradiance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.938805</td>\n",
       "      <td>0.455304</td>\n",
       "      <td>0.160055</td>\n",
       "      <td>0.101979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.153689</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.939932</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.456003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.938404</td>\n",
       "      <td>0.455304</td>\n",
       "      <td>0.165477</td>\n",
       "      <td>0.103931</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.159173</td>\n",
       "      <td>0.098412</td>\n",
       "      <td>0.939531</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.456003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938003</td>\n",
       "      <td>0.455304</td>\n",
       "      <td>0.170898</td>\n",
       "      <td>0.105884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.164657</td>\n",
       "      <td>0.100345</td>\n",
       "      <td>0.939129</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.456003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.937602</td>\n",
       "      <td>0.455304</td>\n",
       "      <td>0.176319</td>\n",
       "      <td>0.107836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.170142</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.938728</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.456003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.937201</td>\n",
       "      <td>0.455304</td>\n",
       "      <td>0.181740</td>\n",
       "      <td>0.109788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.175626</td>\n",
       "      <td>0.104277</td>\n",
       "      <td>0.938327</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.456003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>0.965973</td>\n",
       "      <td>0.377550</td>\n",
       "      <td>0.259132</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.273230</td>\n",
       "      <td>0.181410</td>\n",
       "      <td>0.966734</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.411494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9040</th>\n",
       "      <td>0.965825</td>\n",
       "      <td>0.355341</td>\n",
       "      <td>0.251827</td>\n",
       "      <td>0.238410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.265839</td>\n",
       "      <td>0.194757</td>\n",
       "      <td>0.966587</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.389251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9041</th>\n",
       "      <td>0.965678</td>\n",
       "      <td>0.333132</td>\n",
       "      <td>0.244521</td>\n",
       "      <td>0.251588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.258448</td>\n",
       "      <td>0.208104</td>\n",
       "      <td>0.966439</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.367008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>0.965531</td>\n",
       "      <td>0.310923</td>\n",
       "      <td>0.237215</td>\n",
       "      <td>0.264766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.251058</td>\n",
       "      <td>0.221451</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.344765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>0.965383</td>\n",
       "      <td>0.288715</td>\n",
       "      <td>0.229909</td>\n",
       "      <td>0.277943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.243667</td>\n",
       "      <td>0.234798</td>\n",
       "      <td>0.966144</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.322522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9044 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             T         R  wind_speed  wind_direction  season   weekday  \\\n",
       "0     0.938805  0.455304    0.160055        0.101979     1.0  0.142857   \n",
       "1     0.938404  0.455304    0.165477        0.103931     1.0  0.142857   \n",
       "2     0.938003  0.455304    0.170898        0.105884     1.0  0.142857   \n",
       "3     0.937602  0.455304    0.176319        0.107836     1.0  0.142857   \n",
       "4     0.937201  0.455304    0.181740        0.109788     1.0  0.142857   \n",
       "...        ...       ...         ...             ...     ...       ...   \n",
       "9039  0.965973  0.377550    0.259132        0.225232     0.0  0.571429   \n",
       "9040  0.965825  0.355341    0.251827        0.238410     0.0  0.571429   \n",
       "9041  0.965678  0.333132    0.244521        0.251588     0.0  0.571429   \n",
       "9042  0.965531  0.310923    0.237215        0.264766     0.0  0.571429   \n",
       "9043  0.965383  0.288715    0.229909        0.277943     0.0  0.571429   \n",
       "\n",
       "      last_hour_mean_wind_speed  last_day_mean_wind_direction  \\\n",
       "0                      0.153689                      0.096501   \n",
       "1                      0.159173                      0.098412   \n",
       "2                      0.164657                      0.100345   \n",
       "3                      0.170142                      0.102300   \n",
       "4                      0.175626                      0.104277   \n",
       "...                         ...                           ...   \n",
       "9039                   0.273230                      0.181410   \n",
       "9040                   0.265839                      0.194757   \n",
       "9041                   0.258448                      0.208104   \n",
       "9042                   0.251058                      0.221451   \n",
       "9043                   0.243667                      0.234798   \n",
       "\n",
       "      last_hour_mean_temperature  cos_hour_day  last_hour_mean_irradiance  \n",
       "0                       0.939932      0.258819                   0.456003  \n",
       "1                       0.939531      0.258819                   0.456003  \n",
       "2                       0.939129      0.258819                   0.456003  \n",
       "3                       0.938728      0.258819                   0.456003  \n",
       "4                       0.938327      0.500000                   0.456003  \n",
       "...                          ...           ...                        ...  \n",
       "9039                    0.966734      0.866025                   0.411494  \n",
       "9040                    0.966587      0.965926                   0.389251  \n",
       "9041                    0.966439      0.965926                   0.367008  \n",
       "9042                    0.966292      0.965926                   0.344765  \n",
       "9043                    0.966144      0.965926                   0.322522  \n",
       "\n",
       "[9044 rows x 11 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_max_u_sparse['X_test']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe4baa4d27e3b73db55d4bb4674105e8dd41faaf9e559c3cc8381041ce15293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
