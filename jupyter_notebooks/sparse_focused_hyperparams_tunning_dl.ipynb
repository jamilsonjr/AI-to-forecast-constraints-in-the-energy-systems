{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tunning for Deep Learning Models (full of errors)\n",
    "TODO add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamil\\Documents\\IST\\Thesis\\new_thesis\\code\\AI-to-forecast-constraints-in-the-energy-systems\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "import sys; sys.path.append('..')\n",
    "from thesis_package import utils, aimodels as myai, metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "num_trials = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Sparse Classification Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build optuna study..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_max_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_sparse_bool_constr.csv').drop(columns='timestamps') \n",
    "    exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])\n",
    "    X_max_u_bool_train, X_max_u_bool_test, y_max_u_bool_train, y_max_u_bool_test, scaler = utils.split_and_suffle(exogenous_data, y_max_u_bool[utils.cols_with_positive_values(y_max_u_bool)], test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_max_u_bool_train.astype(float),\n",
    "            'X_test': X_max_u_bool_test.astype(float),\n",
    "            'y_train':y_max_u_bool_train.astype(float),\n",
    "            'y_test': y_max_u_bool_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': True\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=utils.cols_with_positive_values(y_max_u_bool))\n",
    "    f1_score = sklearn.metrics.f1_score(data['y_test'], prediction, average='micro')\n",
    "    return f1_score\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_sparse_classifier_max_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,True\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_sparse_bool_constr.csv').drop(columns='timestamps') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max_u_bool.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we confirm that the target feature is created correctly, being in accord with the sparse dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Balanced Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_max_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_bool_constr.csv')\n",
    "    exogenous_data = pd.read_csv('..\\data\\ground_truth\\\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "    X_max_u_bool_train, X_max_u_bool_test, y_max_u_bool_train, y_max_u_bool_test, scaler = utils.split_and_suffle(exogenous_data, y_max_u_bool[utils.cols_with_positive_values(y_max_u_bool)], test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_max_u_bool_train.astype(float),\n",
    "            'X_test': X_max_u_bool_test.astype(float),\n",
    "            'y_train':y_max_u_bool_train.astype(float),\n",
    "            'y_test': y_max_u_bool_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': True\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=utils.cols_with_positive_values(y_max_u_bool))\n",
    "    f1_score = sklearn.metrics.f1_score(data['y_test'], prediction, average='micro')\n",
    "    return f1_score\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_balanced_classifier_max_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,True\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Regression Sparse Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_max_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv').drop(columns='timestamps')\n",
    "    exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])\n",
    "    X_max_u_train, X_max_u_test, y_max_u_train, y_max_u_test, scaler = utils.split_and_suffle(exogenous_data, y_max_u, test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_max_u_train.astype(float),\n",
    "            'X_test': X_max_u_test.astype(float),\n",
    "            'y_train':y_max_u_train.astype(float),\n",
    "            'y_test': y_max_u_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': False\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=y_max_u.columns)\n",
    "    y_max_u_train = pd.DataFrame(y_max_u_train, columns=y_max_u.columns)\n",
    "    # evaluate the regression performance with my metrics\n",
    "    threshold = data['y_test'].loc[:, data['y_test'].max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    metric = metrics.Metrics()\n",
    "    metric.get_prediction_scores(prediction, data['y_test'], threshold=threshold)\n",
    "    return metric.hybrid_f1\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_regression_sparse_max_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,False\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Regression Focused Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_max_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_focused_constr.csv')\n",
    "    exogenous_data = pd.read_csv('..\\data\\ground_truth\\\\exogenous_data_vm_pu_max_focused.csv').drop(columns=['date'])\n",
    "    X_max_u_train, X_max_u_test, y_max_u_train, y_max_u_test, scaler = utils.split_and_suffle(exogenous_data, y_max_u, scaling=True)\n",
    "    data = {'X_train':X_max_u_train.astype(float),\n",
    "            'X_test': X_max_u_test.astype(float),\n",
    "            'y_train':y_max_u_train.astype(float),\n",
    "            'y_test': y_max_u_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': False\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    # print(model.strategy.model.eval())\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=y_max_u.columns)\n",
    "    # print('bus_16 prediction: ', prediction['bus_16'])\n",
    "    y_max_u_train = pd.DataFrame(y_max_u_train, columns=y_max_u.columns)\n",
    "    # evaluate the regression performance with my metrics\n",
    "    threshold = y_max_u_train.loc[:, y_max_u_train.max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    # print('threshold: ', threshold)\n",
    "    metric = metrics.Metrics()\n",
    "    data['y_test'] = pd.DataFrame(data['y_test'], columns=y_max_u.columns)\n",
    "    # evaluate the regression performance with my metrics\n",
    "    return mean_squared_error(data['y_test'], prediction, squared=False)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_regression_focused_max_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,False\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Regression Filtered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_max_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv').drop(columns='timestamps')\n",
    "    y_max_u = y_max_u[utils.cols_with_positive_values(y_max_u)]\n",
    "    exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])\n",
    "    X_max_u_train, X_max_u_test, y_max_u_train, y_max_u_test, scaler = utils.split_and_suffle(exogenous_data, y_max_u, test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_max_u_train.astype(float),\n",
    "            'X_test': X_max_u_test.astype(float),\n",
    "            'y_train':y_max_u_train.astype(float),\n",
    "            'y_test': y_max_u_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': False\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=y_max_u.columns)\n",
    "    y_max_u_train = pd.DataFrame(y_max_u_train, columns=y_max_u.columns)\n",
    "    # evaluate the regression performance with my metrics\n",
    "    threshold = data['y_test'].loc[:, data['y_test'].max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    metric = metrics.Metrics()\n",
    "    metric.get_prediction_scores(prediction, data['y_test'], threshold=threshold)\n",
    "    return metric.hybrid_f1\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_regression_filtered_max_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,False\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Sparse Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_min_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_sparse_bool_constr.csv').drop(columns='timestamps')\n",
    "    exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])\n",
    "    X_min_u_bool_train, X_min_u_bool_test, y_min_u_bool_train, y_min_u_bool_test, scaler = utils.split_and_suffle(exogenous_data, y_min_u_bool[utils.cols_with_positive_values(y_min_u_bool)], test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_min_u_bool_train.astype(float),\n",
    "            'X_test': X_min_u_bool_test.astype(float),\n",
    "            'y_train':y_min_u_bool_train.astype(float),\n",
    "            'y_test': y_min_u_bool_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': True\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=utils.cols_with_positive_values(y_min_u_bool))\n",
    "    f1_score = sklearn.metrics.f1_score(data['y_test'], prediction, average='micro')\n",
    "    return f1_score\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_sparse_classifier_min_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,True\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Balanced Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_min_u_bool = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_bool_constr.csv')\n",
    "    exogenous_data = pd.read_csv('..\\data\\ground_truth\\\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "    X_max_u_bool_train, X_max_u_bool_test, y_max_u_bool_train, y_max_u_bool_test, scaler = utils.split_and_suffle(exogenous_data, y_min_u_bool[utils.cols_with_positive_values(y_min_u_bool)], test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_max_u_bool_train.astype(float),\n",
    "            'X_test': X_max_u_bool_test.astype(float),\n",
    "            'y_train':y_max_u_bool_train.astype(float),\n",
    "            'y_test': y_max_u_bool_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': True\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=utils.cols_with_positive_values(y_min_u_bool))\n",
    "    f1_score = sklearn.metrics.f1_score(data['y_test'], prediction, average='micro')\n",
    "    return f1_score\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_balanced_classifier_min_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,True\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Regression Sparse Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_min_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv').drop(columns='timestamps')\n",
    "    exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])\n",
    "    X_min_u_train, X_min_u_test, y_min_u_train, y_min_u_test, scaler = utils.split_and_suffle(exogenous_data, y_min_u, test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_min_u_train.astype(float),\n",
    "            'X_test': X_min_u_test.astype(float),\n",
    "            'y_train':y_min_u_train.astype(float),\n",
    "            'y_test': y_min_u_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': False\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=y_min_u.columns)\n",
    "    y_min_u_train = pd.DataFrame(y_min_u_train, columns=y_min_u.columns)\n",
    "    # evaluate the regression performance with my metrics\n",
    "    threshold = data['y_test'].loc[:, data['y_test'].max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    metric = metrics.Metrics()\n",
    "    metric.get_prediction_scores(prediction, data['y_test'], threshold=threshold)\n",
    "    return metric.hybrid_f1\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_regression_sparse_min_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,False\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Regression Focused Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_min_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_focused_constr.csv')\n",
    "    exogenous_data = pd.read_csv('..\\data\\ground_truth\\\\exogenous_data_vm_pu_min_focused.csv').drop(columns=['date'])\n",
    "    X_min_u_train, X_min_u_test, y_min_u_train, y_min_u_test, scaler = utils.split_and_suffle(exogenous_data, y_min_u, scaling=True)\n",
    "    data = {'X_train':X_min_u_train.astype(float),\n",
    "            'X_test': X_min_u_test.astype(float),\n",
    "            'y_train':y_min_u_train.astype(float),\n",
    "            'y_test': y_min_u_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': False\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    # print(model.strategy.model.eval())\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=y_min_u.columns)\n",
    "    # print('bus_16 prediction: ', prediction['bus_16'])\n",
    "    y_min_u_train = pd.DataFrame(y_min_u_train, columns=y_min_u.columns)\n",
    "    # evaluate the regression performance with my metrics\n",
    "    threshold = y_min_u_train.loc[:, y_min_u_train.max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    # print('threshold: ', threshold)\n",
    "    metric = metrics.Metrics()\n",
    "    data['y_test'] = pd.DataFrame(data['y_test'], columns=y_min_u.columns)\n",
    "    # evaluate the regression performance with my metrics\n",
    "    return mean_squared_error(data['y_test'], prediction, squared=False)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_regression_focused_min_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,False\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Filtered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_min_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv').drop(columns='timestamps')\n",
    "    exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv').drop(columns=['date'])\n",
    "    X_min_u_train, X_min_u_test, y_min_u_train, y_min_u_test, scaler = utils.split_and_suffle(exogenous_data, y_min_u[utils.cols_with_positive_values(y_min_u)], test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_min_u_train.astype(float),\n",
    "            'X_test': X_min_u_test.astype(float),\n",
    "            'y_train':y_min_u_train.astype(float),\n",
    "            'y_test': y_min_u_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': False\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=utils.cols_with_positive_values(y_min_u))\n",
    "    y_min_u_train = pd.DataFrame(y_min_u_train, columns=utils.cols_with_positive_values(y_min_u))\n",
    "    # evaluate the regression performance with my metrics\n",
    "    threshold = data['y_test'].loc[:, data['y_test'].max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    metric = metrics.Metrics()\n",
    "    metric.get_prediction_scores(prediction, data['y_test'], threshold=threshold)\n",
    "    return metric.hybrid_f1\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_regression_filtered_min_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,False\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Regression Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-03 17:11:47,458]\u001b[0m A new study created in memory with name: no-name-f5a9bea3-7e0d-416f-a337-2101ad5bceb7\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:12:41,855]\u001b[0m Trial 0 finished with value: 0.9565453113178017 and parameters: {'hidden_size': 79, 'n_layers': 3, 'dropout': 0.3037768168799529, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0017966498130340496, 'epochs': 59, 'batch_size': 1024}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:13:08,337]\u001b[0m Trial 1 finished with value: 0.956518751142784 and parameters: {'hidden_size': 1, 'n_layers': 2, 'dropout': 0.4669293150778069, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.007409207009435189, 'epochs': 51, 'batch_size': 128}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:13:55,407]\u001b[0m Trial 2 finished with value: 0.9479259822621794 and parameters: {'hidden_size': 9, 'n_layers': 1, 'dropout': 0.11242435173130805, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.004415518622123152, 'epochs': 88, 'batch_size': 4}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:14:52,252]\u001b[0m Trial 3 finished with value: 0.5966634553465368 and parameters: {'hidden_size': 27, 'n_layers': 3, 'dropout': 0.08609085253546361, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 7.569272828028098e-05, 'epochs': 86, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:15:06,755]\u001b[0m Trial 4 finished with value: 0.9563633604498547 and parameters: {'hidden_size': 49, 'n_layers': 1, 'dropout': 0.23859298304654752, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.020731245994076428, 'epochs': 19, 'batch_size': 8}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:15:37,546]\u001b[0m Trial 5 finished with value: 0.7231747985974952 and parameters: {'hidden_size': 92, 'n_layers': 3, 'dropout': 0.4254671280333393, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 6.161363708172213e-05, 'epochs': 34, 'batch_size': 1}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:15:58,909]\u001b[0m Trial 6 finished with value: 0.9314034107865998 and parameters: {'hidden_size': 24, 'n_layers': 1, 'dropout': 0.12424188420238508, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 0.0006384223550256372, 'epochs': 38, 'batch_size': 16}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:18:01,385]\u001b[0m Trial 7 finished with value: 0.956518751142784 and parameters: {'hidden_size': 99, 'n_layers': 3, 'dropout': 0.49633640371370497, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.09722218455654721, 'epochs': 69, 'batch_size': 128}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:18:47,549]\u001b[0m Trial 8 finished with value: 0.9536513333600549 and parameters: {'hidden_size': 54, 'n_layers': 2, 'dropout': 0.4436898417911889, 'activation': 'sigmoid', 'optimizer': 'adam', 'lr': 2.4758875495351728e-05, 'epochs': 41, 'batch_size': 32}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:20:14,968]\u001b[0m Trial 9 finished with value: 0.9565235704292728 and parameters: {'hidden_size': 54, 'n_layers': 3, 'dropout': 0.12280850972362528, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.001666654448344495, 'epochs': 97, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:21:33,416]\u001b[0m Trial 10 finished with value: 0.9550068225749265 and parameters: {'hidden_size': 75, 'n_layers': 2, 'dropout': 0.2999151400675733, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.00026081577085546915, 'epochs': 64, 'batch_size': 1024}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:22:38,040]\u001b[0m Trial 11 finished with value: 0.9565185446846638 and parameters: {'hidden_size': 68, 'n_layers': 3, 'dropout': 0.24687702263170289, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0022202383979059437, 'epochs': 72, 'batch_size': 512}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:24:15,744]\u001b[0m Trial 12 finished with value: 0.9565066268431109 and parameters: {'hidden_size': 78, 'n_layers': 3, 'dropout': 0.3293627406382885, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0007176902433458781, 'epochs': 100, 'batch_size': 2}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:24:30,365]\u001b[0m Trial 13 finished with value: 0.9565187359645116 and parameters: {'hidden_size': 53, 'n_layers': 3, 'dropout': 0.01595865944920842, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.017634534992290105, 'epochs': 8, 'batch_size': 64}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:26:15,644]\u001b[0m Trial 14 finished with value: 0.9565405867703741 and parameters: {'hidden_size': 37, 'n_layers': 2, 'dropout': 0.17480547299058244, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0016235398328317983, 'epochs': 100, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:27:37,076]\u001b[0m Trial 15 finished with value: 0.9505617358319552 and parameters: {'hidden_size': 36, 'n_layers': 2, 'dropout': 0.19568671403455562, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 0.00028183610488954056, 'epochs': 60, 'batch_size': 1024}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:28:52,091]\u001b[0m Trial 16 finished with value: 0.9565185669405519 and parameters: {'hidden_size': 36, 'n_layers': 2, 'dropout': 0.34337949046914307, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.007777213797618816, 'epochs': 77, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:29:19,541]\u001b[0m Trial 17 finished with value: 0.7013232190470203 and parameters: {'hidden_size': 66, 'n_layers': 2, 'dropout': 0.18492339111845618, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0002464583296832935, 'epochs': 23, 'batch_size': 1024}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:30:14,218]\u001b[0m Trial 18 finished with value: 0.9565187222923005 and parameters: {'hidden_size': 86, 'n_layers': 2, 'dropout': 0.37357361987209387, 'activation': 'tanh', 'optimizer': 'adam', 'lr': 0.059173832229051614, 'epochs': 50, 'batch_size': 512}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:30:54,713]\u001b[0m Trial 19 finished with value: 0.9565235666173607 and parameters: {'hidden_size': 21, 'n_layers': 1, 'dropout': 0.19123212834010686, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.002483190078064743, 'epochs': 83, 'batch_size': 8}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:31:04,431]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'hidden_size': 41, 'n_layers': 2, 'dropout': 0.2901303421772372, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 1.1728593300655204e-05, 'epochs': 3, 'batch_size': 2}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:32:25,870]\u001b[0m Trial 21 finished with value: 0.9565186262734823 and parameters: {'hidden_size': 63, 'n_layers': 3, 'dropout': 0.060427773027943, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0015540733872303914, 'epochs': 100, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:33:39,838]\u001b[0m Trial 22 finished with value: 0.956363311527669 and parameters: {'hidden_size': 46, 'n_layers': 3, 'dropout': 0.14014135663618812, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0007441532972470579, 'epochs': 92, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:34:53,686]\u001b[0m Trial 23 finished with value: 0.9565184453267794 and parameters: {'hidden_size': 58, 'n_layers': 3, 'dropout': 0.1647748103220586, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.005366406756709147, 'epochs': 95, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:36:40,762]\u001b[0m Trial 24 finished with value: 0.956363347121173 and parameters: {'hidden_size': 75, 'n_layers': 2, 'dropout': 0.04548814016737346, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0013101407559224841, 'epochs': 78, 'batch_size': 16}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:37:40,160]\u001b[0m Trial 25 finished with value: 0.9565020612518832 and parameters: {'hidden_size': 85, 'n_layers': 3, 'dropout': 0.22910834264361174, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.020853048327210227, 'epochs': 56, 'batch_size': 4}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:39:42,602]\u001b[0m Trial 26 finished with value: 0.954925008646136 and parameters: {'hidden_size': 30, 'n_layers': 3, 'dropout': 0.26797024069328085, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.00043246445197177936, 'epochs': 80, 'batch_size': 32}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:40:51,356]\u001b[0m Trial 27 finished with value: 0.9565409623788688 and parameters: {'hidden_size': 15, 'n_layers': 2, 'dropout': 0.09042995380056673, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.002987342890723461, 'epochs': 92, 'batch_size': 64}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:41:37,804]\u001b[0m Trial 28 finished with value: 0.956518448030269 and parameters: {'hidden_size': 15, 'n_layers': 2, 'dropout': 0.3797980713154312, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.003767247597177038, 'epochs': 70, 'batch_size': 64}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:42:00,283]\u001b[0m Trial 29 finished with value: 0.9565182753009156 and parameters: {'hidden_size': 4, 'n_layers': 1, 'dropout': 0.08551368892691212, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 0.009954284771641932, 'epochs': 47, 'batch_size': 64}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:42:44,050]\u001b[0m Trial 30 finished with value: 0.8616453261452041 and parameters: {'hidden_size': 19, 'n_layers': 2, 'dropout': 0.008124405102859847, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.00012958305334500212, 'epochs': 91, 'batch_size': 1}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:43:36,437]\u001b[0m Trial 31 finished with value: 0.9565184329624604 and parameters: {'hidden_size': 42, 'n_layers': 2, 'dropout': 0.15519982194898352, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0021564414376380654, 'epochs': 95, 'batch_size': 128}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:44:18,032]\u001b[0m Trial 32 finished with value: 0.9563545406918039 and parameters: {'hidden_size': 11, 'n_layers': 2, 'dropout': 0.1038180067426521, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0011822110838263832, 'epochs': 87, 'batch_size': 64}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:45:18,971]\u001b[0m Trial 33 finished with value: 0.956501438542413 and parameters: {'hidden_size': 31, 'n_layers': 3, 'dropout': 0.20545017163801085, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.00346353185779768, 'epochs': 100, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:45:55,136]\u001b[0m Trial 34 finished with value: 0.9563352107695081 and parameters: {'hidden_size': 2, 'n_layers': 1, 'dropout': 0.07431277525698321, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.01167154414520918, 'epochs': 86, 'batch_size': 1024}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:47:43,840]\u001b[0m Trial 35 finished with value: 0.9565017312138112 and parameters: {'hidden_size': 60, 'n_layers': 3, 'dropout': 0.042548975659062065, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.005305329391330154, 'epochs': 93, 'batch_size': 4}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:48:44,628]\u001b[0m Trial 36 finished with value: 0.9502354564197785 and parameters: {'hidden_size': 70, 'n_layers': 2, 'dropout': 0.12334149917091282, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.0011242482115818141, 'epochs': 24, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:50:25,219]\u001b[0m Trial 37 finished with value: 0.956518533161445 and parameters: {'hidden_size': 9, 'n_layers': 2, 'dropout': 0.10309083240986483, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.00308291158511897, 'epochs': 80, 'batch_size': 8}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:51:59,556]\u001b[0m Trial 38 finished with value: 0.9565177969791108 and parameters: {'hidden_size': 47, 'n_layers': 3, 'dropout': 0.21545748581851915, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 0.0004403710715198893, 'epochs': 74, 'batch_size': 256}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:53:49,298]\u001b[0m Trial 39 finished with value: 0.9095808837867765 and parameters: {'hidden_size': 96, 'n_layers': 1, 'dropout': 0.16182076026884465, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.0017100189774470285, 'epochs': 65, 'batch_size': 1}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:54:38,635]\u001b[0m Trial 40 finished with value: 0.7147061895810556 and parameters: {'hidden_size': 26, 'n_layers': 3, 'dropout': 0.2703381220080766, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.00014790417666450488, 'epochs': 32, 'batch_size': 16}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:56:02,100]\u001b[0m Trial 41 finished with value: 0.9565017358744723 and parameters: {'hidden_size': 23, 'n_layers': 1, 'dropout': 0.176718279386977, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.002799724811875575, 'epochs': 89, 'batch_size': 8}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:57:18,037]\u001b[0m Trial 42 finished with value: 0.9565182632022696 and parameters: {'hidden_size': 19, 'n_layers': 1, 'dropout': 0.14190583918147004, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.0008505669872890173, 'epochs': 83, 'batch_size': 8}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 17:58:46,188]\u001b[0m Trial 43 finished with value: 0.9565180007822354 and parameters: {'hidden_size': 35, 'n_layers': 1, 'dropout': 0.11779748287034042, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.0004938042153501735, 'epochs': 84, 'batch_size': 8}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:00:07,794]\u001b[0m Trial 44 finished with value: 0.9563633656977236 and parameters: {'hidden_size': 19, 'n_layers': 1, 'dropout': 0.23075584535802754, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.00566034513379671, 'epochs': 96, 'batch_size': 1024}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:01:45,932]\u001b[0m Trial 45 finished with value: 0.9562725496469281 and parameters: {'hidden_size': 10, 'n_layers': 2, 'dropout': 0.3125608397704996, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 0.0021437047700944493, 'epochs': 97, 'batch_size': 128}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:03:29,412]\u001b[0m Trial 46 finished with value: 0.9565187013826407 and parameters: {'hidden_size': 31, 'n_layers': 3, 'dropout': 0.2679875758127656, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.01480790183424997, 'epochs': 89, 'batch_size': 32}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:04:56,340]\u001b[0m Trial 47 finished with value: 0.9124189018063265 and parameters: {'hidden_size': 41, 'n_layers': 2, 'dropout': 0.19301420931075858, 'activation': 'tanh', 'optimizer': 'adam', 'lr': 0.028350193076360504, 'epochs': 57, 'batch_size': 64}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:06:59,126]\u001b[0m Trial 48 finished with value: 0.9564853265886369 and parameters: {'hidden_size': 88, 'n_layers': 3, 'dropout': 0.13660587377352099, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0018565911424674075, 'epochs': 66, 'batch_size': 512}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:07:49,511]\u001b[0m Trial 49 finished with value: 0.9565427324770792 and parameters: {'hidden_size': 51, 'n_layers': 1, 'dropout': 0.358873280092445, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.007961707253831014, 'epochs': 74, 'batch_size': 1024}. Best is trial 0 with value: 0.9565453113178017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  50\n",
      "Best trial:\n",
      "  Value: 0.9565453113178017\n",
      "  Params: \n",
      "    hidden_size: 79\n",
      "    n_layers: 3\n",
      "    dropout: 0.3037768168799529\n",
      "    activation: relu\n",
      "    optimizer: sgd\n",
      "    lr: 0.0017966498130340496\n",
      "    epochs: 59\n",
      "    batch_size: 1024\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_min_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_balanced_constr.csv')\n",
    "    exogenous_data = pd.read_csv('..\\data\\ground_truth\\\\exogenous_data_vm_pu_min_balanced.csv').drop(columns=['date'])\n",
    "    X_min_u_train, X_min_u_test, y_min_u_train, y_min_u_test, scaler = utils.split_and_suffle(exogenous_data, y_min_u, test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_min_u_train.astype(float),\n",
    "            'X_test': X_min_u_test.astype(float),\n",
    "            'y_train':y_min_u_train.astype(float),\n",
    "            'y_test': y_min_u_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': False\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=y_min_u.columns)\n",
    "    y_min_u_train = pd.DataFrame(y_min_u_train, columns=y_min_u.columns)\n",
    "    # evaluate the regression performance with my metrics\n",
    "    threshold = data['y_test'].loc[:, data['y_test'].max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    metric = metrics.Metrics()\n",
    "    metric.get_prediction_scores(prediction, data['y_test'], threshold=threshold)\n",
    "    return metric.hybrid_f1\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_regression_balanced_min_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,False\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-03 18:17:41,140]\u001b[0m A new study created in memory with name: no-name-28bbe3ea-298c-4b62-a2e1-f9ef6310e9b8\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:17:46,589]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'hidden_size': 84, 'n_layers': 3, 'dropout': 0.23249853132558967, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 1.3868061660489762e-05, 'epochs': 2, 'batch_size': 512}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:17:58,006]\u001b[0m Trial 1 finished with value: 0.9846830922654358 and parameters: {'hidden_size': 67, 'n_layers': 1, 'dropout': 0.2082133424539937, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.046296552577011776, 'epochs': 19, 'batch_size': 512}. Best is trial 1 with value: 0.9846830922654358.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:18:16,833]\u001b[0m Trial 2 finished with value: 0.9846832320925641 and parameters: {'hidden_size': 20, 'n_layers': 1, 'dropout': 0.27083185749643957, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.021274105356873296, 'epochs': 62, 'batch_size': 1024}. Best is trial 2 with value: 0.9846832320925641.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:18:57,966]\u001b[0m Trial 3 finished with value: 0.972983381956681 and parameters: {'hidden_size': 6, 'n_layers': 2, 'dropout': 0.330222684050529, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.004784230096367431, 'epochs': 97, 'batch_size': 32}. Best is trial 2 with value: 0.9846832320925641.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:19:16,159]\u001b[0m Trial 4 finished with value: 0.9719617261345368 and parameters: {'hidden_size': 59, 'n_layers': 1, 'dropout': 0.39915728088494484, 'activation': 'sigmoid', 'optimizer': 'adam', 'lr': 0.015447475625433462, 'epochs': 39, 'batch_size': 1024}. Best is trial 2 with value: 0.9846832320925641.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:19:35,044]\u001b[0m Trial 5 finished with value: 0.6441952448917801 and parameters: {'hidden_size': 71, 'n_layers': 1, 'dropout': 0.28571004558627033, 'activation': 'sigmoid', 'optimizer': 'sgd', 'lr': 2.6033116868907153e-05, 'epochs': 58, 'batch_size': 4}. Best is trial 2 with value: 0.9846832320925641.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:19:58,554]\u001b[0m Trial 6 finished with value: 0.0608009576957453 and parameters: {'hidden_size': 67, 'n_layers': 1, 'dropout': 0.40408048870361607, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 1.1621276327117618e-05, 'epochs': 77, 'batch_size': 8}. Best is trial 2 with value: 0.9846832320925641.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:20:12,374]\u001b[0m Trial 7 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 81, 'n_layers': 1, 'dropout': 0.18237076548249542, 'activation': 'tanh', 'optimizer': 'adam', 'lr': 0.09696396096679943, 'epochs': 27, 'batch_size': 128}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:20:37,939]\u001b[0m Trial 8 finished with value: 0.9829369353063702 and parameters: {'hidden_size': 56, 'n_layers': 2, 'dropout': 0.4328434836137752, 'activation': 'tanh', 'optimizer': 'adam', 'lr': 0.0001446074268093786, 'epochs': 49, 'batch_size': 1}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:20:47,361]\u001b[0m Trial 9 finished with value: 0.9020298794142747 and parameters: {'hidden_size': 76, 'n_layers': 2, 'dropout': 0.30552123971785267, 'activation': 'sigmoid', 'optimizer': 'adam', 'lr': 1.142639207516709e-05, 'epochs': 10, 'batch_size': 16}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:21:08,413]\u001b[0m Trial 10 finished with value: 0.9835843936914114 and parameters: {'hidden_size': 100, 'n_layers': 3, 'dropout': 0.0439996848095055, 'activation': 'tanh', 'optimizer': 'adam', 'lr': 0.0014912464801267588, 'epochs': 29, 'batch_size': 128}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:21:24,815]\u001b[0m Trial 11 finished with value: 0.9846834576892012 and parameters: {'hidden_size': 25, 'n_layers': 1, 'dropout': 0.12108468535119618, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.07687056486492953, 'epochs': 57, 'batch_size': 2}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:21:37,388]\u001b[0m Trial 12 finished with value: 0.9846830019767433 and parameters: {'hidden_size': 34, 'n_layers': 1, 'dropout': 0.11578563447787726, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 0.08613456103733223, 'epochs': 33, 'batch_size': 2}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:22:12,917]\u001b[0m Trial 13 finished with value: 0.9826135623960475 and parameters: {'hidden_size': 39, 'n_layers': 2, 'dropout': 0.14180671041623882, 'activation': 'tanh', 'optimizer': 'adam', 'lr': 0.008234670215928618, 'epochs': 77, 'batch_size': 2}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:22:32,812]\u001b[0m Trial 14 finished with value: 0.9772406280890761 and parameters: {'hidden_size': 41, 'n_layers': 1, 'dropout': 0.011986988569685858, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.0017448899792495971, 'epochs': 45, 'batch_size': 256}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:22:42,889]\u001b[0m Trial 15 finished with value: 0.25025072218851674 and parameters: {'hidden_size': 18, 'n_layers': 2, 'dropout': 0.1482829397258913, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0003515704139912208, 'epochs': 23, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:23:03,870]\u001b[0m Trial 16 finished with value: 0.984683112100392 and parameters: {'hidden_size': 98, 'n_layers': 1, 'dropout': 0.09072350672139731, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 0.0943434595828544, 'epochs': 66, 'batch_size': 128}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:23:49,201]\u001b[0m Trial 17 finished with value: 0.9542358450313336 and parameters: {'hidden_size': 28, 'n_layers': 3, 'dropout': 0.19022620608922908, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.02907384469283025, 'epochs': 79, 'batch_size': 128}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:24:16,698]\u001b[0m Trial 18 finished with value: 0.9841628553435299 and parameters: {'hidden_size': 1, 'n_layers': 2, 'dropout': 0.4958417982635572, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 0.006451114926581401, 'epochs': 99, 'batch_size': 2}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:24:25,927]\u001b[0m Trial 19 finished with value: 0.9828854198737569 and parameters: {'hidden_size': 46, 'n_layers': 1, 'dropout': 0.0743384792095253, 'activation': 'sigmoid', 'optimizer': 'adam', 'lr': 0.00057903659749184, 'epochs': 15, 'batch_size': 4}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:24:39,602]\u001b[0m Trial 20 finished with value: 0.9830488860774111 and parameters: {'hidden_size': 82, 'n_layers': 1, 'dropout': 0.16197897994457078, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.0027704762139916087, 'epochs': 37, 'batch_size': 256}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:24:56,375]\u001b[0m Trial 21 finished with value: 0.9845699689940653 and parameters: {'hidden_size': 18, 'n_layers': 1, 'dropout': 0.2657613790199443, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.023889201999505068, 'epochs': 60, 'batch_size': 1024}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:25:12,909]\u001b[0m Trial 22 finished with value: 0.9846834393542253 and parameters: {'hidden_size': 17, 'n_layers': 1, 'dropout': 0.22601036454508713, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.04140997925009087, 'epochs': 58, 'batch_size': 1024}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:25:30,179]\u001b[0m Trial 23 finished with value: 0.9846834455944002 and parameters: {'hidden_size': 27, 'n_layers': 1, 'dropout': 0.17948814322133805, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.05025373911971474, 'epochs': 52, 'batch_size': 8}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:25:47,029]\u001b[0m Trial 24 finished with value: 0.9846833751194147 and parameters: {'hidden_size': 28, 'n_layers': 2, 'dropout': 0.1723934330090216, 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.086933616332753, 'epochs': 44, 'batch_size': 8}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:26:02,016]\u001b[0m Trial 25 finished with value: 0.9843214284343382 and parameters: {'hidden_size': 9, 'n_layers': 1, 'dropout': 0.10974488890726242, 'activation': 'tanh', 'optimizer': 'sgd', 'lr': 0.011084659179656318, 'epochs': 52, 'batch_size': 8}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:26:31,501]\u001b[0m Trial 26 finished with value: 0.9846834681523423 and parameters: {'hidden_size': 52, 'n_layers': 1, 'dropout': 0.05794927371445151, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.046895042592124174, 'epochs': 70, 'batch_size': 1}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:27:04,516]\u001b[0m Trial 27 finished with value: 0.9776660911116141 and parameters: {'hidden_size': 49, 'n_layers': 2, 'dropout': 0.00494772678580771, 'activation': 'tanh', 'optimizer': 'adam', 'lr': 0.014549916073670172, 'epochs': 69, 'batch_size': 1}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:27:41,550]\u001b[0m Trial 28 finished with value: 0.924174219882328 and parameters: {'hidden_size': 93, 'n_layers': 1, 'dropout': 0.051442526513599776, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.004010534758607121, 'epochs': 91, 'batch_size': 1}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:27:47,248]\u001b[0m Trial 29 finished with value: 0.9845101339571272 and parameters: {'hidden_size': 85, 'n_layers': 3, 'dropout': 0.12879556237771309, 'activation': 'sigmoid', 'optimizer': 'adam', 'lr': 0.04372717035228817, 'epochs': 2, 'batch_size': 16}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:28:19,227]\u001b[0m Trial 30 finished with value: 0.9832773472372723 and parameters: {'hidden_size': 56, 'n_layers': 1, 'dropout': 0.06293458463313095, 'activation': 'tanh', 'optimizer': 'adam', 'lr': 4.8097718681317525e-05, 'epochs': 86, 'batch_size': 32}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:28:46,609]\u001b[0m Trial 31 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 29, 'n_layers': 1, 'dropout': 0.2271132614927211, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.050232104835779445, 'epochs': 70, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:29:15,151]\u001b[0m Trial 32 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 37, 'n_layers': 1, 'dropout': 0.22846774137118514, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.06584432282877009, 'epochs': 71, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:29:43,153]\u001b[0m Trial 33 finished with value: 0.9824381283952295 and parameters: {'hidden_size': 35, 'n_layers': 1, 'dropout': 0.23456974795730268, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.031053463005944613, 'epochs': 71, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:30:16,519]\u001b[0m Trial 34 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 62, 'n_layers': 1, 'dropout': 0.33474217817907026, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.04873611671323167, 'epochs': 81, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:30:51,386]\u001b[0m Trial 35 finished with value: 0.9581392932055496 and parameters: {'hidden_size': 63, 'n_layers': 1, 'dropout': 0.3520727530787062, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.019505894019877984, 'epochs': 85, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:31:29,368]\u001b[0m Trial 36 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 76, 'n_layers': 1, 'dropout': 0.3419521555411263, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.06085855328380045, 'epochs': 92, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:32:23,882]\u001b[0m Trial 37 finished with value: 0.9117376035854391 and parameters: {'hidden_size': 77, 'n_layers': 2, 'dropout': 0.3496230955263364, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.012192350809292343, 'epochs': 93, 'batch_size': 512}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:32:55,436]\u001b[0m Trial 38 finished with value: 0.9599417897819322 and parameters: {'hidden_size': 69, 'n_layers': 1, 'dropout': 0.3053577862523382, 'activation': 'sigmoid', 'optimizer': 'adam', 'lr': 0.029642194160919535, 'epochs': 82, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:33:32,823]\u001b[0m Trial 39 finished with value: 0.9224141579542524 and parameters: {'hidden_size': 88, 'n_layers': 1, 'dropout': 0.367381712463693, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.007362373131490169, 'epochs': 92, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:34:01,363]\u001b[0m Trial 40 finished with value: 0.984683493569818 and parameters: {'hidden_size': 75, 'n_layers': 1, 'dropout': 0.20592868043575047, 'activation': 'tanh', 'optimizer': 'adam', 'lr': 0.06784678521552295, 'epochs': 74, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:34:36,342]\u001b[0m Trial 41 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 63, 'n_layers': 1, 'dropout': 0.25582423687168004, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.05549680692643271, 'epochs': 85, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:35:11,317]\u001b[0m Trial 42 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 46, 'n_layers': 1, 'dropout': 0.259467708864688, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.054432971590377424, 'epochs': 89, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:35:48,386]\u001b[0m Trial 43 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 61, 'n_layers': 1, 'dropout': 0.2596063502992092, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.0978835023815245, 'epochs': 86, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:36:27,369]\u001b[0m Trial 44 finished with value: 0.982256578193561 and parameters: {'hidden_size': 64, 'n_layers': 1, 'dropout': 0.3008815718517088, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.033951663078715125, 'epochs': 97, 'batch_size': 128}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:37:02,387]\u001b[0m Trial 45 finished with value: 0.9788995710347892 and parameters: {'hidden_size': 59, 'n_layers': 1, 'dropout': 0.2620382764591977, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.017871103488474073, 'epochs': 87, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:37:34,309]\u001b[0m Trial 46 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 44, 'n_layers': 1, 'dropout': 0.28157284684579176, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.05240526710995618, 'epochs': 81, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:38:09,539]\u001b[0m Trial 47 finished with value: 0.982023095395496 and parameters: {'hidden_size': 44, 'n_layers': 1, 'dropout': 0.28220967808735303, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.022179869731164675, 'epochs': 90, 'batch_size': 64}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:38:35,326]\u001b[0m Trial 48 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 35, 'n_layers': 1, 'dropout': 0.23378724550395863, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.09857170945253878, 'epochs': 63, 'batch_size': 512}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n",
      "\u001b[32m[I 2022-10-03 18:39:10,362]\u001b[0m Trial 49 finished with value: 0.9846835037597281 and parameters: {'hidden_size': 52, 'n_layers': 2, 'dropout': 0.2502530588378781, 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.09735391722488258, 'epochs': 65, 'batch_size': 512}. Best is trial 7 with value: 0.9846835037597281.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  50\n",
      "Best trial:\n",
      "  Value: 0.9846835037597281\n",
      "  Params: \n",
      "    hidden_size: 81\n",
      "    n_layers: 1\n",
      "    dropout: 0.18237076548249542\n",
      "    activation: tanh\n",
      "    optimizer: adam\n",
      "    lr: 0.09696396096679943\n",
      "    epochs: 27\n",
      "    batch_size: 128\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build optuna objective function.\n",
    "import optuna\n",
    "import sklearn \n",
    "\n",
    "def objective(trial):\n",
    "    # Data loading\n",
    "    y_max_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_balanced_constr.csv')\n",
    "    exogenous_data = pd.read_csv('..\\data\\ground_truth\\\\exogenous_data_vm_pu_max_balanced.csv').drop(columns=['date'])\n",
    "    X_max_u_train, X_max_u_test, y_max_u_train, y_max_u_test, scaler = utils.split_and_suffle(exogenous_data, y_max_u, test_size=0.2, scaling=True)\n",
    "    data = {'X_train':X_max_u_train.astype(float),\n",
    "            'X_test': X_max_u_test.astype(float),\n",
    "            'y_train':y_max_u_train.astype(float),\n",
    "            'y_test': y_max_u_test.astype(float)\n",
    "        }\n",
    "    # Dataset object creation\n",
    "    _dataset = myai.ThesisDataset(data)\n",
    "    hyper_params = {\n",
    "        'input_size': _dataset.X.shape[1],\n",
    "        'hidden_size': trial.suggest_int('hidden_size', 1, 100),\n",
    "        'output_size': _dataset.y.shape[1],\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid']),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd']),\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-1, log=True),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 100),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "        'classifier': False\n",
    "        }\n",
    "    model = myai.Context(myai.MultilayerPerceptronStrategy(hyper_params))\n",
    "    model.fit(data)\n",
    "    prediction = model.predict(data)\n",
    "    prediction = pd.DataFrame(prediction, columns=y_max_u.columns)\n",
    "    y_max_u_train = pd.DataFrame(y_max_u_train, columns=y_max_u.columns)\n",
    "    # evaluate the regression performance with my metrics\n",
    "    threshold = data['y_test'].loc[:, data['y_test'].max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    metric = metrics.Metrics()\n",
    "    metric.get_prediction_scores(prediction, data['y_test'], threshold=threshold)\n",
    "    return metric.hybrid_f1\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "# Write the results to a csv file.\n",
    "with open(\"./hyper_params_results/params_mlp_regression_balanced_max_u.csv\", \"w\") as f:\n",
    "    f.write(\"params,value\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"{},{}\\n\".format(key, value))\n",
    "    f.write(\"classifier,False\\n\")\n",
    "    f.write(\"value,{}\\n\".format(trial.value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe4baa4d27e3b73db55d4bb4674105e8dd41faaf9e559c3cc8381041ce15293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
