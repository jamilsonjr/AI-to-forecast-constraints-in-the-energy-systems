{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Results \n",
    "\n",
    "**Summary of the Article**\n",
    "- Methodology Description.\n",
    "- Data Description.\n",
    "- Training.\n",
    "- Testing and Evalutation \n",
    "\n",
    "## Methodology Description\n",
    "\n",
    "The **objective** of this notebook is to obtain the first reuslts of predictions of constraints in  the power flow calculation. The constraints predicted are:\n",
    "- Voltage constraints:\n",
    "    - Maximum Voltage magnitude constraints.\n",
    "    - Minimum Voltage magnitude constraints.\n",
    "- Current constraints:\n",
    "    - Maximum Current magnitude constraints.\n",
    "\n",
    "The **training data** is obtained from the following sources:\n",
    "    Target data:\n",
    "    - Constraints amplitudes of the power flow results create in the `create_target_features.ipynb`. \n",
    "    Exgogenous data:\n",
    "    - Data non related to the test-grid (e.g meteorological data, cos(hour)), created in the `feature_engineering.ipynb`.\n",
    "\n",
    "The **models** trained will be:\n",
    "- Linear Regression.\n",
    "- Gradient Boost Regression.\n",
    "\n",
    "The **metrics** used to evaluate the models will be the metric proposed in the `ml_hybrid_metrics.ipynb` notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Upload and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "y_min_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_min_constr.csv')\n",
    "y_max_u = pd.read_csv('..\\data\\ground_truth\\\\res_bus_vm_pu_max_constr.csv')\n",
    "y_max_i = pd.read_csv('..\\data\\ground_truth\\\\res_line_percent_max_constr.csv')\n",
    "# drop timestemps\n",
    "y_min_u = y_min_u.drop(columns=['timestamps'])\n",
    "y_max_u = y_max_u.drop(columns=['timestamps'])\n",
    "y_max_i = y_max_i.drop(columns=['timestamps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(30, 25))\n",
    "# set the x-axis label\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[1].set_xlabel('Time')\n",
    "axs[2].set_xlabel('Time')\n",
    "# set the y-axis label\n",
    "axs[0].set_ylabel('Bus Voltage [p.u.]')\n",
    "axs[1].set_ylabel('Line Current [kA]')\n",
    "axs[2].set_ylabel('Line Loading [%]')\n",
    "# set the title, bold and fontsize of the title\n",
    "axs[0].set_title('Bus Voltage Constraints', fontsize=20, fontweight='bold')\n",
    "axs[1].set_title('Line Current Constraints', fontsize=20, fontweight='bold')\n",
    "axs[2].set_title('Line Loading Constraints', fontsize=20, fontweight='bold')\n",
    "# Set grid\n",
    "axs[0].grid(True)\n",
    "axs[1].grid(True)\n",
    "axs[2].grid(True)\n",
    "# Data\n",
    "axs[0].plot(y_min_u)\n",
    "axs[1].plot(y_max_u)\n",
    "axs[2].plot(y_max_i)\n",
    "# Don't print nothing on console\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exogenous data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exogenous_data = pd.read_csv('..\\data\\processed\\production\\exogenous_data_extended.csv')\n",
    "# drop date\n",
    "exogenous_data = exogenous_data.drop(columns=['date'])\n",
    "X = exogenous_data\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traing test split with sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "le = LabelEncoder()\n",
    "\n",
    "def split_and_suffle(X, y, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "    X_train['season'] = le.fit_transform(X_train['season'])\n",
    "    X_test['season'] = le.fit_transform(X_test['season'])   \n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_min_u_train, X_min_u_test, y_min_u_train, y_min_u_test = split_and_suffle(X, y_min_u)\n",
    "X_max_u_train, X_max_u_test, y_max_u_train, y_max_u_test = split_and_suffle(X, y_max_u)\n",
    "X_max_i_train, X_max_i_test, y_max_i_train, y_max_i_test = split_and_suffle(X, y_max_i)\n",
    "print(hex(id(X_min_u_train)))\n",
    "print(hex(id(X_max_u_train)))\n",
    "print(hex(id(X_max_i_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "TODO add introductionb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from thesis_package import aimodels as my_ai, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'regressor_min_u.pickle' not in os.listdir('pickles'):\n",
    "    regressor_min_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_min_u.fit(data={'X_train': X_min_u_train, 'y_train': y_min_u_train})\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = {'n_estimators': 1000, 'learning_rate': 0.1, 'loss': 'squared_error'}\n",
    "    regressor_min_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_min_u.fit(data={'X_train': X_min_u_train.values, 'y_train': y_min_u_train.values})\n",
    "    utils.serialize_object('pickles\\\\regressor_min_u', regressor_min_u)\n",
    "else: \n",
    "    regressor_min_u = utils.deserialize_object('pickles\\\\regressor_min_u')\n",
    "prediction_lr_min_u = regressor_min_u.strategies[0].predict(data={'X_test': X_min_u_test})\n",
    "prediction_lr_min_u = pd.DataFrame(prediction_lr_min_u , columns=y_min_u_test.columns)\n",
    "prediction_gb_min_u =  regressor_min_u.strategies[1].predict(data={'X_test': X_min_u_test})\n",
    "prediction_gb_min_u = pd.DataFrame(prediction_gb_min_u, columns=y_min_u_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as cell above but for max_u\n",
    "if 'regressor_max_u.pickle' not in os.listdir('pickles'):\n",
    "    regressor_max_u = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_u.fit(data={'X_train': X_max_u_train, 'y_train': y_max_u_train})\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = {'n_estimators': 1000, 'learning_rate': 0.1, 'loss': 'squared_error'}\n",
    "    regressor_max_u.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_u.fit(data={'X_train': X_max_u_train.values, 'y_train': y_max_u_train.values})\n",
    "    utils.serialize_object('pickles\\\\regressor_max_u', regressor_max_u)\n",
    "else: \n",
    "    regressor_max_u = utils.deserialize_object('pickles\\\\regressor_max_u')\n",
    "prediction_lr_max_u = regressor_max_u.strategies[0].predict(data={'X_test': X_max_u_test})\n",
    "prediction_lr_max_u = pd.DataFrame(prediction_lr_max_u , columns=y_max_u_test.columns)\n",
    "prediction_gb_max_u =  regressor_max_u.strategies[1].predict(data={'X_test': X_max_u_test})\n",
    "prediction_gb_max_u = pd.DataFrame(prediction_gb_max_u, columns=y_max_u_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as cell above but for max_i\n",
    "if 'regressor_max_i.pickle' not in os.listdir('pickles'):\n",
    "    regressor_max_i = my_ai.Context(strategy=my_ai.LinearRegressionStrategy())\n",
    "    regressor_max_i.fit(data={'X_train': X_max_i_train, 'y_train': y_max_i_train})\n",
    "    # Gradient Boost Regression\n",
    "    hyper_params = {'n_estimators': 1000, 'learning_rate': 0.1, 'loss': 'squared_error'}\n",
    "    regressor_max_i.strategy = my_ai.GradientBoostRegressorStrategy(hyper_params)\n",
    "    regressor_max_i.fit(data={'X_train': X_max_i_train.values, 'y_train': y_max_i_train.values})\n",
    "    utils.serialize_object('pickles\\\\regressor_max_i', regressor_max_i)\n",
    "else:\n",
    "    regressor_max_i = utils.deserialize_object('pickles\\\\regressor_max_i')\n",
    "prediction_lr_max_i = regressor_max_i.strategies[0].predict(data={'X_test': X_max_i_test})\n",
    "prediction_lr_max_i = pd.DataFrame(prediction_lr_max_i , columns=y_max_i_test.columns)\n",
    "prediction_gb_max_i =  regressor_max_i.strategies[1].predict(data={'X_test': X_max_i_test})\n",
    "prediction_gb_max_i = pd.DataFrame(prediction_gb_max_i, columns=y_max_i_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "TODO add introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import beepy \n",
    "import numpy as np\n",
    "beepy.beep('coin')\n",
    "from thesis_package import metrics \n",
    "metric = metrics.Metrics()\n",
    "cols=['experience', 'model', 'TP', 'FP', 'FN', 'TN', 'accuracy', 'precision', 'recall', 'f1', 'TP_rmse', 'FP_rmse', 'FN_rmse', 'TN_rmse']\n",
    "results = pd.DataFrame(columns=cols)\n",
    "#threshold_signal = pd.Series(np.ones([2000]) * threshold)\n",
    "def write_result(results, prediction, y_test, threshold, metric, experience, model):\n",
    "    metric.get_prediction_scores(prediction, y_min_u_test, threshold=threshold)\n",
    "    metric.get_report()\n",
    "    # Create new row and concat it to the dataframe results.\n",
    "    row = pd.Series()\n",
    "    row['experience'] = experience\n",
    "    row['model'] = model\n",
    "    row['TP'] = metric.true_positives_ctr\n",
    "    row['FP'] = metric.false_positives_ctr\n",
    "    row['FN'] = metric.false_negatives_ctr\n",
    "    row['TN'] = metric.true_negatives_ctr\n",
    "    row['accuracy'] = metric.accuracy\n",
    "    row['precision'] = metric.precision\n",
    "    row['recall'] = metric.recall\n",
    "    row['f1'] = metric.f1_score\n",
    "    row['TP_rmse'] = metric.true_positives_rmse\n",
    "    row['FP_rmse'] = metric.false_positives_rmse\n",
    "    row['FN_rmse'] = metric.false_negatives_rmse\n",
    "    row['TN_rmse'] = metric.true_negatives_rmse\n",
    "    # Add row to results\n",
    "    results.loc[len(results)] = row\n",
    "    return results\n",
    "try:\n",
    "    # Min U Gradient Boost Regression\n",
    "    threshold = y_min_u_train.loc[:, y_min_u_train.max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    results = write_result(results, prediction_lr_min_u, y_min_u_test, threshold, metric, 'min_u', 'Linear Regression')\n",
    "    results = write_result(results, prediction_gb_min_u, y_min_u_test, threshold, metric, 'min_u', 'Gradient Boost')\n",
    "    # Max U Linear Regression\n",
    "    threshold = y_max_u_train.loc[:, y_max_u_train.max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    results = write_result(results, prediction_lr_max_u, y_max_u_test, threshold, metric, 'max_u', 'Linear Regression')\n",
    "    results = write_result(results, prediction_gb_max_u, y_max_u_test, threshold, metric, 'max_u', 'Gradient Boost')\n",
    "    # Max I Linear Regression\n",
    "    threshold = y_max_i_train.loc[:, y_max_i_train.max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "    results = write_result(results, prediction_lr_max_i, y_max_i_test, threshold, metric, 'max_i', 'Linear Regression')\n",
    "    results = write_result(results, prediction_gb_max_i, y_max_i_test, threshold, metric, 'max_i', 'Gradient Boost')\n",
    "except(Exception) as e:\n",
    "    beepy.beep('robot error')\n",
    "results = results.set_index(['experience', 'model'])\n",
    "beepy.beep('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "threshold = y_max_u_train.loc[:, y_max_u_train.max(axis=0) != 0].max(axis=0).mean() * 0.1 \n",
    "threshold_signal = pd.Series(np.ones([len(y_max_u_test)]) * threshold)\n",
    "# Plot prediction_gb_max_u\n",
    "fig, axs = plt.subplots(1, 2, figsize=(30, 10))\n",
    "axs[0].plot(prediction_gb_max_u[6000:6250])\n",
    "axs[1].plot(y_max_u_test.reset_index(drop=True)[6000:6250])\n",
    "axs[0].plot(threshold_signal[6000:6250])\n",
    "axs[1].plot(threshold_signal[6000:6250])\n",
    "axs[0].set_title('Prediction Gradient Boost Regression')\n",
    "axs[1].set_title('Actual')\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[1].set_xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fe4baa4d27e3b73db55d4bb4674105e8dd41faaf9e559c3cc8381041ce15293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
