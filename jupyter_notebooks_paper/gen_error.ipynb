{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asses the Impact of Variation of the Generation on the Power Flow Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys; sys.path.append('..')\n",
    "from thesis_package import utils, extractor as ex, elements as el, powerflow as pf, metrics as my_metrics, aimodels as my_ai\n",
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'network.pickle' not in os.listdir('..'):\n",
    "    # Create a network from the data.\n",
    "    network = el.Network()\n",
    "    network.create_network_from_xlsx(xlsx_file_path=\"\\data\\\\raw\\\\Data_Example_32.xlsx\")\n",
    "    # Create the pandapower network.\n",
    "    network.create_pandapower_model() # Property name: net_model.\n",
    "    # Plot the network.\n",
    "    network.plot_network()\n",
    "    # Method that receives the .csv files folder and adds the gen profile to the grid elements.\n",
    "    network.add_generation_profiles(generation_profiles_folder_path='.\\data\\processed\\production')\n",
    "    # Method that receives a .csv files folder and adds the load profile to the grid elements.\n",
    "    network.add_load_profiles(load_profiles_folder_path='.\\data\\processed\\consumption')\n",
    "    # Power flow calculation\n",
    "    utils.serialize_object('network', network, message='Serializing network object...')\n",
    "else:\n",
    "    network = utils.deserialize_object('../network', message='Deserializing network...')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Power Flow Calculation with Different Variations on the Generation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "def run_gen_error_experiement(prediction_error):\n",
    "    power_flow = pf.Power_Flow()\n",
    "    path_to_results_folder = '..\\data\\paper\\gen_error_experiment\\prediction_error_{}'.format(prediction_error)\n",
    "    try: \n",
    "        os.listdir(path_to_results_folder)\n",
    "    except: \n",
    "        os.makedirs(path_to_results_folder)\n",
    "    power_flow.run_timeseries_power_flow(network, path_to_results_folder=path_to_results_folder, prediction_error=prediction_error)\n",
    "run_gen_error_experiement(True)\n",
    "run_gen_error_experiement(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the RMSE of the PF Results w.r to the Ground Truth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bus examined is the bus 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_results_pred_error = pd.read_csv('..\\data\\paper\\gen_error_experiment\\prediction_error_True\\pf_res_bus_vm_pu.csv').drop('timestamps', axis=1)\n",
    "pf_results_ref = pd.read_csv('..\\data\\paper\\gen_error_experiment\\prediction_error_False\\pf_res_bus_vm_pu.csv').drop('timestamps', axis=1)\n",
    "pf_results_pred_error['bus_16'][0:500].plot()\n",
    "pf_results_ref['bus_16'][0:500].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rmse = mean_squared_error(pf_results_ref['bus_16'], pf_results_pred_error['bus_16'],  squared=False)\n",
    "result_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = pf_results_ref['bus_16'] - pf_results_pred_error['bus_16']\n",
    "error.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Difference in the Number of Constraints w.r to the Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boolean_datasets(path_to_pf_res_bus):\n",
    "    res_bus_vm_pu = pd.read_csv(path_to_pf_res_bus)\n",
    "    res_bus_vm_pu.drop('timestamps', axis=1, inplace=True) \n",
    "    # Max bus_vm_pu constraint\n",
    "    res_bus_vm_pu_max_constr = res_bus_vm_pu.apply(lambda x: (x - 1.05).apply(lambda y: max(0, y)))\n",
    "    # Min bus_vm_pu constraint\n",
    "    res_bus_vm_pu_min_constr = res_bus_vm_pu.apply(lambda x: (0.95 - x).apply(lambda y: max(0, y)))\n",
    "    # Compute thresholds\n",
    "    max_u_threshold = utils.compute_threshold(res_bus_vm_pu_max_constr)\n",
    "    min_u_threshold = utils.compute_threshold(res_bus_vm_pu_min_constr)\n",
    "    turn_boolean = lambda df, threshold: df.apply(lambda x: x.apply(lambda y: 1 if y > threshold else 0))\n",
    "    # Create boolean data sets\n",
    "    res_bus_vm_pu_max_bool_constr = turn_boolean(res_bus_vm_pu_max_constr, utils.compute_threshold(res_bus_vm_pu_max_constr))\n",
    "    res_bus_vm_pu_min_bool_constr = turn_boolean(res_bus_vm_pu_min_constr, utils.compute_threshold(res_bus_vm_pu_min_constr))\n",
    "    return res_bus_vm_pu_max_bool_constr, res_bus_vm_pu_min_bool_constr\n",
    "# Pred\n",
    "max_u_bool_df, min_u_bool_df = get_boolean_datasets('..\\data\\paper\\gen_error_experiment\\prediction_error_True\\pf_res_bus_vm_pu.csv')\n",
    "max_u_bool_df.to_csv('..\\data\\paper\\gen_error_experiment\\prediction_error_True\\\\bool_df_max_u.csv', index=False)\n",
    "min_u_bool_df.to_csv('..\\data\\paper\\gen_error_experiment\\prediction_error_True\\\\bool_df_min_u.csv', index=False)\n",
    "# Ref\n",
    "max_u_bool_df, min_u_bool_df = get_boolean_datasets('..\\data\\paper\\gen_error_experiment\\prediction_error_False\\pf_res_bus_vm_pu.csv')\n",
    "max_u_bool_df.to_csv('..\\data\\paper\\gen_error_experiment\\prediction_error_False\\\\bool_df_max_u.csv', index=False)\n",
    "min_u_bool_df.to_csv('..\\data\\paper\\gen_error_experiment\\prediction_error_False\\\\bool_df_min_u.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_num_constr = pd.DataFrame(index=[\"max_u\", \"min_u\"], columns=[\"Pred_Error\", \"Ref\"])\n",
    "file_token_name = lambda col: True if col == \"Pred_Error\" else False\n",
    "for col in result_num_constr.columns:\n",
    "    max_u_bool = pd.read_csv('..\\data\\paper\\gen_error_experiment\\prediction_error_{}\\\\bool_df_max_u.csv'\\\n",
    "        .format(file_token_name(col)))\n",
    "    result_num_constr.loc['max_u'][col] = max_u_bool['bus_16'][max_u_bool['bus_16'] == 1].count()\n",
    "    min_u_bool = pd.read_csv('..\\data\\paper\\gen_error_experiment\\prediction_error_{}\\\\bool_df_min_u.csv'\\\n",
    "        .format(file_token_name(col)))\n",
    "    result_num_constr.loc['min_u'][col] = min_u_bool['bus_16'][min_u_bool['bus_16'] == 1].count()\n",
    "result_num_constr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use variations as \"Predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain violation signals.\n",
    "# Ref constraint signal\n",
    "min_constr_ref = pf_results_ref.apply(lambda x: (0.95 - x).apply(lambda y: max(0, y)))\n",
    "max_constr_ref = pf_results_ref.apply(lambda x: (x - 1.05).apply(lambda y: max(0, y)))\n",
    "# Pred error constraint signal\n",
    "min_constr_pred_error = pf_results_pred_error.apply(lambda x: (0.95 - x).apply(lambda y: max(0, y)))\n",
    "max_constr_pred_error = pf_results_pred_error.apply(lambda x: (x - 1.05).apply(lambda y: max(0, y)))\n",
    "# # Compute thresholds\n",
    "max_threshold = utils.compute_threshold(max_constr_ref)\n",
    "min_threshold = utils.compute_threshold(min_constr_ref)\n",
    "print('max_threshold: ', max_threshold)\n",
    "print('min_threshold: ', min_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores max u.\n",
    "max_u_metric = my_metrics.Metrics()\n",
    "max_u_metric.get_prediction_scores(max_constr_pred_error, max_constr_ref, max_threshold)\n",
    "# Compute score min u.\n",
    "min_u_metric = my_metrics.Metrics()\n",
    "min_u_metric.get_prediction_scores(min_constr_pred_error, min_constr_ref, min_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase results\n",
    "# Max u\n",
    "max_u_accuracy = max_u_metric.hybrid_accuracy\n",
    "max_u_precision = max_u_metric.hybrid_precision\n",
    "max_u_recall = max_u_metric.hybrid_recall\n",
    "max_u_f1 = max_u_metric.hybrid_f1\n",
    "max_u_mcc = max_u_metric.hybrid_mcc\n",
    "max_u_evaluation = pd.Series({ 'accuracy': max_u_accuracy, 'precision': max_u_precision, 'recall': max_u_recall, 'f1': max_u_f1, 'mcc': max_u_mcc })\n",
    "# Min u\n",
    "min_u_precision = min_u_metric.hybrid_precision\n",
    "min_u_accuracy = min_u_metric.hybrid_accuracy\n",
    "min_u_recall = min_u_metric.hybrid_recall\n",
    "min_u_f1 = min_u_metric.hybrid_f1\n",
    "min_u_mcc = min_u_metric.hybrid_mcc\n",
    "min_u_evaluation = pd.Series({ 'accuracy': min_u_accuracy, 'precision': min_u_precision, 'recall': min_u_recall, 'f1': min_u_f1, 'mcc': min_u_mcc })\n",
    "pd.DataFrame([max_u_evaluation, min_u_evaluation], index=['max_u', 'min_u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "min_constr_pred_error['bus_16'][5000:6000].plot()\n",
    "min_constr_ref['bus_16'][5000:6000].plot()\n",
    "plt.legend(['Pred_error', 'Ref'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for bus 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bus 16\n",
    "# Compute scores max u.\n",
    "max_u_metric = my_metrics.Metrics()\n",
    "max_u_metric.get_prediction_scores(pd.DataFrame(max_constr_pred_error['bus_16']), pd.DataFrame(max_constr_ref['bus_16']), max_threshold)\n",
    "# Compute score min u.\n",
    "min_u_metric = my_metrics.Metrics()\n",
    "min_u_metric.get_prediction_scores(pd.DataFrame(min_constr_pred_error['bus_16']), pd.DataFrame(min_constr_ref['bus_16']), min_threshold)\n",
    "# Showcase results\n",
    "# Max u\n",
    "max_u_accuracy = max_u_metric.hybrid_accuracy\n",
    "max_u_precision = max_u_metric.hybrid_precision\n",
    "max_u_recall = max_u_metric.hybrid_recall\n",
    "max_u_f1 = max_u_metric.hybrid_f1\n",
    "max_u_mcc = max_u_metric.hybrid_mcc\n",
    "max_u_evaluation = pd.Series({ 'accuracy': max_u_accuracy, 'precision': max_u_precision, 'recall': max_u_recall, 'f1': max_u_f1, 'mcc': max_u_mcc })\n",
    "# Min u\n",
    "min_u_precision = min_u_metric.hybrid_precision\n",
    "min_u_accuracy = min_u_metric.hybrid_accuracy\n",
    "min_u_recall = min_u_metric.hybrid_recall\n",
    "min_u_f1 = min_u_metric.hybrid_f1\n",
    "min_u_mcc = min_u_metric.hybrid_mcc\n",
    "min_u_evaluation = pd.Series({ 'accuracy': min_u_accuracy, 'precision': min_u_precision, 'recall': min_u_recall, 'f1': min_u_f1, 'mcc': min_u_mcc })\n",
    "pd.DataFrame([max_u_evaluation, min_u_evaluation], index=['max_u', 'min_u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "max_constr_pred_error['bus_16'][5000:6000].plot()\n",
    "max_constr_ref['bus_16'][5000:6000].plot()\n",
    "plt.legend(['Pred_error', 'Ref'])\n",
    "plt.title('Max u')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,5))\n",
    "min_constr_pred_error['bus_16'][5000:6000].plot()\n",
    "min_constr_ref['bus_16'][5000:6000].plot()\n",
    "plt.legend(['Pred_error', 'Ref'])\n",
    "plt.title('Min u')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41fc41b670b51109e2ee011a1b5078408ea127dd664427f19249a098f5086286"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
